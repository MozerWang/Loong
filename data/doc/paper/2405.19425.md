# Adaptive In-conversation Team Building for Language Model Agents 

Linxin Song ${ }^{1 *}$, Jiale Liu ${ }^{2 *}$, Jieyu Zhang ${ }^{3}$, Shaokun Zhang ${ }^{2}$, Ao Luo ${ }^{4}$, Shijian Wang ${ }^{5}$,<br>Qingyun Wu ${ }^{2}$, Chi Wang ${ }^{6 \dagger}$<br>${ }^{1}$ University of Southern California ${ }^{2}$ Penn State University ${ }^{3}$ University of Washington<br>${ }^{4}$ Waseda University ${ }^{5}$ Southeast University ${ }^{6}$ Microsoft Research

![](https://cdn.mathpix.com/cropped/2024_06_04_ef686eec59cdf0327152g-01.jpg?height=750&width=1393&top_left_y=888&top_left_x=366)

Figure 1: Two team-building paradigms for LLM agents. The "Static Build" paradigm [1] builds a static team before task execution. Our "Adaptive Build" paradigm uses an adaptive builder agent to form different teams during the task-solving procedure.


#### Abstract

Leveraging multiple large language model (LLM) agents has shown to be a promising approach for tackling complex tasks, while the effective design of multiple agents for a particular application remains an art. It is thus intriguing to answer a critical question: Given a task, how can we build a team of LLM agents to solve it effectively? Our new adaptive team-building paradigm offers a flexible solution, realized through a novel agent design named Captain Agent. It dynamically forms and manages teams for each step of a task-solving process, utilizing nested group conversations and reflection to ensure diverse expertise and prevent stereotypical outputs, allowing for a flexible yet structured approach to problemsolving. A comprehensive evaluation across six real-world scenarios demonstrates that Captain Agent significantly outperforms existing multi-agent methods with $21.94 \%$ improvement in average accuracy, providing outstanding performance without requiring task-specific prompt engineering.


[^0]
## 1 Introduction

The success of large language model (LLM) agents [2, 3, 4, 5, 6] with its outstanding in-context learning [7, 8, 9, 10, 11], planning [12, 13, 14, 15, 16, 17, 18], toolusing [19, 20, 21, 22, 23, 24, 25, 26, 27], and conversation [28, 29, 30] capabilities allow us to relate human's team building and collaboration abilities to the multiple language model agents (multi-agent) system [31, 32, 33, 34, 35, 25, 36, 37, 38, 39, 40, 41]. Humans have developed abilities that enable us to form teams and effectively solve problems. These abilities are rooted in communication, social cognition, problem-solving and decision-making, social learning and imitation, and shared intentionality [42, 43]. The interplay of the above abilities allows people to organize different teams for problems to ensure that tasks are completed successfully, which brings us to a critical question in a multi-agent system:

## Given a task, how can we build a team of LLM agents to solve it effectively?

A straightforward paradigm would be to build a static agent team beforehand based on the task instruction and let them solve the task collaboratively [1,33]. However, this static build method necessitates maintaining a team with all the required expertise for the whole task cycle. As the complexity of the task increases, the total number of team members may grow significantly. Always proceeding with such a large team makes it challenging to manage the team members effectively and efficiently. Furthermore, static teams may lack the adaptability to respond to dynamic changes in task requirements or unforeseen challenges. Imagine a prehistoric human tribe: was everyone involved in every task? The answer is unlikely affirmative. Those responsible for hunting may not participate in medical care and those responsible for cooking may not involve themselves in management. The major task, survival, was ensured by each individual group sticking to their roles and subtasks. In fact, when human organizations handle a complex task, we tend to form multiple teams for each subtask at different stages of the task-solving procedure, which still guarantees a diverse set of expertise is leveraged demanded by the task complexity [44].

Inspired by how humans assemble teams for a complex task, we introduce a new multi-agent team-building paradigm: adaptive build. This paradigm facilitates the flexible assembly of agents with specific skills and knowledge as demands evolve in the process of task-solving. To realize this paradigm, we propose a new adaptive builder agent, Captain Agent, to build, manage, and maintain agent teams for each problem-solving step in the conversation. Captain Agent has two core components: (1) adaptive multi-agent team building and (2) nested group conversation and reflection. Captain Agent will communicate with a User Proxy, who can provide the general task instructions at the beginning. When assigned a task, Captain Agent begins by formulating a strategic plan. This plan involves a cyclical process that continues until the task is successfully completed. In the first phase of the cycle, Captain Agent identifies a specific subtask, outlines the necessary roles, and assembles a team of agents equipped with the appropriate tools. In the subsequent phase, this team engages in a dialogue with a versatile tool to address the subtask. Upon completion, a reflector LLM reviews the process and provides Captain Agent with a detailed reflection report. Based on this feedback, Captain Agent either adjusts the team composition or the subtask instructions and repeats the cycle or concludes the task and presents the final outcomes.

We evaluate state-of-the-art multi-agent approaches for complex task solving and our adaptive build approach with Captain Agent on six real-world scenarios, including many mathematics problemsolving [45], data analysis [46], programming [47], scientific problem-solving [48] (Physics and Chemistry), and world-information retrieval [49]. Our experimental results demonstrated the outstanding ability of Captain Agent in various scenarios without heavy prompt engineering for each scenario but only the basic instructions (e.g., Please solve the following math problems, which does not contain detailed expertise instructions on math, like how to solve algebra problems). Captain Agent achieves distinguishing results compared to other single and multi-agent methods and frameworks when using the same prompt for each task, with an average of $21.94 \%$ improvement on average accuracy. Ablation studies on static and adaptive building paradigms show that the adaptive team outperforms the static team in four of five scenarios (and matches in one scenario), exhibiting the superiority of the adaptive build paradigm across different scenarios. We also demonstrated that handcraft agents and handcraft tools contribute equally to the final results. We further explore incorporating open-weight models as nested group participants' backbone LLM, in which the LLaMA-3-70B outperforms blackbox models like gpt-3.5-turbo and claude-3-sonnet, allowing us to think further about how to reduce the cost in practical applications.

![](https://cdn.mathpix.com/cropped/2024_06_04_ef686eec59cdf0327152g-03.jpg?height=550&width=1396&top_left_y=234&top_left_x=362)

Figure 2: The overall workflow of Captain Agent is: given a user instruction, Captain Agent will plan the task, build an agent team from retrieval and generation, and let the agents solve a decomposed, planned task collaboratively in a group chat. A reflection LLM will review and report the conversation history to Captain Agent. Captain Agent will then conclude or continue solving the problem with a modified team and instructions.

## 2 Adaptive In-conversation Team Building

The proposed Captain Agent contains two key components: (1) adaptive multi-agent team-building, which involves agent and tool retrieval, selection, and generation, and (2) nested group conversation with a reflection mechanism within the multi-agent system.

### 2.1 Overview

The overall workflow of Captain Agent is illustrated in Figure 2. Given a task, Captain Agent is prompted to derive a plan before task execution. According to the plan, Captain Agent will repeat the following two steps until it thinks the task is done and output the results: (Step 1) Captain Agent will first identify a subtask instructed by our prompt, list several roles needed for this subtask, and then create a team of agents accordingly by retrieval, selection, and generation. Each of these will be equipped with predefined tools retrieved from the tool library (Section 2.2); (Step 2) this team of agents will attempt to solve the subtask via conversation with the free-form tool using. Once it's done, a reflector LLM will provide Captain Agent with a reflection report for it to decide whether to adjust the team or subtask instruction or to terminate and output the results (Section 2.3).

### 2.2 Adaptive Multi-agent Team Building

After identifying a subtask in Step 1 following a corresponding prompt, Captain Agent will list several roles for the subtask. These roles will then pass into a retrieval, selection, and generation process guided by Retrieval-Augmented Generation (RAG) [50, 51, 52]. Created agents will be equipped with a well-designed profile (system message ${ }^{3}$ ) and high-quality tools. We illustrated the whole process in Figure 3.

Agent and tool retrieval. Captain Agent will prompt $n$ required roles $\left\{r_{i} \mid i \in 1, \cdots, n\right\}$ with detailed descriptions, including required skills and a possible role name. We use "expert" in Captain Agent prompt to make this process natural. We then retrieve top- $k_{1}$ agents and top- $k_{2}$ tools according to the sentence embedding similarity between the role's description and the agent/tool description recorded in the library. We use Sentence Transformer to calculate the embedding for description between the role and library agents/tools and use cosine similarity as the metric to evaluate the similarity between two sentences, as follows:

$$
\begin{align*}
& \text { top- } k_{1} \text { CosineSimilarity }\left(f\left(r_{i}\right), f\left(a_{\text {lib }}\right)\right) \rightarrow \text { RetrievedAgents, }  \tag{1}\\
& \text { top- } k_{2} \text { CosineSimilarity }\left(f\left(r_{i}\right), f\left(t_{\text {lib }}\right)\right) \rightarrow \text { RetrievedTools } \tag{2}
\end{align*}
$$[^1]

Adaptive Multi-agent Team Building

![](https://cdn.mathpix.com/cropped/2024_06_04_ef686eec59cdf0327152g-04.jpg?height=1404&width=1391&top_left_y=279&top_left_x=367)

Figure 3: Workflow for adaptive multi-agent team building. We retrieve candidate agents and tools according to the roles' description prompted by Captain Agent. Candidate agents and tools will further be linked to a role under the advice of the agent selector. If no agent is linked to a role, a generate process will be performed to create a new agent. It will generate the agent's name and task-specific instructions, combined with general task and coding skills and group chat instructions as the final system message.

where $k_{1}$ and $k_{2}$ are the numbers of retrieved agents and tools from agent library $a_{\text {lib }}$ and tool library $t_{\text {lib }}$, respectively, for $i$-th role $r_{i} . f(\cdot) \in \mathbb{R}^{m}$ denotes the sentence embedding extracted from a Sentence Transformer. After retrieval, each role will be assigned with $k_{1}$ agent candidates and $k_{2}$ valuable tools. We bind agent candidates with the retrieved tools by injecting the tool-using instruction into the corresponding agent's system message.

Agent selection. We prompt an LLM-based agent selector to select the most suitable agent according to the role's description given by Captain Agent and the retrieved agents' description. A JSON template is designed and provided for the agent selector to ensure the format is correct. Specifically, we designed an abstention mechanism for the agent selector, in which the agent selector can output "None" if there is no suitable agent for a role from the top- $k_{1}$ retrieved candidate list. This can prevent irrelevant or redundant agents from being forced to be selected for the current task. The roles marked with "None" will further go into the generation process described as follows.

Agent generation. We design an agent generation process for those roles with no linked agents at the previous step. Specifically, we generate the agent's name and required skills according to the role description given by Captain Agent. These instructions will be combined with general task and coding instructions and group chat instructions as the final system message. We manually design the general task and coding instructions, motivated by Chain-of-thought (CoT) [53] and Reflexion [54]. The final system message will also be compressed to a single-sentence description, which is consumed by the nested group conversation (introduced in the next subsection). We then retrieve tools from the tool library according to the description and inject the tool-using instruction into the generated system message. The generated agent will be added to the agent library afterwards.

### 2.3 Nested Group Conversation and Reflection

Agents selected and created in the adaptive multi-agent team-building process will join a nested group chat room. They will be prompted to collect information from the user's task and solve a subtask from Captain Agent by nested conversation. We then prompt a reflector LLM to retrieve and review the conversation history and fill in the conclusion, the reason for the conclusion, possible contradictions and issues, and flag if the result needs a double check in the pre-designed template.

Nested group conversation. We perform nested group conversations by leveraging the AutoGen [33] framework with a newly designed tool-using paradigm. AutoGen will put all agents in a chat room and select the speaker for each turn by a group chat manager LLM according to the conversation history and each agent's identity. A short description will be generated from the agent's profile for the group chat manager. Agents' code and tool calling will be executed and fed back to the conversation immediately. We inject the tool's description, path-to-python-module, and response case into the related agent's system message. The agent can then write free-form code by following the tools' description and path, naturally incorporating the tools into larger programs. Programs written by all agents will be executed by a user proxy agent with a shared code execution environment, and the results will be fed back to the conversation in real time.

Conversation reflection. The agent's output during the conversation can be inconsistent, including factual errors, hallucinations, and stereotypes. Although other agents have a chance to adjust and rectify this in conversation, they can also get stuck and cause problem-solving failure. Therefore, we propose to detect such in-conversation contradictions and issues by prompting a reflector LLM with a well-designed conversation summarizing prompt template. The reflector will flag the "need double-check" as "Yes" when it detects such inconsistent content and provides a detailed reason. This will trigger Captain Agent to start a verification process by constructing a new nested conversation to double-check the previous results after receiving "Yes" on "need double-check."

### 2.4 Benefits over Static Build

A static team with a small number of team members may limit the team's ability coverage. Although building a large number of agents with comprehensive persona or skill sets can address the limitation in ability coverage, it is challenging for LLMs to handle a long context that introduces all the participant members. Unexpectedly long contexts will primarily reduce the quality of the conversation. Meanwhile, agents with redundant functionality will also be involved in the task-solving process. In contrast, Captain Agent can adaptively select and build more optimized agent teams for the current task, reducing the prompting load for LLMs and redundant output from irrelevant agents without sacrificing the diversity in the agent team.

## 3 Evaluation

### 3.1 Experimental Setup

Scenarios and datasets. For evaluation, we select various real-world scenarios, including mathematics problem-solving, programming, data analysis, world information retrieval, and science problem-solving. Each scenario was chosen for its unique ability to demonstrate specific capabilities and performance metrics of the agent systems. This ensures a holistic assessment of Captain Agent against the baselines across various critical dimensions of computational and cognitive skills. We bind each scenario with a challenging open-source dataset, as shown in Table 1. Due to cost limitations, we sample a subset of MATH according to its original distribution of each question type.

Table 1: Scenarios and the corresponding datasets we choose to perform our main experiments. We perform the main comparison experiments on the whole dataset except MATH. For MATH, we sampled a small subset according to the type distribution.

| Scenario | Dataset | Size | Sample |
| :---: | :---: | :---: | :---: |
| Mathematics problems | MATH [55] | 196 | If $\frac{3 x^{2}-4 x+1}{x-1}=m$, and $x$ can be any real number except 1 <br> what real values can $m$ NOT have? |
| Programming | HumanEval [56] | 164 | def truncate_number(number: float) ->float: <br> """ Given a positive floating point number, it can be decomposed into <br> and integer part (largest integer smaller than given number) and decimals <br> (leftover part always smaller than 1 ). <br>  <br> "". |
| Data Analysis | DABench [57] | 257 | Generate a new feature called "FamilySize" by summing the "SibSp" <br> and "Parch" columns. Then, calculate the Pearson correlation coefficient (r) <br> between the "FamilySize" and "Fare" columns. |
| World Information Retrieval | GAIA [58] | 165 | On the BBC Earth YouTube video of the Top 5 Silliest Animal Moments, <br> what species of bird is featured? |
| (Scientific) Chemistry | SciBench [48] | 41 | Calculate the pressure in kilopascals exerted by $1.25 \mathrm{~g}$ of nitrogen gas <br> in a flask of volume $250 \mathrm{~cm}^{3}$ at $20^{\circ} \mathrm{C}$. |
| (Scientific) Physics | SciBench [48] | 34 | If the coefficient of static friction between the block and plane in the <br> previous example is $\mu_{s}=0.4$, at what angle $\theta$ will the block starts sliding <br> if it is initially at rest? |

Compared methods and implementation. For mathematics problems, programming, data analysis, and scientific scenarios, we investigate the performance of Captain Agent and four different methods, including Vanilla LLM (prompt an LLM once for an answer), AutoAgents [1], Meta-prompting [34], and a two-agent system (a system involving an Assistant agent with an Executor agent) realized with AutoGen [33]. Specifically, we implement AutoAgents with AutoGen as the official implementation is unstable and unsuitable for large-scale experiments. For meta-prompting, we improve the code execution ability of meta-prompting by reproducing it with the AutoGen framework. For Captain Agent, we adopt all-mpnet-base-v2 to calculate the sentence embedding for agent and tool retrieval. A User Proxy Agent will communicate with Captain Agent by providing the feedback of code execution, tool calling (adaptive build), nested conversation reflection results, and a default reply: I'm a proxy, and I can only execute your code and tool or end the conversation. If you think the problem is solved, please reply to me only with 'TERMINATE.' All these methods are equipped with a gpt-4-0125-preview backbone and use the same task-specific prompt (refer to Appendix D). For world information retrieval scenarios, we compare Captain Agent with the top-5 baselines (with reference) reported to the GAIA validation leaderboard, which includes AutoGen: GAIA_Orchestrator (a specific three-agent setting organized by an Orchestrator agent designed for GAIA) [59], FRIDAY [60], Warm-up Act ${ }^{4}$, and HuggingFace Agent [61]. All these baselines have a gpt-4-1106-preview backbone, except the HuggingFace Agent equipped with an LLaMA-3-70B as the backbone.

Agent and tool library. We initialize our agent library based on a small subset of problem instances from each dataset ( $\sim 20$ questions per dataset described in Section 3.4) in Table 1. Specifically, we run Captain Agent on the subset and iteratively update the library by adding the generated agents and keeping our agent library unchanged during the main experiment. Our agent library also supports all hand-crafted agents (of the ConversableAgent class) archived in AutoGen (details in Appendix F). All these agents follow the ConversableAgent interface to converse with each other. Our tool library consists of a suite of callable Python functions intended for freeform coding. The agents can freely import functions from the tool library and write free-form code to integrate the outputs to handle sophisticated tasks (see also Appendix E and G). The library contains three main categories of tools: math, data analysis, and world information retrieval. For each category, we summarize the patterns of the corresponding dataset and manually craft a set of functions that suit the tasks.

### 3.2 Evaluation Protocol

For mathematics, data analysis, and science scenarios, we report the accuracy of each method by comparing the final result from each method and ground truth. To ensure fairness in evaluation, we transform different result formats into a uniform format, preventing the correct answer from being judged incorrect due to format mismatches. For programming scenarios, we run the code provided[^2]

Table 2: Comparison results on different real-world scenarios. We record each scenario's accuracy for each baseline and Captain Agent, and mark the best results in bold. We adopt gpt-4-0125-preview as the backbone LLM model for all baselines and Captain Agent.

| Method | Mathematics | Programming | Data Analysis | (Sci) Chemistry | (Sci) Physics | Avg. |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| Vanilla LLM | 51.53 | 84.76 | 6.61 | 39.02 | 31.25 | 40.98 |
| Meta-prompting | 68.88 | 19.51 | 39.69 | 41.46 | 43.75 | 43.47 |
| AutoAgents | 56.12 | 84.76 | 57.98 | 60.98 | 50.00 | 63.58 |
| AutoGen: Assistant + Executor | 74.49 | 93.90 | 82.88 | 60.98 | 43.75 | 79.89 |
| Captain Agent | $\mathbf{7 7 . 5 5}$ | $\mathbf{9 6 . 9 5}$ | $\mathbf{8 8 . 3 2}$ | $\mathbf{6 5 . 8 5}$ | $\mathbf{5 3 . 1 2}$ | $\mathbf{8 4 . 2 5}$ |

Table 3: Comparison results on world-information retrieval scenario (GAIA validation). We report the accuracy at each level and the average accuracy over three levels and mark the best results in bold. Captain Agent achieves the best with minimal prompt engineering.

| Method | Level 1 | Level 2 | Level 3 | Avg. |
| :--- | :---: | :---: | :---: | :---: |
| Huggingface-Agent (LLaMA-3-70B) | 30.19 | 11.63 | 7.69 | 16.97 |
| Warm-up Act | 35.19 | 15.12 | 0 | 17.58 |
| FRIDAY | 45.28 | 34.88 | $\mathbf{1 1 . 5 4}$ | 34.55 |
| AutoGen: GAIA_Orchestrator | 54.72 | 38.31 | $\mathbf{1 1 . 5 4}$ | 39.39 |
| Captain Agent | $\mathbf{5 6 . 6 0}$ | $\mathbf{3 9 . 5 3}$ | $\mathbf{1 1 . 5 4}$ | $\mathbf{4 0 . 6 0}$ |

from each method and output a unique token if the code successfully passes all tests. We then count the success token and calculate the accuracy for each method.

### 3.3 Main Results

Table 2 and 3 report the comparison results between Captain Agent and eight different baselines on six real-world scenarios. Baseline results on world information retrieval are extracted directly from the GAIA leaderboard.

Findings 1: Diverse agents can help trigger accurate expertise output for problem-solving. By comparing the results from Captain Agent, AutoAgents, and AutoGen Assistant + Executor, we observe that Captain Agent and AutoAgents averagely outperform AutoGen Assistant + Executor on (Sci) Chemistry and (Sci) Physics scenarios. These scenarios required expertise knowledge, which the AutoGen Assistant with a fixed system message is hard to complete. Captain Agent and AutoAgents can create diverse experts by assigning different domain-specific system messages to agents, which helps better trigger the intrinsic knowledge inside an LLM to provide an accurate answer. Captain Agent outperforms AutoAgents in all the scenarios because Captain Agent can provide a high-level plan and solve each step with adaptive instructions and an agent team.

Findings 2: Adaptive team-building boosts performance with no task preference. It is obvious that Captain Agent achieves outstanding results over all scenarios, indicating that Captain Agent is free from task preference. Incorporating different agents into the team at a proper time gives Captain Agent the ability to solve difficult tasks like science and world-information retrieval problems step-by-step. On the other hand, Meta-prompting fails in science scenarios due to the inability to decompose science problems into the fine-grain subtasks that one agent can solve. Captain Agent with the agent-team building paradigm neither requires a task that can be decomposed into a subtask that can only be solved by an agent nor requires all agents to be involved in the conversation. We further discuss the static and adaptive teams in Section 3.4.1.

### 3.4 Analysis and Ablation Studies

In this section, we dive into the difference between static and adaptive team-building, the influence of agent and tool libraries, and the possibility of working with open-weight models. We perform ablation studies on a subset from Table 1. Specifically, we choose 17 problems from MATH and 25 problems from HumanEval according to the AutoGenBench [62], in which the problems are randomly selected from GPT-4 failure set. For DABench, we randomly selected 25 problems, and for

Table 4: Ablation comparison between static and adaptive team-building on the selected subset. We mark the best results in bold. Dynamic team-building during the conversation improves performance in different scenarios.

| Method | Mathematics | Programming | Data Analysis | (Sci) Chemistry | (Sci) Physics |
| :--- | :---: | :---: | :---: | :---: | :---: |
| Static Team | 64.71 | 88.00 | 85.00 | 47.37 | $\mathbf{6 8 . 4 2}$ |
| Adaptive Team (Captain Agent) | $\mathbf{8 2 . 3 5}$ | $\mathbf{9 6 . 0 0}$ | $\mathbf{9 5 . 0 0}$ | $\mathbf{5 2 . 6 3}$ | $\mathbf{6 8 . 4 2}$ |

Table 5: Ablation study of tool library and agent library on world-information retrieval scenario (GAIA). We report the accuracy at each level and the average accuracy over three levels and mark the best results in bold.

| Captain Agent |  | World-information Retrieval |  |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: |
| Agent Library | Tool Library | Level 1 | Level 2 | Level 3 | Avg. |
| - | - | 32.07 | 13.95 | 3.84 | 18.18 |
| $\checkmark$ | - | 37.73 | 30.23 | 7.69 | 29.09 |
| - | $\checkmark$ | 39.62 | 19.78 | 7.69 | 24.24 |
| $\checkmark$ | $\checkmark$ | $\mathbf{5 6 . 6 0}$ | $\mathbf{3 9 . 5 3}$ | $\mathbf{1 1 . 5 4}$ | $\mathbf{4 0 . 6 0}$ |

Table 6: Comparison of different LLM backbones for nested conversation participants on ablation subset. Instructions to the nested conversation is given by a Captain Agent with gpt-4-0125-preview backbone. Best results are marked in red bold and the second best results in blue.

| Backbone LLM | Mathematics | Programming | Data Analysis | (Sci) Chemistry | (Sci) Physics |  |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| Blackbox Models |  |  |  |  |  |  |
| w/ gpt-3.5-turbo | 35.29 | 92.00 | 65.00 | 42.11 | 42.11 |  |
| w/ claude-3-sonnet | 35.29 | 80.00 | 60.00 | 15.79 | 26.32 |  |
| w/ gemini-1.5-pro | 70.58 | 80.00 | 80.00 | $\mathbf{5 7 . 8 9}$ | 42.11 |  |
| w/ gpt-4-0125-preview (default) | $\mathbf{8 2 . 3 5}$ | $\mathbf{9 6 . 0 0}$ | $\mathbf{9 5 . 0 0}$ | 52.63 | $\mathbf{6 8 . 4 2}$ |  |
| Open-weight Models |  |  |  |  |  |  |
| w/ Meta-Llama-3-70B-Instruct | 52.94 | 88.00 | 80.00 | 52.63 | 47.37 |  |
| w/ Mixtral-8x22B-instruct-v0.1 | 29.41 | 76.00 | 55.00 | 47.37 | 21.05 |  |

SciBench, we randomly selected 19 problems for chemistry and physics according to the number of textbooks. The evaluation protocol is the same as in Section 3.3.

### 3.4.1 Static vs. adaptive team-building

To further explore the power of adaptive team-building, we compare adaptive team-building with static team-building. Specifically, we perform a task-specific team-building paradigm by building a team of agents in the same way as Captain Agent at the beginning of each task and letting them solve each problem. We summarized the results in Table 4, showing that the adaptive team-building paradigm outperforms the static team-building paradigm comprehensively.

### 3.4.2 Ablation on tool library and agent library

In this part, we conduct an ablation study on the utility of tool and agent libraries. We remove the tool library, the agent library, and both libraries in turn and evaluate the performance on world-information retrieval tasks, i.e., the GAIA dataset. As shown in Table 5, removing the agent library and tool library can both significantly impair the system's performance. While both the tool and agent libraries can enhance performance independently, optimal results are achieved only when both libraries are employed concurrently. Handling level 1 tasks requires a moderate amount of web browsing and reasoning steps, which can be achieved by several single-turn tool calls or experts writing and executing code iteratively. Introducing both an agent library and tool library makes the system more stable and robust to unknown errors during web interaction, therefore improving the performance. Notably, without an agent library, Captain Agent performs much worse on Level 2 tasks. This is because these tasks are more sophisticated and mostly involve a significant number of web navigation and reasoning steps. Web browsing involves complex and dynamic interactions that are poorly suited to static tool libraries. The agents need to coordinate multiple tools to reach the goal, which is a process prone to error in unexpected web scenarios.

### 3.4.3 Nesting conversation with different backbone LMs

In this section, we try different backbone LLM for nested conversation participants, including blackbox models like gpt-3.5-turbo, claude-3-sonnet, gemini-1.5-pro, gpt-4-0125-preview (default setting for main results), and open-weight models like LLaMA-3-70B (Meta-Llama-3-70BInstruct) and Mixtral-8x22B (Mixtral-8x22B-instruct-v0.1). The instruction for the nested conversation is still given by a Captain Agent equipped with gpt-4-0125-preview backbone. We recorded the experiment results in Table 6. Besides the obvious results that nesting with gpt-4-0125-preview still achieves SOTA on most of the scenarios, we found that gemini-1.5-pro also performs well with roughly $30 \%$ cheaper than gpt-4-0125-preview. LLaMA-3-70B also achieves three second-best results and outperforms two blackbox models with about 16.7 times cheaper than gpt-4-0125-preview ${ }^{5}$. We also notice that models may have task preferences and will influence the quality of nested chat. For example, gpt-3.5-turbo has a great code generation ability, which helps in programming scenarios, and gemini-1.5-pro works better on mathematics and data analysis and chemistry problems.

## 4 Related Work

Large language models (LLMs) represent a significant advancement in artificial intelligence, showcasing remarkable capabilities in various aspects, including reasoning [53, 63, 64, 65, 66, 67], planning [68, 69, 69, 37, 70], and adaptability to novel real-world observations [71, 35, 3, 72, 73, 74]. Leveraging the inherent versatility of LLMs as generalized models adaptable to diverse scenarios, numerous efforts have been dedicated to the development of intelligent agents [33, 32, 25, 75, 76] where LLMs serve as foundational components. For instance, one typical algorithm, React [2], employs one single LLM to iteratively generate both reasoning trajectories and task-specific actions. This interleaved process enables the agent to engage in dynamic reasoning. In addition, LLM agents can also harness external tools [19, 20, 21, 22, 23, 24, 25, 26, 27], leveraging both their internal capabilities and external resources, collaborating effectively to solve more intricate problems.

The success of a single-agent system motivates the development of multiple-agent systems $[31,32,1$, $33,34,35,25,36,37,38,39,40,41]$. Methods focusing on static build require a protocol for agents to communicate with each other in a group chat and a builder that can receive the user's instruction and output an agent list [33, 1, 35]. The builder can be a human [33, 35] or a LLM agent [1]. There are other works breaking down complex tasks into smaller components, each of which is then handled by a single specialized agent with detailed natural-language instructions [77, 78]. This task decomposition reduces the prediction burden on each agent by avoiding irrelevant context. For instance, meta-prompting [77] involves a meta-model decomposing tasks and assigning subtasks to different LLMs for completion and aggregation.

## 5 Conclusion and Discussion

Conclusion. We introduce a new paradigm for multi-agent team-building, adaptive build. This new paradigm helps ensure diversity, prevent limited knowledge extraction and reduce stereotypical outputs. The new paradigm executed by our proposed agent, Captain Agent, manages agent teams for problem-solving steps using adaptive multi-agent team building and nested group conversation and reflection. Experimental results across six real-world scenarios demonstrate Captain Agent's efficacy in various tasks without prompt engineering, achieving superior results compared to existing methods. Ablation studies confirm that each component contributes equally to overall performance, underscoring the robustness of our approach.

Discussion. In this work, we demonstrate the outstanding performance of Captain Agent over six real-world scenarios. Captain Agent can organize a team adaptively and solve the task step-by-step by different teams. Although we only discuss the scene Captain Agent collaborate with a static User Proxy, Captain Agent can collaborate with other specific agents, for example, a sophisticated planner. We also notice that the context length and irrelevant, less important information (e.g., failure code blocks) noise the problem-solving process. Therefore, conversation pruning is a promising future work that minimizes the interference of irrelevant information while reducing cost.[^3]

## References

[1] Chen, G., S. Dong, Y. Shu, et al. Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:2309.17288, 2023.

[2] Yao, S., J. Zhao, D. Yu, et al. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.

[3] Yang, H., S. Yue, Y. He. Auto-gpt for online decision making: Benchmarks and additional opinions. arXiv preprint arXiv:2306.02224, 2023.

[4] Furuta, H., K.-H. Lee, O. Nachum, et al. Multimodal web navigation with instruction-finetuned foundation models. In The Twelfth International Conference on Learning Representations. 2024.

[5] Yang, J., C. E. Jimenez, A. Wettig, et al. Swe-agent: Agent computer interfaces enable software engineering language models, 2024.

[6] Hong, S., Y. Lin, B. Liu, et al. Data interpreter: An llm agent for data science. arXiv preprint arXiv:2402.18679, 2024.

[7] Dong, Q., L. Li, D. Dai, et al. A survey on in-context learning. arXiv preprint arXiv:2301.00234, 2022.

[8] Brown, T., B. Mann, N. Ryder, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.

[9] Yang, J., B. Hui, M. Yang, et al. Iterative forward tuning boosts in-context learning in language models. arXiv preprint arXiv:2305.13016, 2023.

[10] Dai, D., Y. Sun, L. Dong, et al. Why can gpt learn in-context? language models secretly perform gradient descent as meta-optimizers. In Findings of the Association for Computational Linguistics: ACL 2023, pages 4005-4019. 2023.

[11] Li, Y., M. E. Ildiz, D. Papailiopoulos, et al. Transformers as algorithms: Generalization and stability in in-context learning. In International Conference on Machine Learning, pages 19565-19594. PMLR, 2023.

[12] Sun, H., Y. Zhuang, L. Kong, et al. Adaplanner: Adaptive planning from feedback with language models. Advances in Neural Information Processing Systems, 36, 2024.

[13] Xie, J., K. Zhang, J. Chen, et al. Travelplanner: A benchmark for real-world planning with language agents. arXiv preprint arXiv:2402.01622, 2024.

[14] Liu, B., Y. Jiang, X. Zhang, et al. Llm+p: Empowering large language models with optimal planning proficiency. ArXiv, abs/2304.11477, 2023.

[15] Valmeekam, K., A. Olmo, S. Sreedharan, et al. Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change. In Neural Information Processing Systems. 2022.

[16] Wei, J., X. Wang, D. Schuurmans, et al. Chain of thought prompting elicits reasoning in large language models. ArXiv, abs/2201.11903, 2022.

[17] Yuan, S., J. Chen, Z. Fu, et al. Distilling script knowledge from large language models for constrained language planning. In Annual Meeting of the Association for Computational Linguistics. 2023.

[18] Zheng, B., B. Gou, J. Kil, et al. Gpt-4v(ision) is a generalist web agent, if grounded. ArXiv, abs/2401.01614, 2024.

[19] Qin, Y., S. Hu, Y. Lin, et al. Tool learning with foundation models, 2023.

[20] Qin, Y., S. Liang, Y. Ye, et al. Toolllm: Facilitating large language models to master 16000+ real-world apis, 2023.

[21] Schick, T., J. Dwivedi-Yu, R. Dessì, et al. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36, 2024.

[22] Cai, T., X. Wang, T. Ma, et al. Large language models as tool makers. arXiv preprint arXiv:2305.17126, 2023.

[23] Yuan, L., Y. Chen, X. Wang, et al. Craft: Customizing llms by creating and retrieving from specialized toolsets. arXiv preprint arXiv:2309.17428, 2023.

[24] Paranjape, B., S. Lundberg, S. Singh, et al. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.

[25] Zhang, S., J. Zhang, J. Liu, et al. Training language model agents without modifying language models. arXiv preprint arXiv:2402.11359, 2024.

[26] Huang, Y., J. Shi, Y. Li, et al. Metatool benchmark for large language models: Deciding whether to use tools and which to use. arXiv preprint arXiv:2310.03128, 2023.

[27] Ma, Z., W. Huang, J. Zhang, et al. m\&m's: A benchmark to evaluate tool-use for multi-step multi-modal tasks. In Synthetic Data for Computer Vision Workshop@ CVPR 2024. 2024.

[28] Fernandes, P., A. Madaan, E. Liu, et al. Bridging the gap: A survey on integrating (human) feedback for natural language generation. Transactions of the Association for Computational Linguistics, 11:1643-1668, 2023.

[29] Wang, X., Z. Wang, J. Liu, et al. Mint: Evaluating llms in multi-turn interaction with tools and language feedback. arXiv preprint arXiv:2309.10691, 2023.

[30] Yang, J., A. Prabhakar, K. Narasimhan, et al. Intercode: Standardizing and benchmarking interactive coding with execution feedback. Advances in Neural Information Processing Systems, $36,2024$.

[31] Wang, L., C. Ma, X. Feng, et al. A survey on large language model based autonomous agents. arXiv preprint arXiv:2308.11432, 2023.

[32] Xi, Z., W. Chen, X. Guo, et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.

[33] Wu, Q., G. Bansal, J. Zhang, et al. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arXiv preprint arXiv:2308.08155, 2023.

[34] Suzgun, M., A. T. Kalai. Meta-prompting: Enhancing language models with task-agnostic scaffolding. arXiv preprint arXiv:2401.12954, 2024.

[35] Hong, S., X. Zheng, J. Chen, et al. Metagpt: Meta programming for multi-agent collaborative framework. arXiv preprint arXiv:2308.00352, 2023.

[36] Zhang, J., R. Krishna, A. H. Awadallah, et al. Ecoassistant: Using llm assistant more affordably and accurately. arXiv preprint arXiv:2310.03046, 2023.

[37] Valmeekam, K., M. Marquez, S. Sreedharan, et al. On the planning abilities of large language models-a critical investigation. Advances in Neural Information Processing Systems, 36:75993$76005,2023$.

[38] Wang, Y., Z. Wu, J. Yao, et al. Tdag: A multi-agent framework based on dynamic task decomposition and agent generation. arXiv preprint arXiv:2402.10178, 2024.

[39] Saha, S., O. Levy, A. Celikyilmaz, et al. Branch-solve-merge improves large language model evaluation and generation. arXiv preprint arXiv:2310.15123, 2023.

[40] Liang, T., Z. He, W. Jiao, et al. Encouraging divergent thinking in large language models through multi-agent debate. arXiv preprint arXiv:2305.19118, 2023.

[41] Du, Y., S. Li, A. Torralba, et al. Improving factuality and reasoning in language models through multiagent debate. arXiv preprint arXiv:2305.14325, 2023.

[42] Elimari, N., G. Lafargue. Network neuroscience and the adapted mind: Rethinking the role of network theories in evolutionary psychology. Frontiers in psychology, 11:545632, 2020.

[43] Confer, J. C., J. A. Easton, D. S. Fleischman, et al. Evolutionary psychology: Controversies, questions, prospects, and limitations. American psychologist, 65(2):110, 2010.

[44] Mao, A., W. Mason, S. Suri, et al. An experimental study of team size and performance on a complex task. PloS one, 11(4):e0153048, 2016.

[45] Hendrycks, D., C. Burns, S. Kadavath, et al. Measuring mathematical problem solving with the math dataset. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2). 2021.

[46] Hu, X., Z. Zhao, S. Wei, et al. Infiagent-dabench: Evaluating agents on data analysis tasks. arXiv preprint arXiv:2401.05507, 2024.

[47] Le, T. H., H. Chen, M. A. Babar. Deep learning for source code modeling and generation: Models, applications, and challenges. ACM Computing Surveys (CSUR), 53(3):1-38, 2020.

[48] Wang, X., Z. Hu, P. Lu, et al. Scibench: Evaluating college-level scientific problem-solving abilities of large language models. arXiv preprint arXiv:2307.10635, 2023.

[49] Mialon, G., C. Fourrier, T. Wolf, et al. GAIA: a benchmark for general AI assistants. In The Twelfth International Conference on Learning Representations. 2024.

[50] Lewis, P., E. Perez, A. Piktus, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459-9474, 2020.

[51] Gao, Y., Y. Xiong, X. Gao, et al. Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997, 2023.

[52] Ram, O., Y. Levine, I. Dalmedigos, et al. In-context retrieval-augmented language models. Transactions of the Association for Computational Linguistics, 11:1316-1331, 2023.

[53] Wei, J., X. Wang, D. Schuurmans, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.

[54] Shinn, N., F. Cassano, A. Gopinath, et al. Reflexion: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.

[55] Hendrycks, D., C. Burns, S. Kadavath, et al. Measuring mathematical problem solving with the math dataset. NeurIPS, 2021.

[56] Chen, M., J. Tworek, H. Jun, et al. Evaluating large language models trained on code. 2021.

[57] Hu, X., Z. Zhao, S. Wei, et al. Infiagent-dabench: Evaluating agents on data analysis tasks, 2024.

[58] Mialon, G., C. Fourrier, C. Swift, et al. Gaia: a benchmark for general ai assistants. arXiv preprint arXiv:2311.12983, 2023.

[59] GAIA_Orchestrator. Github। autogen: Gaia orchestrator. https://github.com/microsoft/ autogen/tree/gaia_multiagent_v01_march_1st/samples/tools/autogenbench/ scenarios/GAIA/Templates/Orchestrator, 2024.

[60] Wu, Z., C. Han, Z. Ding, et al. Os-copilot: Towards generalist computer agents with selfimprovement. arXiv preprint arXiv:2402.07456, 2024.

[61] Huggingface. Huggingface agents. https://huggingface.co/docs/transformers/en/ transformers_agents, 2024.

[62] AutoGenBench. Github |autogenbench. https://microsoft.github.io/autogen/blog/ 2024/01/25/AutoGenBench, 2024.

[63] Yao, S., D. Yu, J. Zhao, et al. Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural Information Processing Systems, 36, 2024.

[64] Morishita, T., G. Morio, A. Yamaguchi, et al. Learning deductive reasoning from synthetic corpus based on formal logic. In International Conference on Machine Learning, pages 2525425274. PMLR, 2023.

[65] Zhang, S., X. Xia, Z. Wang, et al. Ideal: Influence-driven selective annotations empower in-context learners in large language models. arXiv preprint arXiv:2310.10873, 2023.

[66] Li, L. H., J. Hessel, Y. Yu, et al. Symbolic chain-of-thought distillation: Small models can also" think" step-by-step. arXiv preprint arXiv:2306.14050, 2023.

[67] Ho, N., L. Schmid, S.-Y. Yun. Large language models are reasoning teachers. arXiv preprint arXiv:2212.10071, 2022.

[68] BabyAGI. Github। babyagi. https://github.com/yoheinakajima/babyagi, 2023.

[69] Song, C. H., J. Wu, C. Washington, et al. Llm-planner: Few-shot grounded planning for embodied agents with large language models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 2998-3009. 2023.

[70] Liu, Z., Y. Zhang, P. Li, et al. Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization. arXiv preprint arXiv:2310.02170, 2023.

[71] Shi, W., R. Xu, Y. Zhuang, et al. Ehragent: Code empowers large language models for complex tabular reasoning on electronic health records. arXiv preprint arXiv:2401.07128, 2024.

[72] Dan, Y., Z. Lei, Y. Gu, et al. Educhat: A large-scale language model-based chatbot system for intelligent education. arXiv preprint arXiv:2308.02773, 2023.

[73] Zhou, S., F. F. Xu, H. Zhu, et al. Webarena: A realistic web environment for building autonomous agents. arXiv preprint arXiv:2307.13854, 2023.

[74] Bharadhwaj, H., J. Vakil, M. Sharma, et al. Roboagent: Generalization and efficiency in robot manipulation via semantic augmentations and action chunking. arXiv preprint arXiv:2309.01918, 2023.

[75] Sumers, T. R., S. Yao, K. Narasimhan, et al. Cognitive architectures for language agents. arXiv preprint arXiv:2309.02427, 2023.

[76] Zhou, W., Y. E. Jiang, L. Li, et al. Agents: An open-source framework for autonomous language agents. arXiv preprint arXiv:2309.07870, 2023.

[77] Suzgun, M., A. T. Kalai. Meta-prompting: Enhancing language models with task-agnostic scaffolding. arXiv preprint arXiv:2401.12954, 2024.

[78] Zhuge, M., H. Liu, F. Faccio, et al. Mindstorms in natural language-based societies of mind. arXiv preprint arXiv:2305.17066, 2023.

[79] Zhang, H., J. Da, D. Lee, et al. A careful examination of large language model performance on grade school arithmetic. arXiv preprint arXiv:2405.00332, 2024.

[80] Xu, R., Z. Wang, R.-Z. Fan, et al. Benchmarking benchmark leakage in large language models. arXiv preprint arXiv:2404.18824, 2024.
