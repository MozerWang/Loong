# Large Language Models as Evolutionary Optimizers 

Shengcai Liu<br>Centre for Frontier AI Research, A*STAR<br>Centre for Frontier AI Research<br>Department of Computer Science and Engineering<br>$A * S T A R$<br>Xinghua Qu<br>Tianqiao \& Chrissy Chen Institute<br>quxinghua17@gmail.com<br>Southern University of Science and Technology<br>chen_caishun@cfar.a-star.edu.sg<br>liu_shengcai@cfar.a-star.edu.sg<br>Ke Tang<br>Guangdong Provincial Key Laboratory of<br>Yew-Soon Ong<br>Brain-Inspired Intelligent Computation<br>Centre for Frontier AI Research, $A * S T A R$<br>School of Computer Science and Engineering, Data Science and<br>Southern University of Science and Technology Artificial Intelligence Research Centre, Nanyang Technological University<br>tangk3@ sustech.edu.cn<br>asysong@ntu.edu.sg


#### Abstract

Evolutionary algorithms (EAs) have achieved remarkable success in tackling complex combinatorial optimization problems. However, EAs often demand carefully-designed operators with the aid of domain expertise to achieve satisfactory performance. In this work, we present the first study on large language models (LLMs) as evolutionary combinatorial optimizers. The main advantage is that it requires minimal domain knowledge and human efforts, as well as no additional training of the model. This approach is referred to as LLM-driven EA (LMEA). Specifically, in each generation of the evolutionary search, LMEA instructs the LLM to select parent solutions from current population, and perform crossover and mutation to generate offspring solutions. Then, LMEA evaluates these new solutions and include them into the population for the next generation. LMEA is equipped with a self-adaptation mechanism that controls the temperature of the LLM. This enables it to balance between exploration and exploitation and prevents the search from getting stuck in local optima. We investigate the power of LMEA on the classical traveling salesman problems (TSPs) widely used in combinatorial optimization research. Notably, the results show that LMEA performs competitively to traditional heuristics in finding high-quality solutions on TSP instances with up to 20 nodes. Additionally, we also study the effectiveness of LLM-driven crossover/mutation and the selfadaptation mechanism in evolutionary search. In summary, our results reveal the great potentials of LLMs as evolutionary optimizers for solving combinatorial problems. We hope our research shall inspire future explorations on LLM-driven EAs for complex optimization challenges.


Index Terms-Evolutionary algorithms, large language model, combinatorial optimization, pre-trained model

## I. INTRODUCTION

Evolutionary algorithms (EAs) are a class of algorithms that draw inspiration from natural evolution [1]. By simulating the principles of natural selection and genetic variation, EAs have been widely utilized in tackling complex combinatorial optimization problems arising in various domains, including logistics [2]-[5], cloud computing [6]-[8], manufacturing [9][11], robotics [12], and adversarial example generation [13]. Despite the huge success achieved thus far, EAs, in general,[^0]

still require carefully handcrafted operators to achieve high performance. Typically, the design process of an EA involves algorithm experts analyzing the problem structure, tailoring specialized genetic operators (e.g., crossover and mutation) that exploit this structure most effectively, and continually refining these operators. This process heavily relies on domain expertise and human efforts, and can become even more burdensome when dealing with new problems.

Motivated by the above challenge, recently there has been a surge of research interest in automating (part of) the design process of EAs, primarily through a meta-optimization paradigm [14]. Specifically, these approaches construct a meta-level optimization problem where the decision variables are design choices of the algorithm, and the optimization objective is the algorithm's performance on a pre-collected set of problem instances (called the training set). Then, by solving this meta-optimization problem, the design choices of the algorithm are automatically determined. In the literature, there are various ways to represent the algorithm design choices, ranging from algorithm parameters [15], [16], search heuristics [17]-[20], algorithm selectors [21], to endto-end deep neural networks [22]-[24]. However, the metaoptimization approaches still pose non-trivial challenges, including how to select a representative training set that can sufficiently reflect the target cases where the algorithm will be applied [25], [26], how to build a compact and effective algorithm design space [27], and how to solve the metaoptimization problem [28]. Moreover, these approaches often need to consume significant computational resources to obtain a high-performing algorithm.

Large language models (LLMs) have recently yielded impressive results in a wide range of domains [29]-[33]. These models extract human knowledge by learning from vast amounts of text data and have demonstrated remarkable reasoning and decision-making capabilities [34]-[37]. From this perspective, it is plausible that the knowledge embedded in LLMs also encompasses human experiences and intuitions in designing optimization algorithms. This naturally raises an
interesting question: can LLMs be used to help EAs solve complex optimization problems?

This work provides an affirmative answer to the above question. Specifically, we propose an innovative approach, named LLM-driven EA (LMEA), for solving combinatorial optimization problems. In each generation of the evolutionary search, LMEA constructs a prompt to instruct the LLM to select parent solutions from the current population, and perform crossover and mutation to generate offspring solutions. Then, these new solutions are evaluated and added to the population for the next generation. Additionally, a simple self-adaptation mechanism is integrated into LMEA to control the temperature of the LLM, thus balancing its exploration and exploitation.

From the perspective of designing EAs, LMEA has two appealing features. First, due to the capabilities of LLMs, in LMEA we can describe the optimization problem and the desired solution properties in natural language to instruct the LLM. In consequence, optimization with LMEA enables quick adaptation to different optimization problems by changing the problem description and solution specifications in the prompt. Compared to the traditional practice of formally defining the problem and implementing operators through programming, LMEA follows an approach that is more direct and only demands minimal domain knowledge and human efforts. Second, LMEA leverages the LLM in a zero-shot manner. Here, the term "zero-shot" means that no additional training of the model is required, which is a significant advantage compared to meta-optimization approaches that require extensive computational resources to optimize the algorithm.

We investigate the power of LMEA on the classical traveling salesman problems (TSPs) widely used in combinatorial optimization research. The experimental results demonstrate that, despite its minimal reliance on domain expertise, LMEA performs competitively to the traditional heuristics on TSP instances with up to 20 nodes. Surprisingly, it consistently obtains the optimal solutions on TSP instances with 10 nodes and 15 nodes. Furthermore, we conduct experiments to verify the effectiveness of the LLM-driven genetic operators and the self-adaptation mechanism.

To the best of our knowledge, this is the first attempt of utilizing LLMs in evolutionary combinatorial optimization. Also, we would like to note that this work is not to show that LMEA can outperform those sophisticated specialized solvers for classical combinatorial optimization problems like TSPs. Instead, the goal is to introduce an approach with a significant departure from previous design paradigms of EAs. Importantly, this approach indeed demonstrates its capacity to solve non-trivial hard combinatorial optimization problems. We hope that our results will inspire further exploration of LLM-driven EAs for combinatorial optimization challenges.

The remainder of this paper is organized as follows. Section II briefly reviews the literature on EAs for combinatorial optimization, LLMs and prompts, as well as the intersection between EAs and LLMs. Section III presents the approach LMEA. Experiments on TSPs are presented in Section IV. Finally, Section V concludes the paper with discussions.

## II. RELATED WORKS

## A. EAs for Combinatorial Optimization

Combinatorial optimization involves finding the best possible solution from a finite solution set. It has many applications in various domains [38]. From the perspective of computational complexity, many combinatorial optimization problems are NP-hard due to their discrete and nonconvex nature [39]. For these problems, exact methods such as the branch and bound algorithms [40] can find the optimal solutions, but generally suffer from exponential time complexity. In contrast, meta-heuristics seek to find good (but not necessarily optimal) solutions within reasonable computation time. EAs, as one of the mainstream meta-heuristics, have achieved significant progress in solving combinatorial optimization problems over the past decades and are still undergoing diverse and flourishing development. Currently, EAs have established themselves as state-of-the-art methods for various combinatorial optimization problems [2]-[7], [9]-[12]. These algorithms range from classic EAs like genetic algorithms [2], [3], hybrid approaches such as memetic algorithms [4], [5], [7], [12], to co-evolutionary algorithms [41].

In general, when applying EAs to solve combinatorial optimization problems, algorithm practitioners often need to design operators tailored to the problem to obtain satisfactory performance. These operators can be specific to the solution representations, such as the various crossover variants [42] (e.g., single-point, multi-point, shuffle, and matrix) for binary solution representations in set maximization problems, as well as the k-opt mutation [43] and edge assembly crossover [44] for the permutation-based solution representations in TSPs and vehicle routing problems (VRPs). In certain cases, one also needs to design repair operators [45] to ensure that the solutions found by EAs adhere to problem constraints, and regrouping operators [2] to maintain population diversity. Overall, the design of effective operators relies on a deep understanding of the problem of interest, which requires extensive domain expertise and human efforts [24].

## B. Large Language Models (LLMs) and Prompts

LLMs are large deep neural networks (often with billions of parameters) which are trained on vast amounts of text data to perform next-token prediction, i.e., predict the proceeding token given a sequence of tokens seen before. In the last two years, scaling up LLMs has yielded groundbreaking performance across a broad spectrum of tasks [29]-[33], [46][49]. Among them of particular interest are tasks involving reasoning and decision-making, such as planning [37], [50], [51] and solving mathematical problems [35], [36], [52]. Given the inherent inter-connections between optimization, reasoning, and decision-making, it is likely that LLMs could also demonstrate competence in optimization tasks, which is indeed one motivation behind this work.

A prompt is the instruction that guides LLMs into generating desired output. Although a prompt can be in various forms such as a question, a sentence, or a keyword,

```
Algorithm 1: LLM-driven EA (LMEA)
    Input: The optimization problem $T$, maximum
            number of generations $G$, population size $N$;
    Output: the best found solution $s^{*}$
    $P \leftarrow$ randomly initialize $N$ solutions to $T$;
    $g=1$;
    while $g \leq G$ do
        prompt $\leftarrow$ construct prompt based on $T$ and pop;
        $P^{\prime} \leftarrow$ instruct LLM with prompt to generate $N$
                offspring solutions;
        $P \leftarrow$ the top $N$ solutions among $P \cup P^{\prime}$;
        Self-adapt the temperature of LLM if necessary;
        $g \leftarrow g+1$;
    end
    $s^{*} \leftarrow$ the best solution in $P$;
    return $s^{*}$
```

there has been much evidence [34]-[36] showing that the prompt format can significantly influence the quality of the LLM's output. In general, when faced with a specific task, one needs to carefully craft the prompt to align with the desired outcome. This involves considering the context, the level of detail required, and the clarity of the instruction. Previous research has identified several effective techniques for prompting. For example, one can include several task examples as demonstrations in the prompt, i.e., in-context learning [53], and can explicitly instruct the LLM to think step by step, i.e., chain of thoughts [34]. In this work, to make LLMs function effectively as the operators of EAs, we carefully design a wellstructured prompt that consists of several parts including task descriptions, solution properties, population information, and operator instructions.

## C. Intersection between EAs and LLMs

Currently, research at the intersection of LLMs and EAs is still in its early stage. Due to the remarkable capabilities of LLMs in code generation, several recent works have attempted to combine LLMs with EAs to generate neural network structures [54], programs that fulfill specific functionalities [55], and meta-heuristics [56]. Furthermore, the core ideas of EAs, including natural selection and genetic variations, have also been employed to evolve prompts to enhance the performance of LLMs [57]. Regarding directly applying LLMs to solve optimization problems, there is very limited research. One such work is [58], which presents preliminary results of using LLMs for solving linear regression problems and TSPs. Another very recent work [59] incorporates LLMs as the mutation operator in continuous multi-objective optimization algorithm. However, the utilization of LLMs for evolutionary combinatorial optimization still remains unexplored.

## III. LMEA FOR COMBINATORIAL OPTIMIZATION

In this section, we first present the framework of LMEA, then delve into the construction of prompts to instruct the LLM, and finally describe the self-adaptation mechanism of the LLM's temperature. An overview of LMEA is also illustrated in Figure 1

## A. Algorithm Framework

As presented in Algorithm 1. LMEA follows the conventional EA framework [1]. Given an optimization problem $T$, LMEA first randomly generates $N$ solutions to form the initial population (line 1) and then proceeds with the evolutionary process (lines 3-9). In each generation, LMEA constructs a prompt (line 4) to guide LLM in selecting parent solutions from the current population and then conduct crossover and mutation based on them, generating $N$ offspring solutions (line 5). These $N$ solutions are then combined with the current population (line 6 ) and the top $N$ solutions are retained for the next generation (line 7). In addition, the LLM's temperature would be adjusted if necessary (see Section III-C). Finally, LMEA would terminate when the number of generations reaches a predefined number and the best found solution is returned (lines 10-11).

## B. LLMs as Evolutionary Optimizers

LMEA employs the LLM as evolutionary operators in a zero-shot manner. Specifically, the parent selection and genetic variations (crossover and mutation) are accomplished through the in-context learning process of the LLM [53], which is facilitated by carefully constructed prompts.

To be concrete, the prompt consists of three parts:

- Problem description and solution properties: this part includes the description of the optimization problem to be solved and specifications of the desired solution properties.
- In-context examples: some solutions to the optimization problem and their corresponding fitness are provided as demonstrations for the LLM. Typically, these solutions are derived from the current population.
- Task Instructions: this part provides explicit instructions for the LLM to perform parent selection and carry out crossover and mutation, generating new solutions.

Figure 1 illustrates an example of the constructed prompt when using LMEA to solve TSPs. The problem description contains the coordinates of the points in the TSP instance, while the solution properties specify the constraints that TSP solutions must meet (traversing each point exactly once) and that shorter lengths are preferable. In-context examples consist of TSP solutions from the current population and their corresponding lengths. Task Instructions guide the LLM in generating new TSP solutions.

It is important to note that, unlike the traditional practice of implementing evolutionary operators step-by-step through programming, LMEA does not instruct the LLM on how to precisely perform parent selection, crossover, and mutation. Instead, LMEA instructs the LLM at a higher level using natural language. This approach only requires minimal reliance on domain expertise. Finally, the prompt also strictly defines the format of the LLM's output to enable LMEA to interpret the output easily. For example, the results of parent selection

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-4.jpg?height=1054&width=1741&top_left_y=178&top_left_x=192)

Fig. 1. An overview of LMEA. The right half of this diagram demonstrates an example of the constructed prompt when utilizing LMEA to solve TSPs. The contents within " \{\} " in the prompt will be replaced with the corresponding input.

are enclosed between $<$ selection $>$ and $</$ selection $>$, and the generated solutions are enclosed between $<$ res $>$ and $</$ res $>$.

## C. Self-Adaptation of the LLM's Temperature

The temperature of LLMs, which is used in the sampling process when generating text, is a parameter that controls the randomness or entropy of the text [53]. A higher temperature value increases the randomness, while a lower value makes the model's output more deterministic.

From the perspective of search-based optimization, the temperature of LLMs can be understood as a parameter that controls the exploration in the search process. A higher temperature equips the LLM with stronger exploratory ability. Based on this, we propose a simple rule for adaptively adjusting the temperature: If LMEA fails to find a solution better than the current best for $K$ consecutive generations, the temperature value will be increased by $\alpha$. Typically, the default temperature of LLMs is 1.0 [53]; in this work, we always set $K=20$ and $\alpha=0.1$.

## IV. EXPERIMENTS

We investigate the power of LMEA on TSPs. Specifically, the experiments aim to address the two questions below ${ }^{1}$
- How good is LMEA's performance, especially compared to those traditional hand-designed heuristics?[^1]- Are LLM-driven genetic operators and the self-adaptation mechanism useful in improving the optimization performance?

## A. Test Problem Instances

We considered EUC-2D TSPs, where the nodes are defined on a two-dimensional plane and the distances between two nodes are the same in both directions. Specifically, two different types of TSP instances were generated through the generators which has been used to create testbeds for the 8 -th DIMACS Implementation Challenge $[60]^{2}$

- The portgen generator generates a TSP instance (called a rue instance) by uniformly and randomly placing nodes on a two-dimensional plane.
- The portcgen generator generates a TSP instance (called a clu instance) by randomly placing nodes around different central nodes.

For both types (rue and clu), the instances were generated such that both $x$ and $y$ coordinates of the nodes lie within $[0,100]$. For each instance type, we considered four different problem sizes (number of nodes, denoted as $n$ ), i.e., $n=10,15,20,25$. In summary, there were eight different combinations of instance types and problem sizes. We denote them as rue/clu-10/15/20/25, respectively, and for each of[^2]

TABLE I

TEST RESULTS ON EIGHT TEST SETS WITH DIFFERENT NUMBERS OF NODES ( $n=10,15,20,25)$ AND TSP TYPES (RUE AND CLU). EACH TEST SET CONTAINS 5 TSP INSTANCES, AND THE AVERAGE OPTIMALITY GAP $(\%) \pm$ STANDARD DEVIATION ACHIEVED ON THEM IS REPORTED. ON EACH TEST SET, THE BEST AVERAGE OPTIMALITY GAP IS INDICATED IN BOLD. "\# GENERATIONS" REPRESENTS THE MEAN $\pm$ STANDARD DEVIATION OF THE GENERATION NUMBERS THAT LMEA AND OPRO FINDS THE OPTIMAL SOLUTION. "\# SUCCESSES" COUNTS THE NUMBER OF TSP INSTANCES THAT LMEA AND OPRO FINDS THE OPTIMAL SOLUTION. "N/A" MEANS THAT NO OPTIMAL SOLUTION IS FOUND FOR ANY TSP INSTANCE IN THE TEST SET.

| Test set | Optimality gap $(\%)$ |  |  |  |  |  | \# Generations (\# Successes) |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | $\mathrm{NN}$ | FI | $\mathrm{NI}$ | $\mathrm{RI}$ | LMEA | OPRO | LMEA | OPRO |
| rue-10 | $11.22 \pm 3.35$ | $2.23 \pm 1.26$ | $0.58 \pm 0.58$ | $0.00 \pm 0.00$ | $0.00 \pm 0.00$ | $0.00 \pm 0.00$ | $35.80 \pm 7.17$ | $60.60 \pm 13.68$ |
| rue-15 | $9.84 \pm 3.34$ | $1.08 \pm 1.01$ | $0.79 \pm 0.79$ | $2.45 \pm 1.18$ | $0.06 \pm 0.06$ | $5.23 \pm 2.01$ | $235.25 \pm 6.12(4)$ | $189.00 \pm 0.00$ |
| rue-25 | $10.71 \pm 3.36$ | $2.33 \pm 1.34$ | $1.41 \pm \mathbf{0 . 7 2}$ | $2.41 \pm 0.74$ | $18.72 \pm 3.31$ | $53.59 \pm 8.37$ | N/A (0) | N/A (0) |
| clu-10 | $16.48 \pm 2.02$ | $1.28 \pm 0.79$ | $0.99 \pm 0.99$ | $1.37 \pm 0.84$ | $0.00 \pm 0.00$ | $0.00 \pm 0.00$ | $19.00 \pm 3.30$ | $90.40 \pm 16.55$ |
| clu-15 | $23.39 \pm 4.39$ | $\mathbf{0 . 0 0} \pm \mathbf{0 . 0 0}$ | $0.48 \pm 0.48$ | $0.08 \pm 0.08$ | $0.11 \pm 0.11$ | $8.13 \pm 4.83$ | $152.25 \pm 18.80$ | $153.00 \pm 0.00$ |

them, we generated five TSP instances. For all the 40 generated instances, Concorde [61], an exact TSP solver, was used to obtain their optimal solutions ${ }^{3}$

## B. Baseline Algorithms

We considered the following four traditional heuristics for solving TSPs as baseline algorithms 4

- Nearest neighbor (NN). This heuristic first randomly chooses a node which is the starting point of the tour. Then at each step, the next node is chosen as the one nearest to the last node of the tour and is appended to the tour as the new last node. This process finishes when the tour contains all the nodes.
- Farthest/nearest/random insertion (FI/NI/RI). The insertion heuristics minimize the cost of inserting a node into the tour. At each step, for each node $k$, its position of insertion is determined such that the cost $c(k)=$ $d_{i, k}+d_{k, j}-d_{i, j}$ is minimized, where $i$ and $j$ are adjacent nodes in the current tour and $d$ indicates the distance. The different variants of insertion heuristics differ in how the inserted node is selected. FI selects the node with the largest distance to any node of the tour. NI selects the node that is nearest to any node in the tour. RI selects a random node.

Additionally, we considered the very recent approach Optimization by PROmpting (OPRO) [58] as the baseline. OPRO is also driven by LLMs, but it differs from LMEA in that OPRO does not employ LLM to perform crossover and mutation. Instead, in each generation, OPRO directly instructs the LLM to generate $N$ new solutions based on the current population. Therefore, OPRO can be viewed as a variant of LMEA without LLM-driven genetic operators (crossover and mutation). The comparison between them can validate the effectiveness of LLM-driven genetic operators.

## C. Experimental Setup

To make a fair comparison, for LMEA and OPRO, the population size $N$ and maximum generation number $G$ were[^3]

TABLE II

COMPARISON OF LMEA AND ITS VARIANT WITHOUT SELF-ADAPTATION (LMEA*) ON THE RUE-20 TEST SET.

| Test set | Optimality gap (\%) |  |
| :---: | :---: | :---: |
|  | LMEA | LMEA* |
| rue-20 | $3.94 \pm 1.54$ | $11.82 \pm 2.21$ |

set the same, i.e., $N=16$ and $G=250$. For LMEA, we used the chat-turbo-0613 version of the GPT-3.5 API as the LLM $5^{5}$ On each test set, i.e., rue/clu-10/15/20/25, we executed each algorithm and reported its average optimality gap on the set. The optimality gap is defined as the difference between the length of the best solution found by the algorithm (denoted as $\operatorname{len}\left(s^{*}\right)$ ) and the length of the optimal solution (denoted as $o p t$ ), calculated using $\left(\operatorname{len}\left(s^{*}\right)-o p t\right) / o p t$.

## D. Results and Analysis

The test results are presented in Table I In addition to the optimality gap, the numbers of generations needed by LMEA and OPRO to find the optimal solutions are also reported.

First, it can be observed that on TSP instances with 10 nodes and 15 nodes, LMEA outperforms the heuristics on three out of four test sets, i.e., rue-10/15 and clu-10. Taking a closer look, on the rue/clu-10/15 test sets, it is interesting to find that LMEA consistently finds the optimal solution on 19 out of 20 instances. Considering the size of the solution space of a rue/clu-15 TSP instance is at least in the order of billions, LMEA can find the optimal solution to it within a total fitness evaluation number not exceeding $250 \times 16=4000$ (note that $G=250$ and $N=16$ ). This clearly shows that, despite its minimal reliance on domain expertise, LMEA has the capability to optimize non-trivial NP-hard combinatorial optimization problems like TSPs.

Second, on TSP instances with 20 nodes, LMEA performs slightly worse than the heuristics (except NN). As the node number increases further $(n=25)$, the optimality gap of[^4]

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=1578&width=1766&top_left_y=222&top_left_x=168)

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=285&width=374&top_left_y=237&top_left_x=195)

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=293&width=393&top_left_y=236&top_left_x=627)

(a) rue-10

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=298&width=829&top_left_y=637&top_left_x=190)

(c) rue-15
![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=298&width=826&top_left_y=1041&top_left_x=190)

(e) rue-20
![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=286&width=828&top_left_y=1450&top_left_x=188)

(g) rue-25

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=298&width=827&top_left_y=236&top_left_x=1083)

(b) clu-10
![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=296&width=822&top_left_y=638&top_left_x=1086)

(d) clu-15
![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=300&width=834&top_left_y=1039&top_left_x=1076)

(f) clu-20
![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-6.jpg?height=290&width=830&top_left_y=1446&top_left_x=1077)

(h) clu-25

Fig. 2. Convergence curves: optimality gaps achieved by LMEA and OPRO as generation number increases. For each test set, the left figure illustrates the average optimality of the population, and the right figure illustrates optimality gap of the best found solution

LMEA increases rapidly. Addressing the scalability limitations of LMEA is a crucial area for future research.

Finally, on all the eight test sets, LMEA outperforms OPRO, and the performance gap becomes larger as the node number increases. Figure 2 also illustrates the convergence curves of LMEA and OPRO on all the test sets. It can be observed that in general LMEA can find better solutions more quickly than OPRO. Since OPRO can be viewed as a variant of LMEA without LLM-driven crossover and mutation, these results have confirmed the effectiveness of the LLM-driven genetic operators.

## E. Effectiveness of Self-Adaptation

To validate the effectiveness of the self-adaptation of the LLM's temperature in LMEA, we tested a variant of LMEA without self-adaptation (LMEA*) on the rue-20 test set. The results are presented in Table II. The convergence curves of LMEA and LMEA* are also illustrated in Figure 3. It can be clearly observed that, LMEA can achieve significantly better optimality gaps than LMEA*. Moreover, based on Figure 3 . one can observe that even when the quality of the random initial solutions are worse than that of LMEA*, LMEA is still capable of finding better solutions more quickly. These results demonstrate the effectiveness of self-adaptation.

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-7.jpg?height=379&width=848&top_left_y=220&top_left_x=167)

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-7.jpg?height=301&width=395&top_left_y=234&top_left_x=171)

(a)

![](https://cdn.mathpix.com/cropped/2024_06_04_0e8df43edd8b1008a78cg-7.jpg?height=301&width=396&top_left_y=234&top_left_x=604)

(b)
Fig. 3. Convergence curves of LMEA and its variant without self-adaptation (LMEA*) on the rue-20 test set. (a) Optimality gap of the best found solution as the generation number increases. (b) Average optimality gap of the population as the generation number increases.

## V. DISCUSSIONS AND CONCLUSION

In this work, we explored on employing LLMs as evolutionary combinatorial optimizers, where the LLM repeatedly generates offspring solutions based on the current population. Our investigation demonstrates that LMEA has the capacity of solving non-trivial NP-hard combinatorial optimization problems such as TSPs. Nonetheless, there are many open questions that remain to be explored in future works.

- Improving the scalability of LMEA. Currently LMEA still has limitations in handling relatively large problems. One possible approach to improve the scalability of LMEA is to instruct it to only focus on improving the local parts of the solutions, rather than the whole solution.
- Learning lessons from unsuccessful solutions. Instructing LLMs to learn lessons from incorrect answers has been proven effective in improving their performance [62]. Hence, it is interesting to investigate how such a strategy can boost the performance of LMEA for solving optimization problems.
- Reducing the runtime and cost of LMEA. Currently, executing the full optimization process of LMEA on a small-scale problem is highly expensive and timeconsuming (around half a day) due to frequent interactions with ChatGPT's API. Future works can explore using smaller fine-tuned models for local execution to mitigate this issue.
- Leveraging state-of-the-art prompt engineering. Techniques like chain of thoughts [34] and selfconsistency [35] have the potential to enhance the performance of LMEA.
- Applying LMEA to other problems. It is always interesting to investigate how LMEA would perform on different combinatorial optimization problems.


## ACKNOWLEDGMENTS

This work is supported in part by the Centre for Frontier AI Research (CFAR), Agency for Science, Technology and Research (A*STAR), in part by the School of Computer Science and Engineering at Nanyang Technological University, and in part by the National Natural Science Foundation of
China under Grant 62272210. The research work is carried out in CFAR.

## REFERENCES

[1] J. H. Holland, "Genetic algorithms," Scientific american, vol. 267, no. 1, pp. 66-73, 1992.

[2] T. Vidal, T. G. Crainic, M. Gendreau, N. Lahrichi, and W. Rei, "A hybrid genetic algorithm for multidepot and periodic vehicle routing problems," Operations Research, vol. 60, no. 3, pp. 611-624, 2012.

[3] Ç. Koç, T. Bektaş, O. Jabali, and G. Laporte, "A hybrid evolutionary algorithm for heterogeneous fleet vehicle routing problems with time windows," Computers \& Operations Research, vol. 64, pp. 11-27, 2015

[4] Y. Qi, Z. Hou, H. Li, J. Huang, and X. Li, "A decomposition based memetic algorithm for multi-objective vehicle routing problem with time windows," Computers \& Operations Research, vol. 62, pp. 61-77, 2015.

[5] L. Feng, Y.-S. Ong, M.-H. Lim, and I. W. Tsang, "Memetic search with interdomain learning: A realization between CVRP and CARP," IEEE Transactions on Evolutionary Computation, vol. 19, no. 5, pp. 644-658, 2015.

[6] Z.-H. Zhan, X.-F. Liu, Y.-J. Gong, J. Zhang, H. S.-H. Chung, and Y. Li, "Cloud computing resource scheduling and a survey of its evolutionary approaches," ACM Computing Surveys, vol. 47, no. 4, pp. 1-33, 2015.

[7] C. Wang, H. Ma, G. Chen, and S. Hartmann, "Memetic eda-based approaches to qos-aware fully automated semantic web service composition," IEEE Transactions on Evolutionary Computation, vol. 26, no. 3, pp. 570-584, 2022.

[8] P. Yang, L. Zhang, H. Liu, and G. Li, "Reducing idleness in financial cloud services via multi-objective evolutionary reinforcement learning based load balancer," Science China Information Sciences, vol. 67, no. 2, p. 120102, 2024.

[9] Z. Pan, D. Lei, and L. Wang, "A knowledge-based two-population optimization algorithm for distributed energy-efficient parallel machines scheduling," IEEE transactions on cybernetics, vol. 52, no. 6, pp. 5051$5063,2022$.

[10] S. Zhou, L. Xing, X. Zheng, N. Du, L. Wang, and Q. Zhang, "A selfadaptive differential evolution algorithm for scheduling a single batchprocessing machine with arbitrary job sizes and release times," IEEE transactions on cybernetics, vol. 51, no. 3, pp. 1430-1442, 2019.

[11] F. Zhang, Y. Mei, S. Nguyen, and M. Zhang, "Multitask multiobjective genetic programming for automated scheduling heuristic learning in dynamic flexible job-shop scheduling," IEEE Transactions on Cybernetics, vol. 53, no. 7, pp. 4473-4486, 2023.

[12] S. Starke, N. Hendrich, and J. Zhang, "Memetic evolution for generic full-body inverse kinematics in robotics and animation," IEEE Transactions on Evolutionary Computation, vol. 23, no. 3, pp. 406-420, 2019.

[13] S. Liu, N. Lu, W. Hong, C. Qian, and K. Tang, "Effective and imperceptible adversarial textual attack via multi-objectivization," ACM Transactions on Evolutionay Learnning and Optimization, 2024, just Accepted.

[14] K. Tang and X. Yao, "Learn to optimize - A brief overview," National Science Review, p. nwae132, 042024.

[15] L. C. Bezerra, M. López-Ibánez, and T. Stützle, "Automatic componentwise design of multiobjective evolutionary algorithms," IEEE Transactions on Evolutionary Computation, vol. 20, no. 3, pp. 403-417, 2015.

[16] C. L. Camacho-Villalón, M. Dorigo, and T. Stützle, "Pso-x: A component-based framework for the automatic design of particle swarm optimization algorithms," IEEE Transactions on Evolutionary Computation, vol. 26, no. 3, pp. 402-416, 2021.

[17] L. Feng, Y. Huang, I. W. Tsang, A. Gupta, K. Tang, K. C. Tan, and Y.-S. Ong, "Towards faster vehicle routing by transferring knowledge from customer representation," IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 2, pp. 952-965, 2022.

[18] J. Lin, Z.-J. Wang, and X. Li, "A backtracking search hyper-heuristic for the distributed assembly flow-shop scheduling problem," Swarm and Evolutionary Computation, vol. 36, pp. 124-135, 2017.

[19] E. K. Burke, M. Gendreau, M. Hyde, G. Kendall, G. Ochoa, E. Özcan, and R. Qu, "Hyper-heuristics: A survey of the state of the art," Journal of the Operational Research Society, vol. 64, pp. 1695-1724, 2013.

[20] J. H. Drake, A. Kheiri, E. Özcan, and E. K. Burke, "Recent advances in selection hyper-heuristics," European Journal of Operational Research, vol. 285, no. 2, pp. 405-428, 2020.

[21] K. Zhao, S. Liu, J. X. Yu, and Y. Rong, "Towards feature-free tsp solver selection: A deep learning approach," in Proceedings of the 2021 International Joint Conference on Neural Networks, IJCNN'2021, Virtual Event, Jul 2021, pp. 1-8.

[22] O. Vinyals, M. Fortunato, and N. Jaitly, "Pointer networks," in Proceedings of Advances in Neural Information Processing Systems, NeurIPS'2015, 2015, pp. 2692-2700.

[23] Y. Bengio, A. Lodi, and A. Prouvost, "Machine learning for combinatorial optimization: a methodological tour d'horizon," European Journal of Operational Research, vol. 290, no. 2, pp. 405-421, 2021.

[24] S. Liu, Y. Zhang, K. Tang, and X. Yao, "How good is neural combinatorial optimization? a systematic evaluation on the traveling salesman problem," IEEE Computational Intelligence Magazine, vol. 18, no. 3, pp. 14-28, 2023.

[25] K. Smith-Miles and S. Bowly, "Generating new test instances by evolving in instance space," Computers \& Operations Research, vol. 63, pp. 102-113, 2015.

[26] K. Tang, S. Liu, P. Yang, and X. Yao, "Few-shots parallel algorithm portfolio construction via co-evolution," IEEE Transactions on Evolutionary Computation, vol. 25, no. 3, pp. 595-607, 2021.

[27] A. Biedenkapp, M. Lindauer, K. Eggensperger, F. Hutter, C. Fawcett, and H. H. Hoos, "Efficient parameter importance analysis via ablation with surrogates," in Proceedings of the 31st AAAI Conference on Artificial Intelligence, AAAI'2017, 2017, pp. 773-779.

[28] I. Bello, H. Pham, Q. V. Le, M. Norouzi, and S. Bengio, "Neural combinatorial optimization with reinforcement learning," arXiv preprint arXiv:1611.09940, 2016.

[29] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heintz, and D. Roth, "Recent advances in natural language processing via large pre-trained language models: A survey," ACM Computing Surveys, vol. 56, no. 2, pp. 1-40, 2023.

[30] P. Lee, S. Bubeck, and J. Petro, "Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine," New England Journal of Medicine, vol. 388, no. 13, pp. 1233-1239, 2023.

[31] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F. Tan, and D. S. W. Ting, "Large language models in medicine," Nature medicine, vol. 29, no. 8, pp. 1930-1940, 2023

[32] E. Kasneci, K. Seßler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer, U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier et al., "Chatgpt for good? on opportunities and challenges of large language models for education," Learning and individual differences, vol. 103, p. 102274, 2023

[33] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He, A. Li, M. He, Z. Liu et al., "Summary of chatgpt-related research and perspective towards the future of large language models," Meta-Radiology, p. $100017,2023$.

[34] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H. Chi, Q. V. Le, and D. Zhou, "Chain-of-thought prompting elicits reasoning in large language models," in Proceedings of Advances in Neural Information Processing Systems, NeurIPS'2022, 2022, pp. 24 824-24 837.

[35] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang, A. Chowdhery, and D. Zhou, "Self-consistency improves chain of thought reasoning in language models," in Proceedings of the 11th International Conference on Learning Representations, ICLR'2023, 2023

[36] D. Zhou, N. Schärli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet, Q. V. Le, and E. H. Chi, "Least-to-most prompting enables complex reasoning in large language models," in Proceedings of the 11th International Conference on Learning Representations, ICLR'2023, 2023.

[37] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, and Y. Cao, "React: Synergizing reasoning and acting in language models," in Proceedings of the 11th International Conference on Learning Representations, ICLR'2023, 2023.

[38] B. H. Korte, J. Vygen, B. Korte, and J. Vygen, Combinatorial optimization. Springer, 2011, vol. 1.

[39] D. S. Hochba, "Approximation algorithms for np-hard problems," ACM Sigact News, vol. 28, no. 2, pp. 40-52, 1997.

[40] E. L. Lawler and D. E. Wood, "Branch-and-bound methods: A survey," Operations research, vol. 14, no. 4, pp. 699-719, 1966.

[41] A. Chaabani, S. Bechikh, and L. B. Said, "A new co-evolutionary decomposition-based algorithm for bi-level combinatorial optimization," Applied Intelligence, vol. 48, pp. 2847-2872, 2018.
[42] A. J. Umbarkar and P. D. Sheth, "Crossover operators in genetic algorithms: a review." ICTACT journal on soft computing, vol. 6, no. 1, 2015.

[43] K. Helsgaun, "General k-opt submoves for the lin-kernighan tsp heuristic," Mathematical Programming Computation, vol. 1, pp. 119-163, 2009.

[44] Y. Nagata and S. Kobayashi, "A powerful genetic algorithm using edge assembly crossover for the traveling salesman problem," INFORMS Journal on Computing, vol. 25, no. 2, pp. 346-363, 2013.

[45] S. Salcedo-Sanz, "A survey of repair methods used as constraint handling techniques in evolutionary algorithms," Computer science review, vol. 3, no. 3, pp. 175-192, 2009

[46] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong et al., "A survey of large language models," arXiv preprint arXiv:2303.18223, 2023.

[47] H. Tian, W. Lu, T. O. Li, X. Tang, S.-C. Cheung, J. Klein, and T. F. Bissyandé, "Is chatgpt the ultimate programming assistant-how far is it?" arXiv preprint arXiv:2304.11938, 2023

[48] J. Blocklove, S. Garg, R. Karri, and H. Pearce, "Chip-chat: Challenges and opportunities in conversational hardware design," arXiv preprint arXiv:2305.13243, 2023

[49] M. Zheng, X. Su, S. You, F. Wang, C. Qian, C. Xu, and S. Albanie, "Can gpt-4 perform neural architecture search?" arXiv preprint arXiv:2304.10970, 2023.

[50] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents," in Proceedings of the International Conference on Machine Learning, ICML'2022, 2022, pp. 9118-9147.

[51] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin, E. Zhou et al., "The rise and potential of large language model based agents: A survey," arXiv preprint arXiv:2309.07864, 2023.

[52] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, Y. Wu, B. Neyshabur, G. Gur-Ari, and V. Misra, "Solving quantitative reasoning problems with language models," in Proceedings of Advances in Neural Information Processing Systems, NeurIPS'2022, 2022, pp. 3843-3857.

[53] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. HerbertVoss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, "Language models are few-shot learners," in Proceedings of the Advances in Neural Information Processing Systems, NeurIPS'2020, 2020, pp. 1877-1901.

[54] A. Chen, D. M. Dohan, and D. R. So, "Evoprompting: Language models for code-level neural architecture search," arXiv preprint arXiv: 2302.14838, 2023.

[55] J. Lehman, J. Gordon, S. Jain, K. Ndousse, C. Yeh, and K. O. Stanley, "Evolution through large models," arXiv preprint arXiv: 2206.08896, 2022.

[56] M. Pluhacek, A. Kazikova, T. Kadavy, A. Viktorin, and R. Senkerik, "Leveraging large language models for the generation of novel metaheuristic optimization algorithms," in Companion Proceedings of the 2023 Conference on Genetic and Evolutionary Computation, GECCO'2023, S. Silva and L. Paquete, Eds., 2023, pp. 1812-1820.

[57] Q. Guo, R. Wang, J. Guo, B. Li, K. Song, X. Tan, G. Liu, J. Bian, and Y. Yang, "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers," arXiv preprint arXiv: $2309.08532,2023$.

[58] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen, "Large language models as optimizers," arXiv preprint arXiv. 2309.03409, 2023.

[59] F. Liu, X. Lin, Z. Wang, S. Yao, X. Tong, M. Yuan, and Q. Zhang, "Large language model for multi-objective evolutionary optimization," arXiv preprint arXiv: $2310.12541,2023$.

[60] G. Gutin and A. P. Punnen, The traveling salesman problem and its variations. Springer Science \& Business Media, 2006, vol. 12.

[61] D. Applegate, R. Bixby, V. Chvatal, and W. Cook, "Concorde tsp solver," 2006.

[62] N. Shinn, B. Labash, and A. Gopinath, "Reflexion: an autonomous agent with dynamic memory and self-reflection," arXiv preprint arXiv:2303.11366, 2023.


[^0]:    Correspondence to asysong @ntu.edu.sg

[^1]:    ${ }^{1}$ Code and dataset is available at https://github.com/cschen1205/LMEA

[^2]:    ${ }^{2}$ Generators available at: http://dimacs.rutgers.edu/archive/Challenges/TSP

[^3]:    ${ }^{3}$ Concorde available at https://www.math.uwaterloo.ca/tsp/concorde.html

    ${ }^{4}$ Implementations available at https://github.com/Valdecy/pyCombinatorial

[^4]:    ${ }^{5}$ Details of the API available at: https://platform.openai.com/

