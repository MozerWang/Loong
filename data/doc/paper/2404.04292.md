# Conversational Disease Diagnosis via External Planner-Controlled Large Language Models 

Zhoujian Sun ${ }^{1}$, Cheng Luo ${ }^{1}$, Ziyi Liu ${ }^{2}$, Zhengxing Huang ${ }^{3}$<br>${ }^{1}$ Zhejiang Lab, ${ }^{2}$ Transtek Medical Electronic, ${ }^{3}$ Zhejiang University<br>sunzj@zhejianglab.com, zhengxinghuang@zju.edu.cn


#### Abstract

The development of large language models (LLMs) has brought unprecedented possibilities for artificial intelligence (AI) based medical diagnosis. However, the application perspective of LLMs in real diagnostic scenarios is still unclear because they are not adept at collecting patient data proactively. This study presents a LLM-based diagnostic system that enhances planning capabilities by emulating doctors. Our system involves two external planners to handle planning tasks. The first planner employs a reinforcement learning approach to formulate disease screening questions and conduct initial diagnoses. The second planner uses LLMs to parse medical guidelines and conduct differential diagnoses. By utilizing real patient electronic medical record data, we constructed simulated dialogues between virtual patients and doctors and evaluated the diagnostic abilities of our system. We demonstrated that our system obtained impressive performance in both disease screening and differential diagnoses tasks. This research represents a step towards more seamlessly integrating AI into clinical settings, potentially enhancing the accuracy and accessibility of medical diagnostics.


## 1 Introduction

Enabling artificial intelligence (AI) to diagnose disease has been a long-awaited goal since the concept of medical AI emerged [1]. The development of large language models (LLMs) brings unprecedented opportunities in AI-based diagnosis. Notably, Med-Palm 2 and GPT-4 Turbo have attained high scores on the United States Medical Licensing Examination [2, 3]. Recent research also illustrates that LLMs may perform as well as human doctors in many disease diagnostic tasks [4, 5, 6, 7].

Nonetheless, most LLMs are not adept at collecting patient data, which limits their application perspective. Almost all existing LLM-based studies formulate diagnosis as a question-answer task where LLMs are endowed with all necessary information to answer the diagnostic question [4, 5, 6, 8, 9]. In real diagnosis scenarios, doctors initially have no knowledge about the patient's condition, and patients also cannot comprehensively describe their own conditions. Distinguishing which information is useful and knowing when to collect the information are core skills of a doctor [10]. If a LLM requires a doctor to collect all important information in advance to make a diagnosis, its practical value is quite doubtful, because the doctor usually already knows what disease the patient has when all information is collected. LLM-based diagnostic systems should be capable of collecting information from scratch and then proceeding to diagnosis. This demands that LLM-based diagnostic systems possess excellent planning abilities to proactively ask dozens of appropriate questions through interactions with patients. Most current LLMs lack such planning capabilities. For example, a recent study demonstrated that GPT-4 could achieve high diagnostic accuracy, ranging from $70 \%$ to $90 \%$, when provided with complete patient information for diagnosing skin diseases. However, its accuracy can drop to $30 \%$ to $60 \%$ when it must diagnose starting from scratch [11].

![](https://cdn.mathpix.com/cropped/2024_06_04_538708f7f6d3225d9589g-02.jpg?height=385&width=1097&top_left_y=236&top_left_x=514)

Figure 1: System Overview

In this study, we aim to develop a LLM based diagnostic system that enhances planning capabilities by emulating doctors. Previous research suggests that medical consultations can roughly be divided into two distinct phases [12]. In the first phase, which we call disease screening phase, doctors ask patients a series of questions mainly about their medical history and infer possible diseases based on the responses. This stage relies heavily on doctor's experience. In the second phase, which we call differential diagnosis phase, doctors ask questions to confirm or exclude the diseases suspected in the first phase. The questions asked during the differential diagnosis phase include the patient's laboratory test and medical examination results. This phase relies on objective medical knowledge. Due to the substantial differences between these two phases, we clearly need to develop two different planners when emulating doctors. The first should be data-driven, learning from extensive data on how to conduct consultations, while the second should be knowledge-driven, adhering strictly to medical knowledge and being interpretable.

We primarily face two challenges in implementing the two planners. (1) Real medical consultation dialogue datasets are scarce, which hampers the training of the first planner in a supervised manner. (2) Developing a decision procedure that adheres to medical literature typically requires expert involvement, making the second planner expensive and hard to maintain [13]. In this study, we adopted a reinforcement learning ( $\mathrm{RL}$ ) approach to facilitate the autonomous training of the first planner without the need for expert demonstrations. We used LLMs to analyze patient admission records, identifying each symptom's presence or absence. Subsequently, we utilized a RL method to train the inquiry policy based on the structurized patient symptoms. Following this, we employed a neural network to predict high-risk diseases based on the outcomes of the inquiries. The decision procedure for diagnosing or ruling out diseases is implicitly recorded in medical literature in the form of natural text. Since leading LLMs have achieved capabilities nearly equivalent to junior doctors in natural language processing and medical knowledge, we attempt to summarize decision procedures by directly employing LLMs [14, 3]. Additionally, we have designed a method that allows non-medical experts to refine these decision procedures, thereby reducing reliance on experts.

We evaluated this study through retrospective simulated dialogues. We implemented a simulated doctor comprised of two planners and one LLM (Figure 1). Planners are responsible for determining actions for each round, while the LLM handles the conversion of these actions into natural language and also parses responses into a format readable by the planners. We utilized another LLM to read real electronic medical record (EMR) data, simulating a patient who would respond to any questions posed by the simulated doctor. The simulated doctor was designed to ask a series of questions to diagnose the patient's illness. We conducted tests using the MIMIC-IV dataset [15]. The results show that our planners, controlling the LLM, achieved impressive performance in both phases. We contend that the proposed diagnostic system has the potential to enhance diagnostic precision and accessibility. All source code and data are public available $\square^{1}$

## 2 Related Work

Recent research has illustrated the capabilities of LLMs in aiding disease diagnosis [16, 5, 4, 8]. They use pre-collected patient information to conduct diagnosis. However, a LLM-based diagnostic system should prioritize and emphasize the capability to ask the right questions for information collection in multi-turn dialogue [10]. Existing research seldom explores the multi-turn diagnostic capabilities of[^0]

![](https://cdn.mathpix.com/cropped/2024_06_04_538708f7f6d3225d9589g-03.jpg?height=908&width=1317&top_left_y=234&top_left_x=404)

Figure 2: Diagnosis Screening Planner Optimizing

LLMs, and those that do usually only investigated LLMs' planning abilities in fewer than five rounds of free dialogue, which is far from sufficient to complete diagnostic tasks [17]. To our knowledge, the AMIE model is the only LLM trained to improve the medical information-gathering ability [7]. This model has two limitations. Firstly, it relies solely on patient self-reported symptoms for diagnosis, without incorporating data from medical laboratory tests or imaging reports. Since the symptoms of many diseases overlap, relying solely on symptoms for an accurate diagnosis is not only dangerous but also impractical. Secondly, the AMIE model is trained via a LLM-generated synthetic dialogue dataset. Without concrete evidence demonstrating that LLMs can match the efficacy of experts in medical consultations, the soundness of this approach is questionable.

Before the advent of LLMs, several diagnostic-oriented dialogue systems had been proposed 18,19 , 20, 21]. However, their datasets are originated from online consultations, and the data quality was often questioned. In the past two years, research in various fields has explored ways to make LLMs proactively guide conversations and complete tasks. Most studies use prompt engineering, while some enhance LLMs' planning ability with external planners [22, 23, 24]. However, these methods cannot be utilized in medicine because they still rely on public, high-quality, human annotated dialogue datasets, which in fact do not exist in the medical field. In this study, we will develop a dialogue system without using high-quality medical dialogue data.

LLM-based autonomous agent tackles complex tasks by decomposing them into simpler sub-tasks, addressing each one sequentially. Most research in this area utilizes prompt engineering tricks, e.g., chain of thought, to activate LLM's planning capabilities [25]. However, an autonomous agent typically does not require interaction with the user during the task completion process [26]. In contrast, our system needs to dynamically generate a plan based on the patient's responses.

## 3 Method

### 3.1 Disease Screening Planner

Doctors are required to obtain important information from patients in medical consultations to formulate initial diagnoses, which includes their chief complaints (CC), history of present illness (HPI), past medical history, family history, social history, etc [27]. HPI and CC are usually regarded as
the most critical information, as they form the basis for at most $80 \%$ of patient diagnoses [28]. Despite its importance, collecting HPI and CC is challenging because patients usually cannot comprehensively report their symptoms [10]. As patients may exhibit a subset of hundreds of possible symptoms, it is also impractical to exhaustively query every potential symptom. Doctors need to identify positive symptoms via their own experience with only several questions, thereby facilitating the formulation of a comparatively accurate diagnosis.

We employed an RL approach to train a policy model to ask questions and a supervised learning based screening model to conduct initial diagnosis (Figure 2). We use $h$ to denote the past medical history, family history, and social history of a patient. As $h$ can typically be acquired through straightforward questioning, our study will not focus on collecting such information [27]. We presume $h$ is textual and already known and its embedding is $e_{h}$. We use a planner to ask $N$ questions about patient symptoms in the RL paradigm.

State Space: The state $s_{t}=\left[e_{h}, p_{t}\right]$ is the concatenation of two elements. The first part is $e_{h}$, which is invariable in an episode. $p_{t} \in\{0,1\}^{3 M}$ represents structured HPI and CC, where $M$ denotes the number of symptoms. Each symptom information is presented by a binary triplet, while $[0,0,1],[0,1,0],[1,0,0]$ means the symptom is unknown, confirmed, or denied, respectively. At the beginning, all symptoms are unknown, and their status is updated with every interaction.

Action Space: The action space contains $M(N \ll M)$ actions, where each question asks whether a related symptom is present in the next turn. We presume that there is a two-layer structure within the action space. The first layer refers to general symptoms (such as chest pain), while the secondary layer denotes more specific symptoms (such as chest pain accompanied by fever). Each second-layer symptom is affiliated with a first-layer symptom. We stipulate that the model can only inquire about second-layer symptoms after the patient acknowledges the affiliated first-layer symptoms. Meanwhile, we do not allow the planner to ask the same question twice.

Reward: We set the reward $R_{t}$ to one if the asked symptom exists, and to zero if the asked symptom is denied or not mentioned.

Patient Agent: We use admission records from patient EMRs to construct the patient agent. We first separated an admission record into $h$, HPI, and CC. Then, we structured the textual CC and HPI. Specifically, we utilized a LLM to determine whether patients had a symptom, and ultimately transformed the CC and HPI into a $M$-dimensional binary vector $p^{\text {oracle }}$. Each symptom is represented by one if it is confirmed, or zero if it is denied or not mentioned. A $h$ and a $p^{\text {oracle }}$ formulate a sample. When an agent receives a query from the planner, it can response the answer directly.

Policy Model Learning: We used an actor-critic model to generate the policy $\pi_{t} \in \mathbf{R}^{M}$, which is a stochastic vector, and the value $Q_{t} \in \mathbf{R}$ [29]. Each element in $\pi_{t}$ corresponds to an query action. The value of an element indicates the probability of the policy model selecting the corresponding action. We utilize a multi-layer perceptron (MLP) to learn a representation $r_{t}$ from $s_{t}$ and then use two MLPs to generate $\pi_{t}$ and $Q_{t}$ according to $r_{t}$, respectively. We adopted the proximal policy optimization (PPO) algorithm to train policy [30, 31]. In this study, we preset a maximum number of inquiry rounds, and the PPO will train the RL agent to obtain the maximum reward within these rounds. To improve effectiveness, we assume that the patient agent will proactively disclose one first layer symptom to the RL agent before the first question. Given that patients typically start by describing their areas of discomfort in real medical consultations, we believe this design is justified.

Screening Model Learning: After the policy model is optimized, we will use the final state of episodes to predict the initial diagnosis. As the patient discharge diagnosis is recorded in the EMR, we use a supervised learning method, i.e., MLP, to train the screening classifier.

### 3.2 Differential Diagnosis Planner

The differential diagnosis planner consists of a set of decision procedures, each corresponding to the diagnostic process for a specific disease. We use a LLM to transform medical literature and generate a preliminary structured decision procedure (Figure 3). The planner will parse the procedure and conduct inquiries according to the procedure. The effectiveness of the procedure is then tested in simulated diagnosis dialogues where one LLM with the external planner acts as a doctor and another as a patient, using complete discharge EMR for the patient role. In the simulated interaction, the doctor asks questions based on the decision procedure, and the patient responds based on the EMR

![](https://cdn.mathpix.com/cropped/2024_06_04_538708f7f6d3225d9589g-05.jpg?height=792&width=1298&top_left_y=252&top_left_x=403)

Figure 3: Differential Diagnosis Planner Optimizing

contents. If the EMR does not contain the answer to a question, the patient simulator will indicate that the inquired physical condition is normal. Finally, the doctor simulator concludes with either a confirmed or excluded diagnosis. This outcome is then compared with the actual patient discharge diagnosis to identify any inaccuracies, creating a set of dialogues with incorrect conclusions. These results are analyzed to pinpoint which steps in the procedure led to incorrect diagnoses. According to the analyze result, the procedure undergoes refinement through revisions to its content. The refined decision procedure is then retested and improved iteratively. In this study, the refinement process was completed by a data scientist who does not hold a medical license.

### 3.3 Simulated Dialogues

We conducted retrospective simulated conversations between a doctor simulator and a patient simulator to evaluate the diagnostic performance of our system.

Patient Simulator: We used a LLM to act as a patient. During the disease screening phase, we submitted a patient admission record to the LLM and instructed the LLM to answer questions based on the provided information (prompt is in appendix E.2). This simulation method is widely used in previous studies [7,11]. During the differential diagnosis phase, we submitted the entire EMR data, including laboratory tests and exam reports, as context to respond to the doctor simulator's inquiries.

Doctor Simulator: We employed a LLM controlled by two planners to serve as a doctor in the disease screening phase and the differential diagnosis phase. The planners are responsible for generating questions or conducting diagnoses. The LLM is tasked with translating the questions generated by the two planners into plain language. It also interprets the patient's utterances and categorizes them into a format that the planners can process.

## 4 Experiment

### 4.1 Dataset and Preprocessing

We utilized textual clinical notes from the MIMIC-IV dataset to conduct experiments [15]. The MIMIC-IV contains EMRs for approximately 400,000 admissions to the intensive care unit (ICU) at Beth Israel Deaconess Medical Center in the USA between 2008 and 2019 (a sample is in appendix F. We identified the 98 most common diseases from MIMIC-IV (happened larger than 200 times), excluding injuries from accidents and mental illnesses (disease list is in appendix G). We randomly
selected 40,000 admissions with textual clinical notes from patients whose primary diagnosis (the first diagnosis in the discharge diagnoses) was among these 98 diseases. The reserved clinical notes contain 2,394 words in average, including admission records, discharge summaries, laboratory test results, imaging examinations reports, etc.

The symptom checker developed by the Mayo Clinic was utilized to structure HPI and CC [32]. This symptom checker categorizes common symptoms of patients into 28 first-layer categories and 689 second-layer symptoms. Each second layer symptom is associated with one of the first-layer categories. We used GPT-4 Turbo (1106 preview) to analyze the presence of these 717 symptoms (28+ 689) in each patient's HPI and CC information, thereby converting the textual admission EMR into a 717-dimensional binary vector (prompt in appendix E.1). We transformed the selected 40,000 clinical notes into binary vectors. After the transformation, we randomly selected 400 medical records for evaluation. The results show that GPT-4 Turbo's parsing performance is satisfactory, with both macro recall and macro precision are around $97 \%$, making it is suitable for constructing patient simulators for the development of the disease screening planner.

### 4.2 Experimental Settings

Foundation Models: We used Microsoft Azure GPT-4 Turbo (04-09), GPT-4o (05-13), and Llama3 (70B-instruct) as foundation models of doctor simulators [33, 14, 34]. We used GPT-4 Turbo (04-09) as the foundation model of patient simulators. GPT-4 Turbo and GPT-4o were chosen because they are two of the best LLMs. Llama3 was selected because it is a leading open-source LLM. Of note, transferring medical data outside hospitals often breaches data protection regulations, which means all closed LLMs (e.g., GPT-4o, Gemini-1.5 Pro , Claude-3 Opus) are actually unavailable in practice as they only operate through remote API [35]. We need to ensure our system retains good diagnostic capabilities only with an open-source LLM which can be locally deployed.

Disease Screening Settings: We divided the structured data of 40,000 patients' HPI and CC into three parts for training, validation, and testing, with proportions of $0.7,0.1$, and 0.2 , respectively. All past medical history, social history, and family history information were directly provided, and we used a text embedding model to generate their embeddings [36]. We configured the system to have the patient initially report one positive first-layer symptom to the planner, who can then ask additional 9 or 19 questions. The planner also trains a high-risk disease screening model based on the collected patient information and their primary discharge diagnosis. We used the planner to control a LLM to conduct 300 simulated conversations and evaluate performances.

Differential Diagnosis Settings: We used heart failure as a case to test the planner's ability to make differential diagnoses. Heart failure is the most common disease in the MIMIC-IV dataset and one of the most complex common cardiovascular diseases [37]. We argue if our system can accurately diagnose heart failure, it may also be capable of diagnosing most other diseases. In this study, we used the heart failure diagnostic guideline published by the European society of cardiology as the source of diagnostic knowledge [38]. We randomly selected 160 positive patients (i.e., primary diagnosis is heart failure) and 160 negative patients (i.e., heart failure is not in the discharge diagnosis) from the MIMIC-IV dataset. We randomly selected 120 records (with a $1: 1$ ratio of negative to positive) as the training set for the generation of the decision procedure and 200 records for testing the decision procedure. We used the GPT-4 Turbo ( 0125 preview) and the guideline to generate a preliminary decision procedure (prompt in appendix E.5, result in appendix D.1). Subsequently, we selected 40 samples from the training set for each round of simulated dialogue experiment. We summarized the incorrect diagnoses, had a non-expert review the causes of the errors, and modified the procedure based on the analysis results. This modification process was repeated three times. Finally, we conducted simulated diagnoses on the test data via the refined decision procedure (appendix D.2).

Metrics: We evaluated performances through simulated dialogues between patients and doctors. During the disease screening phase, we assess the system using the Top-N hit rate of the real primary diagnosis in the ranking. For example, a Top 3 Hit rate of 0.50 means that in $50 \%$ of test cases, the true primary discharge diagnosis appears within the top three predictions generated by the disease screening planner. In the differential diagnosis phase, the system can ask up to 20 questions. If the system provides a diagnosis within these 20 questions, the conversation is considered successful. Otherwise, it is deemed a failure, and the corresponding case is treated as a negative sample. We evaluated the differential diagnosis performance via accuracy, precision, recall, and F1 score.

Table 1: Disease Screening Performance

| EP | \# Question | LLM | \# Sample | Top 1 | Top 3 | Top 5 | Top 10 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| No | 10 | GPT-4 Turbo 04-09 | 300 | 0.273 | 0.510 | 0.597 | 0.717 |
| Yes | 10 | GPT-4 Turbo 04-09 | 300 | $\mathbf{0 . 3 3 0}$ | $\mathbf{0 . 5 5 0}$ | $\mathbf{0 . 6 3 7}$ | $\mathbf{0 . 7 7 0}$ |
| No | 10 | Llama3-70B-Instruct | 300 | 0.240 | 0.423 | 0.483 | 0.583 |
| Yes | 10 | Llama3-70B-Instruct | 300 | 0.303 | 0.477 | 0.603 | 0.737 |
| No | 20 | GPT-4 Turbo 04-09 | 300 | 0.310 | 0.523 | 0.590 | 0.727 |
| Yes | 20 | GPT-4 Turbo 04-09 | 300 | 0.310 | 0.527 | 0.610 | 0.753 |
| No | 20 | Llama3-70B-Instruct | 300 | 0.200 | 0.387 | 0.470 | 0.607 |
| Yes | 20 | Llama3-70B-Instruct | 300 | 0.317 | 0.493 | 0.603 | 0.747 |
| No | 10 | GPT-4 Turbo 04-09 | 1000 | 0.279 | 0.507 | 0.597 | 0.714 |
| Yes | 10 | GPT-4 Turbo 04-09 | 1000 | 0.325 | 0.544 | 0.633 | 0.772 |

EP (external planner) set to "yes" means the LLM is controlled by an external planner and "no" means it operates independently, whose prompts are in appendix E. 3 The number of questions is ten (20) because the external planner starts with one symptom and proactively asks nine (19) additional questions.

Table 2: Differential Diagnosis Performance

| EK | LLM | Success Rate | Accuracy | Precision | Recall | F1 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| None | GPT-4 Turbo 04-09 | $86 \%$ | $86 \%$ | $80 \%$ | $95 \%$ | $87 \%$ |
| Text | GPT-4 Turbo 04-09 | $98 \%$ | $73 \%$ | $65 \%$ | $\mathbf{1 0 0 \%}$ | $79 \%$ |
| EP | GPT-4 Turbo 04-09 | $\mathbf{1 0 0 \%}$ | $82 \%$ | $86 \%$ | $76 \%$ | $80 \%$ |
| EP+HF | GPT-4 Turbo 04-09 | $\mathbf{1 0 0 \%}$ | $\mathbf{9 1 \%}$ | $\mathbf{8 9 \%}$ | $\mathbf{9 2 \%}$ | $\mathbf{9 1 \%}$ |
| None | Llama3-70B-Instruct | $0 \%$ | $50 \%$ | $0 \%$ | $0 \%$ | NA |
| Text | Llama3-70B-Instruct | $15 \%$ | $63 \%$ | $\mathbf{9 6 \%}$ | $26 \%$ | $41 \%$ |
| EP | Llama3-70B-Instruct | $\mathbf{1 0 0 \%}$ | $85 \%$ | $\mathbf{9 6} \%$ | $73 \%$ | $83 \%$ |
| EP+HF | Llama3-70B-Instruct | $\mathbf{1 0 0 \%}$ | $\mathbf{9 1} \%$ | $91 \%$ | $\mathbf{9 0 \%}$ | $\mathbf{9 0 \%}$ |

EK (external knowledge) column indicates the method of utilizing knowledge. "None" means no external knowledge is used; "text" uses diagnosis related text from the clinical guideline; "EP" employs a diagnostic procedure directly generated by the LLM into the external planner; "EP+HF" involves a human-corrected diagnostic procedure. Prompts of these experiments are recorded in appendix E. 4 .

### 4.3 Disease Screening Performance

Table 1 provides a comparison of disease screening performance. We found that system's performance is similar when randomly selecting either 1000 or 300 cases. Thus, we argue that using 300 simulated dialogues is sufficient to evaluate our system's performance effectively. Incorporating an external planner (EP) significantly improves the system's disease screening capability. For example, without the EP, GPT-4 Turbo achieves a Top 1 Hit rate of 0.273 , which increases to 0.330 under the guidance of the EP. In the absence of the EP, Llama3 significantly underperforms compared to GPT-4 Turbo, but the performance of Llama3 with the EP surpasses GPT-4 Turbo's without the EP. Meanwhile, we found simply asking more questions does not necessarily lead to better performance. For instance, when asking 20 questions, Llama3's performance significantly decreases, whereas GPT-4 Turbo only sees a significant improvement in its Top 1 Hit rate, with other metrics barely changing. This illustrates the inherent limitations in the planning capabilities of LLMs. Interestingly, even with the use of the EP, posing more questions does not yield performance improvements either. We delved deeper into the experimental results and investigated whether the performance improvement from the EP is due to its superior planning ability in the appendix Be also reported disease screening performance of the GPT-4o in the appendix A.1

### 4.4 Differential Performance

We conducted differential diagnosis tests based on simulated dialogues using the decision procedure (results in Table 2). Llama3's success rate in dialogues is $0 \%$ without external knowledge, indicating it doesn't know when to end a dialogue. Although GPT-4 Turbo significantly outperforms Llama3, it still experiences a $14 \%$ failure rate in dialogues. By incorporating textual form knowledge, the performance of Llama3 significantly improved, with its F1 score increasing from NA to $41 \%$. The

The patient proactively informed the system their past medical history, family history, social history, and they are having shortness of breathing at the beginning. The primary discharge diagnosis is heart failure.

Disease Screening Phase

Round 1

"Doctor": "Do you experience shortness of breath after light to moderate exercise?",

"Patient": "Yes.",

Round 2

"Doctor": "Have you recently developed shortness of breath?",

"Patient": "Yes.",

Round 3

"Doctor": "Do you have a cough?",

"Patient": "No, I do not have a cough.",

Round 4

"Doctor": "Do you feel nauseous or like vomiting?",

"Patient": "No, I do not feel nauseous or like vomiting.",

Round 5

"Doctor": "Do you have abdominal pain?",

"Patient": "No, I do not have abdominal pain.", Round 6

"Doctor": "Do you have diarrhea?",

"Patient": "No, I do not have diarrhea.",

Round 7

"Doctor": "Do you have swelling in your feet or limbs?",

"Patient": "Yes, I have mild swelling of my lower extremities at the end of the day.",

Round 8

"Doctor": "Could you clarify if the swelling in your foot or leg is associated with any pain or redness?",

"Patient": "No, the swelling in my foot or leg is not associated with any pain or redness.",

Round 9

"Doctor": "Is the swelling occurring around your ankle or foot?",

"Patient": "Yes.",

Round 10

"Doctor": "You are in risk of heart failure, pulmonary embolism, pneumonia ..."

![](https://cdn.mathpix.com/cropped/2024_06_04_538708f7f6d3225d9589g-08.jpg?height=1326&width=718&top_left_y=340&top_left_x=1018)

Figure 4: Conversational Diagnosis Sample

performance of GPT-4 Turbo actually decreased, indicating potential knowledge conflicts. Employing decision procedures has proven effective. However, the procedure directly extracted by the LLM is flawed, leading to low recall. This issue can be alleviated with non-expert human feedback (HF). The study demonstrates that the human refinement to the decision procedure improves the system's performance. GPT-4 Turbo's success rate, accuracy and F1 scores can increase from $86 \%, 86 \%$ and $87 \%$ to $100 \%, 91 \%$ and $91 \%$, respectively. The improvement is even more pronounced when using Llama3 as the foundation model, with the success rate soaring from $15 \%$ to $100 \%$, and both accuracy and F1 scores escalating from $63 \%$ and $41 \%$ to $91 \%$ and $90 \%$, respectively. This enhancement elevates the performance of open-source LLMs from unusable to fundamentally usable. We also reported differential diagnosis performance of GPT-4o in the appendix A. 2

In appendix C, we conducted an error analysis to explore why our system still produces incorrect diagnoses in approximately $10 \%$ of cases and more false negative errors compared to GPT-4 Turbo. The analysis shows that most of the false negative errors in our system originate from data quality issues, while most of the false positive errors stem from misdiagnosing patients in the pre-clinical phase. We investigated the performance of using a LLM to review dialogue results and then directly making diagnoses in the appendix as well.

### 4.5 Dialogue Sample

Figure 4 illustrates a case in which the simulated patient initially informs the system (GPT-4 Turbo 04-09 as the foundation model) of their past medical history, family history, social history, and that they are experiencing difficulty breathing. The simulated doctor then conducted 17 dialogue rounds. According to the first ten rounds, the simulated doctor inferred that heart failure was a high-risk disease by asking about patient symptoms. Subsequently, the simulated doctor confirmed that the patient had heart failure by using the decision procedure extracted from the clinical guideline and refined by human. It is worth noting that since this study is retrospective, simulated patients possess all the information needed for a diagnosis. They just do not proactively disclose this information. In real prospective diagnostic scenarios, patients may not know the answers to the simulated doctor's questions either. Asking appropriate questions means the simulated doctor can issue appropriate prescriptions for the patients to undergo tests to obtain necessary information.

## 5 Discussion and Conclusion

This study introduces two planners to enhance LLMs' planning abilities. The disease screening planner improves diagnostic accuracy by utilizing RL to refine the inquiry policy. The differential diagnosis planner further enhances diagnoses by following evidence-based medical guidelines, translating these into structured decision procedures. Experimental results demonstrate that our system achieved impressive performance in conversational diagnostic tasks. To our knowledge, this is the first conversational diagnostic study conducted using real patient data rather than exam or question-answer datasets. Additionally, our system can be directly integrated into open-source LLMs, enabling them to handle dialogue diagnostic tasks comparable to closed LLMs.

Besides performance, our main contribution is the exploration of a new pipeline for utilizing EMRs in diagnostic dialogues. Existing relevant studies usually rely on synthetic dialogue data to fine-tune their LLMs and improving planning abilities, which is generated by larger LLMs such as Med-PaLM 2 or GPT-4 Turbo [7, 39]. However, this method is prohibitively expensive and unaffordable for most institutions. Our study results also suggest that even the most advanced LLMs struggle with conversational diagnostic tasks, casting doubt on the efficacy of synthetic data. Our study does not require dialogue data to fine-tune LLMs, which makes it cost-effective. By structuring textual HPI and CC via a LLM, our planners can be optimized through simulated experimentation, resulting in more effective inquiry policies than those of most current LLMs. Of note, our system surpasses GPT-4 Turbo by using only a standard symptom list and 40,000 EMRs. We argue that by carefully refining the symptom list and fully utilizing millions of EMRs already available in hospitals, the system's planning performance can be further enhanced.

The second contribution of this study is our improved handling of interpretability and reliability issues. The uninterpretability and hallucinations of LLMs raise concerns among doctors about their application perspective [40]. We noticed that interpretability is not necessary during the disease screening phase, as it is often challenging for physicians themselves to clearly explain the rationale behind inquiries. We only need to ensure that LLM behavior adheres to medical literature in the differential diagnosis phase. We demonstrated that merely utilizing textual external knowledge may not improve LLM's planning capabilities to a satisfactory level. Thus, we explored a method that allows a LLM to autonomously generate decision procedures. The decision procedures can be presented in text form, understandable and verifiable by doctors, improving interpretability and reliability. Decision procedures also allow us to identify the causes of errors, which is challenging to accomplish through pure LLM-based diagnostics. Compared to traditional expert system research, we show that it is possible to generate decision procedures without the involvement of human experts [13]. If disease diagnosis decision procedures can be auto-generated by LLMs with non-expert labor, it would enable rapid development of diagnostic workflows for each disease.

Although this study has achieved notable progress in conversational diagnosis, it is still a preliminary investigation with numerous limitations. The study relies on EMRs from ICU, involving patients with complex conditions. We also directly use an off-the-shelf RL algorithm. Consequently, the disease screening performance remains at a low level and requires enhancement. Due to budget limitations, this study only assessed differential diagnosis performance on heart failure. We plan to further refine the inquiry algorithm and seize opportunities to conduct clinical trials, testing the system's performance in real-world medical consultations.

## References

[1] Yanase, J., E. Triantaphyllou. A systematic survey of computer-aided diagnosis in medicine: Past and present developments. Expert Systems with Applications, 138:112821, 2019.

[2] Nori, H., N. King, S. M. McKinney, et al. Capabilities of gpt-4 on medical challenge problems. arXiv preprint arXiv:2303.13375, 2023.

[3] Singhal, K., T. Tu, J. Gottweis, et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617, 2023.

[4] Eriksen, A. V., S. Möller, J. Ryg. Use of gpt-4 to diagnose complex clinical cases, 2023.

[5] Lee, P., S. Bubeck, J. Petro. Benefits, limits, and risks of gpt-4 as an ai chatbot for medicine. New England Journal of Medicine, 388(13):1233-1239, 2023.

[6] Sandmann, S., S. Riepenhausen, L. Plagwitz, et al. Systematic analysis of chatgpt, google search and llama 2 for clinical decision support tasks. Nature Communications, 15(1):2050, 2024.

[7] Tu, T., A. Palepu, M. Schaekermann, et al. Towards conversational diagnostic ai. arXiv preprint arXiv:2401.05654, 2024.

[8] Saab, K., T. Tu, W.-H. Weng, et al. Capabilities of gemini models in medicine. arXiv preprint arXiv:2404.18416, 2024.

[9] Chen, Z., A. H. Cano, A. Romanou, et al. Meditron-70b: Scaling medical pretraining for large language models. arXiv preprint arXiv:2311.16079, 2023.

[10] Sokol, D. Listening to patients is not enough. BMJ, 357, 2017.

[11] Johri, S., J. Jeong, B. A. Tran, et al. Testing the limits of language models: A conversational framework for medical ai assessment. medRxiv, 2023.

[12] Baerheim, A. The diagnostic process in general practice: has it a two-phase structure? Family practice, 18(3):243-245, 2001.

[13] Cowan, R. Expert systems: aspects of and limitations to the codifiability of knowledge. Research Policy, 30(9):1355-1372, 2001.

[14] Achiam, J., S. Adler, S. Agarwal, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.

[15] Johnson, A. E., L. Bulgarelli, L. Shen, et al. Mimic-iv, a freely accessible electronic health record dataset. Scientific data, 10(1):1, 2023.

[16] Patel, S. B., K. Lam. Chatgpt: the future of discharge summaries? The Lancet Digital Health, 5(3):e107-e108, 2023.

[17] Bao, Z., W. Chen, S. Xiao, et al. Disc-medllm: Bridging general large language models and real-world medical consultation. arXiv preprint arXiv:2308.14346, 2023.

[18] Wei, Z., Q. Liu, B. Peng, et al. Task-oriented dialogue system for automatic diagnosis. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 201-207. 2018.

[19] Lin, J., L. Xu, Z. Chen, et al. Towards a reliable and robust dialogue system for medical automatic diagnosis. Open Review, 2020.

[20] Chen, W., C. Zhong, J. Peng, et al. Dxformer: a decoupled automatic diagnostic system based on decoder-encoder transformer with dense symptom representations. Bioinformatics, 39(1):btac744, 2023.

[21] Chen, W., Z. Li, H. Fang, et al. A benchmark for automatic medical consultation system: frameworks, tasks and datasets. Bioinformatics, 39(1):btac817, 2023.

[22] Deng, Y., W. Zhang, W. Lam, et al. Plug-and-play policy planner for large language model powered dialogue agents. In The Twelfth International Conference on Learning Representations. 2023.

[23] Hongru, W., R. Wang, F. Mi, et al. Cue-cot: Chain-of-thought prompting for responding to in-depth dialogue questions with llms. In The 2023 Conference on Empirical Methods in Natural Language Processing. 2023.

[24] Fu, Y., H. Peng, T. Khot, et al. Improving language model negotiation with self-play and in-context learning from ai feedback. arXiv preprint arXiv:2305.10142, 2023.

[25] Wei, J., X. Wang, D. Schuurmans, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.

[26] Wang, L., C. Ma, X. Feng, et al. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):1-26, 2024.

[27] Melms, L., J. R. Schaefer, A. Jerrentrup, et al. A pilot study of patient satisfaction with a self-completed tablet-based digital questionnaire for collecting the patient's medical history in an emergency department. BMC Health Services Research, 21:1-13, 2021.

[28] Hampton, J. R., M. Harrison, J. R. Mitchell, et al. Relative contributions of history-taking, physical examination, and laboratory investigation to diagnosis and management of medical outpatients. Br Med J, 2(5969):486-489, 1975.

[29] Sutton, R. S., A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.

[30] Schulman, J., F. Wolski, P. Dhariwal, et al. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.

[31] Raffin, A., A. Hill, A. Gleave, et al. Stable-baselines3: Reliable reinforcement learning implementations. Journal of Machine Learning Research, 22(268):1-8, 2021.

[32] Clinic, M. Mayo clinic symptom checker, 2024. Accessed: 2024-04-03.

[33] meta. Introducing meta llama 3: The most capable openly available llm to date, 2024. Accessed: 2024-04-28.

[34] OpenAI. Hello gpt-4o, 2024. Accessed: 2024-05-14.

[35] Reese, J. T., D. Danis, J. H. Caufield, et al. On the limitations of large language models in clinical diagnosis. medRxiv, 2023.

[36] OpenAI. Embedding models, 2024. Accessed: 2024-04-28.

[37] Groenewegen, A., F. H. Rutten, A. Mosterd, et al. Epidemiology of heart failure. European journal of heart failure, 22(8):1342-1356, 2020.

[38] McDonagh, T. A., M. Metra, M. Adamo, et al. 2021 esc guidelines for the diagnosis and treatment of acute and chronic heart failure: Developed by the task force for the diagnosis and treatment of acute and chronic heart failure of the european society of cardiology (esc) with the special contribution of the heart failure association (hfa) of the esc. European heart journal, 42(36):3599-3726, 2021.

[39] Chen, J., X. Wang, A. Gao, et al. Huatuogpt-ii, one-stage training for medical adaption of llms, 2023.

[40] Gilbert, S., H. Harvey, T. Melvin, et al. Large language model ai chatbots require approval as medical devices. Nature Medicine, 29(10):2396-2398, 2023.

[41] Young, K. A., C. G. Scott, R. J. Rodeheffer, et al. Progression of preclinical heart failure: a description of stage a and b heart failure in a community population. Circulation: Cardiovascular Quality and Outcomes, 14(5):e007216, 2021.

Table 3: Disease Screening Performance of GPT-4o

| EP | \# Question | LLM | \# Sample | Top 1 | Top 3 | Top 5 | Top 10 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| No | 10 | GPT-4o 05-13 | 300 | 0.297 | 0.537 | 0.610 | 0.733 |
| Yes | 10 | GPT-4o 05-13 | 300 | 0.320 | 0.533 | 0.613 | 0.747 |
| No | 20 | GPT-4o 05-13 | 300 | 0.327 | $\mathbf{0 . 5 5 3}$ | $\mathbf{0 . 6 5 3}$ | 0.747 |
| Yes | 20 | GPT-4o 05-13 | 300 | 0.310 | 0.540 | 0.637 | $\mathbf{0 . 7 7 7}$ |
| Yes | 10 | GPT-4 Turbo 04-09 | 300 | $\mathbf{0 . 3 3 0}$ | 0.550 | 0.637 | 0.770 |

Table 4: Differential Diagnosis Performance of GPT-4o

| EK | LLM | Success Rate | Accuracy | Precision | Recall | F1 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| None | GPT-4o 05-13 | $96 \%$ | $82 \%$ | $74 \%$ | $99 \%$ | $85 \%$ |
| Text | GPT-4o 05-13 | $86 \%$ | $85 \%$ | $78 \%$ | $\mathbf{1 0 0 \%}$ | $87 \%$ |
| None | GPT-4 Turbo 04-09 | $86 \%$ | $86 \%$ | $80 \%$ | $95 \%$ | $87 \%$ |
| Text | GPT-4 Turbo 04-09 | $98 \%$ | $73 \%$ | $65 \%$ | $\mathbf{1 0 0 \%}$ | $79 \%$ |
| EP+HF | GPT-4 Turbo 04-09 | $\mathbf{1 0 0 \%}$ | $\mathbf{9 1 \%}$ | $\mathbf{8 9 \%}$ | $\mathbf{9 2 \%}$ | $\mathbf{9 1 \%}$ |
