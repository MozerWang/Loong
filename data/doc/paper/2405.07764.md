# LGDE: Local Graph-based Dictionary Expansion 

Dominik J. Schindler ${ }^{1, *} \quad$ Sneha Jha $^{1}$ Xixuan Zhang ${ }^{2,3}$<br>Kilian Buehling ${ }^{2,3}$ Annett Heft ${ }^{2,3}$ Mauricio Barahona ${ }^{1}$<br>${ }^{1}$ Imperial College London, UK<br>${ }^{2}$ Weizenbaum Institute Berlin, Germany<br>${ }^{3}$ Free University of Berlin, Germany<br>* Corresponding author: dominik.schindler19@imperial.ac.uk


#### Abstract

Expanding a dictionary of pre-selected keywords is crucial for tasks in information retrieval, such as database query and online data collection. Here we propose Local Graph-based Dictionary Expansion (LGDE), a method that uses tools from manifold learning and network science for the data-driven discovery of keywords starting from a seed dictionary. At the heart of LGDE lies the creation of a word similarity graph derived from word embeddings and the application of local community detection based on graph diffusion to discover semantic neighbourhoods of predefined seed keywords. The diffusion in the local graph manifold allows the exploration of the complex nonlinear geometry of word embeddings and can capture word similarities based on paths of semantic association. We validate our method on a corpus of hate speech-related posts from Reddit and Gab and show that LGDE enriches the list of keywords and achieves significantly better performance than threshold methods based on direct word similarities. We further demonstrate the potential of our method through a real-world use case from communication science, where LGDE is evaluated quantitatively on data collected and analysed by domain experts by expanding a conspiracy-related dictionary.


## 1 Introduction

Dictionary expansion aims to expand a set of preselected keywords by adding related terms that can enhance original queries in keyword-based information retrieval tasks. Designing a dictionary without in-depth knowledge of the vocabulary in the domain of interest is prone to inaccurate, nonspecific or incomplete results. Therefore, expertgenerated seed dictionaries are typically expanded with domain-specific keywords for diverse applications, such as patent searches (Lee et al., 2014), queries of bibliometric databases (Yin et al., 2020) and online forums (Gharibshah et al., 2022), query expansion for more effective web searches (Roy et al., 2016; Kuzi et al., 2016), or collecting topic-specific content from social media platforms (Bruns et al., 2020; Zeng and Schäfer, 2021; Klinger et al., 2022; van Atteveldt et al., 2022). Dictionary expansion is particularly relevant, and challenging, in domains with evolving semantics where word choice and language style are highly specialised and diverge from general language usage or are constantly in flux to ensure exclusive, community-internal communication, to adjust to ongoing events or the emergence of topics and cultural changes, or to avoid legal prosecution (Heft et al., 2023).

When retrieving information around a certain topic, the challenge becomes to find a 'good' dictionary that leads to a corpus containing most documents associated with the topic (high recall) and with few irrelevant documents (high precision). New approaches for data-driven dictionary expansion have leveraged word embedding models to find semantically similar words to pre-selected keywords (Roy et al., 2016; Amsler, 2020; Gharibshah et al., 2022; van Atteveldt et al., 2022; Stoll et al., 2023). While systems based on Large Language Models (LLMs) could also be used for dictionary expansion (Jagerman et al., 2023; Wang et al., 2023; Lei et al., 2024), their application is prohibited in certain domains like hate speech or conspiracy-related communication due to strict moderation filters.

In this work, we build on the idea of data-driven dictionaries but rather than focusing only on words most directly similar to pre-selected keywords, we propose Local Graph-based Dictionary Expansion (LGDE), a method that incorporates tools from manifold learning and network science to explore a graph of semantic similarities built from a domain-specific word level representation. LGDE
expands a pre-selected set of keywords by adding words from their corresponding semantic communities, as determined through fast local community detection in the semantic network (Yu et al., 2020). Through a graph-based manifold representation, LGDE thus captures the local nonlinear geometry of domain-specific word embeddings around seed keywords, and then exploits graph diffusion to find local semantic communities that naturally include multi-step word associations.

To evaluate our method, we consider the task of expanding a dictionary of pre-selected keywords from a human-coded hate speech dataset from the social media platforms Reddit ${ }^{1}$ and $\mathrm{Gab}^{2}$ (Qian et al., 2019). As compared to approaches based on direct word similarities, LGDE leads to a betterexpanded dictionary in terms of $F_{1}$ scores with discovered words significantly more likely to appear in hate speech-related communication. To further showcase the potential of LGDE in a realworld use case, we analyze conspiracy-related posts from the message forum 4 chan $^{3}$ collected through an expert-selected dictionary representative of two conspiracy theories ('Great Replacement' and 'New World Order'). In this case, LGDE shows a quantitative advantage in discovering additional relevant words that would be missed without the chain of word associations

### 1.1 Problem definition

Let us consider a pre-selected list of $n$ keywords $W_{0}=\left\{w_{1}, w_{2}, \ldots, w_{n}\right\}$, denoted the seed dictionary, which are known to be relevant to a certain topic. These initial terms are usually derived from expert knowledge, literature research or existing keyword lists (Gharibshah et al., 2022; Heft et al., 2023). Let us further assume that we have access to a domain-specific corpus of $l$ documents $D=$ $\left\{d_{1}, d_{2}, \ldots, d_{l}\right\}$ related to the topic of interest, and each keyword in $W_{0}$ is contained in at least one document.We can then formulate the dictionary expansion problem: expand the seed dictionary $W_{0}$ by $m$ new words from the domain-specific corpus $D$ to obtain a data-driven expanded dictionary $W=\left\{w_{1}, w_{2}, \ldots, w_{n}, w_{n+1}, \ldots, w_{n+m}\right\}$ such that the newly discovered keywords make $W$ 'more representative' of the topics of interest as measured by evaluation metrics such as the $F_{1}$ score that balances precision and recall.[^0]

### 1.2 Related work

Keyword extraction and query expansion are related tasks but not the same as dictionary expansion. The former refers to the extraction of representative keywords from text without an initial seed dictionary (Firoozeh et al., 2020), whereas the latter relies on user input on query words or phrases, possibly expanding the current query term or suggesting additional terms (Schütze et al., 2008). These tasks have been studied mostly in the context of information retrieval in search engines and often involve relevance user feedback on retrieved documents (Zheng et al., 2020). Here, we use semantic relationships captured in the latent representation space and focus on generating relevant keyword or query terms based on curated seed keywords, without explicit user feedback. Early statistical approaches were based on ranking candidate keywords using TF-IDF or TextRank (Mihalcea and Tarau, 2004) or analysing word co-occurrences directly (Yin et al., 2020). Promising work has also leveraged pre-trained word embeddings to expand a seed dictionary by most similar words (Amsler, 2020; Gharibshah et al., 2022; van Atteveldt et al., 2022; Stoll et al., 2023). Prior work also suggests that global word embeddings may underperform in tasks that benefit from local properties (Diaz et al., 2016). Farmanbar et al. (2020) explore domainspecific query terms but focus on important challenges in end-to-end production pipelines using direct cosine similarities. Tsai and Wang (2014) and Gharibshah et al. (2022) use similar methods adapted to custom domains. The latter are close to our domain-specific setting but do not employ the properties of the semantic network.

### 1.3 Motivation

A data-driven augmented dictionary can be constructed by adding words from a domain-specific vocabulary $V$ of word embedding vectors that are most similar to the keywords in the seed dictionary $W_{0} \subseteq V$ according to the cosine similarity $S_{\text {cos }}$, given by $S_{\text {cos }}(\boldsymbol{u}, \boldsymbol{v}):=\frac{<\boldsymbol{u}, \boldsymbol{v}>}{\|\boldsymbol{u}\|_{2}\|\boldsymbol{v}\|_{2}}$ for two words $\boldsymbol{u}, \boldsymbol{v} \in V$. For a threshold $0 \leqslant \epsilon \leqslant 1$, the thresholding-based expanded dictionary $W(\epsilon)$ is defined as

$$
\begin{equation*}
W(\epsilon):=\bigcup_{\boldsymbol{w} \in W_{0}}\left\{\boldsymbol{v} \in V \mid S_{\cos }(\boldsymbol{w}, \boldsymbol{v}) \geqslant \epsilon\right\} \tag{1}
\end{equation*}
$$

Choosing the parameter $\epsilon$ appropriately can enrich the seed dictionary by considering direct word as-
sociations. To further improve the quality of the expanded dictionary, one can fine-tune the word embeddings in $V$ on a domain-specific corpus $D$ to better capture contextual semantics.

An issue not addressed by thresholding approaches is that direct similarities can be uninformative in noisy, latent space representations, such as word embeddings. This can lead to relatively unspecific word associations in text. One way to circumvent this limitation is to construct geometric graphs that capture the local manifold and explore it via diffusion. This allows us to consider chains of word associations as paths on the graph. Indeed, a seed keyword $\boldsymbol{w} \in W_{0}$ could be similar to a word $\boldsymbol{u} \in V$ (with $S_{\mathrm{cos}}(\boldsymbol{w}, \boldsymbol{u})>\epsilon$ ) which is in turn similar to another word $\boldsymbol{v} \in V$ (with $S_{\cos }(\boldsymbol{u}, \boldsymbol{v})>\epsilon$ ), yet we might have low direct similarity $S_{\mathrm{cos}}(\boldsymbol{w}, \boldsymbol{v})<\epsilon$, reminiscent of cosine similarity not fulfilling the standard triangle inequality (Schubert, 2021). A method based only on direct similarities would then exclude the word $\boldsymbol{v}$ from the data-driven dictionary $W(\epsilon)$, although the chain of strong word associations arguably makes $v$ a sensible candidate for dictionary expansion. Similar problems may also occur when adding the $k$ most similar words for each seed keyword. LGDE uses tools from manifold learning and network scienceto account for such chains of word associations to better capture the local nonlinear geometry of seed keywords, (see Figure 1 for an illustration).

![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-03.jpg?height=405&width=791&top_left_y=1725&top_left_x=244)

Figure 1: In contrast to (a) simple thresholding, (b) LGDE captures the nonlinear local geometry of word embeddings around a seed keyword.

## 2 Methodology

LGDE consists of three steps. In the first step, we derive vectors for the words in our corpus using a fine-tuned word embedding model. In the second step, we compute a similarity graph from the word vectors that captures the local semantic sim- ilarities of the corpus. In the third step, we use local community detection based on graph diffusion to obtain semantic communities of each seed keyword as candidates for dictionary expansion. We detail these steps in the following subsections and also describe a validation strategy for our method.

### 2.1 Fine-tuned word representations

As a starting point, we use GloVe as base word embeddings, generated from general-purpose corpora like Wikipedia 2014 and Gigaword 5 (Pennington et al., 2014). The base GloVe embeddings are available in different dimensions $r=$ $50,100,300$. It is well-known that word embeddings are dependent on the corpus they are trained on. Given that terms often adopt new or additional meanings across domains or over time (e.g., "Apple" may refer to a concept in technology or business domains that came into existence only in the 1970s), we use Mittens (Dingwall and Potts, 2018) to fine-tune GloVe representations to better represent the semantic relationships in our use-case domains. For a set of $N$ words in our domain-specific corpus $D$, the word embeddings $\boldsymbol{v}_{i}, i=1, \ldots, N$, are computed from a retrofitting model that optimises the Mittens cost function

$$
\begin{equation*}
J_{\text {Mittens }}=J_{\mathrm{GloVe}}+\mu \sum_{i \in U}\left\|\boldsymbol{v}_{i}-\boldsymbol{u}_{i}\right\|, \tag{2}
\end{equation*}
$$

where $J_{\text {Glove }}$ is the standard GloVe cost function (Pennington et al., 2014) based on the word co-occurrences in $D, U$ is the index set of words for which pre-trained vector representations $\boldsymbol{u}_{i}$ are available, and $0 \leqslant \mu$ is the hyperparameter that determines the extent of fine-tuning. A small $\mu$ favors greater adaptation of the word representations $\boldsymbol{v}_{i}$ whereas a large $\mu$ favors remaining closer to the base embeddings $\boldsymbol{u}_{i}$. Setting $\mu=0$ means that the word vectors are essentially computed from scratch on the the new corpus. Although the value $\mu=0.1$ was the default used by Dingwall and Potts (2018), we find that a larger value of $\mu$ can improve the quality of embeddings for a small domain-specific corpus $D$. By training the Mittens model, we compute fine-tuned $r$-dimensional word vectors $V=\left\{\boldsymbol{v}_{1}, \boldsymbol{v}_{2}, \ldots, \boldsymbol{v}_{N}\right\} \subsetneq \mathbb{R}^{r}$, for $r=50,100,300$, and we assume $W_{0} \subsetneq V$. While Schnabel et al. (2015) have shown that the length of the word vectors may encode term frequency, we normalize the word vectors to unit length, as the length carries no semantic meaning in our case.

Regarding our choice of GloVe and Mittens, it is worth noting that BERT-based (Devlin et al., 2019) models rely on subword tokenization and, typically, word embeddings are extracted by summing or averaging the subword token embeddings, a heuristic that often degrades the wordlevel semantic network. For instance, a Semeval task on diachronic semantics (Schlechtweg et al., 2020) showed that static or type-based embeddings outperformed contextualized embeddings such as BERT or ELMo (Peters et al., 2018). It is also worth pointing out that BERT-style models are designed for supervised end-to-end finetuning, and not for extracting intermediate embedding layers. Previous studies on obtaining representations from BERT-like models (Vulić et al., 2020) have shown the various issues with representations produced by averaging hidden layers. These are highly task- and domain-dependent and there are no techniques to select a single layer that is reliably better (Bommasani et al., 2020). Work on hidden layer selection for good word-level representations may be an interesting direction but is not the focus of this work.

### 2.2 Semantic network construction

The analysis of the semantic space $V \subsetneq \mathbb{R}^{r}$ is often restricted to the computation of pairwise cosine similarities between words. To explore the full semantic space of our vocabulary $V$ with size $N=|V|$, we construct an undirected, weighted semantic similarity graph $G=(V, E)$, where the nodes correspond to the words in $V$. The weighted edges $E$ are computed from the $N \times N$ matrix of normalised cosine distances:

$$
\begin{equation*}
\tau:=\left\|1-S_{\cos }\right\|_{\max } \tag{3}
\end{equation*}
$$

where $S_{\mathrm{cos}}$ is the cosine similarity and $\|\cdot\|_{\max }$ is the element-wise normalisation with the maxnorm so that all elements of $\tau$ are normalised between $[0,1]$. We also define the matrix of normalised cosine similarities (Altuncu et al., 2019):

$$
\begin{equation*}
S:=1-\tau \tag{4}
\end{equation*}
$$

We would like to obtain a semantic network with edges weighted by the similarity $S$ but $S$ is a dense matrix that contains many small values corresponding to negligible word similarities. To uncover a robust semantic network that only contains the most relevant chains of semantic similarities, we first obtain the undirected and unweighted
Continuous $k$-Nearest Neighbors (CkNN) graph from the distance matrix $\tau$ (Berry and Sauer, 2019). The $N \times N$ adjacency matrix $B^{(k)}$, of the CkNN graph is given by:

$B_{\boldsymbol{u}, \boldsymbol{v}}^{(k)}:= \begin{cases}1 & \text { if } \tau(\boldsymbol{u}, \boldsymbol{v})<\delta \sqrt{\tau\left(\boldsymbol{u}, \boldsymbol{u}_{k}\right) \tau\left(\boldsymbol{v}, \boldsymbol{v}_{k}\right)} \\ 0 & \text { otherwise }\end{cases}$

where $\boldsymbol{u}_{k}, \boldsymbol{v}_{k} \in V$ denote the $k$-th nearest neighbours of $\boldsymbol{u}, \boldsymbol{v} \in V$, respectively, and $\delta>0$ controls the graph density. In contrast with a $k$ Nearest Neighbors (kNN) graph, which does not account for inhomogeneities in the data as it connects a node to all of its $k$ nearest neighbours, the $\mathrm{CkNN}$ construction corrects for different densities and has been shown to approximate consistently the geometry of complex manifolds embedded in a Euclidean space (Berry and Sauer, 2019). Note that $\tau$ is equivalent to using Euclidean distances of normalised word vectors when $\delta=1$. In that case, and assuming $\|\boldsymbol{u}\|_{2}=\|\boldsymbol{v}\|_{2}=1$, we have:

$$
\begin{aligned}
& \tau(\boldsymbol{u}, \boldsymbol{v})<\sqrt{\tau\left(\boldsymbol{u}, \boldsymbol{u}_{k}\right) \tau\left(\boldsymbol{v}, \boldsymbol{v}_{k}\right)} \\
& \Leftrightarrow\|\boldsymbol{u}-\boldsymbol{v}\|_{2}<\sqrt{\left\|\boldsymbol{u}-\boldsymbol{u}_{k}\right\|_{2}\left\|\boldsymbol{v}-\boldsymbol{v}_{k}\right\|_{2}}
\end{aligned}
$$

which follows directly from:

$$
\begin{aligned}
\|\boldsymbol{u}-\boldsymbol{v}\|_{2}^{2} & =\|\boldsymbol{u}\|_{2}^{2}+\|\boldsymbol{v}\|_{2}^{2}-2\langle\boldsymbol{u}, \boldsymbol{v}\rangle_{2} \\
& =2\left(1-S_{\cos }(\boldsymbol{u}, \boldsymbol{v})\right)=C \tau_{\boldsymbol{u}, \boldsymbol{v}}
\end{aligned}
$$

where $C:=2 \max _{\boldsymbol{u}, \boldsymbol{v} \in V}\left(1-S_{\cos }(\boldsymbol{u}, \boldsymbol{v})\right)$ is a constant. Moreover, empirical studies have shown that CkNN with $\delta=1$ and adequate choice of $k$ outperforms other graph constructions for downstream tasks such as data clustering (Liu and Barahona, 2020) and classification (Qian et al., 2021).

Finally, we can define the weighted semantic similarity network $G^{(k)}=\left(V, E^{(k)}\right)$ with adjacency matrix

$$
\begin{equation*}
A^{(k)}:=S \odot B^{(k)} \tag{6}
\end{equation*}
$$

where $\odot$ denotes the element-wise (Hadamard) product. Therefore, the edge weights of the semantic network $G^{(k)}$ are given by the normalised semantic similarity $S$, and its backbone is the sparse CkNN graph $B^{(k)}$ that preserves the topological and local geometric features of the semantic space $V$.

### 2.3 Semantic community detection

The constructed graph $G^{(k)}$ encodes the semantic information contained in our domain-specific
corpus $D$ at a word-level representation with the inter-word weighted edges $E^{(k)}$ capturing relevant semantic similarities between words. Hence, paths in the graph can be interpreted as chains of word associations. Moreover, the keywords in the seed dictionary $W_{0}$ are nodes in the graph and we can study their context and related words by computing their local semantic community structure. To do so, we use the severability method for fast local community detection (Yu et al., 2020) and determine the semantic community $C(\boldsymbol{w})$ for each seed keyword $\boldsymbol{w} \in W_{0}$. Severability is a community detection algorithm that detects local graph communities by exploiting a discrete-time random walk with transition probability matrix $P$, where $P_{u, v}$ is the probability of the random walk jumping from word $\boldsymbol{u} \in V$ to $\boldsymbol{v} \in V$ given by:

$$
\begin{equation*}
0 \leqslant P_{\boldsymbol{u}, \boldsymbol{v}}:=\frac{A_{\boldsymbol{u}, \boldsymbol{v}}^{(k)}}{\sum_{\boldsymbol{v}^{\prime} \in V} A_{\boldsymbol{u}, \boldsymbol{v}^{\prime}}^{(k)}} \leqslant 1 \tag{7}
\end{equation*}
$$

The semantic community $C(\boldsymbol{w})$ of $\boldsymbol{w} \in W_{0}$ is then the subset $C \subseteq V$ (with $\boldsymbol{w} \in C$ ) that maximises the severability quality function $\sigma(C, t)$ for the time scale $t$ :

$$
\begin{equation*}
0 \leqslant \sigma(C, t):=\frac{\rho(C, t)+\mu(C, t)}{2} \leqslant 1 \tag{8}
\end{equation*}
$$

where the mixing term $0 \leqslant \mu(C, t) \leqslant 1$ measures the mixing of the random walker within $C$ over time $t$ and the retention term $0 \leqslant \rho(C, t) \leqslant 1$ quantifies the probability of the random walker not escaping $C$ by time $t$ (see Yu et al. (2020) for details). As $t$ increases, we need a larger-sized community $C \subseteq V$ to trap the random walk and achieve high retention $\rho(C, t)$, but simultaneously, increasing the size of $C$ makes mixing more difficult and leads to a reduced $\mu(C, t)$. To indicate the dependency of the semantic community on $t$ and the $\mathrm{CkNN}$ parameter $k$ we write $C^{(k, t)}(\boldsymbol{w})$. Importantly, severability captures chains of word associations (through paths in the random walk) and allows for overlapping semantic communities (potentially capturing polysemy, if present).

The result of the LGDE method is then the extended dictionary $W(k, t)$ defined as the union of (overlapping) local semantic communities:

$$
\begin{equation*}
W(k, t):=\bigcup_{\boldsymbol{w} \in W_{0}} C^{(k, t)}(\boldsymbol{w}) \tag{9}
\end{equation*}
$$

By construction $W_{0} \subseteq W(k, t) \subseteq V$, and we can expect that the size of $W(k, t)$ generally grows with increasing $k, t \in \mathbb{N}$ such that in the settheoretic limit, we have $\lim _{k, t \rightarrow \infty} W(k, t)=V$. Importantly, our extended dictionary can include words that are connected to a seed keyword $\boldsymbol{w} \in$ $W_{0}$ via a chain of strong word associations.

### 2.4 Evaluation of expanded dictionaries

Consider a domain-specific corpus of $l$ documents $D=\left\{d_{1}, \ldots, d_{l}\right\}$ with ground-truth (humancoded) labels $\boldsymbol{y}$ such that $\boldsymbol{y}_{i}=1$ if document $d_{i}$ has a certain topic of interest (true) and $\boldsymbol{y}_{i}=$ 0 otherwise (false). To assess the quality of a data-driven dictionary $W$ we can evaluate the performance of a simple document classifier $f_{W}$ : $D \rightarrow\{0,1\}$ associated with $W$, where we define $f_{W}(d)=1$ if there exists a keyword in $W$ that appears in the document $d \in D$ and $f_{W}(d)=0$ otherwise. To evaluate the tradeoff between precision and recall of the dictionary $W$ on the potentially unbalanced benchmark data $(D, \boldsymbol{y})$, we compute the macro $F_{1}$ score of its associated classifier $f_{W}$ and denote this number by $F_{1}[W]$. Similarly, $P[W]$ denotes the macro precision and $R[W]$ the macro recall. This evaluation strategy can also be used to train the hyperparameters $0 \leqslant \epsilon \leqslant 1$ in the case of the dictionary $W(\epsilon)$ from Eq. (1) or $k, t$ in the case of the LGDE dictionary $W(k, t)$ from Eq. (9) on a train split of the benchmark data.

It is also possible to evaluate the contribution of a single keyword $w \in W$ to the performance of the dictionary $W$. Let us consider the probability $\mathbb{P}\left[w \in d_{i} \mid y_{i}=1\right]$ that the word $\boldsymbol{w}$ appears in a true document and $\mathbb{P}\left[w \in d_{i} \mid y_{i}=0\right]$ that it appears in a false document. Then we can define the likelihood ratio (LR) (van der Helm and Hische, 1979) of word $\boldsymbol{w}$ as

$$
\begin{equation*}
\operatorname{LR}(\boldsymbol{w}):=\frac{\mathbb{P}\left[w \in d_{i} \mid y_{i}=1\right]}{\mathbb{P}\left[w \in d_{i} \mid y_{i}=0\right]} \tag{10}
\end{equation*}
$$

which is larger than 1 if $\boldsymbol{w}$ is more likely to appear in true documents than in false ones. Words with larger LR can thus be considered to be more representative of true documents. The median LR for all words $\boldsymbol{w} \in W$ denoted by $\operatorname{LR}[W]$ can be used to summarise the individual contributions of keywords to the performance of the dictionary.

## 3 Experiments

### 3.1 Hate speech data

We use a benchmark dataset of 56,099 manually annotated hate speech posts $(D, \boldsymbol{y})$ collected

![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-06.jpg?height=311&width=1585&top_left_y=204&top_left_x=241)

Figure 2: Train $F_{1}$ scores of optimal LGDE dictionaries are higher than of the thresholding-based approach across dictionary sizes in the hate speech experiment for $r=300$. Solid lines are $F_{1}$ scores max-pooled over a window of size 15 , and the dotted line is the train $F_{1}$ score of the seed dictionary for comparison. We observe similar trends for $r=50$ and 100, see Figure 4 in the Appendix.

|  | Seed dictionary | LGDE | Thresholding |
| :--- | :---: | :---: | :---: |
| 50 | 0.856 | $\mathbf{0 . 8 6 1}$ | 0.852 |
| 100 | 0.856 | $\mathbf{0 . 8 7 4}$ | 0.850 |
| 300 | 0.856 | $\mathbf{0 . 8 7 5}$ | 0.846 |

Table 1: Test macro $F_{1}$ scores in hate speech data for different dimensions $r$.

from Reddit and $\mathrm{Gab}^{4}$ by Qian et al. (2019), ${ }^{5}$ of which $19,873(35.4 \%)$ are hate speech ${ }^{6}$ We split the data into train data (75\%) and test data $(25 \%)$ using stratification. We follow Qian et al. (2019) to choose our seed dictionary $W_{0}$ as the five most frequent keywords in the benchmark dataset—"ni**er", "fa**ot", "ret**d", "ret***ed" and " $\mathrm{c} * * \mathrm{t}$ ".

### 3.2 Experimental setup

As outlined in Section 2.1, we first compute finetuned word embeddings $V \subseteq \mathbb{R}^{r}$, filtering out stopwords, infrequent misspellings and very rare words, such that $N:=|V|=7,093$. We found that choosing a relatively large value $\mu=1.0$ produces better-quality word embeddings for various dimensions $r=50,100,300$, where embeddings for out-of-vocabulary (OOV) words are learnt while retaining the quality of pre-existing word embeddings. From the semantic space $V$ we compute the $N \times N$ matrix of normalised cosine similarities $S$ (4).

For each dimension $r$, we then compare the expansion of the seed dictionary $W_{0}$ using the thresholding-based expanded dictionary $W(\epsilon)$[^1]

from Eq. (1) (derived from $S$ ) with the LGDE dictionary $W(k, t)$ from Eq. (9). To control for the size of the different dictionary expansion methods, we require that an expanded dictionary should include at least 30 keywords to facilitate proper comparison but no more than 50 for presentation purposes. Under these constraints, we fine-tune the hyperparameters $0 \leqslant \epsilon \leqslant 1$ of $W(\epsilon)$ and $k, t$ of $W(k, t)$ on the train split of the benchmark data (see Figure 3 and Table 6 in the Appendix for additional information and optimal hyperparameters). We find that LGDE consistently outperforms thresholding across different sizes of the expanded dictionary (Figure 2). We then evaluate the macro F1-scores of the optimised dictionaries on the test split. Finally, we evaluate the individual contributions of keywords in the discovered dictionaries using the likelihood ratio (LR), see Eq. (10), comparing the optimal LGDE dictionary with the thresholding-based dictionary of the closest size.

### 3.3 Results

Table 1 shows that the optimal LGDE dictionaries $W(k, t)$ outperform the optimal thresholdingbased dictionaries $W(\epsilon)$ for all dimensions of the word embeddings, with the overall best dictionary achieved with LGDE at dimension $r=300$. The thresholding-based dictionaries $W(\epsilon)$ do not improve upon the performance of the bare seed dictionary $W_{0}$ because of the inclusion of many nonrelevant terms.

A qualitative assessment of the discovered words (Table 2) shows that LGDE discovers more relevant keywords that lead to hate speech documents, whereas thresholding often produces expected offensive, but largely standard, words without bringing in new semantic context. Some examples of relevant keywords only found by LGDE include "be**er" (a racist term for Hispanic men), " $\mathrm{h} * \mathrm{~g}$ " (a misogynist term for older

| $r$ | LGDE only | Intersection | Thresholding only |
| :---: | :---: | :---: | :---: |
| 50 | altright, awww, baiting, be ${ }^{* *}$, <br> braindead, brainless, btw, commie, <br> commies, $\mathbf{c} * *$ ts, $\mathbf{f} * \mathbf{g}$, fa $* * *$ ts, $\mathbf{f} * *$ ker, <br> gg, go ${ }^{* * \mathbf{m},} \mathbf{h} * \mathbf{g}$, hater, liar, limey, <br> mo*on, pedo, simp, sk**k, s**ts, <br> snowflake, tl, tr**ny, wetback, woah | ![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-07.jpg?height=237&width=355&top_left_y=274&top_left_x=916) | autistic, $\mathbf{b} * * \mathbf{c h}$, bu $* * * *$ it, cared, <br> competent, convicted, $\mathbf{f * * * k}$, in- <br> sane, intellectually, liking, men- <br> tally, morally, offenders, olds, paki, <br> puke, ret $* *$ ds, sane, ugh, yikes |
| 100 | ![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-07.jpg?height=317&width=497&top_left_y=513&top_left_x=396) | $\mathbf{b}^{* *} \mathbf{c h}$, braindead, com- <br> mie, f*g, f**kin, ni ${ }^{* *} \mathbf{a}$, <br> ret**ds, shite, turd, wet- <br> back | as***le, autistic, cared, competent, <br> crybaby, engineers, $\mathbf{f} * * \mathbf{k}, \mathbf{f} * *$ king, <br> hillbilly, honest, incompetent, intel- <br> lectually, mentally, morally, mur- <br> derers, ni ${ }^{* *}$ ers, offenders, slur, <br> weasel, $\mathbf{w}^{* *} \mathbf{r e}$ |
| 300 | ![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-07.jpg?height=350&width=497&top_left_y=829&top_left_x=396) | aww, awww, ni***a, <br> ret $^{* *}$ dation, ret**ds, simp | ![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-07.jpg?height=350&width=468&top_left_y=829&top_left_x=1300) |

Table 2: Discovered words in hate speech data for different embedding dimensions $r$. Words in bold have a large likelihood ratio with $\operatorname{LR}[\boldsymbol{w}] \geqslant 2$.

women), "tr**ny" (a transphobic term for a transgender person) and "go**m" (an antisemitic term for a Jewish person). These derogatory terms, including neologisms and online slang, are part of an informal jargon and are potentially difficult to anticipate beforehand without being part of the online community under investigation. To discover these terms with the thresholding-based approach requires choosing smaller than optimal values of $\epsilon$ and comes with the price of adding many irrelevant terms to $W(\epsilon)$ such that the overall $F_{1}$ performance is reduced. For example, discovering the term "tr**ny" at dimension $r=50$ requires $\epsilon \leqslant 0.719$ such that $|W(\epsilon=0.719)|=192$ with $F_{1}=0.767$; at dimension $r=300$ it requires $\epsilon \leqslant 0.485$ such that $|W(\epsilon=0.485)|=263$ with $F_{1}=0.741$.

| $r$ | LGDE | Thresholding |
| :--- | :---: | :---: |
| 50 | $\mathbf{2 . 2 5}\left(^{*}\right)$ | 1.45 |
| 100 | $\mathbf{2 . 5 9}\left(^{*}\right)$ | 1.53 |
| 300 | $\mathbf{2 . 6 6}\left(^{*}\right)$ | 1.25 |

Table 3: Median likelihood ratios (Eq. 10) of discovered words in hate speech data for different dimensions $r$ with * indicating that LGDE is significantly higher ( $p<0.05$, Mann-Whitney U test).
Table 3 shows that the median LR for words only discovered by LGDE is significantly higher than the median LR for words only discovered by thresholding, i.e, $\operatorname{LR}[W(k, t) \backslash W(\epsilon)]>$ $\operatorname{LR}[W(\epsilon) \backslash W(k, t)]$, and the result is statistically significant for all dimensions ( $p<0.05$, MannWhitney U test). This matches our qualitative assessment that LGDE discovers words more representative of hate speech-related content.

## 4 Application to conspiracy-related content on 4chan

As a further illustration in a real-world use case, we apply LGDE to the problem of collecting conspiracy-related 4chan posts. All content on 4chan is ephemeral and together with complete user anonymity and the absence of content moderation (De Zeeuw and Tuters, 2020) a highly vernacular user culture has developed, which can be partly characterised by its racist and misogynous content. Detecting conspiracy-related content, defined as "the full public communication on and about (alleged) conspiracy theories in various communication venues, including their narrations, counter-narrations, and debunking, as well as neutral observation forms" (Heft et al., 2023, p. 3), can be challenging in this environment as
participants use slang and insider humour to explicitly distinguish themselves from a perceived out-group (De Zeeuw et al., 2020). Therefore, common words used in public debate or scientific literature to describe specific conspiracy theories might deviate from the vocabulary used by 4 chan users. Furthermore, the vocabulary used to describe specific conspiracy theories might change over time, as well as the conspirational narratives themselves, when new events lead to adaptations of conspiracy theories or when new conspiracy theories emerge and are included in the existing canon (Garry et al., 2021; Heft et al., 2023). Using only a literature-based dictionary to retrieve conspiracy-related posts from 4chan is thus insufficient to collect a longitudinal dataset of relevant user comments posted to this platform, rendering a sophisticated method of dictionary expansion necessary. Starting from an expert-selected seed dictionary, we show that LGDE discovers new conspiracy-related words that would be missed without a graph-based perspective.

### 4.1 Data

We assemble an initial seed dictionary $\tilde{W}_{0}$ to be representative of two conspiracy theories ('Great Replacement' and 'New World Order') with 215 keywords including "white genocide", "Illuminati" etc. based on the RPC-Lex dictionary (Puschmann et al., 2022) and other relevant literature (full list in Table 7). Using the fouRplebsAPI (Buehling, 2022), we collect all English language posts published in 22 sample weeks ( 2 weeks in each year from 2011 to 2021) on 4chan's political discussion board /pol/ ${ }^{7}$ leading to a corpus $D$ with 102,058 unique documents. Since many conspiracy-related keywords, such as "great replacement", are multiword phrases, we pre-process the input to include hyphenated terms and noun phrases.

For evaluation and to determine optimal hyperparameters for dictionary expansion with thresholding and LGDE we prepared human-coded benchmark data. As training data, we take a sample of 500 documents from $D$, which was labelled according to the majority vote of three independent human coders (trained student assistants), and we find that 65 documents ( $13.0 \%$ ) are conspiracy-related. We also collected test data independent of $D$ by first sampling a large num-[^2]

ber of random posts from 4chan and then oversampling conspiracy-related documents. The test data consists of 225 documents of which 69 are conspiracy-related $(34.5 \%)$ according to the majority vote of the three independent human coders.

### 4.2 Experimental setup

We restrict our analysis to the 5000 most frequent words in $D$ (excluding stop words but including our seed keywords) denoted by $V$. We then compute fine-tuned word embeddings $V \subseteq \mathbb{R}^{100}$ from our domain-specific corpus $D$, starting from pretrained 100-dimensional GloVe base embeddings, and we use the default value $\mu=0.1$ as our corpus is reasonably large (Dingwall and Potts, 2018). Furthermore, we define the effective seed dictionary $W_{0}=\tilde{W}_{0} \cap V$ as the 109 seed keywords that actually appear in the corpus.

Next, we compare the expansion of the seed dictionary $W_{0}$ using the thresholding-based expanded dictionary $W(\epsilon)$ to the LGDE dictionary $W(k, t)$ both with a maximum of 150 discovered keywords. We perform hyperparameter tuning to obtain the optimal dictionaries but only evaluate the performance of the discovered words $W(\epsilon) \backslash W_{0}$ and $W(k, t) \backslash W_{0}$, as our human-coded train data was collected using the seed dictionary $W_{0}$ (see Table 6 in the Appendix for optimal hyperparameters). To assess the discovered words, three domain experts independently carried out blind annotation of whether discovered terms obtained by both methods (ordered randomly) are suitable to be used as a keyword to search for conspiracyrelated content on 4chan as defined above.

### 4.3 Results

We first evaluate the performance of the two dictionaries using our human-coded test data and we find that the LGDE dictionary $W(k, t)$ has the highest macro $F_{1}$-Score of 0.629 , which is achieved with both higher macro precision and recall than the thresholding-based dictionary $W(\epsilon)$ (Table 5). As expected, the expert-selected seed dictionary has the highest precision but LGDE improves the $F_{1}$ score significantly, in contrast to thresholding.

Our evaluation of the discovered words shows that LGDE discovers significantly more conspiracy-related keywords according to the majority vote of three independent domain experts ( $p<0.005$, Fisher's exact test). In particular, $30.2 \%$ of the words discovered by LGDE are

![](https://cdn.mathpix.com/cropped/2024_06_04_1ad3bf77941f26242fa0g-09.jpg?height=962&width=1562&top_left_y=204&top_left_x=247)

Table 4: Discovered words in conspiracy-related data. Words in bold are classified as conspiracy-related by the majority vote of three independent domain experts $(30.2 \%$ of the words discovered by LGDE and $18.9 \%$ of the words discovered by thresholding). LGDE discovered significantly more conspiracy-related words than thresholdig ( $p<0.005$, Fisher's exact test).

|  | $P$ | $R$ | $F_{1}$ |
| :--- | :---: | :---: | :---: |
| Seed dictionary | $\mathbf{0 . 7 6 9}$ | 0.559 | 0.529 |
| Thresholding | 0.595 | 0.609 | 0.558 |
| LGDE | 0.700 | $\mathbf{0 . 6 2 1}$ | $\mathbf{0 . 6 2 9}$ |

Table 5: Test macro scores for seed and $F_{1}$-optimised discovered dictionaries in application to conspiracyrelated content.

found to be conspiracy-related in contrast to only $18.9 \%$ of the words discovered by thresholding (Table 4). A qualitative assessment of the terms discovered by both methods shows that the quantitative improvement coincides with diverging semantic content of the discovered words. As in the literature-based seed dictionary, many of the terms discovered via thresholding are formal words relating to parts of the population, political philosophies, individuals, or entities. The words discovered via LGDE, on the other hand, are more closely associated with 4chan users' platform-specific rhetoric. They include the anti-Semitic jargon that might seem unremarkable in other contexts, such as "golem" or "good goy" and key vocabulary of related conspiracy narratives, for example "globoho*o", "predictive programming" or "MKUltra". LGDE results also include more multi-word phrases useful for the identification of conspiracy-related posts, such as "Jewish plan" or "Israeli puppet", whose individual components would have been less indicative of conspiracy-related content.

## 5 Conclusion and Discussion

In this work, we have proposed the LGDE framework for data-driven discovery of new keywords that are semantically similar to a pre-defined seed dictionary. Using tools from manifold learning and network science allows us to capture the complex nonlinear geometry of word embeddings and to not only find most similar words but also chains of word associations.

On the task of expanding a seed dictionary of the most frequent hate speech-related keywords, we found that LGDE performs significantly better than a simple thresholding-based approach. In particular, LGDE can take advantage of higher dimensional word embeddings (with richer information in principle) as indicated by higher $F_{1}$-scores and likelihood ratios for $r=300$-dimensional word embeddings. In contrast, the thresholding-
based approach performs worse as the dimensionality is increased. This suggests that LGDE as a manifold learning method better captures the complex nonlinear geometry of high dimensional word embedding spaces, whereas a thresholding-based approach suffers more from the curse of dimensionality. Moreover, in a real-world data collection use case from communication science on a corpus of conspiracy-related 4chan posts, LGDE outperforms thresholding in expanding a curated list of conspiracy-related keywords by platform-specific keywords. Across tasks, the terms provided by LGDE contained a larger variety of formal and informal language, resulting in a heterogeneous set of keywords that represent the neologisms and informal register specific to the corpora under study. This makes LGDE especially informative in cases where researchers cannot assume a comprehensive knowledge of the lexical variety of the object of study.

Studies suggest that the space of word embeddings is at least close to a manifold, e.g., a 'pinched' manifold (Jakubowski et al., 2020). The construction of a $\mathrm{CkNN}$ graph from the word vector embeddings can capture the geometry of complex non-linear manifolds in a manner that is consistent with the geometry of the original space. In particular, Berry and Sauer (2019) show that the $\mathrm{CkNN}$ graph is consistent in the sense that its unnormalised graph Laplacian, which determines the properties of graph diffusions, converges to the Laplace-Beltrami operator in the limit of large data. This preservation of diffusion properties further justifies the subsequent use of the severability method for local community detection (Yu et al., 2020), which is also based on graph diffusion.

## 6 Limitations and future work

We list some limitations in the current work on which we would like to expand in future research. While the experiments employ only English language data, our method is general and the application could be useful for similar data in other languages. It would also be interesting to see the adaptation and evolution of terminology in other domains, e.g., in the scientific literature in relation with the emergence of new sub-disciplines or research areas. Although qualitative assessment is invaluable, the process of manual annotation can be slow and costly and, in particular, labelling hate speech- or conspiracy-related content can pose severe mental health risks to human annotators. In future work, we would like to use LGDE as part of mixed methods approaches (Puschmann et al., 2022) applied to other specialised domains. Specifically, it would be interesting to evaluate the applicability of LGDE to specialised word disambiguation tasks since we observe preliminary evidence of polysemy being captured through overlapping semantic communities (Yu et al., 2020).

## Data and code availability

The hate speech data is publicly available at http s://github.com/jing-qian/A-Bench mark-Dataset-for-Learning-to-Int ervene-in-Online-Hate-Speech and the 4 chan data may be made available upon request. Code for local community detection with severability is available at https://github .com/barahona-research-group/sev erability. An implementation of LGDE and code for all the results and figures presented in this study is available at https://github.com/b arahona-research-group/LGDE.

## Acknowledgements

This study has benefited from discussions in the Advancing Cross-Platform Research in Political Social Media Communication workshop at the Weizenbaum Institute in 2022 and from the first author's presentation in the Computational Methods Division at the International Communication Association Conference in 2023. We thank our student assistants Joana Becker, Dominik Hokamp, Angelika Juhászfor and Katharina Sawade for their invaluable work of labelling benchmark data of conspiracy-related 4chan posts. We also thank Yun William Yu and Angad Khurana for helpful discussions on the implementation of severability and Asem Alaa for valuable suggestions on the Python packaging of the code for this project.

## Funding

Mauricio Barahona acknowledges support from EPSRC grant EP/N014529/1 supporting the EPSRC Centre for Mathematics of Precision Healthcare. Dominik Schindler acknowledges support from the EPSRC (PhD studentship through the Department of Mathematics at Imperial College London) and the Weizenbaum Institute (Research Fellowship). Annett Heft, Kilian Buehling and

Xixuan Zhang acknowledge support by grants from the German Federal Ministry of Education and Research (grant numbers 13N16049 [in the context of the call for proposals Civil Security Societies in Transition] and 16DII135 [in the context of the Weizenbaum Institute]).

## References

M. Tarik Altuncu, Erik Mayer, Sophia N. Yaliraki, and Mauricio Barahona. 2019. From free text to clusters of content in health records: An unsupervised graph partitioning approach. Applied Network Science, 4(1):23.

Michael Amsler. 2020. Using Lexical-Semantic Concepts for Fine-Grained Classification in the Embedding Space. Ph.D. thesis, University of Zurich.

Wouter van Atteveldt, Dafne van Kuppevelt, and Kasper Welbers. 2022. CAVA: An open source $\mathrm{R}$ toolkit for dictionary Coherence, Adaptation, Validation, and Analysis.

Tyrus Berry and Timothy Sauer. 2019. Consistent manifold representation for topological data analysis. Foundations of Data Science, $1(1): 1-38$.

Rishi Bommasani, Kelly Davis, and Claire Cardie. 2020. Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4758-4781, Online. Association for Computational Linguistics.

Axel Bruns, Stephen Harrington, and Edward Hurcombe. 2020. 'Corona? 5G? or both?': The dynamics of COVID-19/5G conspiracy theories on Facebook. Media International Australia, 177(1):12-29.

Kilian Buehling. 2022. fouRplebsAPI: R package for accessing 4 chan posts via the 4 plebs.org API.

Daniël De Zeeuw, Sal Hagen, Stijn Peeters, and Emilija Jokubauskaite. 2020. Tracing normiefication: A cross-platform analysis of the QAnon conspiracy theory. First Monday.
Daniël De Zeeuw and Marc Tuters. 2020. Teh Internet Is Serious Business. Cultural Politics, $16(2): 214-232$.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.

Fernando Diaz, Bhaskar Mitra, and Nick Craswell. 2016. Query expansion with locallytrained word embeddings. arXiv preprint arXiv:1605.07891.

Nicholas Dingwall and Christopher Potts. 2018. Mittens: An Extension of GloVe for Learning Domain-Specialized Representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 212217, New Orleans, Louisiana. Association for Computational Linguistics.

Mojtaba Farmanbar, Nikki Van Ommeren, and Boyang Zhao. 2020. Semantic search with domain-specific word-embedding and production monitoring in fintech. In Proceedings of the 28th International Conference on Computational Linguistics: System Demonstrations, pages 28-33.

Nazanin Firoozeh, Adeline Nazarenko, Fabrice Alizon, and Béatrice Daille. 2020. Keyword extraction: Issues and methods. Natural Language Engineering, 26(3):259-291.

Amanda Garry, Samantha Walther, Rukaya Rukaya, and Ayan Mohammed. 2021. QAnon Conspiracy Theory: Examining its Evolution and Mechanisms of Radicalization. Journal for Deradicalization, (26):152-216.

Joobin Gharibshah, Jakapun Tachaiya, Arman Irani, Evangelos E. Papalexakis, and Michalis Faloutsos. 2022. IKEA: Unsupervised domain-specific keyword-expansion. In 2022 IEEE/ACM International Conference on

Advances in Social Networks Analysis and Mining (ASONAM), pages 496-503.

Annett Heft, Kilian Buehling, Xixuan Zhang, Dominik J. Schindler, and Miriam Milzner. 2023. Challenges of and approaches to data collection across platforms and time: Conspiracyrelated digital traces as examples of political contention. Journal of Information Technology \& Politics, $0(0): 1-17$.

Rolf Jagerman, Honglei Zhuang, Zhen Qin, Xuanhui Wang, and Michael Bendersky. 2023. Query Expansion by Prompting Large Language Models.

Alexander Jakubowski, Milica Gasic, and Marcus Zibrowius. 2020. Topology of Word Embeddings: Singularities Reflect Polysemy. In Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics, pages 103113, Barcelona, Spain (Online). Association for Computational Linguistics.

Ulrike Klinger, W. Lance Bennett, Curd Benjamin Knüpfer, Franziska Martini, and Xixuan Zhang. 2022. From the fringes into mainstream politics: Intermediary networks and movementparty coordination of a global anti-immigration campaign in Germany. Information, Communication \& Society, $0(0): 1-18$.

Saar Kuzi, Anna Shtok, and Oren Kurland. 2016. Query Expansion Using Word Embeddings. In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM '16, pages 1929-1932, New York, NY, USA. Association for Computing Machinery.

Yongho Lee, So Young Kim, Inseok Song, Yongtae Park, and Juneseuk Shin. 2014. Technology opportunity identification customized to the technological capability of SMEs through two-stage patent analysis. Scientometrics, $100(1): 227-244$.

Yibin Lei, Yu Cao, Tianyi Zhou, Tao Shen, and Andrew Yates. 2024. Corpus-Steered Query Expansion with Large Language Models. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), pages 393-401, St. Julian's, Malta. Association for Computational Linguistics.
Zijing Liu and Mauricio Barahona. 2020. Graphbased data clustering via multiscale community detection. Applied Network Science, 5(1):3.

Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order into Text. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 404-411, Barcelona, Spain. Association for Computational Linguistics.

Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe: Global Vectors for Word Representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532-1543, Doha, Qatar. Association for Computational Linguistics.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations.

Cornelius Puschmann, Hevin Karakurt, Carolin Amlinger, Nicola Gess, and Oliver Nachtwey. 2022. RPC-Lex: A dictionary to measure German right-wing populist conspiracy discourse online. Convergence, 28(4):1144-1171.

Jing Qian, Anna Bethke, Yinyin Liu, Elizabeth Belding, and William Yang Wang. 2019. A Benchmark Dataset for Learning to Intervene in Online Hate Speech. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4755-4764, Hong Kong, China. Association for Computational Linguistics.

Yifan Qian, Paul Expert, Pietro Panzarasa, and Mauricio Barahona. 2021. Geometric graphs from data to aid classification tasks with Graph Convolutional Networks. Patterns, 2(4).

Dwaipayan Roy, Debjyoti Paul, Mandar Mitra, and Utpal Garain. 2016. Using Word Embeddings for Automatic Query Expansion.

Dominik Schlechtweg, Barbara McGillivray, Simon Hengchen, Haim Dubossarsky, and Nina Tahmasebi. 2020. Semeval-2020 task 1: Unsupervised lexical semantic change detection. arXiv preprint arXiv:2007.11464.

Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. 2015. Evaluation methods for unsupervised word embeddings. In Proceedings of the 2015 conference on empirical methods in natural language processing, pages 298-307.

Erich Schubert. 2021. A Triangle Inequality for Cosine Similarity. In Similarity Search and Applications, Lecture Notes in Computer Science, pages 32-44, Cham. Springer International Publishing.

Hinrich Schütze, Christopher D Manning, and Prabhakar Raghavan. 2008. Introduction to information retrieval, volume 39. Cambridge University Press Cambridge.

Anke Stoll, Lena Wilms, and Marc Ziegele. 2023. Developing an Incivility Dictionary for German Online Discussions - a Semi-Automated Approach Combining Human and Artificial Knowledge. Communication Methods and Measures, $0(0): 1-19$.

Ming-Feng Tsai and Chuan-Ju Wang. 2014. Financial keyword expansion via continuous word vector representations. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages $1453-1458$.

H J van der Helm and E A Hische. 1979. Application of Bayes's theorem to results of quantitative clinical chemical determinations. Clinical Chemistry, 25(6):985-988.

Ivan Vulić, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, and Anna Korhonen. 2020. Probing pretrained language models for lexical semantics. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7222-7240, Online. Association for Computational Linguistics.

Liang Wang, Nan Yang, and Furu Wei. 2023. Query2doc: Query Expansion with Large Language Models.

Xicheng Yin, Hongwei Wang, Pei Yin, Hengmin Zhu, and Zhenyu Zhang. 2020. A cooccurrence based approach of automatic keyword expansion using mass diffusion. Scientometrics, 124(3):1885-1905.
Yun William Yu, Jean-Charles Delvenne, Sophia N. Yaliraki, and Mauricio Barahona. 2020. Severability of mesoscale components and local time scales in dynamical networks. (arXiv: 2006.02972).

Jing Zeng and Mike S. Schäfer. 2021. Conceptualizing "Dark Platforms". Covid-19-Related Conspiracy Theories on $8 \mathrm{kun}$ and Gab. Digital Journalism, 9(9):1321-1343.

Zhi Zheng, Kai Hui, Ben He, Xianpei Han, Le Sun, and Andrew Yates. 2020. Bert-qe: contextualized query expansion for document reranking. arXiv preprint arXiv:2009.07258.
