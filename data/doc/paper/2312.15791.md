# SantaQlaus: A resource-efficient method to leverage quantum shot-noise for optimization of variational quantum algorithms 

Kosuke Ito $^{1 *}$ and Keisuke Fujii ${ }^{1,2,3 \dagger}$<br>${ }^{1}$ Center for Quantum Information and Quantum Biology,<br>International Advanced Research Institute, Osaka University, Osaka 560-8531, Japan<br>${ }^{2}$ Graduate School of Engineering Science, Osaka University,<br>1-3 Machikaneyama, Toyonaka, Osaka 560-8531, Japan<br>${ }^{3}$ RIKEN Center for Quantum Computing (RQC), Hirosawa 2-1, Wako, Saitama 351-0198, Japan


#### Abstract

We introduce SantaQlaus, a resource-efficient optimization algorithm tailored for variational quantum algorithms (VQAs), including applications in the variational quantum eigensolver (VQE) and quantum machine learning (QML). Classical optimization strategies for VQAs are often hindered by the complex landscapes of local minima and saddle points. Although some existing quantum-aware optimizers adaptively adjust the number of measurement shots, their primary focus is on maximizing gain per iteration rather than strategically utilizing quantum shot-noise (QSN) to address these challenges. Inspired by the classical Stochastic AnNealing Thermostats with Adaptive momentum (Santa) algorithm, SantaQlaus explicitly leverages inherent QSN for optimization. The algorithm dynamically adjusts the number of quantum measurement shots in an annealing framework: fewer shots are allocated during the early, high-temperature stages for efficient resource utilization and landscape exploration, while more shots are employed later for enhanced precision. Numerical simulations on VQE and QML demonstrate that SantaQlaus outperforms existing optimizers, particularly in mitigating the risks of converging to poor local optima, all while maintaining shot efficiency. This paves the way for efficient and robust training of quantum variational models.


## I. INTRODUCTION

Variational quantum algorithms (VQAs) are promising methods as potential applications for noisy intermediatescale quantum (NISQ) devices [1, 2]. In VQAs, the loss function is calculated using quantum circuits, and variational parameters of the circuit are optimized via classical computing. Various VQA paradigms have been introduced [2], including the variational quantum eigensolver (VQE) for ground-state energy approximation [3-6] and others such as QAOA [7-9] and quantum machine learning (QML) [10-17]. In QML, quantum neural networks (QNNs) are expected to offer advantages by operating in a feature space that is classically infeasible. While variational (explicit) QNNs can be integrated into quantum kernel methods (implicit model) [18], their distinct importance is underscored by suggestions that they may excel in generalization performance over the kernel methods [19]. When making predictions, quantum kernel models require evaluation of the kernel between new input data and all training data. Variational QNNs simply need an evaluation of the input data. Notably, in certain QNN classes, this evaluation can be performed using a classical surrogate [20]. Consequently, the efficient training of such variational models gains significant importance.

Classical optimization in VQAs faces multiple challenges that influence the efficiency and reliability of the optimization process. Barren plateau phenomena, characterized by exponentially vanishing gradients, hinder[^0]

trainability [21-28]. Likewise, the landscape of local minima and saddle points introduces additional roadblocks for optimization $[29,30]$. Although methodologies to mitigate barren plateaus are a topic of ongoing investigation, specific choices of ansatz and cost functions can help in this regard $[31-34]$. A core aspect of our research focuses on tackling the issues associated with saddle points and suboptimal local minima as well as efficient resource usage.

Generic classical optimization algorithms, such as Adam [35], Nelder-Mead [36], Powell [37], and SPSA [38] have been widely used in VQAs $[6,13,39-41]$. In addition to these, quantum-aware optimization schemes have been introduced [40, 42-56]. Interestingly, earlier works has noted that low levels of various types of stochastic noise can positively affect the optimization process in VQAs [34, 47, 57-59]. Especially, in VQAs, the evaluation of expectation values inherently includes statistical noise from quantum measurements, which is called quantum shot-noise (QSN). Theoretical analysis supports the idea that QSN can assist in escaping the aforementioned optimization traps [60]. Nevertheless, current optimization algorithms tend to capitalize on positive effects of QSN only implicitly.

In addition, effective resource allocation during optimization is critical for the practical application of VQAs. The emphasis should be on effectively utilizing classical data derived from quantum measurements, instead of merely aiming for precise expectation values [40, 47, 52, 61]. Existing techniques adjust the number of measurement shots to balance resource use, but often without sufficient regard for the risk of encountering saddle points or converging to poor local optima $[40,42,50,52,62,63]$.

Motivated by these observations, we address the following question: Can inherent stochasticity of quantum measurements be strategically leveraged in the optimization process of VQAs in a resource efficient way? In this paper, to explore this avenue, we propose an optimization algorithm Stochastic AnNealing Thermostats with Adaptive momentum and Quantum-noise Leveraging by Adjusted Use of Shots (SantaQlaus). SantaQlaus is inspired by a classical optimizer called Stochastic AnNealing Thermostats with Adaptive momentum (Santa) [64]. Santa employs simulated Langevin diffusion, guided by an annealing thermostat utilizing injected thermal noise, to approach global optimality. A key advantage of Santa is its robustness against noise variations, which aligns well with our objectives.

Our main contribution is an extension of the classical Santa optimizer by integrating the leveraging of QSN, resulting in the SantaQlaus algorithm for the optimization of VQAs. Our proposal seeks to replace the thermal noise in Santa with inherent QSN. We design SantaQlaus to adaptively adjust the number of shots to ensure the variance of the QSN aligns with the thermal noise utilized in Santa, thus enhancing the efficiency of loss function optimization through annealed thermostats. Specifically, during the annealing process, fewer shots are required in the early, high-noise stages, while more shots are allocated to the later, low-noise stages, thus demanding more accurate evaluations. This strategy ensures efficient use of resources without sacrificing accuracy.

Our algorithm is applicable to a wide range of VQAs, especially when the gradient estimator for the loss function shows asymptotic normality. Our method encompasses a general QML framework, accommodating both linear and non-linear dependencies in loss functions, such as mean squared error (MSE), offering flexibility in selecting suitable loss functions for various QML tasks. Additionally, it is compatible with data-independent VQAs like VQE and QAOA. Indeed, we show the asymptotic normality and its explicit form of mini-batch gradient estimators for linear and quadratic loss functions, extendable to general polynomial loss functions. From this analysis, we can compute the appropriate number of shots used in our algorithm.

Through numerical simulations on VQE and QML tasks, we demonstrate the superiority of SantaQlaus over established optimizers like Adam and gCANS, showcasing its efficiency in reducing the number of shots required and improving accuracy.

The remainder of this paper is structured as follows. Sec. II presents a framework for general QML loss functions in VQAs and the evaluation of the associated gradient estimators. In Sec. III, we provide a comprehensive review of the classical Santa algorithm, which lays the groundwork for the method we introduce. Sec. IV introduces the SantaQlaus algorithm, the principal contribution of this study, beginning with the establishment of the concept of asymptotic normality for the gradient estimators. Sec. V details a series of targeted numerical simulations to assess the performance of the SantaQlaus algorithm, offering empirical evidence to validate its efficacy. The paper concludes with Section VI, summarizing key findings and suggesting avenues for future research.

## II. FRAMEWORK

## A. Loss functions for VQAs

Many VQAs are formulated to achieve a goal by minimizing a loss function which is computed by a quantum device with classical parameters to be optimized classically. In this section, we present a general framework for the loss functions in such VQAs mainly focusing on QML, in a similar manner to Refs. [10, 62]. We remark that a wide variety of VQAs can be treated in the framework of QML, including VQE and QAOA just by disregarding the data dependency. The loss functions we explore are formulated to embrace the wide-ranging nature of QML tasks, explicitly accommodating both linear and non-linear dependencies on the expectation values. As non-linear loss functions are prevalent in machine learning and the choice of loss functions critically influence task performance, it is imperative to ensure the generality of our framework to encompass such functions.

In QML, we have a set of quantum states $\mathcal{S}=$ $\left\{\rho\left(\boldsymbol{x}_{1}\right), \cdots, \rho\left(\boldsymbol{x}_{N}\right)\right\}$ used for training specified by a set of input data $\mathcal{D}=\left\{\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{N}\right\}$. Both QC and QQ categories of QML can be put into this formulation, where QC (QQ) aims to learn a classical (quantum) dataset utilizing a quantum algorithm [65-67]. For QC category, the target dataset is the classical data $\mathcal{D}$, and $\mathcal{S}$ is a set of the data-encoded quantum states. Hence, the choice of the data-encoding feature map $\boldsymbol{x} \mapsto \rho(\boldsymbol{x})$ from input data $\boldsymbol{x}$ into quantum feature $\rho(\boldsymbol{x})$ is important, though it is not discussed in detail in this paper. For QQ purpose, $\boldsymbol{x}_{i}$ is regarded as a specification of each target data quantum state, such as classical descriptions of quantum circuits which generate the states [68].

In variational $\mathrm{QML}$, a quantum model is given by a parameterized quantum channel $\mathcal{M}_{\boldsymbol{\theta}}$, and an observable $H$ to be measured. In general, we can consider data dependence of the channel as $\rho(\boldsymbol{x}, \boldsymbol{\theta})=\mathcal{M}_{\boldsymbol{\theta}}[\boldsymbol{x}](\rho(\boldsymbol{x}))$, as in data re-uploading models [69-71]. An observable is given by a hermitian matrix which can be decomposed into directly measured observables $h_{j}(\boldsymbol{x})$ as

$$
\begin{equation*}
H(\boldsymbol{x}, \boldsymbol{w})=\sum_{j=1}^{J} w_{j} c_{j}(\boldsymbol{x}) h_{j}(\boldsymbol{x}) \tag{1}
\end{equation*}
$$

where the observable can be dependent on data $\boldsymbol{x}$ and weight vector $\boldsymbol{w}$ which is also optimized in general. Then, the loss function to be minimized for a given task is given as a $p_{i}$ weighted average

$$
\begin{equation*}
L(\boldsymbol{\theta}, \boldsymbol{w})=\sum_{i=1}^{N} p_{i} \ell\left(\boldsymbol{x}_{i}, E\left(\boldsymbol{x}_{i}, \boldsymbol{\theta}, \boldsymbol{w}\right)\right) \tag{2}
\end{equation*}
$$

where $\ell$ is a generic function of the data and the expectation value

$$
\begin{align*}
E(\boldsymbol{x}, \boldsymbol{\theta}, \boldsymbol{w}) & :=\operatorname{Tr}\left[\mathcal{M}_{\boldsymbol{\theta}}[\boldsymbol{x}](\rho(\boldsymbol{x})) H(\boldsymbol{x}, \boldsymbol{w})\right] \\
& =\sum_{j=1}^{J} w_{j} c_{j}(\boldsymbol{x}) \operatorname{Tr}\left[\mathcal{M}_{\boldsymbol{\theta}}[\boldsymbol{x}](\rho(\boldsymbol{x})) h_{j}(\boldsymbol{x})\right] \\
& =: \sum_{j=1}^{J} w_{j} c_{j}(\boldsymbol{x})\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}} \tag{3}
\end{align*}
$$

Additionally, some regularization term $\lambda f(\boldsymbol{\theta}, \boldsymbol{w})$ with a hyperparameter $\lambda$ may be added to the loss function to enhance the generalization performance. Here, the dependence of the observable on data $\boldsymbol{x}$ is considered for the sake of generality. For example, such a loss function appears in a task to make the output pure state $\rho(\boldsymbol{x}, \boldsymbol{\theta})=|\phi(\boldsymbol{x}, \boldsymbol{\theta})\rangle\langle\phi(\boldsymbol{x}, \boldsymbol{\theta})|$ of the model close to the correct output state $\rho_{x}^{\text {out }}$, where the loss is given by the average fidelity $\sum_{i=1}^{N}\left\langle\phi\left(\boldsymbol{x}_{i}, \boldsymbol{\theta}\right)\left|\rho_{\boldsymbol{x}_{i}}^{\text {out }}\right| \phi\left(\boldsymbol{x}_{i}, \boldsymbol{\theta}\right)\right\rangle / N[72,73]$. This is the case where $\ell(\boldsymbol{x}, E)=E, H(\boldsymbol{x})=\rho_{\boldsymbol{x}}^{\text {out }}$ and $p_{i}=1 / N$ without $\boldsymbol{w}$. Variational quantum error correction (VQEC) $[74,75]$ is another example, where the loss function is given by the fidelity between the error corrected (possibly mixed) output state and the ideal pure state.

This framework is applicable to both supervised and unsupervised learning. In the context of supervised machine learning, we associate each input data point $\boldsymbol{x}_{i}$ with a label $y_{i}=y\left(\boldsymbol{x}_{i}\right)$. It should be noted that the functions $H(\boldsymbol{x}, \boldsymbol{w})$ and $\ell(\boldsymbol{x}, E)$ implicitly depend on these labels, as they are functions of the data points $\boldsymbol{x}$ which include label information via $y(\boldsymbol{x})$. This label-dependency will be considered in the definitions and usage of these functions throughout our discussion. A wide range of the loss functions of VQAs are covered by this form. A few concrete examples are found in the tasks we employ for numerical simulations in Sec. V. A comprehensive review of various loss functions in QML can be found in Ref. [62]. For VQAs not involving input data, such as VQE and QAOA, the framework applies by regarding just a single input data to specify the input state being considered [10]. In VQE, $\boldsymbol{w}$ is fixed and not optimized.

The gradient of the loss function reads

$$
\begin{align*}
\frac{\partial L}{\partial \theta_{j}} & =\sum_{i=1}^{N} p_{i} \frac{\partial \ell}{\partial E} \frac{\partial E}{\partial \theta_{j}}  \tag{4}\\
\frac{\partial L}{\partial w_{j}} & =\sum_{i=1}^{N} p_{i} \frac{\partial \ell}{\partial E} \frac{\partial E}{\partial w_{j}} \tag{5}
\end{align*}
$$

by the chain rule. The derivative with respect to a weight parameter $\frac{\partial E}{\partial w_{j}}$ is computed as

$$
\begin{equation*}
\frac{\partial E}{\partial w_{j}}=c_{j}(\boldsymbol{x})\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}} \tag{6}
\end{equation*}
$$

On the other hand, the derivative $\frac{\partial E}{\partial \theta_{j}}$ is nontrivial in general. Because the expectation value is estimated from finite samples of the measurement outcomes, the simple numerical differentiation becomes inaccurate due to the statistical errors [76]. Instead, in our model, we assume that this derivative can be computed by an analytic form via a parameter-shift rule $[10,77,78]$

$$
\begin{equation*}
\frac{\partial E}{\partial \theta_{j}}=\sum_{k=1}^{R_{j}} a_{k} E\left(\boldsymbol{x}, \boldsymbol{\theta}+\epsilon_{j, k} \boldsymbol{e}_{j}, \boldsymbol{w}\right) \tag{7}
\end{equation*}
$$

where $\boldsymbol{e}_{j}$ is the unit vector in the $j$-th component direction, $a_{k}, \epsilon_{j, k}$ and $R_{i}$ are constants determined by the model. In fact, a parameter-shift rule (PSR) holds for a wide range of the model $\mathcal{M}_{\boldsymbol{\theta}}$ given by parametric unitary gates. Especially, if the parameter is given by the gate $U_{j}\left(\theta_{j}\right)=\exp \left[-i \theta_{j} A_{j} / 2\right]$ with $A_{j}^{2}=I$, we have $[10,78]$

$$
\begin{equation*}
\frac{\partial E}{\partial \theta_{j}}=\frac{E\left(\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2} e_{j}, \boldsymbol{w}\right)-E\left(\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2} \boldsymbol{e}_{j}, \boldsymbol{w}\right)}{2} \tag{8}
\end{equation*}
$$

In this paper, we assume that two-point PSR (8) holds for all the partial derivatives with respect to $\theta_{j}$ in our model.

In the following, unless necessary, we omit $\boldsymbol{w}$ for brevity. We call the simplest kind of a loss function with $\ell(\boldsymbol{x}, E)=E$ a linear loss function. Linear loss functions are used in various QML tasks such as quantum auto encoder $[31,79]$ and VQEC $[74,75]$, as well as the energy expectation value used in VQE and QAOA. Non-linear loss functions are also common in QML, such as MSE and the cross entropy (CE) loss functions. Especially, polynomial loss functions given below are amenable in QML due to the tractability of constructing unbiased estimator:

$$
\begin{equation*}
\ell(\boldsymbol{x}, E)=\sum_{n=0}^{D} a_{n}(\boldsymbol{x}) E^{n} \tag{9}
\end{equation*}
$$

where $D$ is the degree of the polynomial. For MSE given the label $y(\boldsymbol{x})$ for the data $\boldsymbol{x}$, the function $\ell_{\text {MSE }}$ is given as $\ell_{\text {MSE }}(\boldsymbol{x}, E(\boldsymbol{x}, \boldsymbol{\theta}))=(y(\boldsymbol{x})-\tilde{y}(E(\boldsymbol{x}, \boldsymbol{\theta})))^{2}$, where $\tilde{y}(E(\boldsymbol{x}, \boldsymbol{\theta}))$ is a prediction by the model. Typically, the prediction is given by the expectation value of an observable itself $\tilde{y}(E(\boldsymbol{x}, \boldsymbol{\theta}))=E(\boldsymbol{x}, \boldsymbol{\theta})$. In this case, MSE is a kind of the polynomial loss function with $a_{0}(\boldsymbol{x})=y(\boldsymbol{x})^{2}$, $a_{1}(\boldsymbol{x})=-2 y(\boldsymbol{x}), a_{2}(\boldsymbol{x})=1$, and $D=2$. More general polynomial loss functions are actually used in classical machine learning [80]. Ref. [80] introduces Taylor-CE, a truncated Taylor series expansion of the CE loss, with the truncation degree serving as a hyperparameter. Notably, Taylor-CE has been demonstrated to outperform its counterparts in various multiclass classification tasks with label noise, provided that the truncation degree is selected appropriately.

The gradient of a polynomial loss function is given as

$$
\begin{aligned}
& \frac{\partial \ell}{\partial E}(\boldsymbol{x}, E(\boldsymbol{x}, \boldsymbol{\theta})) \\
= & \sum_{n=1}^{D} n a_{n}(\boldsymbol{x}) E(\boldsymbol{x}, \boldsymbol{\theta})^{n-1}
\end{aligned}
$$

$$
\begin{align*}
& =\sum_{n=1}^{D} n a_{n}(\boldsymbol{x})\left(\sum_{j} w_{j} c_{j}(\boldsymbol{x})\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right)^{n-1} \\
& =\sum_{n=1}^{D} n a_{n}(\boldsymbol{x}) \\
& \sum_{b_{1}+b_{2}+\cdots+b_{J}=n-1}\binom{n-1}{\boldsymbol{b}} \prod_{j}\left(w_{j} c_{j}(\boldsymbol{x})\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right)^{b_{j}} \tag{10}
\end{align*}
$$

where $\binom{n-1}{b}:=\frac{(n-1)!}{b_{1}!b_{2}!\cdots b_{J}!}$. Thus, computing the derivative with respect to $\theta_{j}\left(w_{j}\right)$ for $D \geq 3(D \geq 2)$ needs an estimate of $\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}^{n}$ with $n \geq 2$. For MSE, the derivative with respect to the weight $w_{j}$ needs an estimate of the squared expectation value.

## B. Shot allocation

We must decide how to allocate the number of shots to use for the estimation of multiple terms $\left\langle h_{j}(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}$, taking into account which terms can be measured simultaneously. Several strategies have been proposed for the efficient measurement of multiple observables [4, 6, 81-89]. One simple way is to allocate the shots proportionally to the weight of each simultaneously measurable group deterministically or randomly [42]. The weighted random sampling (WRS) achieves an unbiased estimates of the whole loss function even with few number of total shots [42], while weighted deterministic sampling (WDS) may be favorable if the observables are grouped into few groups with similar weights. For simplicity, let each $h_{j}(\boldsymbol{x})$ denote an observable composed of a single group with unit operator norm. Then, we suppose that the number of shots $s_{i, j}$ to measure $h_{j}\left(\boldsymbol{x}_{i}\right)$ is distributed following some probability distribution $P\left(s_{i, j}\right)$ in general. Care is needed to estimate a power of an expectation value $\left\langle h_{j}\left(\boldsymbol{x}_{i}\right)\right\rangle^{n}$, as the power of a sample average is not an unbiased estimator because powers of each single sample introduce the bias. In our framework, based on the U-statistic formalism [62,90], an unbiased estimator of $\left\langle h_{j}\left(\boldsymbol{x}_{i}\right)\right\rangle^{n}$ is obtained as

$$
\begin{equation*}
\hat{\mathcal{E}}_{i, j, n}=\frac{1}{\mathbb{E}\left[\binom{s_{i, j}}{n}\right]} \sum_{1 \leq k_{1}<k_{2}<\cdots<k_{n} \leq s_{i, j}} \prod_{l=1}^{n} r_{i, j, k_{l}} \tag{11}
\end{equation*}
$$

where $r_{i, j, k}$ denotes the outcome of $k$-th measurement of $h_{j}\left(\boldsymbol{x}_{i}\right)$, and $\mathbb{E}[X]$ denotes the expectation value of $X$.

## C. Mini-batch gradient

This subsection discusses the implementation and benefits of the mini-batch gradient approach in the context of quantum machine learning, contrasting it with the random shot allocation strategy. A recent optimizer, Refoqus, as mentioned in Ref. [62], incorporates a unique strategy wherein the number of shots is randomly allocated among data points. This allocation is based on the weight of each term and is an extension of Rosalin [42] designed for VQE. Consequently, the data points under evaluation are randomly chosen with replacement during the estimation of each gradient component. The number of data points evaluated is autonomously determined through this method.

Despite providing an unbiased gradient estimator that respects weights, this strategy has potential pitfalls for machine learning applications. Firstly, by independently selecting random data points for each gradient component, inter-component gradient correlations are overlooked. As a result, the estimated gradient could be noisier compared to when these correlations are considered. Secondly, choosing data points with replacement means that assessing the entire dataset requires more time than without replacement. Furthermore, in common scenarios with a uniform weight $p_{i}=1 / N$, uniformly distributing shots across data points in Refoqus often results in the evaluation of a maximal number of data points for the given shot count. Although such a distribution can minimize the variance of the estimator for a preset shot count, this does not necessarily lead to better optimization performance. This observation mirrors the fact that stochastic gradient descent often outperforms full-batch gradient descent, even though the latter uses the 'true' gradient. In general, the number of data points evaluated at each iteration can have intricate effects on generalization performance, with fewer data points typically yielding superior results.

Consistent with prevalent machine learning practices, we opt for a mini-batch gradient. For simplicity, we consider cases with a uniform weight $p_{i}=1 / N$. In a minibatch strategy, the mini-batch gradient $\nabla \tilde{L}$ of the loss function is evaluated as

$$
\begin{align*}
\frac{\partial \tilde{L}}{\partial \theta_{j}}(\boldsymbol{\theta}) & =\frac{1}{m} \sum_{l=1}^{m} \frac{\partial \ell}{\partial E}\left(\boldsymbol{x}_{i_{l}}, E\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right)\right) \frac{\partial E}{\partial \theta_{j}}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right) \\
& =: \frac{1}{m} \sum_{l=1}^{m} \mathrm{f}_{j}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right) \tag{12}
\end{align*}
$$

Here, a mini-batch $\left\{\boldsymbol{x}_{i_{1}}, \cdots, \boldsymbol{x}_{i_{m}}\right\}$ of size $m$ is chosen randomly from the dataset $\mathcal{D}$ without replacement until the whole dataset is evaluated, at which point it is refreshed. We allocate an equal number of shots for the evaluation of each data point. In cases where the weight $p_{i}$ is not uniform, a more effective strategy would be to allocate the number of shots in accordance with this weight. While this strategy introduces the mini-batch size $m$ as an additional hyperparameter, it can lead to superior performance. Indeed, in our simulations in Sec. V, Refoqus underperforms relative to optimizers that utilize a minibatch gradient, including the one we propose.

## III. STOCHASTIC ANNEALING THERMOSTATS IN CLASSICAL MACHINE LEARNING

In this section, as a preliminary to presenting our algorithm, we discuss Santa [64], a classical optimizer that serves as the foundational basis for our approach. Santa was originally developed as an intermediary between stochastic-gradient Markov chain Monte Carlo (SG-MCMC) methods and stochastic optimization, effectively amalgamating the two paradigms. We start by reviewing the underlying principles of Bayesian sampling and SG-MCMC algorithms, emphasizing their relevance to stochastic optimization, as articulated in Ref. [64].

## A. Bayesian sampling and stochastic optimizations, SG-MCMC algorithms

Stochastic optimization methods aim to obtain optimal parameters for an objective function. Common stochastic optimization methods, such as stochastic gradient descent (SGD), can only find some local minima for non-convex objective functions. On the other hand, the Bayesian approach provides a probabilistic framework, offering not just point estimates but entire distributions over possible parameter values. Here, instead of directly finding the optimal parameters, we estimate the likelihood of the parameters given the data. This probabilistic viewpoint allows for a more exploratory and holistic understanding of the parameter space.

More precisely, the Bayesian approach to machine learning aims to infer the model parameters $\boldsymbol{\theta} \in \mathbb{R}^{d}$, from the posterior given by

$$
\begin{equation*}
p\left(\boldsymbol{\theta} \mid \boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N}\right)=\frac{p(\boldsymbol{\theta}) \prod_{i=1}^{N} p\left(\boldsymbol{x}_{i} \mid \boldsymbol{\theta}\right)}{\int p(\boldsymbol{\theta}) \prod_{j=1}^{N} p\left(\boldsymbol{x}_{j} \mid \boldsymbol{\theta}\right) d \boldsymbol{\theta}} \tag{13}
\end{equation*}
$$

upon observing data $\left\{\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N}\right\}$. Here, $p(\boldsymbol{\theta})$ represents the prior, while $p\left(\boldsymbol{x}_{i} \mid \boldsymbol{\theta}\right)$ denotes the likelihood of data $\boldsymbol{x}_{i}$ given the model parameter $\boldsymbol{\theta}$. Sampling from the Bayesian posterior distribution offers unique advantages. It allows models to express uncertainty about parameter values, potentially leading to more robust and generalizable solutions.

This task can be equivalently framed as sampling from a probability distribution proportional to $p(\boldsymbol{\theta}) \prod_{i=1}^{N} p\left(\boldsymbol{x}_{i} \mid \boldsymbol{\theta}\right)=e^{-L(\boldsymbol{\theta})}$, where the negative logposterior $L(\boldsymbol{\theta})$, is defined as

$$
\begin{equation*}
L(\boldsymbol{\theta})=-\log p(\boldsymbol{\theta})-\sum_{i=1}^{N} \log p\left(\boldsymbol{x}_{i} \mid \boldsymbol{\theta}\right) \tag{14}
\end{equation*}
$$

If $N$ is large, we use a mini-batch stochastic loss function $\tilde{L}_{t}(\boldsymbol{\theta}):=-\log p(\boldsymbol{\theta})-\frac{N}{m} \sum_{j=1}^{m} \log p\left(\boldsymbol{x}_{j_{i}} \mid \boldsymbol{\theta}\right)$ in the same way as the stochastic optimization. The posterior is the same as the Gibbs distribution $\propto e^{-\beta L(\boldsymbol{\theta})}$, with the inverse temperature $\beta=1$ and the potential energy $L(\boldsymbol{\theta})$.
In fact, the tempered Bayesian posterior $\beta \neq 1$ is recognized as a generalized form of the Bayesian posterior [9195]. Lowering the value of $\beta$ to less than 1 has been shown to improve the robustness of convergence [96]. This effect has been further explored within the framework of safeBayesian methods [97-100]. Recent research [101-103] has highlighted the cold posterior effect, wherein sampling from a cold posterior with $\beta>1$ can offer even better generalization in some scenarios. This approach emphasizes regions of the parameter space that are more consistent with both the prior and the data, providing a nuanced balance between fitting the data and not overfitting. More generally, the posterior given as the Gibbs distribution $\propto e^{-\beta L(\boldsymbol{\theta})}$ for general loss function $L$ is called Gibbs posterior. This analogy offers a link between the Bayesian posterior sampling and the stochastic optimization approaches. Particularly, as $\beta$ tends toward infinity, the procedure converges to the maximum a posteriori (MAP) estimation, aiming for the global minima of the loss function $L$ [104]. Thus, sampling from a cold posterior $\propto e^{-\beta L(\boldsymbol{\theta})}$ with an elevated $\beta$ guides us closer to minimizing $L$ globally.

In that sense, the sampling approach can also be applied to optimization of general objective functions $L(\boldsymbol{\theta})$ that extend beyond the negative log-posterior, even when they do not have a clear interpretation related to a posterior. Additionally, it's worth noting that the term $-\log p(\boldsymbol{\theta})$ is translated to a regularization term. Indeed, the well-known $L_{2}$-regularization aligns with the Gaussian prior.

In practice, exact sampling from the posterior is too expensive and we need some approximated sampling method. SG-MCMC approaches offer efficient sampling methods. The basic one is the stochastic gradient Langevin dynamics (SGLD) [105] which updates the parameters as $\boldsymbol{\theta}_{t}=\boldsymbol{\theta}_{t-1}-\eta_{t} \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)+\sqrt{2 \eta_{t} \beta^{-1}} \boldsymbol{\zeta}_{t}$ with the learning rate $\eta_{t}$ and the inverse temperature $\beta$, where $\zeta_{t} \sim \mathcal{N}\left(0, I_{d}\right)$ is the additional noise term drawn from the standard normal distribution. SGLD has been also applied in VQAs [59]. SGLD approximates the (cold) posterior for $\beta=1(\beta>1)$ by simulating the overdamped Langevin dynamics. The stochastic gradient Hamiltonian Monte Carlo (SGHMC) [106] incorporates momentum, which corresponds to the underdamped Langevin diffusion. Given the recognized importance of momentum in deep model training within stochastic optimization [107], its incorporation is a logical progression. Indeed, SGHMC's connection to SGD with momentum was already highlighted in Ref. [106]. Introducing the friction term in SGHMC is crucial to stabilize the target stationary distribution, preventing stochastic noise from blowing the parameters far away. Yet, even with this friction term, SGHMC can deviate from the desired thermal equilibrium distribution, particularly when stochastic noise model is poorly estimated. As remedies, the stochastic gradient Nosé-Hoover thermostat (SGNHT) [108] and its multivariate counterpart (mSGNHT) [109] were proposed, adapting the friction term to emulate the energy
conservation of the Nosé-Hoover thermostat $[110,111]$.

Another important technique is the preconditioning. In the context of stochastic optimization and SG-MCMC, preconditioning is a technique that aims to improve convergence by appropriately transforming the underlying parameter space, thereby using a metric incorporating a geometric structure that fits the problem. For a preconditioned SGD [112-114], the update rule is modified by a preconditioner matrix $P_{t}$ as $\boldsymbol{\theta}_{t}=\boldsymbol{\theta}_{t-1}-\eta_{t} P_{t} \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)$. Adaptive stochastic optimizers such as AdaGrad [115], RMSprop [116], Adam [35], and their variants incorporate adaptive preconditioning by utilizing historical gradient information to adjust the learning rate for each parameter. Preconditioning strategies have also found their way into SG-MCMC algorithms [117-119]. Actually, the significance of judicious preconditioning is widely acknowledged in both realms [112, 117-119].

## B. The classical Santa optimizer

Extending the mSGNHT by incorporating adaptive preconditioning and a simulated annealing scheme on the system temperature, Stochastic AnNealing Thermostats with Adaptive momentum (Santa) was proposed as an optimizer for classical objective functions [64]. Santa algorithm is based on a simulated dynamics of the following stochastic differential equation (SDE) given an inverse temperature $\beta$ :

$$
\left\{\begin{align*}
d \boldsymbol{\theta}= & G_{1}(\boldsymbol{\theta}) \boldsymbol{p} d t \\
d \boldsymbol{p}= & \left(-G_{1}(\boldsymbol{\theta}) \nabla \tilde{L}_{t}(\boldsymbol{\theta})-\boldsymbol{\Xi} \boldsymbol{p}\right) d t \\
& +\left(\frac{1}{\beta} \nabla G_{1}(\boldsymbol{\theta})+G_{1}(\boldsymbol{\theta})\left(\boldsymbol{\Xi}-G_{2}(\boldsymbol{\theta})\right) \nabla G_{2}(\boldsymbol{\theta})\right) d t  \tag{15}\\
& +\sqrt{\frac{2}{\beta}} G_{2}(\boldsymbol{\theta}) d \boldsymbol{w} \\
d \boldsymbol{\Xi}= & \left(\operatorname{diag}\left(\boldsymbol{p}^{2}\right)-\frac{1}{\beta} I\right) d t
\end{align*}\right.
$$

where $\boldsymbol{w}$ is the standard Brownian motion, $G_{1}$ and $G_{2}$ respectively gives preconditioning for $L(\boldsymbol{\theta})$ and the Brownian motion, which encode the respective geometric information. Here, $\nabla G(\boldsymbol{\theta})$ for a matrix $G$ denotes a vector whose $i$-th element is $\sum_{j} \frac{\partial}{\partial \theta_{j}} G_{i, j}(\boldsymbol{\theta})$. Setting $G_{1}=I$ and $G_{2}$ constant reduces to the SDE for mSGNHT [109]. The terms with $\nabla G_{1}(\boldsymbol{\theta})$ and $\nabla G_{2}(\boldsymbol{\theta})$ reflect the spatial variation of the metrics so as to maintain the stationary distribution. Actually, SDE (15) has the target distribution $p_{\beta}(\boldsymbol{\theta})=e^{-\beta L(\boldsymbol{\theta})} / Z_{\beta}$ with the normalization factor $Z_{\beta}$ as its stationary distribution under reasonable assumptions on stochastic noise as we discuss later. A remarkable feature of SDE (15) is that the thermostats $\boldsymbol{\Xi}$ maintain the target stationary distribution irrespective of the detail of stochastic noise. Hence, assuming the ergodicity [120, 121], we obtain approximate samples from the target distribution $p_{\beta}$ after sufficiently long time. Then, in the Santa algorithm, the inverse temperature $\beta$ is slowly annealed towards sufficiently large values (hence low temperature) to explore the parameter space to reach near the global optima of the objective function. After this exploration stage, Santa enters the refinement stage by taking the zero-temperature limit $\beta \rightarrow \infty$ and $\boldsymbol{\Xi}$ is fixed to a "learned value" in the exploration stage. The refinement stage is a stochastic optimization with adaptive preconditioning using a learned friction parameter $\boldsymbol{\Xi}$. Indeed, under mild conditions, the asymptotic convergence of Santa algorithm towards the global optima has been shown [64]. In fact, it is reported that Santa outperforms conventional optimizers such as SGD, SGD with momentum, SGLD, RMSprop, and Adam in several benchmark tasks [64]. Ref. [64] tested Santa on training feedforward and convolutional neural networks on the MNIST dataset as well as training recurrent neural network for the task of sequence modeling on four different polyphonic music sequences of piano. In all cited tasks, Santa demonstrates the highest level of performance.

To numerically implement the parameter updates according to SDE (15), we need approximations. As a simplest Euler scheme introduces relatively high approximation error $[64,122]$, the symmetric splitting scheme (SSS) $[64,122,123]$ is recommended. In Santa, splitting SDE (15), SSS is implemented by solving each of the following sub-SDEs for finite time steps:

$A:\left\{\begin{array}{l}d \boldsymbol{\theta}=G_{1}(\boldsymbol{\theta}) \boldsymbol{p} d t \\ d \boldsymbol{p}=0 \\ d \boldsymbol{\Xi}=\left(\operatorname{diag}\left(\boldsymbol{p}^{2}\right)-\frac{1}{\beta_{t}} I\right) d t\end{array}\right.$,

$B:\left\{\begin{array}{l}d \boldsymbol{\theta}=0 \\ d \boldsymbol{p}=-\boldsymbol{\Xi} \boldsymbol{p} d t, \\ d \boldsymbol{\Xi}=0\end{array}\right.$

$O:\left\{\begin{aligned} d \boldsymbol{\theta} & =0 \\ d \boldsymbol{p} & =-G_{1}(\boldsymbol{\theta}) \nabla \tilde{L}_{t}(\boldsymbol{\theta}) d t \\ & +\left(\frac{1}{\beta_{t}} \nabla G_{1}(\boldsymbol{\theta})+G_{1}(\boldsymbol{\theta})\left(\boldsymbol{\Xi}-G_{2}(\boldsymbol{\theta})\right) \nabla G_{2}(\boldsymbol{\theta})\right) d t \\ & +\sqrt{\frac{2}{\beta_{t}} G_{2}(\boldsymbol{\theta})} d \boldsymbol{w} \\ d \boldsymbol{\Xi} & =0 .\end{aligned}\right.$

For a step size $h$, the solutions are given as

$$
\begin{aligned}
& A:\left\{\begin{array}{l}
\boldsymbol{\theta}_{t}=\boldsymbol{\theta}_{t-1}+G_{1}\left(\boldsymbol{\theta}_{t}\right) \boldsymbol{p}_{t-1} h \\
\boldsymbol{p}_{t}=\boldsymbol{p}_{t-1} \\
\boldsymbol{\Xi}_{t}=\boldsymbol{\Xi}_{t-1}+\left(\operatorname{diag}\left(\boldsymbol{p}_{t-1}^{2}\right)-\frac{1}{\beta_{t}} I\right) h
\end{array}\right. \\
& B:\left\{\begin{aligned}
\boldsymbol{\theta}_{t} & =\boldsymbol{\theta}_{t-1} \\
\boldsymbol{p}_{t} & =\exp \left(-\boldsymbol{\Xi}_{t-1} h\right) \boldsymbol{p}_{t-1} \\
\boldsymbol{\Xi}_{t} & =\boldsymbol{\Xi}_{t-1}
\end{aligned}\right.
\end{aligned}
$$

$$
O:\left\{\begin{align*}
\boldsymbol{\theta}_{t} & =\boldsymbol{\theta}_{t-1}  \tag{16}\\
\boldsymbol{p}_{t} & =\boldsymbol{p}_{t-1}-G_{1}\left(\boldsymbol{\theta}_{t}\right) \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right) h \\
& +\left(\frac{1}{\beta_{t}} \nabla G_{1}\left(\boldsymbol{\theta}_{t}\right)+G_{1}\left(\boldsymbol{\theta}_{t}\right)\left(\boldsymbol{\Xi}-G_{2}\left(\boldsymbol{\theta}_{t}\right)\right) \nabla G_{2}\left(\boldsymbol{\theta}_{t}\right)\right) h \\
& +\sqrt{\frac{2}{\beta_{t}} h G_{2}\left(\boldsymbol{\theta}_{t}\right) \boldsymbol{\zeta}_{t}} \\
\boldsymbol{\Xi}_{t} & =\boldsymbol{\Xi}_{t-1}
\end{align*}\right.
$$

where $\boldsymbol{\zeta}_{t}$ is a random vector drawn from $\mathcal{N}(\mathbf{0}, I)$. Here, we neglect the change in $G_{1}(\boldsymbol{\theta})$ and $G_{2}(\boldsymbol{\theta})$ within a single parameter update given that $h$ is small enough. Then, in Santa, parameters are updated in order $A-B-O-B-A$ with half steps $h / 2$ on $A$ and $B$ updates, and full steps $h$ on the $O$ updates.

SDE (15) implicitly includes stochastic noise in the mini-batch approximation of the gradient of the loss function $\nabla \tilde{L}_{t}(\boldsymbol{\theta})$. Based on the central limit theorem, this stochastic noise can be approximated as $G_{1}(\boldsymbol{\theta}) \nabla \tilde{L}_{t}(\boldsymbol{\theta}) d t \approx G_{1}(\boldsymbol{\theta}) \nabla L(\boldsymbol{\theta}) d t+\mathcal{N}(0,2 B(\boldsymbol{\theta}) d t)$ with the diffusion matrix $B(\boldsymbol{\theta})$ of the stochastic gradient noise [106]. Then, for general total diffusion matrix $D(\boldsymbol{\theta})=$ $\frac{1}{\beta} G_{2}(\boldsymbol{\theta})+B(\boldsymbol{\theta})$ including both the injected part $\frac{1}{\beta} G_{2}(\boldsymbol{\theta})$ and stochastic noise part $B(\boldsymbol{\theta})$, more precise SDE with the desired stationary distribution becomes [108]

$$
\left\{\begin{align*}
d \boldsymbol{\theta}= & G_{1}(\boldsymbol{\theta}) \boldsymbol{p} d t  \tag{17}\\
d \boldsymbol{p}= & \left(-G_{1}(\boldsymbol{\theta}) \nabla L(\boldsymbol{\theta})-\boldsymbol{\Xi} \boldsymbol{p}\right) d t \\
& +\left(\frac{1}{\beta} \nabla G_{1}(\boldsymbol{\theta})+G_{1}(\boldsymbol{\theta})(\boldsymbol{\Xi}-D(\boldsymbol{\theta})) \nabla D(\boldsymbol{\theta})\right) d t \\
& +\sqrt{2 D(\boldsymbol{\theta})} d \boldsymbol{w} \\
d \boldsymbol{\Xi}= & \left(\boldsymbol{p} \boldsymbol{p}^{T}-\frac{1}{\beta} I\right) d t
\end{align*}\right.
$$

In fact, it has been shown [108] that the stationary distribution $\pi_{\beta}(\boldsymbol{\theta}, \boldsymbol{p}, \boldsymbol{\Xi})$ of $\mathrm{SDE}$ (17) is given by

$$
\begin{equation*}
\pi_{\beta}(\boldsymbol{\theta}, \boldsymbol{p}, \boldsymbol{\Xi}) \propto e^{-\beta L(\boldsymbol{\theta})-\frac{\beta}{2} \boldsymbol{p}^{T} \boldsymbol{p}-\frac{\beta}{2}} \operatorname{Tr}\left[(\boldsymbol{\Xi}-D(\boldsymbol{\theta}))^{T}(\boldsymbol{\Xi}-D(\boldsymbol{\theta}))\right] \tag{18}
\end{equation*}
$$

Hence, the marginal stationary distribution of (18) is the desired one $p_{\beta}(\boldsymbol{\theta}) \propto e^{-\beta L(\boldsymbol{\theta})}$. SDE (15) used in Santa is assured to have the same stationary distribution by assuming the diagonal form of $D(\boldsymbol{\theta})$ and neglecting $B(\boldsymbol{\theta})$ in the term with $\nabla D(\boldsymbol{\theta})$. This assumption is reasonable when $G_{2}(\boldsymbol{\theta})$ is diagonal and the number of the evaluated data is large enough so that $B(\boldsymbol{\theta})$ and its derivatives are small compared to $G_{2}(\boldsymbol{\theta})$ [108]. Indeed, only diagonal $G_{2}(\boldsymbol{\theta})$ is used in Santa. Remarkably, the offdiagonal parts of the SDE for $\boldsymbol{\Xi}$ can be omitted in this case, which considerably reduces the computational cost.

The thermostat variable $\boldsymbol{\Xi}$ maintains the system temperature by controlling the friction to imposing that the component-wise kinetic energy $p_{i}^{2} / 2$ is close to $1 /(2 \beta)$. If the energy is bigger than this value, the momentum $\boldsymbol{p}$ experiences more friction, and the opposite for lower energy values. Moreover, the thermostat "absorbs" the effects of the stochastic term of $D(\boldsymbol{\theta})$ [108]. In fact, as seen from the stationary distribution (18), the distribution of $\Xi$ is changed to a matrix normal distribution with mean $D(\boldsymbol{\theta})$ reflecting stochastic noise $D(\boldsymbol{\theta})$, and the marginal stationary distribution of $\boldsymbol{\theta}$ is left invariant irrespective of $D(\boldsymbol{\theta})$. As a result, even with imprecise estimation of stochastic noise $B(\boldsymbol{\theta})$, we can stably obtain the stationary distribution by the dynamics (15). This feature is especially beneficial in its application to VQAs.

## IV. THE SANTAQLAUS ALGORITHM

The classical Santa algorithm obtains (near) global optimality by leveraging annealed thermostats with injected noise. In VQAs, evaluations of the objective function are inherently noisy due to quantum measurements. Inspired by this natural intersection of noise characteristics, we propose SantaQlaus, an optimization algorithm designed to leverage intrinsic QSN in VQAs in a resourceefficient manner, emulating thermal noise used in Santa. Incorporating the asymptotic normality of gradient estimators, our approach justifies the use of QSN as an analogue to thermal noise. Specifically, the asymptotic normality not only provides theoretical underpinning for its use but also guides the adjustment of shot numbers to align with the desired level of thermal noise. We start by discussing the asymptotic normality of gradient estimators of loss functions.

## A. Asymptotic normality of gradient estimators

This section delves into the asymptotic normality of gradient estimators for loss functions as a precursor to the deployment of the SantaQlaus algorithm.

Let $\hat{\mathbf{f}}(\boldsymbol{x}, \boldsymbol{\theta})_{\boldsymbol{s}}=\left(\hat{\mathrm{f}}_{1}(\boldsymbol{x}, \boldsymbol{\theta})_{\boldsymbol{s}}, \cdots, \hat{\mathrm{f}}_{d}(\boldsymbol{x}, \boldsymbol{\theta})_{\boldsymbol{s}}\right)^{T}$ denote an estimator of the stochastic gradient of loss function $L$ evaluated at a single data point $\boldsymbol{x}$ (see Eq. (12)) using $s=\left(s_{1}, \cdots, s_{d}\right)$ shots for each component, where $d$ is the number of the parameters including the weight parameters. We assume a central limit theorem-like asymptotic normality in the following form:

$$
\begin{align*}
\hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta})_{\boldsymbol{s}} & =\mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta})+\mathcal{N}\left(0, \frac{S_{j}(\boldsymbol{x}, \boldsymbol{\theta})}{s_{j}}\right)+o\left(\frac{1}{\sqrt{s_{j}}}\right) \\
& \approx \mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta})+\mathcal{N}\left(0, \frac{S_{j}(\boldsymbol{x}, \boldsymbol{\theta})}{s_{j}}\right) \tag{19}
\end{align*}
$$

with some function $S_{j}(\boldsymbol{x}, \boldsymbol{\theta})$, where $\approx$ denotes an approximation up to the leading order terms. Here, the notation $\mathcal{N}\left(\mu, \sigma^{2}\right)$ is abused to denote a random variable following the normal distribution with mean $\mu$ and variance $\sigma^{2}$. A wide range of loss functions actually satisfies this form
of asymptotic normality as seen below. It is worth noting that we do not enforce $s_{j}$ to be strictly equal to the total number of shots used for estimating each $\mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta})$. Rather, $s_{j}$ is considered a parameter that characterizes the estimator in such a way that it appears in Eq. (19). A set of rules for determining the number of shots required to evaluate the expectation values needed for estimating $\mathrm{f}_{j}$ is defined in terms of $s_{j}$.

For instance, we consider a simple linear loss function with $\ell(E(\boldsymbol{x}, \boldsymbol{\theta}, w))=w\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}$ given by a single observable $h(\boldsymbol{x})$. We have $\mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)=w\left(\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2}} \boldsymbol{e}_{j}-\right.$ $\left.\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2} e_{j}}\right) / 2(j \leq d-1)$ and $\mathrm{f}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)=\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}$, where the weight $w$ is assigned as $d$-th parameter. Hence, an estimator $\hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta})_{\boldsymbol{s}}$ is simply given by sample means as

$$
\begin{align*}
& \hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{s}=\frac{w}{2}\left(\sum_{k=1}^{s_{j}} \frac{r_{k}^{+}}{s_{j}}-\sum_{k^{\prime}=1}^{s_{j}} \frac{r_{k^{\prime}}^{-}}{s_{j}}\right) \quad(j \leq d-1)  \tag{20}\\
& \hat{\mathrm{f}}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{s}=\sum_{k=1}^{s_{d}} \frac{r_{k}}{s_{d}} \tag{21}
\end{align*}
$$

where $r_{k}$ and $r_{k}^{ \pm}$denote the outcome of $k$-th measurement of $h(\boldsymbol{x})$ with parameters $\boldsymbol{\theta}$ and $\boldsymbol{\theta} \pm \frac{\pi}{2} \boldsymbol{e}_{j}$ respectively. We note that $2 s_{j}$ shots are used to estimate $j$-th component because $s_{j}$ shots are used for each shifted parameter. In this case, the central limit theorem reads

$$
\begin{align*}
& \hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{\boldsymbol{s}} \\
\approx & \mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)+\mathcal{N}\left(0, w^{2} \frac{\sigma_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2} e_{j}}^{2}+\sigma_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2} e_{j}}^{2}}{4 s_{j}}\right) \quad(j \leq d-1) \\
& \hat{\mathrm{f}}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{\boldsymbol{s}} \\
\approx & \mathrm{f}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)+\mathcal{N}\left(0, \frac{\sigma_{\boldsymbol{x}, \boldsymbol{\theta}}^{2}}{s_{d}}\right) \tag{22}
\end{align*}
$$

where $\sigma_{\boldsymbol{x}, \boldsymbol{\theta}}^{2}$ denotes the variance of $h(\boldsymbol{x})$ with respect to the state $\rho(\boldsymbol{x}, \boldsymbol{\theta})$. It is straightforward to generalize Eq. (22) to more general cases where we have multiple observables $h_{k}(\boldsymbol{x})$ to evaluate. We remark that the samples obtained with WRS are equivalent to $s_{j}$ i.i.d. samples where each single sample is drawn by measuring a randomly chosen term $h_{k}(\boldsymbol{x})$. Hence, we can directly apply the above arguments.

For polynomial loss functions, $\mathrm{f}_{j}$ includes a polynomial of the expectation values of observables in general. We can apply a central limit theorem for Ustatistic [90] in such cases. As a typical example, we consider a quadratic loss function $\ell(\boldsymbol{x}, E(\boldsymbol{x}, \boldsymbol{\theta}, w))=$ $\sum_{z=0}^{2} a_{z}(\boldsymbol{x})\left(w\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right)^{z}$, including the MSE loss for a prediction given by $w\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}$. In this case, the partial derivatives reads

$$
\begin{aligned}
& \mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w) \\
= & w\left(\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2}} e_{j}-\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2}} e_{j}\right)
\end{aligned}
$$

$$
\begin{align*}
& \times\left(\frac{a_{1}(\boldsymbol{x})}{2}+w a_{2}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right) \quad(j \leq d-1)  \tag{23}\\
& \mathrm{f}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w) \\
= & a_{1}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}+2 w a_{2}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}^{2} \tag{24}
\end{align*}
$$

Then, for given $s$, unbiased estimators of the derivatives are given by

$$
\begin{align*}
\hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{s}= & w\left(\sum_{k=1}^{s_{j}} \frac{r_{k}^{+}}{s_{j}}-\sum_{k^{\prime}=1}^{s_{j}} \frac{r_{k^{\prime}}^{-}}{s_{j}}\right) \\
& \times\left(\frac{a_{1}(\boldsymbol{x})}{2}+w a_{2}(\boldsymbol{x}) \sum_{k=1}^{s_{d}} \frac{r_{k}}{s_{d}}\right) \quad(j \leq d-1)  \tag{25}\\
\hat{\mathrm{f}}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{s}= & a_{1}(\boldsymbol{x}) \sum_{k=1}^{s_{d}} \frac{r_{k}}{s_{d}}+2 w a_{2}(\boldsymbol{x}) \sum_{1 \leq k_{1} \neq k_{2} \leq s_{d}} \frac{r_{k_{1}} r_{k_{2}}}{s_{d}\left(s_{d}-1\right)} \tag{26}
\end{align*}
$$

with the same notations as above. In this estimator, we use $s_{j}$ shots to evaluate at each shifted parameter and $s_{d}$ shots for the unshifted parameter. Hence, $2 \sum_{j=1}^{d-1} s_{j}+s_{d}$ shots are used in total. For the circuit parameters $j \leq$ $d-1$, the estimator composed of a product of sample means of independent random variables. We note that sequences of two independent and identically distributed (i.i.d.) random variables $X_{1}, \cdots, X_{n_{1}}$ and $Y_{1}, \cdots, Y_{n_{2}}$ with respective means $\mu_{X}, \mu_{Y}$ satisfy

$$
\begin{align*}
& \sum_{k=1}^{n_{1}} \frac{X_{k}}{n_{1}} \sum_{k^{\prime}=1}^{n_{2}} \frac{Y_{k^{\prime}}}{n_{2}}-\mu_{X} \mu_{Y} \\
= & \mu_{X}\left(\sum_{k^{\prime}=1}^{n_{2}} \frac{Y_{k^{\prime}}}{n_{2}}-\mu_{Y}\right)+\left(\sum_{k=1}^{n_{1}} \frac{X_{k}}{n_{1}}-\mu_{X}\right) \mu_{Y} \\
& +\left(\sum_{k=1}^{n_{1}} \frac{X_{k}}{n_{1}}-\mu_{X}\right)\left(\sum_{k^{\prime}=1}^{n_{2}} \frac{Y_{k^{\prime}}}{n_{2}}-\mu_{Y}\right) \tag{27}
\end{align*}
$$

Then, we can apply the central limit theorem to $\sum_{k=1}^{n_{1}} \frac{X_{k}}{n_{1}}-\mu_{X}$ and $\sum_{k^{\prime}=1}^{n_{2}} \frac{Y_{k^{\prime}}}{n_{2}}-\mu_{Y}$. Because the product of the convergent sequences converges to the product of their limits, the third term of the right hand side (RHS) of Eq. (27) turns out to be of sub-leading order. Hence, we obtain

$$
\begin{equation*}
\hat{\mathrm{f}}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{s} \approx \mathrm{f}_{j}(\boldsymbol{x}, \boldsymbol{\theta}, w)+\mathcal{N}\left(0, \frac{S_{j}(\boldsymbol{x}, \boldsymbol{\theta})}{s_{j}}\right) \tag{28}
\end{equation*}
$$

with

$$
\begin{align*}
& S_{j}(\boldsymbol{x}, \boldsymbol{\theta}) \\
= & \mu_{2}^{2}\left(\sigma_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2} \boldsymbol{e}_{j}}^{2}+\sigma_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2} \boldsymbol{e}_{j}}^{2}\right)+\kappa_{j} \mu_{1}^{2} w^{2} a_{2}(\boldsymbol{x})^{2} \sigma_{\boldsymbol{x}, \boldsymbol{\theta}}^{2} \tag{29}
\end{align*}
$$

where $\left.\mu_{1}:=h(\boldsymbol{x})\right\rangle_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2}} \boldsymbol{e}_{j}-\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2}} e_{j}$ and $\mu_{2}:=$ $\frac{a_{1}(\boldsymbol{x})}{2}+w a_{2}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}$, and we assume that $s_{j} / s_{d} \rightarrow \kappa_{j}$.

For the weight parameter $j=d$, we apply the theory of U-statistic. For i.i.d. random variables $X_{1}, \cdots, X_{n}$, U-statistic with respect
to a symmetric function $\Phi\left(\xi_{1}, \cdots, \xi_{m}\right)$ is defined as $\sum_{1 \leq k_{1} \neq \cdots \neq k_{m} \leq n} \Phi\left(X_{k_{1}}, \cdots, X_{k_{m}}\right) /[n(n-1) \cdots(n-m+$ 1)]. Thus, Eq. (26) coincides with the U-statistic with respect to the function $\Phi\left(\xi_{1}, \xi_{2}\right)=\frac{a_{1}(\boldsymbol{x})}{2}\left(\xi_{1}+\xi_{2}\right)+$ $2 w a_{2}(\boldsymbol{x}) \xi_{1} \xi_{2}$. Therefore, applying a central limit theorem for U-statistics [90], we obtain

$$
\begin{equation*}
\hat{\mathrm{f}}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{\boldsymbol{s}} \approx \mathrm{f}_{d}(\boldsymbol{x}, \boldsymbol{\theta}, w)_{\boldsymbol{s}}+\mathcal{N}\left(0, \frac{S_{d}(\boldsymbol{x}, \boldsymbol{\theta})}{s_{d}}\right) \tag{30}
\end{equation*}
$$

where

$$
\begin{align*}
S_{d}(\boldsymbol{x}, \boldsymbol{\theta})= & \sigma_{\boldsymbol{x}, \boldsymbol{\theta}}^{2}\left[a_{1}(\boldsymbol{x})^{2}+8 w a_{1}(\boldsymbol{x}) a_{2}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right. \\
& \left.+16\left(w a_{2}(\boldsymbol{x})\langle h(\boldsymbol{x})\rangle_{\boldsymbol{x}, \boldsymbol{\theta}}\right)^{2}\right] . \tag{31}
\end{align*}
$$

This way, we obtain the asymptotic normality in a concrete form for quadratic loss functions. We can apply similar calculations to more general polynomial loss functions.

An unbiased estimator $\hat{\mathbf{f}}(\boldsymbol{\theta})_{\boldsymbol{s}}$ of the stochastic gradient $\nabla \tilde{L}(\boldsymbol{\theta})$ is given as

$$
\begin{equation*}
\hat{\mathrm{f}}_{j}(\boldsymbol{\theta})_{s}:=\frac{1}{m} \sum_{l=1}^{m} \hat{\mathrm{f}}_{j}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right)_{s} \tag{32}
\end{equation*}
$$

with respect to a mini-batch $\left\{\boldsymbol{x}_{i_{1}}, \cdots, \boldsymbol{x}_{i_{m}}\right\}$ of size $m$. Then, we further apply the central limit theorem with respect to the mini-batch average as follows. From the asymptotic normality Eq. (19), we have

$$
\begin{align*}
\hat{\mathrm{f}}_{j}(\boldsymbol{\theta})_{s} & \approx \frac{1}{m} \sum_{l=1}^{m}\left(\mathrm{f}_{j}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right)+\sqrt{\frac{S_{j}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right)}{s_{j}}} \zeta_{l}\right) \\
& =\frac{\partial \tilde{L}}{\partial \theta_{j}}(\boldsymbol{\theta})+\frac{1}{m} \sum_{l=1}^{m} \sqrt{\frac{S_{j}\left(\boldsymbol{x}_{i_{l}}, \boldsymbol{\theta}\right)}{s_{j}}} \zeta_{l, j} \tag{33}
\end{align*}
$$

where $\zeta_{l, j}(l=1, \cdots, m),(j=1, \cdots, d)$ are independent standard normally distributed random variables $\sim$ $\mathcal{N}(0,1)$. For simplicity, assuming that $N$ is large enough compared to $m$, we neglect the influence of the sampling without replacement, so that $x_{i_{l}}(l=1, \cdots, m)$ can be treated as approximately i.i.d. random variables, which are uniformly drawn from the dataset $\mathcal{D}$. Indeed, the following arguments based on this approximation can be justified by a central limit theorem for random partition $[124,125]$. Then, $\sqrt{\frac{S\left(\boldsymbol{x}_{i_{1}}, \boldsymbol{\theta}\right)}{\boldsymbol{s}}} \zeta_{1}, \cdots, \sqrt{\frac{S\left(\boldsymbol{x}_{i_{m}}, \boldsymbol{\theta}\right)}{s}} \zeta_{m}$ can be regarded as a sequence of i.i.d. random vectors, whose mean is $\mathbf{0}$, and the covariance reads

$$
\begin{align*}
\mathbb{E}\left[\sqrt{\frac{S_{j}(\boldsymbol{X}, \boldsymbol{\theta})}{s_{j}} \frac{S_{k}(\boldsymbol{X}, \boldsymbol{\theta})}{s_{k}}} \zeta_{j} \zeta_{k}\right] & =\frac{\mathbb{E}_{\boldsymbol{X}}\left[S_{j}(\boldsymbol{X}, \boldsymbol{\theta})\right]}{s_{j}} \delta_{j, k} \\
& =: \frac{S_{j}(\boldsymbol{\theta})}{s_{j}} \delta_{j, k} \tag{34}
\end{align*}
$$

where $\mathbb{E}_{\boldsymbol{X}}$ denotes the expectation with respect to the data sampling $\boldsymbol{X}$. Here a fraction of vectors mean component-wise. Product $\boldsymbol{v}_{1} \boldsymbol{v}_{2}$ of two vectors $\boldsymbol{v}_{1}$ and $\boldsymbol{v}_{2}$ also denote component-wise product in the following. Then, from Eq. (33), the central limit theorem with respect to the sum $\frac{1}{m} \sum_{l=1}^{m} \sqrt{\frac{S\left(\boldsymbol{x}_{\left.i_{l}, \boldsymbol{\theta}\right)}\right.}{s}} \zeta_{l}$ yields an approximation

$$
\begin{equation*}
\hat{\mathbf{f}}(\boldsymbol{\theta})_{\boldsymbol{s}} \approx \nabla \tilde{L}_{t}(\boldsymbol{\theta})+\mathcal{N}\left(\mathbf{0}, \operatorname{diag}\left(\frac{\boldsymbol{S}(\boldsymbol{\theta})}{m \boldsymbol{s}}\right)\right) \tag{35}
\end{equation*}
$$

where $\mathcal{N}(\boldsymbol{\mu}, \Sigma)$ denotes a random vector following the multivariate Gaussian distribution with mean $\boldsymbol{\mu}$ and covariance matrix $\Sigma$.

## B. Details of SantaQlaus

As detailed in the previous section, because samples obtained by quantum measurements are i.i.d. random variables, we can apply central limit theorems to typical loss functions, so that QSN in a quantum evaluation of each component of the stochastic gradient follows a Gaussian distribution. More precisely, with fairly broad applicability, we assume an asymptotic normality Eq. (19) of an estimator $\hat{\mathbf{f}}(\boldsymbol{x}, \boldsymbol{\theta})_{s}$ of the stochastic gradient of loss function $L$ evaluated at each data point $\boldsymbol{x}$. Based on this, we have derived an approximation of the stochastic gradient

$$
\begin{equation*}
\hat{\mathbf{f}}(\boldsymbol{\theta})_{\boldsymbol{s}} \approx \nabla \tilde{L}_{t}(\boldsymbol{\theta})+\mathcal{N}\left(\mathbf{0}, \operatorname{diag}\left(\frac{\boldsymbol{S}(\boldsymbol{\theta})}{m \boldsymbol{s}}\right)\right) \tag{36}
\end{equation*}
$$

which is restated for convenience. In Eq. (36), the term $\nabla \tilde{L}_{t}(\boldsymbol{\theta})$ only includes noise due to the mini-batch approximation, and QSN is isolated as Gaussian noise $\mathcal{N}\left(\mathbf{0}, \operatorname{diag}\left(\frac{\boldsymbol{S}(\boldsymbol{\theta})}{m \boldsymbol{s}}\right)\right)$. Hence, as QSN is approximated as additive Gaussian noise with diagonal covariance matrix, we can use it as thermal noise in Santa. We can achieve this by adjusting the number $\boldsymbol{n}=m \boldsymbol{s}$ to yield the variance corresponding to the desired thermal noise. In the parameter update rule (16) of Santa, with an estimate $\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{s}$ of $G_{1}\left(\boldsymbol{\theta}_{t}\right)$, the stochastic gradient appears as $\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{s} \hat{\mathbf{f}}\left(\boldsymbol{\theta}_{t}\right)_{s} h$, which reads

$$
\begin{align*}
& \hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} \hat{\mathbf{f}}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} h \\
\approx & \hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{s} \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right) h+h \hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} \operatorname{diag}\left(\sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t} \tag{37}
\end{align*}
$$

Comparing with the thermal noise term $\mathcal{N}\left(\mathbf{0}, \frac{2}{\beta_{t}} h G_{2}\left(\boldsymbol{\theta}_{t}\right)\right)$, we obtain the following equation to be satisfied for emulating the thermal noise by QSN:

$$
\begin{align*}
& \hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)+\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} \operatorname{diag}\left(\sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t} \\
= & G_{1}\left(\boldsymbol{\theta}_{t}\right) \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)+\sqrt{\frac{2}{\beta_{t} h} G_{2}\left(\boldsymbol{\theta}_{t}\right)} \boldsymbol{\zeta}_{t} \tag{38}
\end{align*}
$$

We remark that $\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}}$ may also includes the noise in general. Although this condition is not always possible to satisfy for arbitrary $G_{1}$ and $G_{2}$, using diagonal preconditioners $G_{1}$ and $G_{2}$ makes it possible to solve Eq. (38) easily. Indeed, we use the RMSprop preconditioner and set $G_{2}(\boldsymbol{\theta}) h=G_{1}(\boldsymbol{\theta})$ as in the original Santa [64] for computational feasibility (see Algorithm 1). RMSprop preconditioner corresponds to $G_{1}\left(\boldsymbol{\theta}_{t}\right)=\operatorname{diag}\left(1 / \boldsymbol{v}_{t}^{1 / 4}\right)$, where $\boldsymbol{v}_{t}=\sigma \boldsymbol{v}_{t-1}+(1-\sigma)\left(\nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)\right)^{2}$ is an exponential moving average of the squared gradient with a parameter $0<\sigma<1$. We leave as future works to incorporate more general preconditioners such as the quantum Fisher metric $[43,44]$. In addition, we assume that $\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right)$ can be approximated as

$$
\begin{equation*}
\hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right) \approx G_{1}\left(\boldsymbol{\theta}_{t}\right)\left(I+\operatorname{diag}\left(\boldsymbol{g}\left(\boldsymbol{\theta}_{\boldsymbol{t}}\right) \sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t}\right) \tag{39}
\end{equation*}
$$

up to the leading order, where the random vector $\zeta_{t}=$ $\mathcal{N}(\mathbf{0}, I)$ is shared with the noise in $\hat{\mathbf{f}}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}} \approx \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)+$ $\sqrt{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right) / \boldsymbol{n}} \boldsymbol{\zeta}_{t}$. In this case, Eq. (38) reads

$$
\begin{align*}
& G_{1}\left(\boldsymbol{\theta}_{t}\right) \operatorname{diag}\left(\boldsymbol{g}\left(\boldsymbol{\theta}_{t}\right) \sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right) \boldsymbol{\zeta}_{t} \\
& \quad+G_{1}\left(\boldsymbol{\theta}_{t}\right) \operatorname{diag}\left(\sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t} \\
& =\sqrt{\frac{2}{\beta_{t} h} G_{2}\left(\boldsymbol{\theta}_{t}\right)} \boldsymbol{\zeta}_{t} \tag{40}
\end{align*}
$$

Thus, substituting $G_{2}(\boldsymbol{\theta})=G_{1}(\boldsymbol{\theta}) / h$, we obtain the appropriate number of shots as follows:

$$
\begin{align*}
& \boldsymbol{n} \\
= & \left\lceil\frac{\beta_{t} h^{2}}{2} G_{1}\left(\boldsymbol{\theta}_{t}\right)\left(1+\boldsymbol{g}\left(\boldsymbol{\theta}_{t}\right) \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)\right)^{2} \boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)\right] \text {. } \tag{41}
\end{align*}
$$

In particular, by neglecting the noise in $\boldsymbol{v}_{t-1}$ of the previous iteration, $G_{1}$ of the RMSprop preconditioner actually satisfies Eq. (39) since it is given by an estimate of the squared gradient. For RMSprop preconditioner, we have

$$
\begin{align*}
& \hat{G}_{1}\left(\boldsymbol{\theta}_{t}\right) \\
\approx & \operatorname{diag}\left(\left(\sigma \boldsymbol{v}_{t-1}+(1-\sigma) \hat{\mathbf{f}}\left(\boldsymbol{\theta}_{t}\right)_{\boldsymbol{s}}^{2}\right)^{-\frac{1}{4}}\right) \\
\approx & G_{1}\left(\boldsymbol{\theta}_{t}\right)\left(I+2(1-\sigma) \operatorname{diag}\left(\frac{\nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{v}_{t}} \sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t}\right)^{-\frac{1}{4}} \\
\approx & G_{1}\left(\boldsymbol{\theta}_{t}\right)\left(I-\frac{(1-\sigma)}{2} \operatorname{diag}\left(\frac{\nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{v}_{t}} \sqrt{\frac{\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)}{\boldsymbol{n}}}\right) \boldsymbol{\zeta}_{t}\right) \tag{42}
\end{align*}
$$

where we use the Taylor expansion and neglect the terms of sub-leading order. Hence, $\boldsymbol{g}\left(\boldsymbol{\theta}_{t}\right)=-0.5(1-$ $\sigma) \nabla \tilde{L}_{t}\left(\boldsymbol{\theta}_{t}\right) / \boldsymbol{v}_{t}$ holds. Then, estimating the gradient using the number of shots given by Eq. (41), we apply parameter update rule (16) of Santa. We call this optimization algorithm SantaQlaus, which stands for Stochastic
AnNealing Thermostats with Adaptive momentum and Quantum-noise Leveraging by Adjusted Use of Shots. A small number of shots is sufficient when the temperature is high, and as the optimization proceeds and the temperature is lowered, the number of shots required is increased. This allows us to efficiently leverage QSN to explore the parameter space in accordance with the Langevin diffusion while saving the number of shots. Though the exact evaluation of $\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)$ is infeasible, we can estimate it by computing the mini-batch average of an estimator of $\boldsymbol{S}\left(\boldsymbol{x}_{\boldsymbol{i}_{l}}, \boldsymbol{\theta}\right)$. For linear loss function, we can estimate $\boldsymbol{S}\left(\boldsymbol{x}_{\boldsymbol{i}_{l}}, \boldsymbol{\theta}\right)$ by the unbiased variance. For general polynomial loss functions, we can estimate it via corresponding U-statistics. In particular, it is straightforward to calculate the U-statistics to estimate Eq. (29) and (31) for quadratic loss functions including MSE. However, we should note that an unbiased estimator given by a Ustatistic is not guaranteed to be positive for general cases. If an estimate of $\boldsymbol{S}\left(\boldsymbol{x}_{\boldsymbol{i}_{l}}, \boldsymbol{\theta}\right)$ is negative, we cannot use it to calculate the number of shots. In such a case, when the obtained estimator takes a negative value, we switch to use a biased estimator guaranteed to be positive, which is obtained by simply substituting corresponding sample means (unbiased variance) to expectation values (variance). In addition, we use the exponential moving average as estimates of the quantities for the next iteration similarly to $[40,50]$. Of course this approach is subject to errors resulting from taking the ceil and estimation errors, but the thermostat absorbs their effects, as seen in the previous section. We remark that the overhead of estimating $\boldsymbol{S}\left(\boldsymbol{\theta}_{t}\right)$ is only classical calculation of the statistics using the same samples of quantum outputs as those used in estimating the gradient. Santa algorithm is especially a good fit for leveraging QSN this way. This strategy can be straightforwardly applied to other VQAs without input data such as VQE, not only limited to $\mathrm{QML}$.

We note that the variance of QSN cannot exceed that at the minimum number of shots. An option to address this constraint, as well as the variance estimation error, is to inject noise with the missing variance. Although this approach might potentially enhance the ergodicity of the dynamics, our numerical experiments did not validate the benefit of this option, as it primarily delayed the optimization. The pitfalls seem to eclipse the advantages, given there is no necessity for precise sampling at the outset and the appropriate variance of the noise to inject is challenging to estimate accurately.

The convergence theorem towards the global optima under mild conditions for Santa [64] remains valid for SantaQlaus. Even if the actual variance of QSN does not exactly yield thermal noise $\frac{2}{\beta_{t}} G_{2}\left(\boldsymbol{\theta}_{t}\right) \boldsymbol{\zeta}_{t}$ to be emulated, we can redefine $G_{2}(\boldsymbol{\theta})$ so that thermal noise with it coincides with actual QSN. In this way, we obtain the same SDE as the original Santa with this redefined $G_{2}(\boldsymbol{\theta})$. Thus, we can apply convergence theorem [64, Theorem 2] to SantaQlaus to guarantee its convergence. Moreover, even though the approximation by the cen-
tral limit theorem might be imprecise due to the limited shots in early iterations, regarding an iteration with a sufficient number of shots as the starting point ensures that the asymptotic convergence behavior remains unaffected. Practically speaking, the sampling accuracy in initial iterations does not significantly influence the optimization.

Another remark is drawn for the application of SantaQlaus to quadratic loss functions. As it is impractical to set the ratio $\kappa_{j}=s_{j} / s_{d}$ in Eq. (29) a priori, we instead enforce $\kappa_{j} \leq 1$ and use an upper bound $\bar{S}_{j}(\boldsymbol{x}, \boldsymbol{\theta}):=$ $\mu_{2}^{2}\left(\sigma_{\boldsymbol{x}, \boldsymbol{\theta}+\frac{\pi}{2} \boldsymbol{e}_{j}}^{2}+\sigma_{\boldsymbol{x}, \boldsymbol{\theta}-\frac{\pi}{2}}^{2} \boldsymbol{e}_{j}\right)+\mu_{1}^{2} w^{2} a_{2}(\boldsymbol{x})^{2} \sigma_{\boldsymbol{x}, \boldsymbol{\theta}}^{2} \geq S_{j}(\boldsymbol{x}, \boldsymbol{\theta})$ to determine $s_{j}$. We can do so by first computing $s_{j}$ using $\bar{S}_{j}(\boldsymbol{x}, \boldsymbol{\theta})(j \leq d-1)$, and $s_{d}$ via $S_{d}(\boldsymbol{x}, \boldsymbol{\theta})$. Then, we use $\max \left\{s_{1}, \cdots, s_{d}\right\}$ shots to measure $h(\boldsymbol{x})$ at the unshifted parameter $\boldsymbol{\theta}$. In this way, we can adjust the variance of QSN to be at least smaller than that of the desired thermal noise.

A practical implementation of our SantaQlaus algorithm is summarized in Algorithm 1. Here, we reparameterize as $\eta=h^{2}, \boldsymbol{u}=\sqrt{\eta} \boldsymbol{p}$, and $\operatorname{diag}(\boldsymbol{\alpha})=\sqrt{\eta} \boldsymbol{\Xi}$ as in Ref. $[64,108]$. We do not use the update rule of the refinement stage because we cannot make QSN exactly zero in contrast to the classical case. Instead, we can incorporate the refinement stage into the annealing schedule of $\beta_{t}$ in such a way that a large enough value of $\beta_{t}$ is used in the refinement. We detail an example of such a strategy later. One obstacle in an implementation of Santa's update rule is the terms with $\nabla G_{1}(\boldsymbol{\theta})$ and $\nabla G_{2}(\boldsymbol{\theta})$ in SDE (15). Exact calculation of $\nabla G_{1}(\boldsymbol{\theta})$ and $\nabla G_{2}(\boldsymbol{\theta})$ is infeasible in general. As shown in Ref. [64], one approach is to approximate them by applying Taylor expansion with respect to the parameter update. This approach actually yields a computationally efficient approximation. However, in practice, this approximation can be numerically unstable due to the time discretization and rapid changes in some components of the preconditioner. As a remedy, it was empirically found beneficial to simply drop out the terms with $\nabla G_{1}$ and $\nabla G_{2}$ [64]. Even if this is done, slightly biased samples do not affect the optimization so much as our purpose is not to obtain the accurate sampling from the target distribution. In fact, such a small bias is absorbed into the error in the estimated stochastic noise. Even for a sampling task, it has been shown that the bias caused by neglecting the derivatives of the preconditioner can be controlled to be small for the RMSprop preconditioner [119]. Then, we also neglect the terms with $\nabla G_{1}$ and $\nabla G_{2}$ in a practical implementation, just as done in the classical Santa [64].

Additionally, we introduce a warm-up iteration number, denoted as $t_{0}$, and a component-wise scale factor, $\boldsymbol{g}_{t}$, for the preconditioner to enhance flexibility. During the very early iterations, the estimation for quantities such as $\boldsymbol{S}$ and $\boldsymbol{G}$ can be unstable, with some components disproportionately large. Incorporating such unstable values into the moving average can be detrimental. Consequently, the number of shots $\boldsymbol{n}$ computed from these

```
Algorithm 1. SantaQlaus (a practical implementa-
```

tion). The function $i \operatorname{Evaluate}(\boldsymbol{\theta}, s, m)$ evaluates the
mini-batch gradient estimator $\mathbf{f}=\hat{\mathbf{f}}(\boldsymbol{\theta})_{s}$ for the ob-
jective loss function with a size $m$ mini-batch, using
the number of shots determined by $s$. This function
also returns an estimator $\boldsymbol{S}$ of $\boldsymbol{S}(\boldsymbol{\theta})$ obtained by tak-
ing mini-batch average of the corresponding U-statistic
computed from the measurement outcomes. The reg-
ularization term (or a prior) can also be specified in
iEvaluate. The function $s$ Count $(s, m)$ returns the to-
tal number of shots expended in iEvaluate $(\boldsymbol{\theta}, s, m)$.
For example, for a linear loss function whose gradi-
ent is computed by two-point parameter shift rule (8),
$s \operatorname{Count}(s, m)=2 m \sum_{i} s_{i}$. We can also straightfor-
wardly apply this algorithm to a VQA without data
dependence such as VQE just by neglecting the argu-
ment $m$ and setting $m=1$.
Input: Learning rate $\eta_{t}$, initial parameter $\boldsymbol{\theta}_{0}$, minimum
number of shots $s_{\min }$, total shot budget $s_{\text {max }}$ available
for the optimization, annealing schedule $\beta_{t}$, mini-batch
size $m_{t}$, scale factor of the preconditioner $\boldsymbol{g}_{t}$, warm-up it-
eration number $t_{0}$, hyperparameters $\sigma, C$, and $\lambda$, running
average constant $\mu$
: Initialize: $\boldsymbol{\theta} \leftarrow \boldsymbol{\theta}_{0}, \quad t \leftarrow 1, s_{\text {tot }} \leftarrow 0, \boldsymbol{s} \leftarrow$
$\left(s_{\text {min }}, \cdots, s_{\text {min }}\right)^{\mathrm{T}}, \boldsymbol{\xi}^{\prime} \leftarrow(0, \cdots, 0)^{\mathrm{T}}, \boldsymbol{\chi}^{\prime} \leftarrow(0, \cdots, 0)^{\mathrm{T}}$,
$\boldsymbol{\Gamma}^{\prime} \leftarrow(0, \cdots, 0)^{\mathrm{T}}, \boldsymbol{v} \leftarrow(0, \cdots, 0)^{T}, \boldsymbol{u} \leftarrow \sqrt{\eta_{1}} \mathcal{N}(0, I)$,
$\alpha \leftarrow \sqrt{\eta_{1}} C$
while $s_{\text {tot }} \leq s_{\max }$ do
$\mathbf{f}, \boldsymbol{S} \leftarrow i \operatorname{Evaluate}\left(\boldsymbol{\theta}, s, m_{t}\right)$
$s_{\text {tot }} \leftarrow s_{\text {tot }}+s \operatorname{Count}\left(\boldsymbol{s}, m_{t}\right)$
$\boldsymbol{v} \leftarrow \sigma \boldsymbol{v}+(1-\sigma) \mathbf{f}^{2}$
$\boldsymbol{G} \leftarrow \boldsymbol{g}_{t} / \sqrt{\lambda+\sqrt{\boldsymbol{v}}}$
$\boldsymbol{\theta} \leftarrow \boldsymbol{\theta}+\boldsymbol{G} \boldsymbol{u} / 2$
$\boldsymbol{\alpha} \leftarrow \boldsymbol{\alpha}+\left(\boldsymbol{u}^{2}-\eta_{t} / \beta_{t}\right) / 2$
$\boldsymbol{u} \leftarrow \exp (-\boldsymbol{\alpha} / 2) \boldsymbol{u}$
$\boldsymbol{u} \leftarrow \boldsymbol{u}-\eta_{t} \boldsymbol{G} \mathbf{f}$
$\boldsymbol{u} \leftarrow \exp (-\boldsymbol{\alpha} / 2) \boldsymbol{u}$
$\boldsymbol{\alpha} \leftarrow \boldsymbol{\alpha}+\left(\boldsymbol{u}^{2}-\eta_{t} / \beta_{t}\right) / 2$
$\boldsymbol{\theta} \leftarrow \boldsymbol{\theta}+\boldsymbol{G} \boldsymbol{u} / 2$
$t \leftarrow t+1$
if $t>t_{0}$ then
$\boldsymbol{\xi}^{\prime} \leftarrow \mu \boldsymbol{\xi}^{\prime}+(1-\mu) \boldsymbol{S}$
$\boldsymbol{\xi} \leftarrow \boldsymbol{\xi}^{\prime} /\left(1-\mu^{t-t_{0}}\right)$
$\chi^{\prime} \leftarrow \mu \chi^{\prime}+(1-\mu) \mathbf{f}$
$\chi \leftarrow \chi^{\prime} /\left(1-\mu^{t-t_{0}}\right)$
$\boldsymbol{\Gamma}^{\prime} \leftarrow \mu \boldsymbol{\Gamma}^{\prime}+(1-\mu) \boldsymbol{G}$
$\boldsymbol{\Gamma} \leftarrow \boldsymbol{\Gamma}^{\prime} /\left(1-\mu^{t-t_{0}}\right)$
$\boldsymbol{v}^{\prime} \leftarrow \sigma \boldsymbol{v}+(1-\sigma) \boldsymbol{\chi}$
$\gamma \leftarrow\left(1-0.5(1-\sigma) \chi^{2} / \boldsymbol{v}^{\prime}\right)^{2}$
$\boldsymbol{n} \leftarrow\left\lceil\beta_{t} \eta_{t} \boldsymbol{\Gamma} \boldsymbol{\xi} / 2\right\rceil$
$s \leftarrow\left\lceil\boldsymbol{n} / m_{t}\right\rceil$
$s \leftarrow \operatorname{clip}\left(s, s_{\text {min }}\right.$, None $)$
else
$\boldsymbol{s} \leftarrow\left(s_{\text {min }}, \cdots, s_{\text {min }}\right)^{\mathrm{T}}$
end if
end while

early estimates may be erratic. To counteract this, it
is advantageous to disregard these values in a few early iterations. We might choose a small value for $t_{0}$, such as 5 . While the default for $\boldsymbol{g}_{t}$ can be set to 1 , when components have varying optimal scales, adjusting the learning rate individually for each component is beneficial. For instance, in regression tasks of QML with a scaled observable, as discussed in Sec. V B, allowing the scale parameter to adjust quickly is favorable as it significantly influences the success of the regression. However, introducing a component-wise different learning rate $\boldsymbol{\eta}_{t}$ is not justified because $\eta_{t}$ represents time. We empirically found that such modifications degrade the performance.

As the shot budget is important, schedules of hyperparameter settings of such as $\beta_{t}, \eta_{t}$, or $m_{t}$ based on the number of shots may be useful. For instance, we use the following function of the expended shots $s_{\text {tot }}$ to determine the value of the hyperparameters to be used:

$f_{s_{0}, s_{\text {end }}}^{y_{0}, y_{\text {end }}, a}\left(s_{\text {tot }}\right):=y_{0}\left[\frac{s_{\text {tot }}-s_{0}}{s_{\text {end }}-s_{0}}\left(\left(\frac{y_{\text {end }}}{y_{0}}\right)^{\frac{1}{a}}-1\right)+1\right]^{a}$.

This function takes the predetermined values $y_{0}$ and $y_{\text {end }}$ at the start $s_{0}$ and the end $s_{\text {end }}$ respectively, and the curve of the growth is controlled by $a \neq 0$.

## C. Incorporating quantum error mitigation

In the context of VQAs executed on NISQ devices, addressing hardware noise is important. Quantum error mitigation (QEM) techniques offer a pathway for estimating the output of an ideal, noiseless circuit from noisy ones [126-138], without large resource overhead required in quantum error correction. In principle, it is possible to consider the noisy ansatz instead as our model. However, to obtain an accurate result, we finally need to remove the effects of the hardware noise at least for the evaluation of the final outputs after the optimization, highlighting the need for QEM in real devices $[6,133,139]$. Thus, we should aim to optimize the parameters with respect to the noiseless model. While some VQA tasks exhibit resilience to hardware noise $[57,140,141]$, the presence of such noise can introduce computational bias in gradient estimation, thereby altering the loss landscape and complicating optimization in general [22, 141]. Prior research indicates that employing QEM during optimization can potentially enhance the performance [13, 142-144], although QEM is unlikely to resolve the noise-induced barren plateau [22, 142]. However, it is not always the case, as the application of QEM inherently introduces a trade-off: while it reduces bias, it increases the sampling variance $[142,145-148]$. For instance, probabilistic error cancellation (PEC) effectively applying the inverse map of the noise channel via sampling the circuits according to a quasi-probability decomposition of the inverse map [128, 129, 144]. As a result, it yields an unbiased estimator of the noiseless expectation value at the expense of increased variance. Zero noise extrapolation (ZNE) $[126,128,129]$ also yields a bias-reduced estimator with the increased variance.

The integration of QEM techniques into SantaQlaus may offer a resource-efficient use of these methods during optimization. For example, PEC can be seamlessly incorporated into the SantaQlaus framework. PEC provides an unbiased estimator for the gradient, enabling optimization of the noiseless model effectively [143]. The distinction lies in the increased number of circuit terms that must be sampled, as dictated by the quasi-probability decomposition of the inverse noise map. In SantaQlaus, an appropriate total number of measurement shots can be computed from the gradient estimator's variance $\boldsymbol{S}(\boldsymbol{\theta})$, obtained from the PEC samples. These shots are then allocated based on the quasi-probability distribution. This approach enables SantaQlaus to operate using an unbiased gradient in the presence of hardware noise via PEC, while also automatically adjusting resource usage for efficiency. In a sense, SantaQlaus may also leverage hardware noise that is "converted" to sampling noise with increased variance via $\mathrm{QEM}$.

Similarly, ZNE can be incorporated into SantaQlaus to provide a bias-reduced estimator of the gradient. Although the estimator is not perfectly unbiased in ZNE, such a bias-reduced estimator may still offer satisfactory performance in optimizing variational parameters, as observed in an experiment [13]. Other QEM methods such as Clifford data regression [130] can be incorporated in a similar manner. This way, SantaQlaus has a potential to utilize QEM in a resource-efficient manner.

## V. NUMERICAL SIMULATIONS

In this section, we demonstrate the performance of SantaQlaus optimizers against a range of existing optimizers through numerical simulations of a benchmark VQAs. For the optimization process, we simulate the sampling of the outcomes of quantum measurements of loss functions via Qulacs [149]. The resulting optimization curves are plotted based on the exact evaluations via state vector calculations provided by Qulacs. We do not include hardware noise.

We benchmark SantaQlaus against several other optimization algorithms. As a representative of generic optimizers, we employ Adam [35], renowned for its broadly effective performance. To test the advantages of adaptive shots-adjusting strategy of SantaQlaus over simpler methods, we use Adam with a predetermined increased number of shots, denoted as Adam with dynamic shots (Adam-DS). In addition, we compare SantaQlaus with existing shot-adaptive optimizers, such as gCANS [50] and its QML-specific variant, Refoqus [62].

As another optimizer that aims for global optimality with MCMC approach, we pick up MCMC-VQA [58]. It is based on Metropolis-Hastings steps using injected stochastic noise, which can be resource-intensive to
achieve sufficient mixing. The shot resource efficiency of MCMC-VQA has not been comprehensively studied. We also compare SantaQlaus with MCMC-VQA in a VQE task (Sec. V A).

We fix a part of the hyperparameters to recommended values throughout the benchmarks. For SantaQlaus, we use $\sigma=0.99, C=5, \lambda=10^{-8}, \mu=0.99, \eta_{1}=0.01$, $s_{\min }=4$, and $t_{0}=5$. For Adam, $\beta_{1}=0.9, \beta_{2}=0.99$, $\epsilon=10^{-8}$ are used. In MCMC-VQA, we use the inverse temperature $\beta=0.2$ and the noise parameter $\xi=0.5$ as recommended in Ref. [58]. We do not use artificial noise injection in SantaQlaus since we could not find any improvements. For each optimizer, we choose the best hyperparameters in a grid search. For all scheduled hyperparameters, we use the function $f_{s_{0}, y_{\text {end }}, a}^{y_{0}, y_{\text {end }}, a}\left(s_{\text {tot }}\right)$ given in Eq. (43) to assign the value according to the expended shots. For the performance with respect to the shots resource usage, we empirically found this strategy is better than the usual one based on a function of the number of the iteration.

We use a gradually decreasing learning rate $\eta_{t}=$ $f_{0, s_{\max }}^{\eta_{1}, \eta_{\text {end }}, a_{\text {LR }}}\left(s_{t}\right)$, where $s_{t}$ denotes $s_{\text {tot }}$ up to $t$-th iteration. For gCANS and Refoqus, the fixed learning rate $1 / L$ is used with the Lipschitz constant $L$ of the gradient. Throughout the benchmarks and the other optimizers, we use $\eta_{1}=0.01$ and $\eta_{\text {end }}=0.001$. The exponent $a_{\mathrm{LR}}$ is chosen for each benchmark and each optimizer.

As for the annealing schedule of SantaQlaus, we employ two-fold stages corresponding to burn-in and refinement, though the update rules remain unchanged. We set the number of burn-in shots $s_{\mathrm{b}}$ such that the stage switches when that number of shots is used. From the start until $s_{\mathrm{b}}$ shots used, $\beta_{t}$ is given by $\beta_{t}=f_{0, s_{\mathrm{b}}}^{\beta_{0}, \beta_{\mathrm{b}}, a_{1}}\left(s_{t}\right)$ with parameters $\beta_{0}, \beta_{\mathrm{b}}$, and $a_{1}$ which determine the schedule, where $s_{t}$ is the total number of shots used before $t$-th iteration. We use $\beta_{0}=10$ throughout the simulations. Then, we use another schedule $f_{s_{\mathrm{b}}, \beta_{\mathrm{max}}}^{\beta_{\mathrm{r}}, a_{\mathrm{r}}, a_{2}}\left(s_{t}\right)$ for the refinement stage. In addition, we scale the inverse temperature as $\beta_{t}=f_{s_{\mathrm{b}}, s_{\mathrm{m}}}^{\beta_{\mathrm{b}}, a_{2}}\left(s_{t}\right) /\left(r \eta_{t}\right)$ in the refinement stage, in order to avoid decrease in the number of shots when $\eta_{t}$ is decreased. We use $r=100$.

## A. VQE of 1-dimensional Transverse field Ising model

As a benchmark, we begin by a VQE task of the 1dimensional transverse field Ising spin chain with open boundary conditions for the system size $N=6$ and 12 , where the Hamiltonian is given as

$$
\begin{equation*}
H=-J \sum_{i=1}^{N-1} Z_{i} Z_{i+1}-g \sum_{i=1}^{N} X_{i} \tag{44}
\end{equation*}
$$

Our goal is to obtain the ground state energy by minimizing the expected energy as the loss function. We consider the case with $g / J=1.5$. It is obvious that the interaction term $\sum_{i=1}^{N-1} Z_{i} Z_{i+1}$ or the transverse field term $\sum_{i=1}^{N} X_{i}$

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-13.jpg?height=629&width=830&top_left_y=171&top_left_x=1103)

FIG. 1. The parameterized quantum circuit used in the numerical simulation of the VQE task of a 1dimensional transverse Ising spin chain.

can be measured at once. We employ WDS to allocate the number of shots for them, as they form only two groups with similar weights. If $s$ shots are used in total, we deterministically allocate $s J(N-1) / M$ to the former and $\operatorname{sg} N / M$ to the latter, where $M=J(N-1)+g N$. The results are shown in terms of the precision of the per-site energy $\Delta E /(J N)$, where $\Delta E$ denotes the difference of the exact energy expectation value evaluated at the parameters obtained by the optimization from the groundstate energy. For this problem, we used the ansatz shown in Fig. 1 with $D=3$ following [40].

The results depicted in Fig. 2 shows the performance of various optimizers in the context of VQE tasks for 1d transverse Ising spin chains with open boundary conditions. The median of the loss function and the interquartile range (IQR), i. e. the range between the first and third quartiles, are displayed. Across scenarios with $N=6$ and $N=12$, SantaQlaus consistently demonstrates superior performance relative to the other optimizers.

For SantaQlaus, we employ $s_{\mathrm{b}}=0.8 s_{\max }, \beta_{\mathrm{b}}=\beta_{\mathrm{r}}=$ $10^{4}, a_{1}=a_{2}=5$, and $a_{\mathrm{LR}}=0.5$ for both $N=6$ and $N=12$. The learning rate exponent $a_{\mathrm{LR}}=0.1$ is used for Adam. In Adam-DS, the number of shots is gradually increased from 4 to 100 (500) according to the function (43) with $a=10$ for $N=6(N=12)$. For MCMCVQA, MCMC stage is chosen as $0.4 s_{\max }$, which is the best among $0.4 s_{\max }, 0.6 s_{\max }$, and $0.8 s_{\max }$. The learning rate exponent $a_{\mathrm{LR}}=0.3$ is used.

For $N=6$, we include Adam with fixed number of shots, denoted by Adam10 and Adam100 with each used number of shots. As a result of the grid search, 10 is the best for the fixed number of shots among 10, 50, 100, 500, and 1000. Adam-DS with tuned hyperparameters performs better than them, which implies a merit of simple dynamic shot-number increasing. SantaQlaus is even faster than that and achieves better accuracy, indicating
![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-14.jpg?height=572&width=1826&top_left_y=164&top_left_x=168)

FIG. 2. Comparison of performance of the optimizers for the VQE tasks of $1 \mathrm{~d}$ transverse Ising spin chain with open boundary conditions. Every graph shows the median (solid curve) and the IQR (the highlighted region) of 20 runs of the optimizations with different random initial parameters. The exact expectation values are plotted to indicate the performance. (a) $N=4$. The per-site ground energy approximation precision $\Delta E /(J N)$ vs number of shots. (b) $N=12$. The value $\Delta E /(J N)$ vs number of shots.

benefits beyond simple dynamic shot strategies.

For $N=12$, SantaQlaus attains the best median precision again. While Adam-DS sometimes achieves comparable precision with SantaQlaus, it gets to poor local minima in some trials, as seen from its widespread of the IQR. In stark contrast, SantaQlaus reliably maintains high precision, underscored by its narrower interquartile spread.

Despite its rapid initial progress, gCANS gets stuck in local minima at an early stage of optimization. One contributing factor is that when the parameters enter a local mode or reach a stationary point, the shot-allocation rule of gCANS prescribes a large number of shots. This is because the number of shots in gCANS is inversely proportional to the norm of the gradient. MCMC-VQA does not seem to achieve sufficient mixing within this shot budget to exhibit the efficacy of MCMC sampling.

Overall, these results show that SantaQlaus is more efficient and effective in exploring the loss landscape compared to other optimizers, consistently finding better solutions.

## B. Benchmark regression task

We next test SantaQlaus on a QML regression task investigated in Ref. [19]. A QNN used here consists of feature encoding unitary $U(\boldsymbol{x})$ and the trainable unitary $V(\boldsymbol{\theta})$ which form the model state $|\psi(\boldsymbol{x} ; \boldsymbol{\theta})\rangle=$ $V(\boldsymbol{\theta}) U(\boldsymbol{x})|0\rangle$. Given some set $\mathcal{D}=\left\{\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{N}\right\}$ of input data vectors, the label $g(\boldsymbol{x})$ of each data $\boldsymbol{x}$ is generated by the model with a randomly chosen target parameter $\boldsymbol{\theta}^{*} \in[0,2 \pi)$ as

$$
\begin{equation*}
g(\boldsymbol{x})=w^{*}\left\langle\psi\left(\boldsymbol{x} ; \boldsymbol{\theta}^{*}\right)\left|Z_{1}\right| \psi\left(\boldsymbol{x} ; \boldsymbol{\theta}^{*}\right)\right\rangle \tag{45}
\end{equation*}
$$

where $w^{*}$ is a scale factor that sets the standard deviation of the labels to 1 over the dataset, and $Z_{1}$ denotes the
Pauli $Z$ on the first qubit. Our goal is to do a regression of these labels by $w\left\langle\psi\left(\boldsymbol{x} ; \boldsymbol{\theta}^{*}\right)\left|Z_{1}\right| \psi\left(\boldsymbol{x} ; \boldsymbol{\theta}^{*}\right)\right\rangle$ via tuning $w$ and $\boldsymbol{\theta}$ without knowing the target parameters. We use the MSE as the loss function. As the correct parameters exist, the representability of the ansatz does not matter in this task.

As the input data, we use a dimensionality-reduced feature vectors of fashion MNIST [150] via principal component analysis following Ref. [19]. We use $M=1100$ data points as the whole dataset. In each training, the size of the training dataset is 880 and the test data size is 220. We use the same feature encoding circuit $U(\boldsymbol{x})$ and trainable circuit $V(\boldsymbol{\theta})$ as Ref. [19]. The feature encoding is similar to the one proposed in Ref. [13], which is given as:

$$
\begin{equation*}
U(\boldsymbol{x})\left|0^{\otimes N}\right\rangle=U_{z}(\boldsymbol{x}) H^{\otimes N} U_{z}(\boldsymbol{x}) H^{\otimes N}\left|0^{\otimes N}\right\rangle \tag{46}
\end{equation*}
$$

with

$$
\begin{equation*}
U_{z}(\boldsymbol{x})=\exp \left(-i \pi\left[\sum_{i=1}^{N} x_{i} Z_{i}+\sum_{j=1, j>i}^{N} x_{i} x_{j} Z_{i} Z_{j}\right]\right) \tag{47}
\end{equation*}
$$

for $N$-qubit system, where $H$ denotes the Hadamard gate. As for the trainable circuit $V(\theta)$, these are composed of $D$ layers of single-qubit rotations $R\left(\theta_{i, j}\right)$ on each of the qubits, interlaid with $C Z=|1\rangle\langle 1| \otimes Z$ gates between nearest neighbours in the circuit, where $R\left(\theta_{i, j}\right)=$ $R_{X}\left(\theta_{i, j, 0}\right) R_{Y}\left(\theta_{i, j, 1}\right) R_{Z}\left(\theta_{i, j, 2}\right)$. We implemented simulations for the case of $N=4, D=10$ (133 parameters), and $N=10, D=2$ (91 parameters). We employ $s_{\mathrm{b}}=0.5 s_{\max }, \beta_{\mathrm{b}}=5000(500), \beta_{\mathrm{r}}=10^{4}\left(10^{3}\right)$, and $a_{1}=a_{2}=3$ for $N=4(N=10)$. The learning rate exponent $a_{\mathrm{LR}}=0.3$ is used for both SantaQlaus and Adam-DS. In Adam-DS, the number of shots is gradually increased from 4 to 100 according to the function (43) with $a=2$. For both optimizers, the batch size is

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-15.jpg?height=1124&width=1827&top_left_y=159&top_left_x=165)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-15.jpg?height=545&width=889&top_left_y=172&top_left_x=171)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-15.jpg?height=556&width=863&top_left_y=725&top_left_x=181)

(b)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-15.jpg?height=544&width=870&top_left_y=183&top_left_x=1113)

(d)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-15.jpg?height=505&width=840&top_left_y=772&top_left_x=1117)

FIG. 3. Comparison of performance of the optimizers for the regression task. Every graph shows the median (solid curve) and the IQR (the highlighted region) of 20 trials of the regression with different training data and the initial parameters. The MSE for the prediction obtained by the exact expectation values is plotted to indicate the performance. (a) 4-qubit 10 layers. MSE for train data vs number of shots. (b) 4-qubit 10 layers. MSE for test data vs number of shots. (c) 10-qubit 2 layers. MSE for train data vs number of shots. (d) 10-qubit 2 layers. MSE for test data vs number of shots.

gradually increased from 2 to 16 according to the function (43) with $a=2$.

The performance of different optimizers for the regression task is shown in Fig. 3. Clearly, SantaQlaus demonstrates superior performance compared to other optimizers, achieving the lowest median MSE for both training and test data. Regarding the 4 -qubit case shown in (a) and (b) of Fig. 3, while Adam-DS displays some optimization progression, SantaQlaus consistently achieves lower MSE, indicating its enhanced accuracy and efficient use of shot resources. Turning to the 10 -qubit scenario in graphs (c) and (d) of Fig. 3, the optimization landscape appears notably challenging. Here, Refoqus is unable to escape from a plateau without showing significant improvement as the number of shots increases. Adam-DS, while presenting some improvement in the median MSE, has a large upper quartile, suggesting that it often becomes trapped in less optimal regions of the optimization landscape. In contrast, SantaQlaus consistently delivers a lower median MSE and exhibits a decreasing upper quartile, highlighting its robust capability in navigating and optimizing even in such challenging landscapes.

## C. Classification of Iris dataset with local depolarizing noise

Finally, we test SantaQlaus on a classification task using the Iris dataset [151]. The Iris dataset comprises three classes of Iris flowers, with 50 samples per class, and includes four features for each sample. We use the normalized input data $\boldsymbol{z}$ given by $z_{i, j}=\left(x_{i, j}-\right.$ $\left.\min _{k}\left(x_{k, j}\right)\right) /\left(\max _{k}\left(x_{k, j}\right)-\min _{k}\left(x_{k, j}\right)\right)$, where $x_{i, j}$ denotes the $j$-th feature of the $i$-th data point. We randomly select 120 data points used for the training. Then, the remaining 30 data points are used as the test data.

We employ the ansatz $|\psi(\boldsymbol{x} ; \boldsymbol{\theta})\rangle$ given by the same feature encoding and trainable circuits as those for the previous QML benchmark in Sec. VB with $N=4$ and $D=4$. We use $Z_{1} \otimes Z_{2}$ as the observable to be measured, which yields two bits $\left(b_{1}, b_{2}\right)$ as an outcome. Then, we assign a label of the class $y\left(b_{1}, b_{2}\right):=b_{1}+2 b_{2}(\bmod 3)$ to each outcome. The label prediction for each data point $x$ is determined by the most frequently occurring value of $y\left(b_{1}, b_{2}\right)$, based on repeated measurements of $|\psi(\boldsymbol{x} ; \boldsymbol{\theta})\rangle$. Hence, the label value with the highest proba-
(a)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-16.jpg?height=515&width=898&top_left_y=211&top_left_x=169)

(c)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-16.jpg?height=510&width=872&top_left_y=772&top_left_x=171)

(b)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-16.jpg?height=510&width=878&top_left_y=214&top_left_x=1103)

(d)

![](https://cdn.mathpix.com/cropped/2024_06_04_80a0a9730f39f5f427afg-16.jpg?height=499&width=857&top_left_y=775&top_left_x=1103)

FIG. 4. Comparison of performance of the optimizers for the classification of the Iris dataset. Every graph shows the median (solid curve) and the IQR (the highlighted region) of 20 trials of the training with different training data and the initial parameters. The dashed curves depict the median of learning curves in the absence of the depolarizing noise (only shot noise). Plotted MSE and error rate are computed from the exact expectation values without hardware noise, while training are done with finite number of shots under the influence of the local depolarizing noise. (a) MSE for train data vs number of shots. (b) MSE for test data vs number of shots. (c) Error rate for train data vs number of shots. (d) Error rate for test data vs number of shots.

bility emerges as the predicted label with infinitely many measurements. As the loss function to be minimized, we use the MSE of the success probability given as

$$
\begin{equation*}
L(\boldsymbol{\theta})=\frac{1}{M} \sum_{i=1}^{M}\left(1-p\left(\boldsymbol{x}_{i}, \boldsymbol{\theta}\right)\right)^{2} \tag{48}
\end{equation*}
$$

where $p\left(\boldsymbol{x}_{i}, \boldsymbol{\theta}\right)$ denotes the probability of obtaining the correct label for the data point $\boldsymbol{x}_{i}$ with the model parameter $\boldsymbol{\theta}$. This is the same as the mean squared failure probability. Because this is MSE, we obtain unbiased estimators of the gradient and its variance as we have seen in Sec. II A and IV A. That is the reason of this choice of the loss function in this benchmark.

In this simulation, hardware noise is incorporated, specifically modeled as local depolarizing noise. To represent this, a single-qubit (two-qubit) depolarizing channel is introduced after every single-qubit (two-qubit) gate, with the exception of $Z$-rotation gates. The error probabilities assigned are $10^{-3}$ for single-qubit gates and $10^{-2}$ for two-qubit gates.
As for the hyperparameters specific to this benchmark, we employ $s_{\mathrm{b}}=0.5 s_{\max }, \beta_{\mathrm{b}}=10^{4}, \beta_{\mathrm{r}}=5 \times 10^{4}$, and $a_{1}=a_{2}=3$ for SantaQlaus. The learning rate exponent $a_{\mathrm{LR}}=0.3$ is used for both SantaQlaus and Adam-DS. In Adam-DS, the number of shots is gradually increased from 4 to 10 according to the function (43) with $a=3$. For both optimizers, the batch size is gradually increased from 2 to 16 according to the function (43) with $a=1$.

The performance of different optimizers for this classification task is shown in Fig. 4. Here, the error rate is defined as the proportion of incorrectly predicted labels to the total number of data points. Both MSE and the error rate are calculated by the exact expectation values in the absence of noise, to evaluate the achievable performance of the obtained model. To account for misclassification arising from statistical errors, we assume a worst-case scenario. In this scenario, a data point $\boldsymbol{x}_{i}$ is considered misclassified if the difference $\Delta p\left(\boldsymbol{x}_{i}\right)$ between the highest and the second-highest label probabilities is less than $2 \epsilon$, where $\epsilon$ is a positive constant. This approach is relevant because if the statistical error in probability
distribution estimation exceeds $\epsilon$ and $\Delta p\left(\boldsymbol{x}_{i}\right)$ is smaller than $2 \epsilon$, there is a risk of predicting an incorrect label, even when the highest probability corresponds to the correct label. To estimate the probability within the precision of $\epsilon$, we need $1 / \epsilon^{2}$ times sampling overhead for both the direct estimation using a quantum device, and the acquisition of a classical surrogate [20]. Here, we choose $\epsilon=10^{-2}$ corresponding to the sampling overhead $10^{4}$.

According to the resulting learning curves in Fig. 4, SantaQlaus demonstrates the highest performance even in the presence of the local depolarizing noise. For both the MSE and the error rate, we can clearly see that the ability of SantaQlaus to efficiently exploring better optimal parameters surpasses the others. Notably, our results imply that SantaQlaus is much more robust to the hardware noise than the other methods. Indeed, the presence of hardware noise significantly impairs the learning performance of the Adam-DS optimizer. In contrast, SantaQlaus maintains nearly consistent performance levels under the same noise. This robustness may be attributed to the efficient exploration strategy of SantaQlaus, which leverages QSN with its adaptively adjusted variance. It is suggested that this strategy is also effective in navigating challenging landscape which may be caused by hardware noise.

## VI. CONCLUSION

In this study, we introduced SantaQlaus, an optimizer designed to strategically leverage inherent QSN for efficient loss landscape exploration while minimizing the number of quantum measurement shots. The algorithm is applicable to a broad spectrum of loss functions encountered in VQAs and QML, including those that are non-linear. Incorporating principles from the classical Santa algorithm [64], SantaQlaus exploits annealed QSN to effectively evade saddle points and poor local minima. The algorithm adjusts the number of measurement shots to emulate appropriate thermal noise based on the asymptotic normality of QSN in the gradient estimator. This adjustment requires only a small classical computational overhead for variance estimation. Moreover, the update rule of our algorithm includes thermostats from Santa that provide robustness against estimation errors of the variance of QSN. SantaQlaus naturally attains resource efficiency by initiating the optimization process with a low shot count during the high-temperature early stages, and gradually increasing the shot count for more precise gradient estimation as the temperature decreases.

We have demonstrated the efficacy of SantaQlaus through numerical simulations on benchmark tasks in VQE, regression task, and a multiclass classification under the influence of the local depolarizing noise. Our optimizer consistently outperforms existing algorithms, which often get stuck in suboptimal local minima or flat regions of the loss landscape. Our results imply that compared to shot-adaptive strategies like gCANS, SantaQlaus excels in directly addressing the challenges in the loss landscape rather than merely maximizing iteration gains. SantaQlaus also exhibits advantages over basic shot-number annealing approaches like Adam-DS. Moreover, our simulation implies that SantaQlaus is robust against hardware noise, which may also highlight the efficiency of the exploration strategy of SantaQlaus leveraging QSN.

Looking ahead, additional research is needed to assess performance of SantaQlaus in experiments. The demonstrated robustness of SantaQlaus against hardware noise indicates its potential for promising results in practical experiments. This aspect warrants comprehensive investigation to fully understand and leverage its capabilities in real-world applications. Incorporating QEM techniques into SantaQlaus also offers a promising route for experimental deployments. For QNNs, combining SantaQlaus with a recent noise-aware training strategy [144] could potentially enhance robustness and efficiency under realistic conditions. Incorporating advanced preconditioning techniques, such as Fisher information, may provide further improvements. These avenues remain open for future exploration.

## ACKNOWLEDGMENTS

This work is supported by MEXT Quantum Leap Flagship Program (MEXT QLEAP) Grant Number JPMXS0120319794, and JST COI-NEXT Grant Number JPMJPF2014.
[1] J. Preskill, "Quantum Computing in the NISQ era and beyond," Quantum 2, 79 (2018).

[2] M. Cerezo, A. Arrasmith, R. Babbush, S. C. Benjamin, S. Endo, K. Fujii, J. R. McClean, K. Mitarai, X. Yuan, L. Cincio, and P. J. Coles, "Variational quantum algorithms," Nature Reviews Physics 3, 625 (2021).

[3] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O'Brien, "A variational eigenvalue solver on a photonic quantum processor," Nature Communications 5, 4213
(2014).

[4] P. J. J. O'Malley, R. Babbush, I. D. Kivlichan, J. Romero, J. R. McClean, R. Barends, J. Kelly, P. Roushan, A. Tranter, N. Ding, B. Campbell, Y. Chen, Z. Chen, B. Chiaro, A. Dunsworth, A. G. Fowler, E. Jeffrey, E. Lucero, A. Megrant, J. Y. Mutus, M. Neeley, C. Neill, C. Quintana, D. Sank, A. Vainsencher, J. Wenner, T. C. White, P. V. Coveney, P. J. Love, H. Neven, A. Aspuru-Guzik, and J. M. Martinis, "Scalable quantum simulation of molecular energies," Phys. Rev. X 6,

031007 (2016).

[5] B. Bauer, D. Wecker, A. J. Millis, M. B. Hastings, and M. Troyer, "Hybrid quantum-classical approach to correlated materials," Phys. Rev. X 6, 031045 (2016).

[6] A. Kandala, A. Mezzacapo, K. Temme, M. Takita, M. Brink, J. M. Chow, and J. M. Gambetta, "Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets," Nature 549, 242 (2017).

[7] E. Farhi, J. Goldstone, and S. Gutmann, "A Quantum Approximate Optimization Algorithm," arXiv:1411.4028 (2014).

[8] E. Farhi and A. W. Harrow, "Quantum Supremacy through the Quantum Approximate Optimization Algorithm," arXiv:1602.07674 (2016).

[9] J. S. Otterbach, R. Manenti, N. Alidoust, A. Bestwick, M. Block, B. Bloom, S. Caldwell, N. Didier, E. S. Fried, S. Hong, P. Karalekas, C. B. Osborn, A. Papageorge, E. C. Peterson, G. Prawiroatmodjo, N. Rubin, C. A. Ryan, D. Scarabelli, M. Scheer, E. A. Sete, P. Sivarajah, R. S. Smith, A. Staley, N. Tezak, W. J. Zeng, A. Hudson, B. R. Johnson, M. Reagor, M. P. da Silva, and C. Rigetti, "Unsupervised Machine Learning on a Hybrid Quantum Computer," arXiv:1712.05771 (2017).

[10] K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, "Quantum circuit learning," Phys. Rev. A 98, 032309 (2018).

[11] E. Farhi and H. Neven, "Classification with Quantum Neural Networks on Near Term Processors," arXiv:1802.06002 (2018).

[12] M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, "Parameterized quantum circuits as machine learning models," Quantum Science and Technology 4, 043001 (2019).

[13] V. Havlíček, A. D. Córcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, "Supervised learning with quantum-enhanced feature spaces," Nature 567, 209 (2019).

[14] M. Schuld and N. Killoran, "Quantum machine learning in feature hilbert spaces," Phys. Rev. Lett. 122, 040504 (2019).

[15] M. Schuld and F. Petruccione, Supervised Learning with Quantum Computers, 1st ed. (Springer Publishing Company, Incorporated, 2018).

[16] M. Schuld, A. Bocharov, K. M. Svore, and N. Wiebe, "Circuit-centric quantum classifiers," Phys. Rev. A 101, 032308 (2020).

[17] H.-Y. Huang, M. Broughton, M. Mohseni, R. Babbush, S. Boixo, H. Neven, and J. R. McClean, "Power of data in quantum machine learning," Nature Communications 12, 2631 (2021).

[18] M. Schuld and F. Petruccione, "Quantum models as kernel methods," in Machine Learning with Quantum Computers (Springer International Publishing, Cham, 2021) pp. 217-245.

[19] S. Jerbi, L. J. Fiderer, H. Poulsen Nautrup, J. M. Kübler, H. J. Briegel, and V. Dunjko, "Quantum machine learning beyond kernel methods," Nature Communications 14, 517 (2023).

[20] F. J. Schreiber, J. Eisert, and J. J. Meyer, "Classical surrogates for quantum learning models," Phys. Rev. Lett. 131, 100803 (2023).

[21] J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Babbush, and H. Neven, "Barren plateaus in quantum neu- ral network training landscapes," Nature Communications 9, 4812 (2018).

[22] S. Wang, E. Fontana, M. Cerezo, K. Sharma, A. Sone, L. Cincio, and P. J. Coles, "Noise-induced barren plateaus in variational quantum algorithms," Nature Communications 12, 6961 (2021).

[23] A. Arrasmith, M. Cerezo, P. Czarnik, L. Cincio, and P. J. Coles, "Effect of barren plateaus on gradient-free optimization," Quantum 5, 558 (2021).

[24] A. V. Uvarov and J. D. Biamonte, "On barren plateaus and cost function locality in variational quantum algorithms," Journal of Physics A: Mathematical and Theoretical 54, 245301 (2021).

[25] K. Sharma, M. Cerezo, L. Cincio, and P. J. Coles, "Trainability of dissipative perceptron-based quantum neural networks," Phys. Rev. Lett. 128, 180505 (2022).

[26] C. Ortiz Marrero, M. Kieferová, and N. Wiebe, "Entanglement-induced barren plateaus," PRX Quantum 2, 040316 (2021).

[27] Z. Holmes, K. Sharma, M. Cerezo, and P. J. Coles, "Connecting ansatz expressibility to gradient magnitudes and barren plateaus," PRX Quantum 3, 010313 (2022).

[28] Z. Holmes, A. Arrasmith, B. Yan, P. J. Coles, A. Albrecht, and A. T. Sornborger, "Barren plateaus preclude learning scramblers," Phys. Rev. Lett. 126, 190501 (2021).

[29] L. Bittel and M. Kliesch, "Training variational quantum algorithms is np-hard," Phys. Rev. Lett. 127, 120502 (2021).

[30] E. R. Anschuetz and B. T. Kiani, "Quantum variational algorithms are swamped with traps," Nature Communications 13, 7760 (2022).

[31] M. Cerezo, A. Sone, T. Volkoff, L. Cincio, and P. J. Coles, "Cost function dependent barren plateaus in shallow parametrized quantum circuits," Nature Communications 12, 1791 (2021).

[32] A. Pesah, M. Cerezo, S. Wang, T. Volkoff, A. T. Sornborger, and P. J. Coles, "Absence of barren plateaus in quantum convolutional neural networks," Phys. Rev. X 11, 041011 (2021).

[33] K. Zhang, M.-H. Hsieh, L. Liu, and D. Tao, "Toward Trainability of Deep Quantum Neural Networks," arXiv:2112.15002 (2021).

[34] T. L. Patti, K. Najafi, X. Gao, and S. F. Yelin, "Entanglement devised barren plateau mitigation," Phys. Rev. Res. 3, 033090 (2021).

[35] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," Proceedings of the 3rd International Conference on Learning Representations (2014).

[36] J. A. Nelder and R. Mead, "A simplex method for function minimization," Computer Journal 7, 308 (1965).

[37] M. J. D. Powell, "An efficient method for finding the minimum of a function of several variables without calculating derivatives," The Computer Journal 7, 155 (1964), https://academic.oup.com/comjnl/article-pdf/7/2/155/959784/070

[38] J. C. Spall, "A stochastic approximation technique for generating maximum likelihood parameter estimates," in Proceedings of the American Control Conference (Minneapolis, MN, 1987) pp. 1161-1167.

[39] W. Lavrijsen, A. Tudor, J. Müller, C. Iancu, and W. de Jong, "Classical optimizers for noisy intermediate-scale quantum devices," in 2020 IEEE In-
ternational Conference on Quantum Computing and Engineering (QCE) (2020) pp. 267-277.

[40] J. M. Kübler, A. Arrasmith, L. Cincio, and P. J. Coles, "An Adaptive Optimizer for Measurement-Frugal Variational Algorithms," Quantum 4, 263 (2020).

[41] R. LaRose, A. Tikku, É. O'Neel-Judy, L. Cincio, and P. J. Coles, "Variational quantum state diagonalization," npj Quantum Information 5, 57 (2019).

[42] A. Arrasmith, L. Cincio, R. D. Somma, and P. J. Coles, "Operator Sampling for Shot-frugal Optimization in Variational Algorithms," arXiv:2004.06252 (2020).

[43] J. Stokes, J. Izaac, N. Killoran, and G. Carleo, "Quantum Natural Gradient," Quantum 4, 269 (2020).

[44] B. Koczor and S. C. Benjamin, "Quantum natural gradient generalized to noisy and nonunitary circuits," Phys. Rev. A 106, 062416 (2022).

[45] K. M. Nakanishi, K. Fujii, and S. Todo, "Sequential minimal optimization for quantum-classical hybrid algorithms," Physical Review Research 2, 043158 (2020).

[46] R. M. Parrish, J. T. Iosue, A. Ozaeta, and P. L. McMahon, "A Jacobi Diagonalization and Anderson Acceleration Algorithm For Variational Quantum Algorithm Parameter Optimization," arXiv:1904.03206 (2019).

[47] R. Sweke, F. Wilde, J. Meyer, M. Schuld, P. K. Faehrmann, B. Meynard-Piganeau, and J. Eisert, "Stochastic gradient descent for hybrid quantumclassical optimization," Quantum 4, 314 (2020).

[48] B. Koczor and S. C. Benjamin, "Quantum analytic descent," Phys. Rev. Research 4, 023017 (2022).

[49] B. van Straaten and B. Koczor, "Measurement cost of metric-aware variational quantum algorithms," PRX Quantum 2, 030324 (2021).

[50] A. Gu, A. Lowe, P. A. Dub, P. J. Coles, and A. Arrasmith, "Adaptive shot allocation for fast convergence in variational quantum algorithms," arXiv:2108.10434 (2021).

[51] M. Menickelly, Y. Ha, and M. Otten, "Latency considerations for stochastic optimizers in variational quantum algorithms," arXiv:2201.13438 (2022).

[52] S. Tamiya and H. Yamasaki, "Stochastic gradient line bayesian optimization for efficient noise-robust optimization of parameterized quantum circuits," npj Quantum Information 8, 90 (2022).

[53] L. Bittel, J. Watty, and M. Kliesch, "Fast gradient estimation for variational quantum algorithms," arXiv:2210.06484 (2022).

[54] C. Moussa, M. H. Gordon, M. Baczyk, M. Cerezo, L. Cincio, and P. J. Coles, "Resource frugal optimizer for quantum machine learning," arXiv:2211.04965 (2022).

[55] G. Boyd and B. Koczor, "Training variational quantum circuits with covar: Covariance root finding with classical shadows," Phys. Rev. X 12, 041022 (2022).

[56] E. Fontana, M. Cerezo, A. Arrasmith, I. Rungger, and P. J. Coles, "Non-trivial symmetries in quantum landscapes and their resilience to quantum noise," Quantum 6,804 (2022).

[57] L. Gentini, A. Cuccoli, S. Pirandola, P. Verrucchi, and L. Banchi, "Noise-resilient variational hybrid quantumclassical optimization," Phys. Rev. A 102, 052414 (2020).

[58] T. L. Patti, O. Shehab, K. Najafi, and S. F. Yelin, "Markov chain monte carlo enhanced variational quan- tum algorithms," Quantum Science and Technology 8, 015019 (2022).

[59] S. Duffield, M. Benedetti, and M. Rosenkranz, "Bayesian learning of parameterised quantum circuits," Machine Learning: Science and Technology 4, 025007 (2023).

[60] J. Liu, F. Wilde, A. A. Mele, L. Jiang, and J. Eisert, "Stochastic noise can be helpful for variational quantum algorithms," arXiv:2210.06723 (2022).

[61] D. Wecker, M. B. Hastings, and M. Troyer, "Progress towards practical quantum variational algorithms," Phys. Rev. A 92, 042303 (2015).

[62] C. Moussa, M. H. Gordon, M. Baczyk, M. Cerezo, L. Cincio, and P. J. Coles, "Resource frugal optimizer for quantum machine learning," Quantum Science and Technology 8, 045019 (2023).

[63] K. Ito, "Latency-aware adaptive shot allocation for run-time efficient variational quantum algorithms," arXiv:2302.04422 (2023).

[64] C. Chen, D. Carlson, Z. Gan, C. Li, and L. Carin, "Bridging the gap between stochastic gradient mcmc and stochastic optimization," in Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, Proceedings of Machine Learning Research, Vol. 51, edited by A. Gretton and C. C. Robert (PMLR, Cadiz, Spain, 2016) pp. 1051-1060.

[65] E. Aïmeur, G. Brassard, and S. Gambs, "Machine learning in a quantum world," in Advances in Artificial Intelligence, edited by L. Lamontagne and M. Marchand (Springer Berlin Heidelberg, Berlin, Heidelberg, 2006) pp. 431-442.

[66] V. Dunjko, J. M. Taylor, and H. J. Briegel, "Quantumenhanced machine learning," Phys. Rev. Lett. 117, 130501 (2016).

[67] L. Buffoni and F. Caruso, "New trends in quantum machine learning(a)," Europhysics Letters 132, 60004 (2021).

[68] A. Nakayama, K. Mitarai, L. Placidi, T. Sugimoto, and K. Fujii, "VQE-generated Quantum Circuit Dataset for Machine Learning," arXiv:2302.09751 (2023).

[69] A. Pérez-Salinas, A. Cervera-Lierta, E. Gil-Fuster, and J. I. Latorre, "Data re-uploading for a universal quantum classifier," Quantum 4, 226 (2020).

[70] M. Schuld, R. Sweke, and J. J. Meyer, "Effect of data encoding on the expressive power of variational quantum-machine-learning models," Phys. Rev. A 103, 032430 (2021).

[71] M. C. Caro, E. Gil-Fuster, J. J. Meyer, J. Eisert, and R. Sweke, "Encoding-dependent generalization bounds for parametrized quantum circuits," Quantum 5, 582 (2021).

[72] K. Sharma, M. Cerezo, L. Cincio, and P. J. Coles, "Trainability of dissipative perceptron-based quantum neural networks," Phys. Rev. Lett. 128, 180505 (2022).

[73] K. Beer, D. Bondarenko, T. Farrelly, T. J. Osborne, R. Salzmann, D. Scheiermann, and R. Wolf, "Training deep quantum neural networks," Nature Communications 11, 808 (2020).

[74] I. Cong, S. Choi, and M. D. Lukin, "Quantum convolutional neural networks," Nature Physics 15, 1273 (2019).

[75] P. D. Johnson, J. Romero, J. Olson, Y. Cao, and A. Aspuru-Guzik, "QVECTOR: an algorithm for device-tailored quantum error correction,"

arXiv:1711.02249 (2017).

[76] A. W. Harrow and J. C. Napp, "Low-depth gradient measurements can improve convergence in variational hybrid quantum-classical algorithms," Phys. Rev. Lett. 126, 140502 (2021).

[77] D. Wierichs, J. Izaac, C. Wang, and C. Y.-Y. Lin, "General parameter-shift rules for quantum gradients," Quantum 6, 677 (2022).

[78] M. Schuld, V. Bergholm, C. Gogolin, J. Izaac, and N. Killoran, "Evaluating analytic gradients on quantum hardware," Phys. Rev. A 99, 032331 (2019).

[79] J. Romero, J. P. Olson, and A. Aspuru-Guzik, "Quantum autoencoders for efficient compression of quantum data," Quantum Science and Technology 2, 045001 (2017).

[80] L. Feng, S. Shu, Z. Lin, F. Lv, L. Li, and B. An, "Can cross entropy loss be robust to label noise?" in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI'20 (2021).

[81] H.-Y. Huang, R. Kueng, and J. Preskill, "Predicting many properties of a quantum system from very few measurements," Nature Physics 16, 1050 (2020).

[82] I. Hamamura and T. Imamichi, "Efficient evaluation of quantum observables using entangled measurements," npj Quantum Information 6, 56 (2020).

[83] O. Crawford, B. v. Straaten, D. Wang, T. Parks, E. Campbell, and S. Brierley, "Efficient quantum measurement of Pauli operators in the presence of finite sampling error," Quantum 5, 385 (2021).

[84] C. Hempel, C. Maier, J. Romero, J. McClean, T. Monz, H. Shen, P. Jurcevic, B. P. Lanyon, P. Love, R. Babbush, A. Aspuru-Guzik, R. Blatt, and C. F. Roos, "Quantum chemistry calculations on a trapped-ion quantum simulator," Phys. Rev. X 8, 031022 (2018).

[85] A. F. Izmaylov, T.-C. Yen, R. A. Lang, and V. Verteletskyi, "Unitary partitioning approach to the measurement problem in the variational quantum eigensolver method," Journal of Chemical Theory and Computation 16, 190 (2020).

[86] H. J. Vallury, M. A. Jones, C. D. Hill, and L. C. L. Hollenberg, "Quantum computed moments correction to variational estimates," Quantum 4, 373 (2020).

[87] V. Verteletskyi, T.-C. Yen, and A. F. Izmaylov, "Measurement optimization in the variational quantum eigensolver using a minimum clique cover," The Journal of Chemical Physics 152, 124114 (2020), https://doi.org/10.1063/1.5141458.

[88] A. Zhao, A. Tranter, W. M. Kirby, S. F. Ung, A. Miyake, and P. J. Love, "Measurement reduction in variational quantum algorithms," Phys. Rev. A 101, 062322 (2020).

[89] B. Wu, J. Sun, Q. Huang, and X. Yuan, "Overlapped grouping measurement: A unified framework for measuring quantum states," Quantum 7, 896 (2023).

[90] W. Hoeffding, "A Class of Statistics with Asymptotically Normal Distribution," The Annals of Mathematical Statistics 19, 293 (1948)

[91] .

[92] D. A. McAllester, "Pac-bayesian stochastic model selection," Machine Learning 51, 5 (2003).

[93] A. Barron and T. Cover, "Minimum complexity density estimation," IEEE Transactions on Information Theory 37, 1034 (1991).

[94] S. Walker and N. L. Hjort, "On bayesian consistency," Journal of the Royal Statistical Society. Series B (Sta- tistical Methodology) 63, 811 (2001).

[95] T. Zhang, "From $\epsilon$-entropy to kl-entropy: Analysis of minimum information complexity density estimation," The Annals of Statistics 34, 2180 (2006).

[96] T. Zhang, "Learning bounds for a generalized family of bayesian posterior distributions," in Advances in Neural Information Processing Systems, Vol. 16, edited by S. Thrun, L. Saul, and B. Schölkopf (MIT Press, 2003).

[97] P. Grünwald, "Safe learning: bridging the gap between bayes, mdl and statistical learning theory via empirical convexity," in Proceedings of the 24th Annual Conference on Learning Theory, Proceedings of Machine Learning Research, Vol. 19, edited by S. M. Kakade and U. von Luxburg (PMLR, Budapest, Hungary, 2011) pp. $397-420$.

[98] P. Grünwald, "The safe bayesian," in Algorithmic Learning Theory, edited by N. H. Bshouty, G. Stoltz, N. Vayatis, and T. Zeugmann (Springer Berlin Heidelberg, Berlin, Heidelberg, 2012) pp. 169-183.

[99] P. Grünwald, "Safe probability," Journal of Statistical Planning and Inference 195, 47 (2018), confidence distributions.

[100] P. Grünwald and T. van Ommen, "Inconsistency of Bayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It," Bayesian Analysis 12, 1069 (2017).

[101] F. Wenzel, K. Roth, B. Veeling, J. Swiatkowski, L. Tran, S. Mandt, J. Snoek, T. Salimans, R. Jenatton, and S. Nowozin, "How good is the Bayes posterior in deep neural networks really?" in Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research, Vol. 119, edited by H. D. III and A. Singh (PMLR, 2020) pp. 10248-10259.

[102] V. Fortuin, A. Garriga-Alonso, F. Wenzel, G. Ratsch, R. E. Turner, M. van der Wilk, and L. Aitchison, "Bayesian neural network priors revisited," in Third Symposium on Advances in Approximate Bayesian Inference (2021).

[103] K. Pitas and J. Arbel, "Cold Posteriors through PAC-Bayes," arXiv:2206.11173 (2022).

[104] S. Geman and D. Geman, "Stochastic relaxation, gibbs distributions, and the bayesian restoration of images," IEEE Transactions on Pattern Analysis and Machine Intelligence PAMI-6, 721 (1984).

[105] M. Welling and Y. W. Teh, "Bayesian learning via stochastic gradient langevin dynamics." in ICML, edited by L. Getoor and T. Scheffer (Omnipress, 2011) pp. 681-688.

[106] T. Chen, E. Fox, and C. Guestrin, "Stochastic gradient hamiltonian monte carlo," in Proceedings of the 31st International Conference on Machine Learning, Proceedings of Machine Learning Research, Vol. 32, edited by E. P. Xing and T. Jebara (PMLR, Bejing, China, 2014) pp. 1683-1691.

[107] I. Sutskever, J. Martens, G. Dahl, and G. Hinton, "On the importance of initialization and momentum in deep learning," in Proceedings of the 30th International Conference on Machine Learning, Proceedings of Machine Learning Research, Vol. 28, edited by S. Dasgupta and D. McAllester (PMLR, Atlanta, Georgia, USA, 2013) pp. 1139-1147.

[108] N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, and H. Neven, "Bayesian sampling using stochastic gradient thermostats," in Advances in Neural Information

Processing Systems, Vol. 27, edited by Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Weinberger (Curran Associates, Inc., 2014).

[109] Z. Gan, C. Chen, R. Henao, D. Carlson, and L. Carin, "Scalable deep poisson factor analysis for topic modeling," in Proceedings of the 32nd International Conference on Machine Learning, Proceedings of Machine Learning Research, Vol. 37, edited by F. Bach and D. Blei (PMLR, Lille, France, 2015) pp. 1823-1832.

[110] S. Nosé, "A unified formulation of the constant temperature molecular dynamics methods," The Journal of Chemical Physics 81, 511 (1984), https://pubs.aip.org/aip/jcp/article-pdf/81/1/511/9722

[111] W. G. Hoover, "Canonical dynamics: Equilibrium phase-space distributions," Phys. Rev. A 31, 1695 (1985).

[112] Y. Dauphin, H. de Vries, and Y. Bengio, "Equilibrated adaptive learning rates for non-convex optimization," in Advances in Neural Information Processing Systems, Vol. 28, edited by C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett (Curran Associates, Inc., 2015).

[113] X.-L. Li, "Preconditioned stochastic gradient descent," IEEE Transactions on Neural Networks and Learning Systems 29, 1454 (2018).

[114] X.-L. Li, "Online Second Order Methods for NonConvex Stochastic Optimizations," arXiv:1803.09383 (2018).

[115] J. Duchi, E. Hazan, and Y. Singer, "Adaptive subgradient methods for online learning and stochastic optimization," Journal of Machine Learning Research 12, 2121 (2011).

[116] T. Tieleman and G. Hinton, "Lecture 6.5 - rmsprop: Divide the gradient by a running average of its recent magnitude," Technical report (2012).

[117] M. Girolami and B. Calderhead, "Riemann manifold langevin and hamiltonian monte carlo methods," Journal of the Royal Statistical Society: Series B (Statistical Methodology) 73, 123 (2011), https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j. 14

[118] S. Patterson and Y. W. Teh, "Stochastic gradient riemannian langevin dynamics on the probability simplex," in Advances in Neural Information Processing Systems, Vol. 26, edited by C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger (Curran Associates, Inc., 2013).

[119] C. Li, C. Chen, D. Carlson, and L. Carin, "Preconditioned stochastic gradient langevin dynamics for deep neural networks," in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI'16 (AAAI Press, 2016) pp. 1788-1794.

[120] R. Khasminskii and G. Milstein, Stochastic Stability of Differential Equations, Stochastic Modelling and Applied Probability (Springer Berlin Heidelberg, 2011).

[121] S. J. Vollmer, K. C. Zygalakis, and Y. W. Teh, "Exploration of the (non-)asymptotic bias and variance of stochastic gradient langevin dynamics," Journal of Machine Learning Research 17, 1 (2016).

[122] C. Chen, N. Ding, and L. Carin, "On the convergence of stochastic gradient mcmc algorithms with high-order integrators," in Proceedings of the 28th International Conference on Neural Information Processing Systems Volume 2, NIPS'15 (MIT Press, Cambridge, MA, USA, 2015) pp. 2278-2286.
[123] C. Li, C. Chen, K. Fan, and L. Carin, "High-order stochastic gradient thermostats for bayesian learning of deep models," in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI'16 (AAAI Press, 2016) pp. 1795-1801.

[124] X. Li and P. Ding, "General forms of finite population central limit theorems with applications to causal inference," Journal of the American Statistical Association 112, 1759 (2017), https://doi.org/10.1080/01621459.2017.1295865.

[125] E. L. Lehmann, Nonparametrics: Statistical Methods Based on Ranks (Holden-Day, Inc., San Francisco, 6/511_11.

[126] Y. Li and S. C. Benjamin, "Efficient variational quantum simulator incorporating active error minimization," Phys. Rev. X 7, 021050 (2017).

[127] S. Endo, Z. Cai, S. C. Benjamin, and X. Yuan, "Hybrid quantum-classical algorithms and quantum error mitigation," Journal of the Physical Society of Japan 90, 032001 (2021), https://doi.org/10.7566/JPSJ.90.032001.

[128] K. Temme, S. Bravyi, and J. M. Gambetta, "Error mitigation for short-depth quantum circuits," Phys. Rev. Lett. 119, 180509 (2017).

[129] S. Endo, S. C. Benjamin, and Y. Li, "Practical quantum error mitigation for near-future applications," Phys. Rev. X 8, 031027 (2018).

[130] P. Czarnik, A. Arrasmith, P. J. Coles, and L. Cincio, "Error mitigation with Clifford quantum-circuit data," Quantum 5, 592 (2021).

[131] A. Strikis, D. Qin, Y. Chen, S. C. Benjamin, and Y. Li, "Learning-based quantum error mitigation," PRX Quantum 2, 040330 (2021).

[132] E. van den Berg, Z. K. Minev, A. Kandala, and K. Temme, "Probabilistic error cancellation with sparse pauli-lindblad models on noisy quantum processors," Nature Physics 19, 1116 (2023).

[133] A. Kandala, K. Temme, A. D. Córcoles, A. Mezzacapo, J. M. Chow, and J. M. Gambetta, "Error mitigation 67-9868.2extends6bue. computational reach of a noisy quantum processor," Nature 567, 491 (2019).

[134] Z. Cai, "Resource-efficient Purification-based Quantum Error Mitigation," arXiv:2107.07279 (2021).

[135] A. Mari, N. Shammah, and W. J. Zeng, "Extending quantum probabilistic error cancellation by noise scaling," Phys. Rev. A 104, 052607 (2021).

[136] P. D. Nation, H. Kang, N. Sundaresan, and J. M. Gambetta, "Scalable mitigation of measurement errors on quantum computers," PRX Quantum 2, 040326 (2021).

[137] B. Yang, R. Raymond, and S. Uno, "Efficient quantum readout-error mitigation for sparse measurement outcomes of near-term quantum devices," Phys. Rev. A 106, 012423 (2022).

[138] Z. Cai, R. Babbush, S. C. Benjamin, S. Endo, W. J. Huggins, Y. Li, J. R. McClean, and T. E. O'Brien, "Quantum Error Mitigation," arXiv:2210.00921 (2022).

[139] Y. Kim, A. Eddins, S. Anand, K. X. Wei, E. van den Berg, S. Rosenblatt, H. Nayfeh, Y. Wu, M. Zaletel, K. Temme, and A. Kandala, "Evidence for the utility of quantum computing before fault tolerance," Nature 618,500 (2023).

[140] K. Sharma, S. Khatri, M. Cerezo, and P. J. Coles, "Noise resilience of variational quantum compiling," New Journal of Physics 22, 043006 (2020).

[141] E. Fontana, N. Fitzpatrick, D. M. n. Ramo, R. Duncan, and I. Rungger, "Evaluating the noise resilience of variational quantum algorithms," Phys. Rev. A 104, 022403 (2021).

[142] S. Wang, P. Czarnik, A. Arrasmith, M. Cerezo, L. Cincio, and P. J. Coles, "Can Error Mitigation Improve Trainability of Noisy Variational Quantum Algorithms?" arXiv:2109.01051 (2021).

[143] S. T. Jose and O. Simeone, "Error-mitigation-aided optimization of parameterized quantum circuits: Convergence analysis," IEEE Transactions on Quantum Engineering 3, 1 (2022).

[144] H. Wang, J. Gu, Y. Ding, Z. Li, F. T. Chong, D. Z. Pan, and S. Han, "Quantumnat: Quantum noise-aware training with noise injection, quantization and normalization," in Proceedings of the 59th ACM/IEEE Design Automation Conference, DAC '22 (Association for Computing Machinery, New York, NY, USA, 2022) pp. 1-6.

[145] Y. Quek, D. S. França, S. Khatri, J. J. Meyer, and J. Eisert, "Exponentially tighter bounds on limitations of quantum error mitigation," arXiv:2210.11505 (2022).

[146] K. Tsubouchi, T. Sagawa, and N. Yoshioka, "Univer- sal cost bound of quantum error mitigation based on quantum estimation theory," arXiv:2208.09385 (2022).

[147] R. Takagi, H. Tajima, and M. Gu, "Universal sampling lower bounds for quantum error mitigation," arXiv:2208.09178 (2022).

[148] R. Takagi, S. Endo, S. Minagawa, and M. Gu, "Fundamental limits of quantum error mitigation," npj Quantum Information 8, 114 (2022).

[149] Y. Suzuki, Y. Kawase, Y. Masumura, Y. Hiraga, M. Nakadai, J. Chen, K. M. Nakanishi, K. Mitarai, R. Imai, S. Tamiya, T. Yamamoto, T. Yan, T. Kawakubo, Y. O. Nakagawa, Y. Ibe, Y. Zhang, H. Yamashita, H. Yoshimura, A. Hayashi, and K. Fujii, "Qulacs: a fast and versatile quantum circuit simulator for research purpose," Quantum 5, 559 (2021).

[150] H. Xiao, K. Rasul, and R. Vollgraf, "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms," arXiv:1708.07747 (2017).

[151] E. Anderson, "The species problem in iris," Annals of the Missouri Botanical Garden 23, 457 (1936).


[^0]:    * kosuke.ito.qiqb@osaka-u.ac.jp

    $\dagger$ fujii@qc.ee.es.osaka-u.ac.jp

