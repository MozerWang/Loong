# Log-Harnack Inequality and Bismut Formula for Singular McKean-Vlasov SDEs 

Xing Huang ${ }^{a)}$, Feng-Yu Wang ${ }^{a), b)}$<br>a)Center for Applied Mathematics, Tianjin University, Tianjin 300072, China<br>xinghuang@tju.edu.cn<br>b)Department of Mathematics, Swansea University, Bay Campus, SA1 8EN, United Kingdom<br>wangfy@tju.edu.cn<br>July 26,2022


#### Abstract

The log-Harnack inequality and Bsimut formula are established for McKeanVlasov SDEs with singularities in all (time, space, distribution) variables, where the drift satisfies a standard integrability condition in time-space, and may be discontinuous in the distance induced by any Dini function. The main results extend existing ones derived for the case where the drift is $L$-differentiable and Lipchitz continuous in distribution with respect to the quadratic Wasserstein distance.


AMS subject Classification: 60H10, 60B05.

Keywords: McKean-Vlasov SDEs, Log-Harnack inequality, Bismut formula, Dini function, Wasserstein distance.

## 1 Introduction

Let $\mathscr{P}$ be the set of all probability measures on $\mathbb{R}^{d}$ equipped with the weak topology, and let $W_{t}$ be an $m$-dimensional Brownian motion on a complete filtration probability space $\left(\Omega,\left\{\mathscr{F}_{t}\right\}_{t \geq 0}, \mathscr{F}, \mathbb{P}\right)$. Consider the following McKean-Vlasov SDE on $\mathbb{R}^{d}$ :

$$
\begin{equation*}
\mathrm{d} X_{t}=b_{t}\left(X_{t}, \mathscr{L}_{X_{t}}\right) \mathrm{d} t+\sigma_{t}\left(X_{t}\right) \mathrm{d} W_{t}, \quad t \in[0, T] \tag{1.1}
\end{equation*}
$$

*Supported in part by NNSFC (11801406, 11831014, 11921001).
where $T>0$ is a fixed time, $\mathscr{L}_{X_{t}}$ is the distribution of $X_{t}$, and

$$
b:[0, T] \times \mathbb{R}^{d} \times \mathscr{P} \rightarrow \mathbb{R}^{d}, \quad \sigma:[0, T] \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{d} \otimes \mathbb{R}^{m}
$$

are measurable. Because of its wide applications, this type SDE has been intensively investigated, see for instance $[3,4,7,8,14,15,18]$ and the survey $[9]$.

In this paper, we study the regularity of (1.1) for distributions in

$$
\mathscr{P}_{k}:=\left\{\mu \in \mathscr{P}:\|\mu\|_{k}:=\mu\left(|\cdot|^{k}\right)^{\frac{1}{k}}<\infty\right\}, \quad k \in(1, \infty)
$$

Note that $\mathscr{P}_{k}$ is a Polish space under the Wasserstein distance

$$
\mathbb{W}_{k}(\mu, \nu)=\inf _{\pi \in \mathscr{C}(\mu, \nu)}\left(\int_{\mathbb{R}^{d} \times \mathbb{R}^{d}}|x-y|^{k} \pi(\mathrm{d} x, \mathrm{~d} y)\right)^{\frac{1}{k}}
$$

where $\mathscr{C}(\mu, \nu)$ is the set of all couplings of $\mu$ and $\nu$. The SDE (1.1) is called wellposed for distributions in $\mathscr{P}_{k}$, if for any initial value $X_{0}$ with $\mathscr{L}_{X_{0}} \in \mathscr{P}_{k}$ (respectively, any initial distribution $\gamma \in \mathscr{P}_{k}$ ), it has a unique solution (respectively, a unique weak solution) $X=\left(X_{t}\right)_{t \in[0, T]}$ such that $\mathscr{L}_{X .}:=\left(\mathscr{L}_{X_{t}}\right)_{t \in[0, T]} \in C\left([0, T] ; \mathscr{P}_{k}\right)$. In this case, for any $\gamma \in \mathscr{P}_{k}$, let $P_{t}^{*} \gamma=\mathscr{L}_{X_{t}^{\gamma}}$ for the solution $X_{t}^{\gamma}$ with $\mathscr{L}_{X_{0}^{\gamma}}=\gamma$. We study the regularity of the map

$$
\mathscr{P}_{k} \ni \gamma \mapsto P_{t} f(\gamma):=\mathbb{E}\left[f\left(X_{t}^{\gamma}\right)\right]=\int_{\mathbb{R}^{d}} f d\left\{P_{t}^{*} \gamma\right\}
$$

for $t \in(0, T]$ and $f \in \mathscr{B}_{b}\left(\mathbb{R}^{d}\right)$, where $\mathscr{B}_{b}\left(\mathbb{R}^{d}\right)$ is the space of bounded measurable functions on $\mathbb{R}^{d}$.

As powerful tools charactering the regularity in distribution for stochastic systems, the dimension-free Harnack due to [19], the log-Harnack inequality introduced in [20], and the Bismut formula developed from [5] have been intensively investigated, see the monograph [21] for the study on SPDEs and applications. In recent years, the log-Harnack inequality and Bismut formula have also been established for McKean-Vlasov SDEs with drifts $L$-differentiable and $\mathbb{W}_{2}$-Lipschitz continuous in distribution. Below we present a brief summary.

When $b_{t}(x, \mu)=b_{t}^{(0)}(x)+b_{t}^{(1)}(x, \mu)$, where $b^{(0)}$ satisfies some integrability condition on $(t, x)$ and $b_{t}^{(1)}$ is Lipschitz continuous in $(x, \mu) \in \mathbb{R}^{d} \times \mathscr{P}_{2}$, the log-Harnack inequality

$$
P_{t} \log f(\tilde{\gamma}) \leq \log P_{t} f(\gamma)+\frac{c}{t} \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}, \quad t \in(0, T], f \in \mathscr{B}_{b}^{+}\left(\mathbb{R}^{d}\right), \gamma, \tilde{\gamma} \in \mathscr{P}_{2}
$$

has been established in [24], where $c>0$ is a constant and $\mathscr{B}_{b}^{+}\left(\mathbb{R}^{d}\right)$ is the space of positive elements in $\mathscr{B}_{b}\left(\mathbb{R}^{d}\right)$. This is equivalent to the entropy-cost inequality

$$
\operatorname{Ent}\left(P_{t}^{*} \gamma \mid P_{t}^{*} \tilde{\gamma}\right) \leq \frac{c}{t} \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}, \quad t \in(0, T], \gamma, \tilde{\gamma} \in \mathscr{P}_{2}
$$

where Ent is the relative entropy, i.e. for any $\mu, \nu \in \mathscr{P}, \operatorname{Ent}(\nu \mid \mu):=\infty$ if $\nu$ is not absolutely continuous with respect to $\mu$, while

$$
\operatorname{Ent}(\nu \mid \mu):=\mu(\rho \log \rho)=\int_{\mathbb{R}^{d}}(\rho \log \rho) \mathrm{d} \mu, \quad \text { if } \rho:=\frac{\mathrm{d} \nu}{\mathrm{d} \mu} \text { exists. }
$$

See also $[12,22,23]$ for $\log$-Harnack inequalities with more regular $b^{(0)}$, and see $[16]$ for the dimension-free Harnack inequality with power.

When $b_{t}^{(1)}(x, \mu)$ is $L$-differentiable in $\mu \in \mathscr{P}_{k}$ (see Definition 3.1), the following type Bismut formula is established in [24]:

$$
D_{\phi}^{I} P_{t} f(\mu)=\mathbb{E}\left[f\left(X_{t}^{\mu}\right) M_{t}^{\mu, \phi}\right], \quad t \in(0, T], f \in \mathscr{B}_{b}\left(\mathbb{R}^{d}\right), \mu \in \mathscr{P}_{k}, \phi \in L^{k}\left(\mathbb{R}^{d} \rightarrow \mathbb{R}^{d} ; \mu\right)
$$

where $M_{t}^{\mu, \phi}$ is an explicit martingale. See $[22,17,2,10]$ for earlier results with more regular $b^{(0)}$. We note that a derivative estimate is presented in [6] for the heat kernel when the drift is of type $b_{t}(x, \mu(V))$ for some Hölder continuous function $\phi$, where $\mu(V):=\int_{\mathbb{R}^{d}} V \mathrm{~d} \mu$. In this case the drift is Lipschitz continuous in distribution with respect to the distance induced by $\varepsilon$-Hölder continuous functions for some $\varepsilon \in(0,1)$ :

$$
\mathbb{W}_{\varepsilon}(\mu, \nu):=\sup \left\{|\mu(f)-\nu(f)|:|f(x)-f(y)| \leq|x-y|^{\varepsilon}\right\}
$$

In this paper, we establish the log-Harnack inequality and Bismut formula for the drift being only Lipschitz continuous in distribution with respect to

$$
\mathbb{W}_{\alpha}(\mu, \nu):=\sup \{|\mu(f)-\nu(f)|:|f(x)-f(y)| \leq \alpha(|x-y|)\}
$$

where $\alpha$ is the square root of a Dini function, i.e. $\alpha$ is concave with $\alpha(0)=0, \alpha^{\prime}(s)>0$

for $s>0$, and $\int_{0}^{1} \frac{\alpha(s)^{2}}{s} \mathrm{~d} s<\infty$ (Dini condition for $\alpha^{2}$ ). Thus, the continuity of drift in distribution is even weaker than the Dini continuity, i.e. it may be discontinuous in the distance induced by Dini functions.

In the existing study of dimension-free/log Harnack inequalities and Bismut formulas for singular SDEs, a key technique is to regularize the drift in the spatial variable $x$ by using Zvonkin's transform [28]. The idea of the present paper is to realize this type regularization also in the distribution variable, by using a-prior derivative estimates and Bismut formula for (distribution independent) singular SDEs.

## 2 Log-Harnack Inequality

Since $\mathbb{W}_{2}$ is involved in the log-Harnack inequality, in this section we mainly consider (1.1) for distributions in $\mathscr{P}_{2}$, but the drift may be discontinuous in $\mathbb{W}_{k}$ for any $k>0$. We first state the concrete assumption and the main result on the log-Harnack inequality, then present a complete proof in a separate subsection.

### 2.1 Assumption and main result

We will allow $b_{t}(x, \cdot)$ to be merely Lipschitz continuous in the sum of $\mathbb{W}_{2}$ and the Wasserstein distance induced by the square root of a Dini function.

Let $\alpha$ be in the following class

$\mathscr{A}:=\left\{\alpha:[0, \infty) \rightarrow[0, \infty)\right.$ is increasing and concave, $\left.\alpha(0)=0, \int_{0}^{1} \frac{\alpha(r)^{2}}{r} \mathrm{~d} r \in(0, \infty)\right\}$, where $\int_{0}^{1} \frac{\alpha(r)^{2}}{r} \mathrm{~d} r<\infty$ is the Dini condition for $\alpha^{2}$. For a (real or Banach valued) function $f$, let

$$
[f]_{\alpha}:=\sup _{x \neq y} \frac{|f(x)-f(y)|}{\alpha(|x-y|)}
$$

be its continuity modulus in $\alpha$. Define the Wasserstein distance induced by $\alpha$ :

$$
\mathbb{W}_{\alpha}(\mu, \nu):=\sup _{[f]_{\alpha} \leq 1}|\mu(f)-\nu(f)|, \quad \mu, \nu \in \mathscr{P}_{\alpha}:=\{\mu \in \mathscr{P}: \mu(\alpha(|\cdot|))<\infty\}
$$

where $f$ are real functions and $\mu(f)=\int_{\mathbb{R}^{d}} f \mathrm{~d} \mu$.

By the concavity of $\alpha, \mathbb{W}_{\alpha}$ is a complete distance on $\mathscr{P}_{\alpha}, \mathscr{P}_{k} \subset \mathscr{P}_{\alpha}$ for $k \geq 1$, and

$$
\begin{equation*}
\alpha(s+t) \leq \alpha(s)+\alpha(t), \quad \alpha(r t) \leq r \alpha(t), \quad s, t>0, r \geq 1 \tag{https://cdn.mathpix.com/cropped/2024_05_26_ad8ce8e666f2455d6fc1g-04.jpg?height=52&width=95&top_left_y=1275&top_left_x=240}
\end{equation*}
$$

These inequalities follow from $\alpha(0)=0$ and the decreasing monotonicity of $\alpha^{\prime}$ such that

$$
\alpha^{\prime}(s+t) \leq \alpha^{\prime}(s), \quad \frac{\mathrm{d}}{\mathrm{d} t} \alpha(r t)=r \alpha^{\prime}(r t) \leq r \alpha^{\prime}(t), \quad s, t \geq 0, r \geq 1
$$

Since $\alpha$ is increasing with $\int_{0}^{1} \frac{\alpha(s)^{2}}{s} \mathrm{~d} s>0$, we have $\alpha(1)>0$ so that the second estimate in $(2.1)$ with $r=t^{-1}$ yields

$$
\begin{equation*}
\alpha(t) \geq \alpha(1) t>0, \quad t \in(0,1] \tag{2.2}
\end{equation*}
$$

To measure the singularity in $(t, x) \in[0, T] \times \mathbb{R}^{d}$, we recall locally integrable functional spaces presented in [25]. For any $t>s \geq 0$ and $p, q \in(1, \infty)$, we write $f \in \tilde{L}_{p}^{q}([s, t])$ if $f:[s, t] \times \mathbb{R}^{d} \rightarrow \mathbb{R}$ is measurable with

$$
\|f\|_{\tilde{L}_{p}^{q}([, t])}:=\sup _{y \in \mathbb{R}^{d}}\left\{\int_{s}^{t}\left(\int_{B(y, 1)}|f(r, x)|^{p} \mathrm{~d} x\right)^{\frac{q}{p}} \mathrm{~d} r\right\}^{\frac{1}{q}}<\infty
$$

where $B(y, 1):=\left\{x \in \mathbb{R}^{d}:|x-y| \leq 1\right\}$ is the unit ball centered at point $y$. When $s=0$, we simply denote

$$
\tilde{L}_{p}^{q}(t)=\tilde{L}_{p}^{q}([0, t]), \quad\|f\|_{\tilde{L}_{p}^{q}(t)}=\|f\|_{\tilde{L}_{p}^{q}([0, t])}
$$

We take $(p, q)$ from the space

$$
\mathscr{K}:=\left\{(p, q): p, q>2, \frac{d}{p}+\frac{2}{q}<1\right\}
$$

and make the following assumption where $\nabla$ is the gradient in $x \in \mathbb{R}^{d}$.

(A) There exist $\alpha \in \mathscr{A}, k \in(1, \infty), \kappa \in[0, \infty), K \in(0, \infty), l \in \mathbb{N}$, and

$$
1 \leq f_{i} \in \tilde{L}_{p_{i}}^{q_{i}}(T), \quad\left(p_{i}, q_{i}\right) \in \mathscr{K}, \quad 0 \leq i \leq l
$$

such that the following conditions hold.

$\left(A_{1}\right)\left(\sigma_{t} \sigma_{t}^{*}\right)(x)$ is invertible and $\sigma_{t}(x)$ is weakly differentiable in $x$ such that

$$
\begin{aligned}
& \left\|\sigma \sigma^{*}\right\|_{\infty}+\left\|\left(\sigma \sigma^{*}\right)^{-1}\right\|_{\infty}<\infty, \quad|\nabla \sigma| \leq \sum_{i=1}^{l} f_{i} \\
& \lim _{\varepsilon \downarrow 0} \sup _{t \in[0, T],\left|x-x^{\prime}\right| \leq \varepsilon}\left\|\left(\sigma_{t} \sigma_{t}^{*}\right)(x)-\left(\sigma_{t} \sigma_{t}^{*}\right)\left(x^{\prime}\right)\right\|=0
\end{aligned}
$$

(A) $b_{t}(x, \mu)=b_{t}^{(0)}(x)+b_{t}^{(1)}(x, \mu)$, where for any $t \in[0, T], x, y \in \mathbb{R}^{d}, \mu, \nu \in \mathscr{P}_{k}$,

$$
\begin{aligned}
& \left|b_{t}^{(0)}(x)\right| \leq f_{0}(t, x), \quad\left|b_{t}^{(1)}(x, \mu)\right| \leq K+\kappa|x|+\kappa\|\mu\|_{k} \\
& \left|b_{t}^{(1)}(x, \mu)-b_{t}^{(1)}(y, \nu)\right| \leq K\left\{|x-y|+\mathbb{W}_{\alpha}(\mu, \nu)+\mathbb{W}_{k}(\mu, \nu)\right\}
\end{aligned}
$$

We first observe that (A) implies the well-posedness of (1.1) for distributions in $\mathscr{P}_{k}$. Since $\alpha(0)=0$ and $\alpha$ is concave, there exists a constant $c>0$ such that

$$
\sup _{[f]_{\alpha} \leq 1}|f(x)-f(0)| \leq \alpha(|x|) \leq c+c|x|^{k}, \quad x \in \mathbb{R}^{d}
$$

Thus,

$$
\begin{equation*}
\frac{1}{c} \mathbb{W}_{\alpha}(\mu, \nu) \leq \mathbb{W}_{k, v a r}(\mu, \nu):=\sup _{|f| \leq 1+|\cdot|^{k}}|\mu(f)-\nu(f)| \tag{2.3}
\end{equation*}
$$

So, by [23, Theorem 3.1(1)] for $D=\mathbb{R}^{d}$, under assumption (A), (1.1) is well-posed for distributions in $\mathscr{P}_{k}$, and for any $n \geq 1$ there exists a constant $c_{n}>0$ such that

$$
\mathbb{E}\left[\sup _{t \in[0, T]}\left|X_{t}\right|^{n} \mid \mathscr{F}_{0}\right] \leq c_{n}\left(1+\left|X_{0}\right|^{n}\right)
$$

Consequently,

$$
\begin{equation*}
\sup _{t \in[0, T]}\left\|P_{t}^{*} \gamma\right\|_{n}^{n}=\mathbb{E}\left[\sup _{t \in[0, T]}\left|X_{t}^{\gamma}\right|^{n}\right] \leq c_{n}\left(1+\|\gamma\|_{n}^{n}\right), \quad n \geq 1 \tag{2.4}
\end{equation*}
$$

Theorem 2.1. Assume (A) with $k=2$, let

$$
\tilde{\alpha}(r):=\left(\int_{0}^{r} \frac{\alpha(t)^{2}}{t} \mathrm{~d} t\right)^{\frac{1}{2}}, \quad r \geq 0
$$

Then there exists a constant $c>0$ such that for any $t \in(0, T]$ and $\gamma, \tilde{\gamma} \in \mathscr{P}_{2}$,

$$
\operatorname{Ent}\left(P_{t}^{*} \gamma \mid P_{t}^{*} \tilde{\gamma}\right) \leq \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}\left\{\frac{c}{t}+\tilde{\alpha}\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2} \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2}}\right\}
$$

If in particular $\kappa=0\left(\right.$ i.e. $b^{(1)}$ is bounded $)$, there exists a constant $c>0$ such that

$$
\operatorname{Ent}\left(P_{t}^{*} \gamma \mid P_{t}^{*} \tilde{\gamma}\right) \leq \frac{c}{t} \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}, \quad t \in(0, T], \gamma, \tilde{\gamma} \in \mathscr{P}_{2}
$$

### 2.2 Proof of Theorem 2.1

Although in Theorem 2.1 we assume (A) for $k=2$, for later use we will also consider general $k \in[1, \infty)$. For any $\gamma \in \mathscr{P}_{k}$, consider the decoupled SDE of (1.1):

$$
\mathrm{d} X_{t}^{x, \gamma}=b_{t}\left(X_{t}^{x, \gamma}, P_{t}^{*} \gamma\right) \mathrm{d} t+\sigma_{t}\left(X_{t}^{x, \gamma}\right) \mathrm{d} W_{t}, \quad X_{0}^{x, \gamma}=x
$$

By (A), this SDE is well-posed, so that the solution is a standard Markov process, see [24, Theorem 2.1]. Let $P_{t}^{\gamma}$ be the associated Markov semigroup, i.e.

$$
P_{t}^{\gamma} f(x):=\mathbb{E}\left[f\left(X_{t}^{x, \gamma}\right)\right], \quad t \in[0, T], x \in \mathbb{R}^{d}, f \in \mathscr{B}_{b}\left(\mathbb{R}^{d}\right)
$$

Noting that $X_{t}^{x, \gamma}$ solves (1.1) if the initial value $x$ is random with distribution $\gamma$, by the standard Markov property of $X_{t}^{x, \gamma}$, we have

$$
P_{t} f(\gamma):=\int_{\mathbb{R}^{d}} f(x)\left(P_{t}^{*} \gamma\right)(\mathrm{d} x)=\int_{\mathbb{R}^{d}} P_{t}^{\gamma} f(x) \gamma(\mathrm{d} x), \quad f \in \mathscr{B}_{b}\left(\mathbb{R}^{d}\right)
$$

Lemma 2.2. Let $\sigma$ and $b$ satisfy (A). For any $p \geq 1$, there exists a constant $c_{p}>0$ such that

$$
\begin{gather*}
\mathbb{E}\left[\left|X_{t}^{x, \gamma}-x\right|^{p}\right] \leq c_{p}\left(1+\kappa|x|^{p}+\kappa\|\gamma\|_{k}^{p}\right) t^{\frac{p}{2}}, \quad t \in[0, T], x \in \mathbb{R}^{d}, \gamma \in \mathscr{P}_{k},  \tag{2.5}\\
\mathbb{E}\left[\sup _{t \in[0, T]}\left|X_{t}^{x, \gamma}-X_{t}^{y, \gamma}\right|^{p}\right] \leq c_{p}|x-y|^{p}, \quad x, y \in \mathbb{R}^{d}, \gamma \in \mathscr{P}_{k} . \tag{2.6}
\end{gather*}
$$

Proof. By [23, Theorem 2.1(1)], (A) implies (2.6). It remains to prove (2.5). To this end, we use Zvonkin's transform.

For any $\lambda>0$, consider the following PDE for $u:[0, T] \times \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}$ :

$$
\begin{equation*}
\frac{\partial}{\partial t} u_{t}(x)+\left(\mathscr{L}_{t}^{\gamma} u_{t}\right)(x)+b_{t}^{(0)}(x)=\lambda u_{t}(x), \quad u_{T}=0 \tag{2.7}
\end{equation*}
$$

where

$$
\begin{equation*}
\mathscr{L}_{t}^{\gamma}=\frac{1}{2} \operatorname{tr}\left\{\left(\sigma_{t} \sigma_{t}^{*}\right) \nabla^{2}\right\}+\nabla_{b_{t}\left(\cdot, P_{t}^{*} \gamma\right)} \tag{2.8}
\end{equation*}
$$

By [24] and (A), for large enough constants $\lambda, c>0$ independent of $\gamma,(2.7)$ has a unique solution $u^{\lambda, \gamma}$ satisfying

$$
\begin{equation*}
\left\|u^{\lambda, \gamma}\right\|_{\infty}+\left\|\nabla u^{\lambda, \gamma}\right\|_{\infty} \leq \frac{1}{5}, \quad\left\|\nabla^{2} u^{\lambda, \gamma}\right\|_{\tilde{L}_{p}^{q}(T)} \leq c \tag{2.9}
\end{equation*}
$$

So, for any $t \in[0, T]$,

$$
\begin{equation*}
x \mapsto \Theta_{t}^{\lambda, \gamma}(x):=x+u_{t}^{\lambda, \gamma}(x), \quad x \in \mathbb{R}^{d} \tag{2.10}
\end{equation*}
$$

is a homeomorphism on $\mathbb{R}^{d}$. By Itô's formula (see [24]), we derive

$$
\begin{equation*}
\mathrm{d} \Theta_{t}^{\lambda, \gamma}\left(X_{t}^{x, \gamma}\right)=\left\{\lambda u_{t}^{\lambda, \gamma}\left(X_{t}^{x, \gamma}\right)+b_{t}^{(1)}\left(X_{t}^{x, \gamma}, P_{t}^{*} \gamma\right)\right\} \mathrm{d} t+\left\{\left(\nabla \Theta_{t}^{\lambda, \gamma}\right) \sigma_{t}\right\}\left(X_{t}^{x, \gamma}\right) \mathrm{d} W_{t} \tag{2.11}
\end{equation*}
$$

By (A), (2.4) and (2.9), there exists a constant $C>1$ such that

$$
\begin{aligned}
& C^{-1}\left|X_{t}^{x, \gamma}\right|-C \leq\left|\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{x, \gamma}\right)\right| \leq C+C\left|X_{t}^{x, \gamma}\right| \\
& \left|\lambda u_{t}^{\lambda, \gamma}\left(X_{t}^{x, \gamma}\right)+b_{t}^{(1)}\left(X_{t}^{x, \gamma}, P_{t}^{*} \gamma\right)\right| \leq C\left(1+\kappa\left|X_{t}^{x, \gamma}\right|+\kappa\|\gamma\|_{k}\right) \\
& \left\|\left\{\left(\nabla \Theta_{t}^{\lambda, \gamma}\right) \sigma_{t}\right\}\left(X_{t}^{x, \gamma}\right)\right\| \leq C, \quad(t, x, \gamma) \in[0, T] \times \mathbb{R}^{d} \times \mathscr{P}_{k}
\end{aligned}
$$

This together with (2.11) implies (2.5).

Lemma 2.3. Assume (A). Then there exists a constant $c>0$ such that

$$
\begin{equation*}
\mathbb{W}_{k}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right) \leq c \mathbb{W}_{k}(\gamma, \tilde{\gamma})+c \int_{0}^{t} \mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right) \mathrm{d} s, \quad t \in[0, T], \gamma, \tilde{\gamma} \in \mathscr{P}_{k} \tag{2.12}
\end{equation*}
$$

Proof. We take $\mathscr{F}_{0}$-measurable random variables $X_{0}^{\gamma}, X_{0}^{\tilde{\gamma}}$ such that

$$
\begin{equation*}
\mathscr{L}_{X_{0}^{\gamma}}=\gamma, \quad \mathscr{L}_{X_{0}^{\tilde{\gamma}}}=\tilde{\gamma}, \quad \mathbb{W}_{k}(\gamma, \tilde{\gamma})^{k}=\mathbb{E}\left[\left|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right|^{k}\right] \tag{2.13}
\end{equation*}
$$

By $(2.7),(2.8)$ and Itô's formula, we derive

$$
\begin{align*}
& \mathrm{d} \Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right)=\left\{\lambda u_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right)+b_{t}^{(1)}\left(X_{t}^{\tilde{\gamma}}, P_{t}^{*} \gamma\right)\right\} \mathrm{d} t \\
& \quad+\nabla_{b_{t}\left(X_{t}^{\tilde{\gamma}}, P_{t}^{*} \tilde{\gamma}\right)-b_{t}\left(X_{t}^{\tilde{\tilde{}}}, P_{t}^{*} \gamma\right)} \Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right) \mathrm{d} t+\left\{\left(\nabla \Theta_{t}^{\lambda, \gamma}\right) \sigma_{t}\right\}\left(X_{t}^{\tilde{\gamma}}\right) \mathrm{d} W_{t} \tag{2.14}
\end{align*}
$$

Combining this with (2.11) and (A), we prove the desired estimate by using the maximal functional inequality, Khasminskii's estimate and stochastic Gronwall's inequality, see for instance the proof of $[13$, Lemma 2.1] for details. Below we simply outline the procedure.

By $\left(A_{2}\right)$ we have

$$
\begin{aligned}
& \left|b_{t}\left(X_{t}^{\tilde{\gamma}}, P_{t}^{*} \tilde{\gamma}\right)-b_{t}\left(X_{t}^{\tilde{\gamma}}, P_{t}^{*} \gamma\right)\right|+\left|b_{t}^{(1)}\left(X_{t}^{\tilde{\gamma}}, P_{t}^{*} \gamma\right)-b_{t}^{(1)}\left(X_{t}^{\gamma}, P_{t}^{*} \gamma\right)\right| \\
& \leq K\left\{\left|X_{t}^{\gamma}-X_{t}^{\tilde{\gamma}}\right|+\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right)\right\}
\end{aligned}
$$

Combining this with (2.11), (2.14), $\left(A_{1}\right)$, the maximal functional inequality and Khasminskii's estimate (see [25, Lemma 2.1 and Lemma 4.1]), we derive

$$
\begin{aligned}
& \mathrm{d}\left|\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\gamma}\right)-\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right)\right|^{k+1} \leq \mathrm{d} M_{t}+\left|X_{t}^{\gamma}-X_{t}^{\tilde{\tilde{}}}\right|^{k+1} \mathrm{~d} \mathscr{L}_{t} \\
& \quad+c_{1}\left\{\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right)\right\}\left|\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\gamma}\right)-\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right)\right|^{k} \mathrm{~d} t
\end{aligned}
$$

where $c_{1}>0$ is a constant, $\mathscr{L}_{t}$ is an adapted increasing process with $\mathbb{E}\left[\mathrm{e}^{\lambda \mathscr{L}_{T}}\right]<\infty$ for any $\lambda>0$, and $M_{t}$ is a local martingale. Since (2.9) implies

$$
\frac{1}{2}\left|X_{t}^{\tilde{\gamma}}-X_{t}^{\gamma}\right| \leq\left|\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\gamma}\right)-\Theta_{t}^{\lambda, \gamma}\left(X_{t}^{\tilde{\gamma}}\right)\right| \leq 2\left|X_{t}^{\tilde{\gamma}}-X_{t}^{\gamma}\right|
$$

by the stochastic Gronwall inequality (see [26, Lemma 3.7]), we find a constant $c_{2}>1$ such that

$$
\begin{aligned}
& \left\{\mathbb{E}\left[\sup _{s \in[0, t]}\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k} \mid \mathscr{F}_{0}\right]\right\}^{1+k^{-1}}-c_{2}\left|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right|^{k+1} \\
& \leq c_{2} \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)\right\} \mathbb{E}\left[\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k} \mid \mathscr{F}_{0}\right] \mathrm{d} s, \quad t \in[0, T]
\end{aligned}
$$

So, there exists a constant $c_{3}>0$ such that for any $t \in[0, T]$,

$$
\begin{aligned}
& \mathbb{E}\left[\sup _{s \in[0, t]}\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k} \mid \mathscr{F}_{0}\right]-c_{2}\left|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right|^{k} \\
& \leq c_{2}\left(\int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)\right\} \mathbb{E}\left[\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k} \mid \mathscr{F}_{0}\right] \mathrm{d} s\right)^{\frac{k}{k+1}} \\
& \leq \frac{1}{2} \mathbb{E}\left[\sup _{s \in[0, t]}\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k} \mid \mathscr{F}_{0}\right]+c_{3}\left(\int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)\right\} \mathrm{d} s\right)^{k}
\end{aligned}
$$

This together with (2.13) yields

$$
\begin{aligned}
& \mathbb{W}_{k}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right) \leq \sup _{s \in[0, t]}\left(\mathbb{E}\left[\left|X_{s}^{\tilde{\gamma}}-X_{s}^{\gamma}\right|^{k}\right]\right)^{\frac{1}{k}} \\
& \leq\left(2 c_{2}\right)^{\frac{1}{k}} \mathbb{W}_{k}(\gamma, \tilde{\gamma})+\left(2 c_{3}\right)^{\frac{1}{k}} \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)+\mathbb{W}_{k}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)\right\} \mathrm{d} s, t \in[0, T]
\end{aligned}
$$

By Gronwall's inequality, this implies the desired estimate for some constant $c>0$.

We will need the following Hölder inequality for concave functions.

Lemma 2.4. Let $\alpha:[0, \infty) \rightarrow[0, \infty)$ be concave. For any non-negative random variables $\xi$ and $\eta$,

$$
\begin{equation*}
\mathbb{E}[\alpha(\xi) \eta] \leq\|\eta\|_{L^{p}(\mathbb{P})} \alpha\left(\|\xi\|_{L^{\frac{p}{p-1}}(\mathbb{P})}\right), \quad p \geq 1 \tag{2.15}
\end{equation*}
$$

Consequently, for any random variable $\xi$ on $\mathbb{R}^{d}, f \in C\left(\mathbb{R}^{d} ; \mathbb{B}\right)$ for a Banach space $\left(\mathbb{B},\|\cdot\|_{\mathbb{B}}\right)$ with $[f]_{\alpha}<\infty$, and real random variable $\eta$ with $\mathbb{E}[\eta]=0$,

$$
\begin{equation*}
\|\mathbb{E}[f(\xi) \eta]\|_{\mathbb{P}} \leq[f]_{\alpha}\|\eta\|_{L^{p}(\mathbb{P})} \alpha\left(\|\xi-x\|_{L^{\frac{p}{p-1}}(\mathbb{P})}\right), \quad p \geq 1, x \in \mathbb{R}^{d} \tag{2.16}
\end{equation*}
$$

Proof. It suffices to prove for $\mathbb{E}\left[\left.\eta\right|^{p}\right] \in(0, \infty)$. Let $\mathbb{Q}:=\frac{\eta}{\mathbb{E}[\eta]} \mathbb{P}$. By Jensen's and Hölder's inequalities, and using (2.1), we obtain

$$
\begin{aligned}
& \mathbb{E}[\alpha(\xi) \eta]=\mathbb{E}[|\eta|] \mathbb{E}_{\mathbb{Q}}[\alpha(\xi)] \leq \mathbb{E}[|\eta|] \alpha\left(\mathbb{E}_{\mathbb{Q}}[\xi]\right) \leq \mathbb{E}[|\eta|] \alpha\left(\frac{\left(\mathbb{E}\left[|\eta| p^{p}\right)^{\frac{1}{p}}\right.}{\mathbb{E}[|\eta|]}\left(\mathbb{E}\left[\left.\xi\right|^{\frac{p}{p-1}}\right]\right)^{\frac{p-1}{p}}\right) \\
& \leq \mathbb{E}[|\eta|]\left\{\frac{\left(\mathbb{E}\left[|\eta|^{p}\right]\right)^{\frac{1}{p}}}{\mathbb{E}[|\eta|]} \alpha\left(\left(\mathbb{E}\left[\left.\xi\right|^{\frac{p}{p-1}}\right)\right)^{\frac{p-1}{p}}\right)\right\}=\left(\mathbb{E}\left[|\eta|^{p}\right]\right)^{\frac{1}{p}} \alpha\left(\left(\mathbb{E}\left[|\xi|^{\frac{p}{p-1}}\right]\right)^{\frac{p-1}{p}}\right)
\end{aligned}
$$

Then the second inequality follows by noting that $\mathbb{E}[\eta]=0$ implies

$$
\|\mathbb{E}[f(\xi) \eta]\|_{\mathbb{B}}=\|\mathbb{E}[\{f(\xi)-f(x)\} \eta]\|_{\mathbb{B}} \leq[f]_{\alpha} \mathbb{E}[\alpha(|\xi-x|)|\eta|]
$$

Lemma 2.5. Assume (A). If $\alpha_{k}(s):=\alpha\left(s^{1 /(k-1)}\right)$ is concave in $s \geq 0$, then there exists $a$ constant $c>0$ such that

$$
\begin{aligned}
& \mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right) \leq c \mathbb{W}_{k}(\tilde{\gamma}, \gamma)\left\{\frac{\alpha\left(\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)}{\sqrt{t}}\right. \\
& \left.\quad+\tilde{\alpha}\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}}\right\}, \quad t \in(0, T], \gamma, \tilde{\gamma} \in \mathscr{P}_{k}
\end{aligned}
$$

Consequently, there exists a constant $c>0$ such that for any $\gamma, \tilde{\gamma} \in \mathscr{P}_{k}$,

$$
\begin{equation*}
\sup _{t \in[0, T]} \mathbb{W}_{k}\left(P_{t}^{*} \gamma, P_{t}^{*} \tilde{\gamma}\right) \leq \tilde{\alpha}\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}} \mathbb{W}_{k}(\gamma, \tilde{\gamma}) \tag{2.17}
\end{equation*}
$$

Proof. It suffices to prove the first estimate, since it implies (2.17) according to Lemma 2.3 .

Let $X_{0}^{\gamma}$ and $X_{0}^{\tilde{\gamma}}$ be in (2.13). For any $\varepsilon \in[0,2]$, let

$$
X_{0}^{\gamma^{\varepsilon}}:=X_{0}^{\gamma}+\varepsilon\left(X_{0}^{\tilde{\gamma}}-X_{0}^{\gamma}\right), \quad \gamma^{\varepsilon}:=\mathscr{L}_{X_{0}^{\gamma \varepsilon}}
$$

and let $X_{t}^{\gamma^{\varepsilon}}$ solve (1.1) with initial value $X_{0}^{\gamma^{\varepsilon}}$. Then

$$
\begin{gather*}
\gamma^{\varepsilon}(|\cdot|) \leq 2\|\gamma\|_{k}+2\|\tilde{\gamma}\|_{k}, \quad \varepsilon \in[0,2]  \tag{2.18}\\
\mathbb{W}_{k}\left(\gamma^{\varepsilon}, \gamma^{\varepsilon+r}\right)^{k} \leq \mathbb{E}\left[\left|X_{0}^{\gamma^{\varepsilon}}-X_{0}^{\gamma^{\varepsilon+r}}\right|^{k}\right]=r^{k} \mathbb{W}_{k}(\gamma, \tilde{\gamma})^{k}, \quad \varepsilon, r \in[0,1] \tag{2.19}
\end{gather*}
$$

For any $\varepsilon \geq 0$, consider the SDE

$$
\begin{equation*}
\mathrm{d} X_{t}^{x, \gamma^{\varepsilon}}=b_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}, P_{t}^{*} \gamma^{\varepsilon}\right) \mathrm{d} t+\sigma_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}\right) \mathrm{d} W_{t}, \quad X_{0}^{x, \gamma^{\varepsilon}}=x, t \in[0, T] \tag{2.20}
\end{equation*}
$$

For any $r \in(0,1)$, let

$$
\eta_{t}^{\varepsilon, r}=\left[\sigma_{t}^{*}\left(\sigma_{t} \sigma_{t}^{*}\right)^{-1}\right]\left(X_{t}^{x, \gamma^{\varepsilon}}\right)\left[b_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}, P_{t}^{*} \gamma^{\varepsilon+r}\right)-b_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}, P_{t}^{*} \gamma^{\varepsilon}\right)\right], \quad t \in[0, T]
$$

By (A), there exists a constant $c_{1}>0$ such that

$$
\begin{equation*}
\sup _{t \in[0, T]}\left|\eta_{t}^{\varepsilon, r}\right| \leq c_{1}\left\{\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)+\mathbb{W}_{k}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)\right\}, \quad r, \varepsilon \in[0,1] \tag{2.21}
\end{equation*}
$$

By Gisranov's theorem,

$$
R_{t}^{\varepsilon, r}:=\exp \left\{\int_{0}^{t}\left\langle\eta_{s}^{\varepsilon, r}, \mathrm{~d} W_{s}\right\rangle-\frac{1}{2} \int_{0}^{t}\left|\eta_{s}^{\varepsilon, r}\right|^{2} \mathrm{~d} s\right\}, \quad t \in[0, T]
$$

is a martingale, and

$$
W_{t}^{\varepsilon, r}=W_{t}-\int_{0}^{t} \eta_{s}^{\varepsilon, r} \mathrm{~d} s, \quad t \in[0, T]
$$

is a Brownian motion under the probability $\mathbb{Q}^{\varepsilon, r}:=R_{T}^{\varepsilon, r} \mathbb{P}$. Rewrite (2.20) as

$$
\mathrm{d} X_{t}^{x, \gamma^{\varepsilon}}=b_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}, P_{t}^{*} \gamma^{\varepsilon+r}\right) \mathrm{d} t+\sigma_{t}\left(X_{t}^{x, \gamma^{\varepsilon}}\right) \mathrm{d} W_{t}^{\varepsilon, r}, \quad X_{0}^{x, \gamma^{\varepsilon}}=x, \quad t \in[0, T]
$$

By the weak uniqueness we obtain

$$
\mathscr{L}_{\left\{X_{t}^{x, \gamma^{\varepsilon}}\right\}_{t \in[0, T]} \mid \mathbb{Q}^{\varepsilon, r}}=\mathscr{L}_{\left\{X_{t}^{x, \tau, r^{+}}{ }_{\}_{t \in[0, T]}},\right.}
$$

where $\mathscr{L}_{\cdot \mid \mathbb{Q}^{\varepsilon, r}}$ is the law under $\mathbb{Q}^{\varepsilon, r}$, so that

$$
P_{t}^{P^{\varepsilon+r}} f(x)-P_{t}^{\gamma^{\varepsilon}} f(x)=\mathbb{E}\left[f\left(X_{t}^{x, \gamma^{\varepsilon}}\right)\left(R_{t}^{\varepsilon, r}-1\right)\right], \quad f \in \mathscr{B}_{b}\left(\mathbb{R}^{d}\right), \varepsilon, r \in(0,1]
$$

Hence,

$$
\begin{aligned}
& P_{t} f\left(\gamma^{\varepsilon+r}\right)-P_{t} f\left(\gamma^{\varepsilon}\right)=\gamma^{\varepsilon+r}\left(P_{t}^{\gamma^{\varepsilon+r}} f\right)-\gamma^{\varepsilon}\left(P_{t}^{\gamma^{\varepsilon}} f\right) \\
& =\gamma^{\varepsilon+r}\left(P_{t}^{\gamma^{\varepsilon+r}} f-P_{t}^{\gamma^{\varepsilon}} f\right)+\gamma^{\varepsilon+r}\left(P_{t}^{\gamma^{\varepsilon}} f\right)-\gamma^{\varepsilon}\left(P_{t}^{\gamma^{\varepsilon}} f\right) \\
& =\int_{\mathbb{R}^{d}} \mathbb{E}\left[f\left(X_{t}^{x, \gamma^{\varepsilon}}\right)\left(R_{t}^{\varepsilon, r}-1\right)\right] \gamma^{\varepsilon+r}(\mathrm{~d} x)+\mathbb{E}\left[P_{t}^{\gamma^{\varepsilon}} f\left(X_{0}^{\gamma^{\varepsilon+r}}\right)-P_{t}^{\gamma^{\varepsilon}} f\left(X_{0}^{\gamma^{\varepsilon}}\right)\right]
\end{aligned}
$$

so that

$$
\begin{align*}
& \mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon+r}, P_{t}^{*} \gamma^{\varepsilon}\right)^{2}=\sup _{[f]_{\alpha} \leq 1}\left|P_{t} f\left(\gamma^{\varepsilon+r}\right)-P_{t} f\left(\gamma^{\varepsilon}\right)\right|^{2} \leq I_{1}+I_{2} \\
& I_{1}:=2 \sup _{[f]_{\alpha} \leq 1}\left|\int_{\mathbb{R}^{d}} \mathbb{E}\left[f\left(X_{t}^{x, \gamma^{\varepsilon}}\right)\left(R_{t}^{\varepsilon, r}-1\right)\right] \gamma^{\varepsilon+r}(\mathrm{~d} x)\right|^{2}  \tag{2.22}\\
& I_{2}:=2\left|\mathbb{E} \int_{0}^{r} \frac{\mathrm{d}}{\mathrm{d} \theta} P_{t}^{\gamma^{\varepsilon}} f\left(X_{0}^{\gamma^{\varepsilon+\theta}}\right) \mathrm{d} \theta\right|^{2}=2\left|\mathbb{E} \int_{0}^{r}\left\{\nabla_{X_{0}^{\gamma}-X_{0}^{\gamma}} P_{t}^{\gamma^{\varepsilon}} f\left(X_{0}^{\gamma^{\varepsilon+\theta}}\right)\right\} \mathrm{d} \theta\right|^{2} .
\end{align*}
$$

Below we estimate $I_{1}$ and $I_{2}$ respectively.

By $(2.21)$, we obtain

$$
\begin{align*}
& \mathbb{E}\left|R_{t}^{\varepsilon, r}-1\right|^{2}=\mathbb{E}\left[\left(R_{t}^{\varepsilon, r}\right)^{2}-1\right] \leq \operatorname{esssup}_{\Omega}\left(\mathrm{e}^{\int_{0}^{t}\left|\eta_{s}^{\varepsilon, r}\right|^{2} \mathrm{~d} s}-1\right) \\
& \leq \operatorname{esssup}_{\Omega}\left(\mathrm{e}^{\int_{0}^{t}\left|\eta_{s}^{\varepsilon, r}\right|^{2} \mathrm{~d} s} \int_{0}^{t}\left|\eta_{s}^{\varepsilon, r}\right|^{2} \mathrm{~d} s\right)  \tag{2.23}\\
& \leq \psi(\varepsilon, r) \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma^{\varepsilon}, P_{s}^{*} \gamma^{\varepsilon+r}\right)^{2}+\mathbb{W}_{k}\left(P_{s}^{*} \gamma^{\varepsilon}, P_{s}^{*} \gamma^{\varepsilon+r}\right)^{2}\right\} \mathrm{d} s
\end{align*}
$$

where for $c_{2}:=2 c_{1}^{2}$,

![](https://cdn.mathpix.com/cropped/2024_05_26_ad8ce8e666f2455d6fc1g-11.jpg?height=83&width=944&top_left_y=449&top_left_x=558)

By (2.3) and (2.4) for $n=k$, we have

$$
\begin{equation*}
\bar{\psi}:=\sup _{\varepsilon, r \in[0,1]} \psi(\varepsilon, \gamma)<\infty \tag{2.25}
\end{equation*}
$$

Combining this with (2.1), (2.5), (2.23), (2.18) and Lemma 2.4, we can find constants $k_{1}, k_{2}>1$ such that

$$
\begin{aligned}
& \left(\int_{\mathbb{R}^{d}[f]_{\alpha} \leq 1} \sup \left|\mathbb{E}\left[f\left(X_{t}^{x, \gamma^{\varepsilon}}\right)\left(R_{t}^{\varepsilon, r}-1\right)\right]\right| \gamma^{\varepsilon+r}(\mathrm{~d} x)\right)^{2} \\
& \leq\left(\int_{\mathbb{R}^{d}} \alpha\left(k_{1}\left(1+\kappa|x|+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right) \sup _{x}\left(\mathbb{E}\left[\left|R_{t}^{\varepsilon, r}-1\right|^{2}\right]\right)^{\frac{1}{2}} \gamma^{\varepsilon+r}(\mathrm{~d} x)\right)^{2} \\
& \leq \alpha\left(k_{1}\left(1+\kappa \gamma^{\varepsilon+r}(|\cdot|)+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)^{2} \sup _{x} \mathbb{E}\left[\left|R_{t}^{\varepsilon, r}-1\right|^{2}\right] \\
& \leq k_{2} \alpha\left(\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)^{2} \psi(\varepsilon, r) \\
& \quad \times \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma^{\varepsilon}, P_{s}^{*} \gamma^{\varepsilon+r}\right)^{2}+\mathbb{W}_{k}\left(P_{s}^{*} \gamma^{\varepsilon}, P_{s}^{*} \gamma^{\varepsilon+r}\right)^{2}\right\} \mathrm{d} s, \quad t \in[0, T]
\end{aligned}
$$

Combining this with (2.1), (2.12), (2.19), (2.18), and letting

$$
\Gamma_{t}(\varepsilon, r):=\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)^{2}+\int_{0}^{t} \mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma^{\varepsilon}, P_{s}^{*} \gamma^{\varepsilon+r}\right)^{2} \mathrm{~d} s
$$

we find a constant $c_{4}>0$ such that

$$
\begin{equation*}
I_{1} \leq c_{4} \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2} \psi(\varepsilon, r)\left(r^{2} \mathbb{W}_{k}(\gamma, \tilde{\gamma})^{2}+\int_{0}^{t} \Gamma_{s}(\varepsilon, r) \mathrm{d} s\right), \quad t \in[0, T] \tag{2.26}
\end{equation*}
$$

Next, by $[24$, Theorem $2.1(2)]$, we have

$$
\nabla_{v} P_{t}^{\gamma^{\varepsilon}} f(x)=\mathbb{E}\left[f\left(X_{t}^{x, \gamma^{\varepsilon}}\right) \int_{0}^{t} \frac{1}{t}\left\langle\left[\sigma_{s}^{*}\left(\sigma_{s} \sigma_{s}^{*}\right)^{-1}\right]\left(X_{s}^{x, \gamma^{\varepsilon}}\right) \nabla_{v} X_{s}^{x, \gamma^{\varepsilon}}, \mathrm{d} W_{s}\right\rangle\right], v \in \mathbb{R}^{d}
$$

and for any $j \geq 1$ there exists a constant $C_{j}>0$ such that

$$
\mathbb{E}\left[\sup _{s \in[0, T]}\left|\nabla_{v} X_{s}^{x, \gamma^{\varepsilon}}\right|^{j}\right] \leq C_{j}|v|^{j}, \quad v \in \mathbb{R}^{d}, \varepsilon \in[0,1]
$$

Combining this with (2.5), (A) and Lemma 2.4, we find constants $c_{5}>0$ such that

$$
\sup _{[f]_{\alpha} \leq 1}\left|\nabla P_{t}^{\gamma^{\varepsilon}} f\right|(x) \leq \frac{c_{5}}{\sqrt{t}} \alpha\left(\left(1+\kappa|x|+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)
$$

Combining this with Lemma 2.4 for $\alpha_{k}(s):=\alpha\left(s^{1 /(k-1)}\right)$ replacing $\alpha$, and using (2.1), we find a constant $c_{6}>0$ such that

$$
\begin{align*}
& I_{2} \leq 2\left(\mathbb{E}\left[\left|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right| \int_{0}^{r}\left|\nabla P_{t}^{\gamma^{\varepsilon}} f\left(X_{0}^{\gamma \varepsilon+\theta}\right)\right| \mathrm{d} \theta\right]\right)^{2} \\
& \leq \frac{c_{6}}{t}\left(\int_{0}^{r}\left\|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right\|_{L^{k}(\mathbb{P})}\right.  \tag{2.27}\\
& \left.\times \alpha_{k}\left(t^{\frac{k-1}{2}}\left(1+\kappa\left\|X_{0}^{\gamma^{\varepsilon+\theta}}\right\|_{L^{k}(\mathbb{P})}+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{k-1}\right) \mathrm{d} \theta\right)^{2} \\
& \leq \frac{c_{6} r^{2}}{t}\left(\mathbb{E}\left[\left|X_{0}^{\gamma}-X_{0}^{\tilde{\gamma}}\right|^{k}\right]\right)^{\frac{2}{k}} \alpha\left(\left(1+2 \kappa\|\gamma\|_{k}+2 \kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)^{2}
\end{align*}
$$

By (2.1), we find some constant $c^{\prime}>0$ such that

$$
\begin{equation*}
\int_{0}^{T} \frac{\alpha\left(r t^{\frac{1}{2}}\right)^{2}}{t} \mathrm{~d} t=2 \int_{0}^{r T^{\frac{1}{2}}} \frac{\alpha(s)^{2}}{s} \mathrm{~d} s \leq c^{\prime} \tilde{\alpha}(r)^{2}<\infty, \quad r \geq 1 \tag{2.28}
\end{equation*}
$$

So, (2.27) together with (2.22) and (2.26) yields that for some constant $c_{7}>0$,

$$
\begin{align*}
& \Gamma_{t}(\varepsilon, r) \leq c_{7} r^{2} \mathbb{W}_{k}(\gamma, \tilde{\gamma})^{2} H_{t}(\varepsilon, r)+c_{7} F(\varepsilon, r) \int_{0}^{t} \Gamma_{s}(\varepsilon, r) \mathrm{d} s \\
& H_{t}(\varepsilon, r):= \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2} \psi(\varepsilon, r)+\tilde{\alpha}\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}  \tag{2.29}\\
& \quad+\alpha\left(\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)^{2} t^{-1} \\
& F(\varepsilon, r):=\alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2} \psi(\varepsilon, r), \quad \varepsilon, r \in[0,1], t \in[0, T]
\end{align*}
$$

By Gronwall's inequality and (2.29), for any $\varepsilon, r \in[0,1]$ we have

$$
\begin{aligned}
& \mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)^{2} \leq \Gamma_{t}(\varepsilon, r) \\
& \leq c_{7} r^{2} \mathbb{W}_{k}(\gamma, \tilde{\gamma})^{2}\left\{H_{t}(\varepsilon, r)+c_{7} F(\varepsilon, r) \mathrm{e}^{c_{7} F(\varepsilon, r) T} \int_{0}^{t} H_{s}(\varepsilon, r) \mathrm{d} s\right\}, \quad t \in[0, T]
\end{aligned}
$$

This together with (2.12) and (2.24)-(2.25) implies that $\psi(\varepsilon, r)$ is bounded in $(\varepsilon, r) \in[0,1]^{2}$ with $\psi(\varepsilon, r) \rightarrow c_{2}$ as $r \rightarrow 0$, so that by the dominated convergence theorem we find a constant $c>0$ such that

$$
\begin{align*}
& \limsup _{r \downarrow 0} \frac{\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)}{r} \\
& \leq c \mathbb{W}_{k}(\tilde{\gamma}, \gamma)\left\{\frac{\alpha\left(\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)}{\sqrt{t}}\right.  \tag{2.30}\\
& \left.\quad+\tilde{\alpha}\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}}\right\}
\end{align*}
$$

where we have used the fact that for some constant $C>1$,

$$
\alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}} \leq \mathrm{e}^{C \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}}
$$

By the triangle inequality,

$$
\left|\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \gamma^{\varepsilon}\right)-\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \gamma^{\varepsilon+r}\right)\right| \leq \mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right), \quad \varepsilon, r \in[0,1]
$$

so that the (2.30) implies that $\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \gamma^{\varepsilon}\right)$ is Lipschitz continuous (hence a.e. differentiable) in $\varepsilon \in[0,1]$ for any $t \in(0, T]$, and

$$
\begin{aligned}
& \left|\frac{\mathrm{d}}{\mathrm{d} \varepsilon} \mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma, P_{t}^{*} \gamma^{\varepsilon}\right)\right| \leq \limsup _{r \downarrow 0} \frac{\mathbb{W}_{\alpha}\left(P_{t}^{*} \gamma^{\varepsilon}, P_{t}^{*} \gamma^{\varepsilon+r}\right)}{r} \\
& \leq c \mathbb{W}_{k}(\tilde{\gamma}, \gamma)\left\{\frac{\alpha\left(\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) t^{\frac{1}{2}}\right)}{\sqrt{t}}\right. \\
& \left.\quad+\tilde{\alpha}\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right) \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{k}+\kappa\|\tilde{\gamma}\|_{k}\right)^{2}}\right\}, \quad \varepsilon \in[0,1]
\end{aligned}
$$

Noting that $\gamma^{1}=\tilde{\gamma}$, this implies the desired estimate.

Proof of Theorem 2.1. Let $k=2$ so that $\alpha_{k}=\alpha$ is concave as needed by Lemma 2.5. According to $\left[23\right.$, Theorem 2.3] for $D=\mathbb{R}^{d}$, see also [27, Theorem 4.1], (A) implies the following $\log$-Harnack inequality for some constant $c_{0}>0$ and any $\gamma \in \mathscr{P}_{2}$ :

$$
P_{t}^{\gamma} \log f(x) \leq \log P_{t}^{\gamma} f(y)+\frac{c_{0}}{t}|x-y|^{2}, \quad x, y \in \mathbb{R}^{d}, t \in(0, T], f \in \mathscr{B}_{b}^{+}\left(\mathbb{R}^{d}\right)
$$

Then by $[23,(4.13)]$, see also [11, Theorem 2.1], it suffices to find a constant $c>0$ such that

$$
\begin{align*}
& \sup _{t \in(0, T]} \log \mathbb{E}\left[\left|R_{t}^{\gamma, \tilde{\gamma}}\right|^{2}\right]  \tag{2.31}\\
& \leq c \tilde{\alpha}\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2} \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2}} \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}, \quad \gamma, \tilde{\gamma} \in \mathscr{P}_{2}
\end{align*}
$$

where

$$
\begin{aligned}
& R_{t}^{\gamma, \tilde{\gamma}}:=\mathrm{e}^{\int_{0}^{t}\left\langle\eta_{s}^{\gamma, \tilde{\gamma}}, \mathrm{d} W_{s}\right\rangle-\frac{1}{2} \int_{0}^{t}\left|\eta_{s}^{\gamma, \tilde{\gamma}}\right|^{2} \mathrm{~d} s} \\
& \eta_{s}^{\gamma, \tilde{\gamma}}:=\left\{\sigma_{s}^{*}\left(\sigma_{s} \sigma_{s}^{*}\right)^{-1}\right\}\left(X_{s}^{\gamma}\right)\left\{b_{s}\left(X_{s}^{\gamma}, P_{s}^{*} \tilde{\gamma}\right)-b_{s}\left(X_{s}^{\gamma}, P_{s}^{*} \gamma\right)\right\}, \quad s \leq t \leq T
\end{aligned}
$$

Noting that (A) implies

$$
\left|\eta_{s}^{\gamma, \tilde{\gamma}}\right|^{2} \leq c_{1}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}+\mathbb{W}_{2}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}\right\}, \quad s \in[0, T]
$$

for some constant $c_{1}>0$, we have

$$
\mathbb{E}\left[\left|R_{t}^{\gamma, \tilde{\gamma}}\right|^{2}\right] \leq \mathrm{e}^{c_{1} \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}+\mathbb{W}_{2}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}\right\} \mathrm{d} s}
$$

Moreover, by (2.28) and Lemma 2.5, there exists a constant $c>0$ such that

$$
\begin{aligned}
& \sup _{t \in[0, T]} \int_{0}^{t}\left\{\mathbb{W}_{\alpha}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}+\mathbb{W}_{2}\left(P_{s}^{*} \gamma, P_{s}^{*} \tilde{\gamma}\right)^{2}\right\} \mathrm{d} s \\
& \leq c \tilde{\alpha}\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2} \mathrm{e}^{c \alpha\left(1+\kappa\|\gamma\|_{2}+\kappa\|\tilde{\gamma}\|_{2}\right)^{2}} \mathbb{W}_{2}(\gamma, \tilde{\gamma})^{2}
\end{aligned}
$$

Therefore, (2.31) holds for some constant $c>0$.

## References

[1] S. Albeverio, Y. G. Kondratiev, M. Röckner, Differential geometry of Poisson spaces, C R Acad Sci Paris Sér I Math. 323(1996), 1129-1134.

[2] J. Bao, P. Ren, F.-Y. Wang, Bismut formulas for Lions derivative of McKean-Vlasov SDEs with memory, J. Differential Equations 282(2021), 285-329.

[3] M. Bauer, T. M-Brandis, Existence and regularity of solutions to multi-dimensional mean-field stochastic differential equations with irregular drift, arXiv:1912.05932.

[4] M. Bauer, T. M-Brandis, F. Proske, Strong solutions of mean-field stochastic differential equations with irregular drift, Electron. J. Probab. 23(2018), 1-35.

[5] J. M. Bismut, Large Deviations and the Malliavin Calculus, Boston: Birkhäuser, MA, 1984.

[6] P.-E. Chaudru de Raynal, Strong well-posedness of McKean-Vlasov stochastic differential equation with Hölder drift, Stochatic Process. Appl. 130(2020), 79-107.

[7] G. Crippa, C. De Lellis, Estimates and regularity results for the Di Perna- Lions flow, J. Reine Angew. Math. 616(2008), 15-46.

[8] I. Csiszár, J. Körne, Information Theory: Coding Theorems for Discrete Memoryless Systems, Academic Press, New York, 1981.

[9] X. Huang, P. Ren, F.-Y. Wang, Distribution dependent stochastic differential equations, Front. Math. China 16(2021), 257-301.

[10] X. Huang, Y. Song, F.-Y. Wang, Bismut formula for intrinsic/Lions derivatives of distribution dependent SDEs with singular coefficients, Discrete Contin. Dyn. Syst. $42(2022), 4597-4614$.

[11] X. Huang, W. Lv, Exponential Ergodicity and propagation of chaos for pathdistribution dependent stochastic Hamiltonian system, arXiv:2109.13728v3.

[12] X. Huang, F.-Y. Wang, Distribution dependent SDEs with singular coefficients, Stochatic Process. Appl. 129 (2019), 4747-4770.

[13] X. Huang, F.-Y. Wang, Singular McKean-Vlasov (reflecting) SDEs with distribution dependent noise, J. Math. Anal. Appl. 514(2022), 126301 21pp.

[14] D. Lacker, On a strong form of propagation of chaos for McKean-Vlasov equations, Electron. Commun. Probab. 23(2018), 1-11.

[15] Yu. S. Mishura, A. Yu. Veretennikov, Existence and uniqueness theorems for solutions of McKean-Vlasov stochastic equations, Theo. Probab. Math. Statist. 103(2020), 59-101.

[16] P. Ren, Singular McKean-Vlasov SDEs: Well-posedness, regularities and Wang's Hanrack inequality, arXiv:2110.08846.

[17] P. Ren, F.-Y. Wang, Bismut Formula for Lions Derivative of Distribution Dependent SDEs and Applications, J. Differential Equations 267(2019), 4745-4777.

[18] A.-S. Sznitman, Topics in propagation of chaos, In "École d’Été de Probabilités de Sain-Flour XIX-1989", Lecture Notes in Mathematics 1464, p. 165-251, Springer, Berlin, 1991.

[19] F.-Y. Wang, Logarithmic Sobolev inequalities on noncompact Riemannian manifolds, Probab. Theory Relat. Fields 109(1997), 417-424.

[20] F.-Y. Wang, Harnack inequalities on manifolds with boundary and applications, J. Math. Pures Appl. 94(5010), 304-321.

[21] F.-Y. Wang, Harnack Inequality and Applications for Stochastic Partial Differential Equations, Springer, New York, 2013.

[22] F.-Y. Wang, Distribution-dependent SDEs for Landau type equations, Stochatic Process. Appl. 128(2018), 595-621.

[23] F.-Y. Wang, Distribution dependent reflecting stochastic differential equations, arXiv:2106.12737.

[24] F.-Y. Wang, Regularity estimates and intrinsic-Lions derivative formula for singular McKean-Vlasov SDEs, arXiv:2109.02030.

[25] P. Xia, L. Xie, X. Zhang, G. Zhao, $L^{q}\left(L^{p}\right)$-theory of stochastic differential equations, Stochatic Process. Appl. 130(5020), 5188-5211.

[26] L. Xie, X. Zhang, Ergodicity of stochastic differential equations with jumps and singular coefficients, Ann. Inst. Henri Poincaré Probab. Stat. 56(2020), 175-229.

[27] C. Yuan, S.-Q. Zhang, A study on Zvonkin's transformation for stochastic differential equations with singular drift and related applications, J. Differential Equations $297(2021), 277-319$.

[28] A. K. Zvonkin, A transformation of the phase space of a diffusion process that removes the drift, Math. Sb. 93(1974), 129-149.
