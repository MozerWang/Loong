# LLMs as Potential Brainstorming Partners for Math and Science Problems - Case Studies and Analysis 

Sophia Gu*


#### Abstract

With the recent rise of widely successful deep learning models, there is emerging interest among professionals in various math and science communities to see and evaluate the stateof-the-art models' abilities to collaborate on finding or solving problems that often require creativity and thus brainstorming.

While a significant chasm still exists between current human-machine intellectual collaborations and the resolution of complex math and science problems, such as the six unsolved Millennium Prize Problems (Institute, 2023), our initial investigation into this matter reveals a promising step towards bridging the divide. This is due to the recent advancements in Large Language Models (LLMs). More specifically, we conduct comprehensive case studies to explore both the capabilities and limitations of the current state-of-the-art LLM, notably GPT-4 from OpenAI (2023), in collective brainstorming with humans.


## 1 Introduction

This paper serves two primary purposes: First, as Large Language Models (LLMs) continue to exhibit superior performance across various tasks and gain popularity for myriad use cases, we present significant case studies and qualitative analysis, illustrating the potentials and limitations of the current state-of-the-art LLM, when serving as a brainstorming partner in supporting the math and science communities in advanced settings, along with concrete prompts, methodologies, as well as complete human-machine conversation logs. Traditional apprehensions around AI in professional usages stem from the difficulty in understanding its reasoning process. There is thus a compelling need for concrete case studies that capture a model's transparent dialogues and white-boxed cognitive processes (Barnes et al., 2023; Kohli, 2023). The emergence of LLMs mitigates such fears through both explicit and interactive discussions with a human in the loop, accompanied by detailed Chainof-Thoughts (Wei et al., 2022). Hence, LLMs unlock an opportunity for professionals to engage[^0]

more confidently with $\mathrm{AI}$ in real-time. Our work in particular assesses whether GPT-4 can partake effectively in such brainstorming sessions, such as discovering new research problems, refining problem formulations, suggesting potential methods or out-of-the-box solutions, through iterative ideation with a human, a process that we often incorporate when brainstorming with other professionals.

Second, we venture beyond traditionally welldefined questions that have largely defined the assessments of deep learning models' artificial general intelligence (AGI), e.g. Bubeck et al. (2023)1. Professional math and science often involve more open-ended questions. We, therefore, take a step forward to also explore and evaluate GPT-4's abilities in the formulation of new, potentially ambiguous problems and approaches. ${ }^{2}$

Through hand-designed experiments and qualitative analysis, we illuminate both the potential and limitations of GPT-4 as a brainstorming partner across various scientific disciplines, including but not limited to mathematics, statistics, physics, and beyond. For instance, our conversation with GPT-4 leads to a potentially novel approach to the longstanding $n$-body problem, drawing upon inspiration not only from classical physics but also from other fields such as deep learning, topology, etc. See Table 1 for a brief overview of this problem. These examples underline the power of merging LLMs' expansive knowledge base with an individual's own professional training.

Additionally, we propose an initiation prompt script and various strategies to facilitate collective brainstorming conversations with GPT-4.

By identifying and demonstrating the unique advantages of LLMs, thereby expanding the horizon of the potential of future LLMs, the results we show here not only demonstrate to what extent the[^1]

## Problem Statement:

We consider three point masses under the influence of gravitational forces in three-dimensional space, where the solution is a time evolution of their positions.

## Approach:

We propose to form the set of all possible solutions as a high-dimensional manifold, with each point on the manifold representing a specific state of the three-body system, then use a deep learning model to learn this manifold. The model would be trained on a large dataset generated by simulating the three-body problem under a variety of initial conditions. Techniques from string theory, such as compactification, could be used to make this high-dimensional manifold more manageable, while preserving the essential features. The DL model would need to identify and learn local structures within the manifold. These structures could then be used as building blocks to construct an approximation of the manifold.

## Suggestion of Data Collection:

To train the model, we would require a vast amount of simulated data. This data would consist of time evolution of three-body systems under a variety of initial conditions.

Table 1: An example of an open research question that we converse with GPT-4. This table only presents a brief problem and approach description as produced solely by our conversation with GPT-4, without using any external sources for aid, e.g. for the problem statement lookup or for consulting any existing solutions. Note: GPT-4, at the time of our testing, May 2023, did not have a web-searching feature and it only used knowledge that it learned by September 2021. While we present the 3-body problem in this overview as a simplified illustration, the methodology we devised could, however, be more powerful to the general $n$-body problem with a large $n$.

current LLMs can help in professional settings in math and science-related fields but also highlight avenues for future LLM developments.

This study serves to stimulate further exploration into the potential of LLMs and possibly similar integrations into other state-of-the-art deep learning models, as intellectual partners, augmenting problem discovery, creative problem-solving, and iterative idea build-up with humans, skills that are often needed in both open and closed-ended queries in math and science disciplines. Nonetheless, the insights garnered are applicable beyond this context.

## 2 Related Works

Historically, investigations into human-machine collaboration oriented towards a mutual goal, were primarily conducted in structured environments. AI systems such as the chess-playing (Campbell et al., 2002; Zhang and Yu, 2020) have demonstrated significant capabilities in these well-defined domains. However, their effectiveness in less structured scenarios, such as brainstorming, remains largely unexplored.

DL's considerable advancements in scientific research are also evident, with prominent examples include its assistance in predicting protein struc- tures (Team, 2021) and in discovering new antibiotic (Trafton, 2020). However, the narratives often illustrate DL as a functional tool, with the underlying discovery processes remaining opaque. Consequently, the idea of DL serving as a true intellectual partner is still nascent.

Regarding DL's mathematical capabilities, many prior works have focused primarily on problems with definite answers, and thus their performance can be measured against massive data available from books, the web, or other sources. For instances, transformer-based models such as Schlag et al. (2019) have shown encouraging results on mathematical problem-solving benchmark datasets. Further, the creation of a public dataset to test LLMs against a few fine-grained criteria in graduate-level math in Frieder et al. (2023) shows researchers' emerging interest towards LLMs' capability beyond elementary math. Nonetheless, these models and resources are largely dedicated to solve well-defined math problems. In real professional settings, one often faces unforeseen problems and need to come up with innovative strategies or solutions. For example, when constructing or developing new theories. The work of Davies et al. (2021), which frames an ML approach for
mathematical research, is remarkable but tailors its method to the specific problems addressed and positions ML more as a tool than an intellectual ally. Ours is a first step towards exploring DL's potential abilities in assisting in more general professional problems, with the potential of involving the LLM in all stages of research.

Furthermore, a recurrent theme with traditional ML methods is that they appear as inscrutable black boxes, particularly to those lacking expertise in them - a sentiment echoed in the work by Wang et al. (2019), which examines the use of AutoAI and AutoML platforms in supporting human data scientists. These findings highlight the challenges in leveraging ML for broader mathematical and scientific tasks and underscore the need for more explicit conversations and understanding between humans and machines. Therefore, the interactive nature and the transparent dialogue process with GPT-4 offers a great remedy.

Our study of GPT-4 encompasses its abilities to comprehend complex or ambiguous queries, formulate research statements, suggest relevant and potential methodologies, and more generally, engage in iterative discovery process with a human user, who may have some domain knowledge in the problems they are studying. By illustrating the efficacy of GPT-4 as a complementary brainstorming counterpart that is poised to offer unique perspectives, enrich and augment our capabilities in research and other professional usages, our work fills a notable gap in the current literature.

## 3 Main Studies

In this section, we present four experiments along with qualitative analysis of the effectiveness of brainstorming with GPT-4. Appendix A lists complete records of all the dialogues, and we recommend referencing the corresponding logs for each experiment when reading this section. These comprehensive supplies of evidence aim for objectivity and are intended to provide concrete, factual references for benefiting and assisting the community's further use cases and studies.

### 3.1 GPT-4 Setup and Initiation Prompt

The experiments conducted here utilize the May 2023 version of GPT-4's interactive interface. It is important to note that changes and improvements are to be expected in future iterations of GPT.

We present an initiation prompt in Table 2. The specifics of the introductory paragraphs can be adjusted to better align with individual expectations. For instance, one might specify a particular role that fits your background or your target audience group's, to establish the baseline level of dialogue comprehension ${ }^{3}$. See also the discussion in 4.2 to optionally append an additional prompt.

### 3.2 Theme

In these experiments, we aim to replicate the spirit of professional usages and hit some broad aspects that are commonly encountered across these disciplines, which typically involves exploring and expanding an idea, getting closer to formulating a research problem, drawing inspiration, or even solving the problem.

To illustrate more general use cases, while our experiments encompass topics across various areas, a common theme is high-dimensionality, a key area in mathematics, statistics, theoretical physics, deep learning, and beyond. This focus primarily stems from the potential benefits of studying problems that require high-dimensional imagination; for instance, problems that involve high-dimensional data, space, objects such as high-dimensional algebraic structures, etc. It is an area where humans naturally face challenges (MetaAI et al., 2022), but could be complemented by deep learning.

However, our choice of this theme is not intended to be restrictive. The principal objective is to leverage the unique strengths of a machine brainstorming partner. DL excels in several unique areas where humans may have natural limitations, such as the broad set of world and domain knowledge that LLMs possess. This particular strength is abundantly demonstrated in all of our experiments.

### 3.3 Experiment I: Möbius and Bugs

## Refer to Appendix A. 1 for this experiment's log.

With many mathematical or scientific concepts such as those in category theory or quantum mechanics, understanding the concept or the question itself often brings one very close to knowing the answer. Thus, instead of solely pursuing a solution, we also focus on exploring GPT-4's ability in assisting us to understand concepts in full. Through this[^2]

You are an intelligent Al who is especially good at: [typical properties or traits that you want GPT-4 to focus on, e.g., analyzing data, identifying patterns, and explaining complex concepts in understandable ways].

I am [a role of your choice]. Both of us possess unique strengths - some we share, others are distinct to each of us. We should leverage our respective strengths in this collaboration.

By acknowledging that we both make mistakes, when I present an idea, ponder over it and do not hesitate to point out any inaccuracies. Similarly, when I correct you, assess the validity of my point; If it holds, fix it and remember it for the future.

As we embark on this journey of discovery, our goal is to collectively brainstorm and iteratively build upon each other's ideas until we reach a satisfactory stage. If anything is unclear, speak up. In this intellectual conversation, be patient and articulate your thoughts with clarity, step by step.

Once all of this is etched into your silicon soul, we will dive right in!

Table 2: An example setup script for collaborative brainstorming with GPT-4, emphasizing that GPT-4 should act as a complementary brainstorming partner and leverage its unique skills to assist with our problems.

process, we may, as well, generate new research questions or uncover new problems.

We began our experiment by asking GPT-4 what is the Möbius strip. This seemingly random prompt, selected without a pre-planned conversational path, yielded delightfully surprising results. GPT-4 promptly pulled up pertinent concepts and definitions and took us on a step-by-step journey to visualize a Möbius strip using 2D representations. It also intuitively elucidated why a manifold, such as a Klein bottle, can only be interception-free in a higher dimension space.

As the discussion unfolded, we guided our discourse with GPT-4 towards potential expansions of the initial topic. This was achieved by drawing on the interesting points GPT-4 raised. In the dialogues, we notice that GPT-4 cannot independently discern what is intriguing or ask questions spontaneously. Therefore, human guidance, armed with pertinent knowledge and a sense of the conversation's desired trajectory, would be helpful.

Nonetheless, GPT-4 offered satisfying responses that gradually deepened our collaborative discussion, transforming an initially simple inquiry "What is the Möbius strip" - into an interconnected series of explorations. Throughout the conversation, it is also notable that GPT-4 could independently find mathematical patterns during brainstorming, leading to potentially new mathematical problems and concepts.

This experiment illustrates how an interactive LLM may assist humans in visualizing and under- standing high-dimensional structures. Additionally, it provides insight into the question raised in MetaAI et al. (2022): "What potential exists for the integration of AI in the discovery process of mathematics?". Our experiment begins to shed light on this potential, showcasing the autonomous abstraction, generalization and pattern-finding abilities of DL models, and thus offering evidence of LLMs' capability to aid in mathematical discovery.

### 3.4 Experiment II: Cats and Dogs

Refer to Appendix A. 2 for this experiment's log.

In this conversation, we collaborated with GPT4 to explore the optimal dimension for the CLIP image embeddings Radford et al. (2021) utilized in the multimodal model proposed by Gu et al. (2022). Given the challenge of conceptualizing and discerning structures in 768-dimensional CLIP vectors, our dual objectives were: 1) to understand the pairwise relationships among the four images, two cats and two dogs, featured in the Appendix in the aforementioned work with GPT-4's assistance; and 2) to facilitate the determination of an appropriate layer size in a neural network, which is reminiscent of the linear adapter proposed in the same study.

We are interested in carrying out this experiment because discerning the correct layer size is a typical challenge for many machine learning researchers and engineers, while unearthing the relationships between contrastively-learned image and text embeddings may help illuminate a path towards more effectively bridging the multimodal gap.

While GPT-4 could not provide direct answers to our queries due to its current limitations in performing numerical computations, it offered pertinent statistical insights. Upon further inquiries, GPT-4 also supplied step-by-step methodologies and explanations. Some of these were in alignment with techniques used in the original work, while others suggested additional avenues for potential followups. Overall, we found it to be a constructive and thought-provoking brainstorming session.

Looking forward, once GPT-4 has acquired computational and code execution capabilities, it would become a more powerful and helpful intellectual ally by also helping to discern patterns and extract meaningful insights from real data, for example, the actual CLIP vectors in this experiment. We offer some potential strategies for common data science problems using LLMs in Appendix B.

### 3.5 Experiment III: The $\boldsymbol{n}$-body problem

Refer to Appendix A. 3 for this experiment's log.

Our exploration commenced with a classical physics problem - the $n$-body problem, with a specific focus on the three-body problem due to its comparative simplicity for presentation. However, our choice of $n$ need not be restricted to three.

We summoned historical figures of great intellect to brainstorm modern approaches to this age-old problem, incorporating advanced technologies and recent mathematical discoveries, an example of which is shown in Table 3. We also provide common strategies employed when conversing with GPT-4 for this open question in Table 4. We initially steered the conversation towards using a highdimensional manifold as a model for the solution - this marked our first major intervention to divert from approximated solutions and move towards analytical ones.

As the conversation unfolded, we incorporated deep learning into our discussions. Some experts posited that accurate predictions from neural networks can guide us towards unveiling hidden patterns, echoing the approach demonstrated in Davies et al. (2021). The distinction here is that the idea of employing numerous results produced by neural networks for the guided recognition of underlying structures was advanced by virtual and/or historical experts. The discussion eventually led us to consider using an autoencoder, an ML model that could be employed to discern a lower-dimensional representation of the high-dimensional manifold. This could help us uncover structures in the solution space that would otherwise be counterintuitive and challenging to understand in their original form.

However, we were not content with pattern discovery by humans alone because the problem is pertaining to a rather high-dimensional space, so we moved forward to find a potentially better approach. At this juncture, we made our second significant intervention - examining the autonomous pattern-finding capabilities of deep learning models. We proposed that neural networks should be able to handle the high-dimensional space directly, bypassing the need to transform it into a lossy lowdimensional representation. Our conversation ultimately evolved towards integrating string theory and convolutional neural networks to understand the local dynamics of the three-body problem. The idea was to leverage these granular insights as foundational elements for learning the overarching structure of the manifold. The inspiration was drawn from CNNs, which capitalize on the immediate neighborhood structure of data, and string theory could be useful in compactification.

We also briefly discussed amassing a large simulated dataset using a variety of initial conditions to train the deep learning model. Although many details require further clarification and there are challenges yet to be addressed, as indicated in the experiment log, the proposed approach is novel, with the potential to inspire a new analytical solution to the $n$-body problem.

This experiment highlights the strength of utilizing creative and powerful prompts to invoke experts across different eras. More importantly, it illustrates how the current LLMs could offer a wealth of domain-specific knowledge, leading to fresh, innovative approaches to longstanding open problems. Using the $n$-body problem as our basis, we called upon historical figures, modern technologies, and newer mathematical discoveries to brainstorm solutions, hinting at possible advancements in tackling such complex problems.

### 3.6 Experiment IV: The wicked Queen and the seven Dwarfs

Refer to Appendix A. 4 for this experiment's log.

In this experiment, we showcase how GPT-4 can contribute to brainstorming concrete solutions to questions that require thinking out-of-box. More specifically, it demonstrates how human and LLM can work in tandem, each providing unique insights

Witten: ...However, the potential information loss from reducing its dimensions should be taken into account. In string theory, we often deal with high-dimensional spaces, and we might have some ideas to contribute.

LeCun: Edward, your point is very valid. To work with high-dimensional data in machine learning, we often use techniques like convolutional layers that exploit the local structure of the data. Could we find a similar way to exploit the local structure of this high-dimensional manifold?

Witten: That's an interesting thought, Yann... The dynamics of these local interactions might provide insights into the overall structure of the manifold.

Bengio: We could perhaps train a deep learning model to recognize and learn these local structures, using them as building blocks to construct an approximation of the entire manifold.

Table 3: Example snapshot of collaborative brainstorming with GPT-4 about the $n$-body problem.

## Common Strategies for Collective Brainstorming

Strategy 1: Begin the conversation by forging a shared understanding with GPT-4. Following this, you may also invite GPT-4 to illuminate the inherent challenges associated with the problem in question.

## Examples:

Could you provide me with a brief overview of the n-body problem, along with its latest updates?

Can you highlight the primary challenges in attempting to solve the three-body problem analytically?

Strategy 2: To garner inspiration, particularly from domains outside your expertise, consider engaging with virtual great minds from varied disciplines for collective brainstorming. You can then guide the overall conversation using your personal intuition and knowledge.

## Examples:

Suppose you could bring in any relevant mathematicians and scientists from history, introducing them to later discoveries regarding the 3-body problem, and then asking them to contemplate solutions for the challenges you have highlighted. From their discussion, let's collectively attempt to devise a new, potentially viable approach to this problem.

While the idea of finding approximate solutions is appealing, this method has been exploited to a great extent. Instead, let's shift our focus to exploring the potential existence of a usable analytical solution for "good" initial conditions.

Rather than relying on humans to analyze and identify patterns through a lower-dimensional representation of the high-dimensional manifold, which results in information loss, can we leverage deep learning to discover hidden structures of the solution in its original high-dimensional space?

Strategy 3: Having GPT-4 to recall pertinent points from earlier dialogues, because language models cannot keep track of very distant history, and generate new insights based on them is crucial for brainstorming, particularly when we draw upon a broad array of expertise through multiple rounds of collaborative and iterative ideation. Therefore, it is recommended to explicitly instruct GPT-4 to do so.

## Examples:

Please summarize the past ten conversations and generate three most pertinent insights.

Note that everyone is encouraged to pose questions and build upon the ideas of others.

Table 4: Prompting strategies for collaborative brainstorming with GPT-4.
and building upon thorough understanding of the other's ideas to reach a creative solution together.

The solution to this problem ${ }^{4}$ involves an intriguing combination of binary configurations, errorcorrecting codes, and a geometric interpretation in high-dimensional space. The question, in response to Gowers' comment, "a mathematical question that necessitates more than brute force and does not easily categorize into standard problem sets", offers a case in point. Such problems require the "right idea" mentioned in MetaAI et al. (2022).

While GPT-4 initially found it challenging to independently land on the "right idea" , as we were simulating a collaborative brainstorming process, our hinted directions were able to steer it towards the correct line of thinking. GPT-4 made substantial contributions to the problem-solving process with our collective knowledge. Notably, it was GPT-4 that first suggested the use of Hamming distance, marking a key breakthrough. In the end, this joint effort resulted in a comprehensive and robust solution, which was also proposed by GPT-4, while considering our contributed insights. It is worth pointing out that GPT-4 did grapple with a few minor details, but these did not influence the general correctness of the final solution it brought up.

To provide more evidence, we include another similar experiment in Appendix A.5. Instead of following the current theme, it leverages and explores another intriguing cognitive difference between humans and language models: logic versus probability. In this example, you can observe that GPT-4 sometimes made illogical arguments, only to regain coherence later on. A plausible explanation is that LMs rely on likelihood maximization when generating subsequent text autoregressively. This means that GPT-4 considers words that are probable to appear together, not whether they logically follow each other as humans typically do ${ }^{6}$.

## 4 Discussions

Our study has revealed that GPT-4 can, in general, engage in effective brainstorming conversations with a human. Together with the large amount of common sense and expert knowledge stored and learned by the model itself, it is particularly suited[^3]

for problem formulation, recurrent ideation, and creative problem-solving. It does, however, lack a degree of understanding of many subjects, and like humans, can make mistakes and often has difficulties judging its own proposals or answers. This shortcoming can be mitigated when the human in the conversation has some degree of domain knowledge to make judgments and steer the conversation in more informed and desired directions.

### 4.1 GPT-4's Plausible Potential as a Collaborative Brainstormer

Lessons gleaned from these experiments are largely positive, demonstrating the commendable potential of GPT-4 to effectively collaborate in the exploration and iterative development of ideas across various problems in math and science. This process allows for a clear comprehension of the subject matter at hand.

Comprehending complex questions and whiteboxed communication: In particular, GPT-4 has exhibited proficiency in understanding our queries without difficulty. It articulates thoughts with clarity and precision, adopting a detailed chain of reasoning that considerably mitigates the typical challenge of interpreting AI's cognitive pathways. While completely bridging the understanding gap between humans and machines-an essential step for more effective intellectual collaboration-remains a challenge that can be further improved in the future, LLMs offer a golden opportunity to better comprehend machine's thought processes, thereby bolstering the confidence and efficacy of our exchanges of ideas.

Broad knowledge base and its significant potential in brainstorming for open questions and opening up new avenues to old problems: GPT-4 has notably demonstrated its potential to serve as a valuable partner in brainstorming open-ended topics, which is helpful for making new discoveries. These can range from exploring and formulating research statements to transforming vague ideas into more concrete definitions. Further, given a specific problem, GPT-4 can suggest promising methodologies by drawing from a vast pool of past practices and experiences. It can also aid in the search for novel, unforeseen strategies, harnessing expertise and knowledge from a diverse array of fields that an individual might not be aware of. In collective brainstorming, there are even more potential use cases. By leveraging their unique strengths, LLMs
can potentially fill gaps where human capabilities fall short, thereby opening new avenues for substantially pushing the frontiers of math and science.

Problem-solving abilities: On the problemsolving front, GPT-4 has also exhibited competence by identifying similar pre-existing problems and appropriating analogous techniques for reasoning and demonstrating complex ideas. This process parallels that of a student preparing for an exam by working through sets of problems, with the key difference being the vast practice problem database that has been used to train GPT-4.

LLMs versus Search: In comparison to search, our case studies highlight the key strengths of LLMs in the context of brainstorming:

- Iterative ideation: LLMs excel in building upon ideas iteratively, a capability not mirrored in search.
- Transparent thought process: LLMs offer a chain-of-thoughts reasoning and explanation, crucial for brainstorming.
- Knowledge breadth: Both LLMs, through learning, and search through stored information, encompass a broad range of common sense and knowledge, important for brainstorming as they offer a multitude of potential approaches by looking at problems from different angles. However, unlike search, which works well for prevalent questions with known answers, LLMs' advantage is enhanced through iterative ideation, and as evident in our experiments, they can autonomously suggest relevant, personalized knowledge tailored to the problem at hand.


### 4.2 GPT-4's Possible Limitations

Suggesting methods based on superficial similarity with other problems but otherwise not fitting the specific question in discussion: Similar to students who may lack deep comprehension of underlying concepts, GPT-4 could also sometimes employ an inappropriate technique that superficially appears to suit a problem's needs. GPT-4 might identify apparent similarities across problems and suggest a shared strategy, which does not always lead to a correct solution. We have noticed this tendency across several case studies.

Lack of reciprocal critique: Throughout our dialogues, we generally steered the conversations, identifying and emphasizing interesting points in

## Prompt for GPT-4 to Autonomously Ask Questions

We will together explore [a topic of your choice], but instead of you answering my questions, I would like you to always come up with good, thought-provoking questions that can move our conversation forward.

Table 5: An example prompt to explicitly set up GPT-4 to ask questions.

GPT-4's responses and asking GPT-4 to expand upon them. In a more desirable collaborative environment, reciprocal inquiry and critique are expected. Particularly when a human errs, we would anticipate our brainstorming partner to catch that mistake and bring it to our attention. However, such corrective actions from GPT-4 were extremely limited. Particularly, in Experiment I, we showcase a scenario where GPT-4 fails to identify or correct mistakes that its human partner makes. This underlines the need for human supervision, ideally from someone with awareness of the subject being discussed, to course-correct the conversations.

Lack of autonomous self-inquiry: GPT-4's inadequate ability to organically and autonomously generate thought-provoking questions, and is only activated to a reasonable extent when suitably prompted ${ }^{7}$, which are important for augmenting the horizon of existing knowledge, may present an impediment to more effective brainstorming. To mitigate this problem, we introduce an effective prompt, shown in Table 5, that could be added at the beginning of a conversation.

## 5 Conclusions

Despite some shortcomings, LLMs like GPT-4 show significant potential as intellectual collaborators in various professional settings. Our study reveals LLMs' considerable capabilities, positioning them as actively contributing partners in the brainstorming process rather than passive tools.

Our experiments also highlight that GPT-4, while powerful, is not infallible. This underscores the necessity for critical evaluation of the model's[^4]outputs, instead of accepting them at face value. By identifying potential and addressing the limitations of GPT-4, we hope that future LLMs will be better equipped to complement our skills, broaden our capacities, and deepen our understanding in mathematical and scientific disciplines. Ultimately, our interactions with LLMs facilitate a symbiotic relationship that nurtures progress and innovation in both open and close-ended problems.

## Ethics Statement

While this work does not develop a new model, but rather surfaces the capabilities that are already present in GPT-4, we invite further discussions surrounding the broader ethical implications linked to advancements in LLMs in general. For example, one possible point of contention could be the potential of future LLMs to displace human workers. However, our primary interest, as illustrated in our experiment theme, lies in harnessing the unique capabilities that LLMs may offer, such as higher-dimensional thinking and expansive world knowledge, that humans do not naturally possess. We posit that these attributes hold the potential to significantly elevate and advance the landscape of research across a wide spectrum of disciplines.

It is also worth noting, as demonstrated in our studies, that the training, experience, and domainspecific knowledge of a human - for instance, mathematical intuition -- are essential for steering and driving meaningful conversations with an LLM. Absent these factors, fruitful exchanges would likely be unattainable. Consequently, rather than viewing LLMs as potential replacements for human intellect, we perceive them as complementary partners that are poised to enrich and enhance our innate cognitive skills, and thus to help making the past impossibilities possible.

## References

Elizabeth Barnes, Sara Beery, Josh Bloom, and Kyle Cranmer. 2023. Scientific discovery and the environment.

Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.

Murray Campbell, A Joseph Hoane Jr, and Feng-hsiung
Hsu. 2002. Deep blue. Artificial intelligence, 134(12):57-83.

Alex Davies, Petar Veličković, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Tomašev, Richard Tanburn, Peter Battaglia, Charles Blundell, András Juhász, et al. 2021. Advancing mathematics by guiding human intuition with ai. Nature, 600(7887):7074 .

Simon Frieder, Luca Pinchetti, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Alexis Chevalier, and Julius Berner. 2023. Mathematical capabilities of chatgpt. arXiv preprint arXiv:2301.13867.

Sophia Gu, Christopher Clark, and Aniruddha Kembhavi. 2022. I can't believe there's no images! learning visual tasks using only language data. arXiv preprint arXiv:2211.09778.

Clay Mathematics Institute. 2023. The millennium prize problems.

Pushmeet Kohli. 2023. The potential of ai in advancing science and the importance of ensuring ai's responsible use.

MetaAI, Joelle Pineau, Timothy Gowers, and Yann LeCun. 2022. Is human led mathematics over? panel with joelle pineau, timothy gowers and yann lecun.

OpenAI. 2023. Gpt-4 technical report.

Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748-8763. PMLR.

Imanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic, Jürgen Schmidhuber, and Jianfeng Gao. 2019. Enhancing the transformer with explicit relational encoding for math problem solving. arXiv preprint arXiv:1910.06611.

AlphaFold Team. 2021. Alphafold: A solution to a 50 -year-old grand challenge in biology.

Anne Trafton. 2020. Artificial intelligence yields new antibiotic.

Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray. 2019 Human-ai collaboration in data science: Exploring data scientists' perceptions of automated ai. Proceedings of the ACM on human-computer interaction, 3(CSCW):1-24.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.

Hongming Zhang and Tianyang Yu. 2020. Alphazero. Deep Reinforcement Learning: Fundamentals, Research and Applications, pages 391-415.
