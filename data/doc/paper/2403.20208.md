# Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science 

Yazheng Yang ${ }^{1}$ Yuqi Wang ${ }^{1}$ Sankalok Sen ${ }^{1}$ Lei Li $^{1}$ Qi Liu ${ }^{1}$


#### Abstract

In the domain of data science, the predictive tasks of classification, regression, and imputation of missing values are commonly encountered challenges associated with tabular data. This research endeavors to apply Large Language Models (LLMs) towards addressing these predictive tasks. Despite their proficiency in comprehending natural language, LLMs fall short in dealing with structured tabular data. This limitation stems from their lacking exposure to the intricacies of tabular data during their foundational training. Our research aims to mitigate this gap by compiling a comprehensive corpus of tables annotated with instructions and executing large-scale training of Llama-2 on this enriched dataset. Furthermore, we investigate the practical application of applying the trained model to zero-shot prediction, fewshot prediction, and in-context learning scenarios. Through extensive experiments, our methodology has shown significant improvements over existing benchmarks. These advancements highlight the efficacy of tailoring LLM training to solve table-related problems in data science, thereby establishing a new benchmark in the utilization of LLMs for enhancing tabular intelligence.


## 1. Introduction

Tables are used in various fields such as finance, data analytics, and logistics. In the context of data science, classification and regression as well as handling with missing values, the predominant tasks of predicting over tabular data, play a central role across diverse industries, attracting increasing interest in research of leveraging AI technologies to comprehend tabular data for improving the efficiency of processing[^0]

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-01.jpg?height=417&width=829&top_left_y=651&top_left_x=1057)

Figure 1. Illustration of our methodology for the training of Large Language Models (LLMs) with tables and the subsequent application of our model to downstream tasks.

tasks related to tables.

The essence of tabular data resides in its complex, multidimensional interactions and structural intricacies, which present formidable challenges in capturing the nuanced internal semantics embedded therein. Previous efforts to address these challenges still encounter several problems: 1) Traditional methodologies explore a range of strategies for conducting feature engineering, from the implementation of embedding layers and cell modeling modules for the continuous vector representation of data (Yin et al., 2020a; Herzig et al., 2020; Huang et al., 2020; Gorishniy et al., 2022; Wang \& Sun, 2022; Yang et al., 2024), to the adoption of textualization techniques to convert data into a natural language format (Gorishniy et al., 2021; Liu et al., 2022; Hegselmann et al., 2023; Wang et al., 2024). However, the development of feature engineering, tailored to specific tasks, often depends on human-derived assumptions and knowledge, limiting the models' ability to generalize due to the anchoring of the feature selection process in human biases and limitations. 2) Current approaches for employing LLMs in addressing tabular tasks rely heavily on converting tables into natural language texts through serialization methods (Gong et al., 2020; Li et al., 2023; Zhang et al., 2023; Zhao et al., 2023). However, the absence of specialized pretraining on tables limits the potential benefits of leveraging LLMs for modeling tabular data and interpreting human instructions. 3) Although several existing methods (Gong et al., 2020; Li et al., 2023; Zhang et al., 2023; Zhao et al., 2023) entail continuously pretraining on tabular data, they predominantly focus on generic text-generation tasks, such as table-to-text,
generating SQL queries from text (text-to-SQL), and answering questions based on tables (TableQA). These approaches overlook more prevalent data science tasks, including classification, regression, and the management of missing values. 4) The absence of an extensive pretraining corpus of tables tailored for data science tasks, further impedes the applicability and transferability of existing methodologies (Herzig et al., 2020; Yin et al., 2020b; Zhu et al., 2023; Slack \& Singh, 2023). This deficiency may not adequately validate the model's adaptability across diverse tasks.

This study aims to explore the potential of LLMs in comprehending and leveraging the relational and semantic richness inherent in tabular data through large-scale, table-specific pretraining. To achieve this objective, we have compiled an extensive pretraining corpus comprising a diverse array of tables sourced primarily from Kaggle, which hosts vast quantities of tabular data in CSV format across approximately 300 domains. This corpus provides our model with exposure to a wide spectrum of tabular structures and content, thereby enhancing its capacity to generalize across different data types and facilitating a deeper understanding of the relationships within the tabular data. Furthermore, we propose a straightforward approach by adopting the self-supervised learning paradigm, inherent in LLMs, applied to our curated collection of tabular data, aiming to unearth intricate data patterns, automate feature engineering processes, and refine predictive modeling techniques. Specifically, we introduce a unified training framework that seamlessly integrates table contents with task-specific instructions, enabling the execution of various training tasks and fostering reasoning between the provided instructions and the tabular data. With the innate human intent understanding capabilities offered by LLMs, our pretraining approach further equips LLMs with the combined benefits of table comprehension and natural language understanding, enabling them to effectively tackle challenging predictive tasks.

Our exploration into the large-scale pretraining of LLMs on tabular data and their subsequent application to tabular tasks in data science yields several significant contributions:

- We introduce an straightforward yet innovative pretraining approach tailored to acclimate LLMs to the specificities of tabular data, thereby expanding their utility beyond conventional language processing tasks to encompass a wide range of data science applications.
- We compile and leverage a vast and varied dataset, comprising approximately 13 billion examples across 300 domains, to facilitate this specialized pretraining. This dataset represents a substantial resource for advancing research in this field.
- Our trained model demonstrates impressive performance, substantiated through extensive experimental analysis and comparative assessments across 30 classification and regression tasks. Compared to the Llama2, our approach achieves an average improvement of $8.9 \%$ in classification tasks and $10.7 \%$ in regression tasks. For missing value prediction tasks, our model outperforms GPT-4 by $27 \%$. Furthermore, our model exhibits a significant $28.8 \%$ improvement in extremefew-shot (4-shot) predictions on diverse datasets and a notable $18.8 \%$ progress in tasks involving extensive context learning. In the context of extensive context learning, our model shows a remarkable performance increase of $25.9 \%$ over Llama-2 80K (Fu et al., 2024).


## 2. Related Works

Beyond traditional tree-based methodologies such as XGBoost (Chen \& Guestrin, 2016) and random forests, the field of solving tabular predictive problem has increasingly incorporated deep learning (DL) techniques. An illustrative example is NODE (Popov et al., 2019), which merges neural decision trees with dense connections. This approach enhances the ensemble model concept by combining the advantages of end-to-end gradient-based optimization with the hierarchical representation learning of tree-based methods. Nevertheless, such approaches results in increased model complexity, potentially diminishing their adaptability and capacity for generalization across diverse tasks. Additionally, the Transformer architecture has been adopted as a backbone in contemporary deep learning models (Wang et al., 2021; Huang et al., 2020; Gorishniy et al., 2021; Hollmann et al., 2022; Wang \& Sun, 2022). For example, the TabTransformer (Huang et al., 2020) introduces column embeddings before their integration into the Transformer model, whereas the FT-Transformer (Gorishniy et al., 2021) employs a feature tokenizer to transform individual columns into vector form. Similarly, UniTabE (Yang et al., 2024) introduces a unified tabular encoder that supports pretraining on tables of various structures. However, these methodologies necessitate substantial expertise in the development of taskspecific feature engineering and architectural modifications, posing challenges to scalability and the standardization of approaches.

Recent advancements in the application of LLMs for tabular data tasks have initiated a breadth of investigations. TaBERT (Yin et al., 2020a) introduces an approach that involves transforming each table row into a sequence of text for the purpose of learning joint representations of structured tables and natural language utterances through specialized feature engineering. TUTA (Wang et al., 2021) employs a unique bi-dimensional tree structure to ascertain cell coordinates and calculate distances between cells. XTab (Zhu et al., 2023) explores the use of federated learning for the collaborative training of data-specific and shared

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-03.jpg?height=696&width=1637&top_left_y=221&top_left_x=214)

Figure 2. Illustration of the initial pretraining phase of a LLM applying the Mask-Then-Predict strategy (on the left), followed by the multi-task training phase customized for downstream tasks such as classification and regression (on the right). Through the former phase, the LLM acquires unstructured knowledge embedded within tables. Subsequently, during the latter phase, it enhances its capability for reasoning between instructions and tabular contents.

Transformer blocks. TabLLM (Hegselmann et al., 2023) engages in zero-shot and few-shot classification tasks by transforming table rows into natural language texts, utilizing either manually created serialization templates or those derived from LLMs. A significant challenge encountered in the training processes of these models is the lack of a comprehensive pretraining corpus of tables specifically curated for data science applications, which limits the models' applicability and transferability. In an effort to avoid the direct training process, TabPFN (Hollmann et al., 2022) adopt in-context learning (ICL) (Brown et al., 2020) techniques while carrying out classification.

Although previous research has explored pretraining on tables, it is essential to delineate significant distinctions that set apart our approach: 1) Prior studies (Gu et al., 2022; Zhao et al., 2023; Li et al., 2023; Zhang et al., 2023; Wang et al., 2024) primarily concentrate on pretraining for textgeneration tasks rather than focusing on the predictive tasks pertinent to data science. This orientation towards generative capabilities does not directly address the nuanced needs of data science applications that require predictive modeling. 2) There is a notable scarcity of comprehensive training corpora specifically curated for data science scenarios. For example, TaPas (Herzig et al., 2020) augments BERT with additional positional embeddings tailored for encoding tabular data structures. Nevertheless, its pretraining regimen is predominantly geared towards semantic parsing and table question answering tasks, rather than predictive data science tasks. Similarly, PASTA (Gu et al., 2022) enhances the Transformer architecture with a specialized mechanism for table operation manipulation and is pretrained on a relatively limited dataset designed for sentence-table cloze tasks, aim- ing primarily at table-based fact verification applications. Recently, TableLlama (Zhang et al., 2023) undertakes finetuning on Llama-2 to facilitate the generation of target text across a broad spectrum of general tabular tasks of text generation, such as TableQA, table fact verification, and table-grounded dialogue generation. Consequently, these methodologies diverge significantly from ours in both focus and application, underscoring a distinct pathway pursued in our research.

## 3. Methodology

This section delineates the fundamental elements of our methodology, comprising the standardized approach to serialization for presenting LLMs with a unified format (\$3.1), the process of further training LLMs on tabular data (\$3.2), our assembled training corpus ( $\$ 3.3$ ), and the application of the trained model to downstream tasks (\$3.4). Subsequent subsections elaborate on each component of our approach in detail. Figure 2 visualizes our proposed bifurcated training regimen. The initial phase, illustrated in the left section of the figure, involves pretraining the LLM through a Mask-Then-Predict task, aiming to assimilate unstructured knowledge from tables. The subsequent phase, depicted in the right section, engages in tailored multi-task training for downstream applications, encompassing both classification and regression tasks.

### 3.1. Unified Serialization

Motivated by the findings of recent research (Shin et al., 2023), which demonstrates the superior efficacy of the Mark-

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-04.jpg?height=260&width=749&top_left_y=214&top_left_x=227)

Figure 3. The unified prompt template used for combining the instruction with tables to form the model input in both pretraining and finetuning in downstream tasks.

down format over conventional tabular formats including CSV and HTML, we choose to serialize tables in Markdown. This decision is further justified by Markdown's capability to maintain the intrinsic structure of tables and support various structural formats with minimal requirement for complex feature engineering.

Furthermore, we utilize a unified prompt template, as illustrated in Figure 3, to amalgamate task-specific instructions with table content. This approach is intended to augment Large Language Models' (LLMs) proficiency in extracting and deriving insights from the text surrounding tables, thereby enhancing their capability to perform reasoning tasks that span both instructions and tabular data. Such a methodology highlights the critical role of adopting a structured, yet adaptable, input format in elevating the model's efficacy across an array of tabular tasks. This approach ultimately facilitates a uniform training and fine-tuning paradigm for LLMs, ensuring a consistent and effective method for enhancing model performance in processing and analyzing tabular data.

### 3.2. Two Stage Training with Tables

To conduct pretraining, we employ the Mask-Then-Predict objective, which mirrors the established Masked Language Model (MLM) approach in NLP, aiming to improve the model's contextual understanding and its grasp of relationships within table-related data. Our model also undergoes multi-task training tailored to downstream applications, intending to infuse the model with domain-specific knowledge pertinent to tabular content, thereby enhancing its proficiency in understanding table data. By integrating these objectives, our strategy seeks to combine generalization, context awareness, and task-specific skills, facilitating the development of versatile and effective models for diverse downstream applications.

Mask-Then-Predict Pretraining Following the MLM approach that leverages self-supervised learning inherent in the data, we adopt a Mask-Then-Predict strategy by randomly masking sections within input tables, thus enforcing the model to infer the obscured values from their surrounding context. Such a process significantly enhances the model's capacity for knowledge acquisition from table data. In addi- tion, our method establishes a unified pretraining framework that encompasses a diverse set of tasks: predicting the names of columns, the numerical content of cells, and the textual content of cells. By engaging the model in these varied prediction tasks, this enables the model to develop a nuanced understanding of table structure, semantics, and the interplay between textual and numerical information within tables. Regarding the masking granularity within a table, it's more effective to consider the entire cell as the fundamental unit rather than individual tokens. This rationale is grounded in the fact that each table cell typically contains a discrete piece of information, often representing complete entities or attributes crucial to the understanding of the data's structural and semantic integrity. Such granularity also maintains the contextual coherence of the data and aids the model in comprehending the interrelationships among cells.

The challenge of encountering multiple missing values within a table commonly arises in real applications. To address this issue, the quantity of masked cells is dynamically varied during pretraining. The left section of Figure 2 elucidates a case with three masked cells. Those masked cell are substituted their content with distinctive sentinel tokens (for instance, " $<$ missing_value_0 0 ", â€œ $<$ missing_value_1 $>$ ", ..., "<missing_value_\{N-1\}>"). Subsequently, the model is tasked with inferring the original content of these masked cells by utilizing the contextual cues emanating from the adjacent, unobscured cells.

Multi-Task Training for Downstream Task Apart from acquiring knowledge within tables via the Mask-Then-Predict pretraining, we further refine the model's specialization through multi-task training phase. This phase uses datasets tailored for classification and regression tasks, aimed at augmenting the model's capability to reason about tabular instructions and contents. This method also dedicates to bolstering transferability and performance across downstream tasks. It is important to note that the datasets used in training are distinct from those used for evaluation experiments. The training corpus is specifically enriched by annotating 12 regression and 12 classification datasets with instructions. This proactive exposure of the pretrained LLM to varied problem-solving contexts, mirroring downstream applications, is expected to cultivate a more comprehensive and adaptable understanding of task-specific demands. Consequently, this strategy should enhance the model's generalization, effectiveness, and ability to adjust to the nuances of downstream tasks.

As illustrated on the right side of Figure 2, each example is structured using our unified prompt template prior to being inputted into our model. To accommodate a variety of regression and classification tasks, our model is crafted to predict actual text sequences rather than single values or class probability distributions. This design choice avoids

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-05.jpg?height=632&width=846&top_left_y=215&top_left_x=173)

Figure 4. The domain distribution: the percentages of the top-32 domains of tables collected from Kaggle. The tables that we collect cover around 300 domains.

relying on the integration of LLM with an additional head layer, thereby enabling the model to effectively meet diverse task requirements.

### 3.3. Pretraining Data Collection

To construct a comprehensive dataset of tables for our LLM pretraining, we engage in a dual-faceted data collection strategy. We first collect an extensive dataset from Kaggle for the Mask-Then-Predict objective, providing a broad and varied range of tabular data sourced from actual applications. This diversity enables effective learning from tables, enriching the model's knowledge base. In addition, for the goal of facilitating adaptation to downstream tasks, we meticulously annotate dominant tabular datasets, primarily those relevant to classification and regression tasks. This collected corpus guarantees that the model benefits from both the broad knowledge gained during LLM pretraining and the in-depth insights of tabular data, significantly boosting its versatility and effectiveness in a variety of real-world applications. About the license and ethical consideration, please refer to Appendix A.

Our tables for pretraining, sourced from Kaggle, spans 300 domains and includes 13 billion examples, ensuring comprehensive coverage across a wide range of fields. This diversity positions our model to potentially achieve domain independence, enhancing its versatility. Our study focuses on tabular data, specifically excluding image, audio, and video data. Hence, we categorize the data into numerical and textual types, common in data science, with numerical data processed to a precision of up to five digits. As illustrated in Figure 5, the bulk consists of numerical columns, highlighting a focus on quantitative data, including integers, decimals, and percentages. Textual columns make up nearly $40 \%$ of the dataset, encompassing unstructured text such

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-05.jpg?height=521&width=723&top_left_y=241&top_left_x=1102)

Figure 5. The data type distribution: the percentages of numerical columns and textual columns in our collected Kaggle tables.

Table 1. Comparison of statistics of our training corpus with prior work's pretraining datasets.

| Method | \#Examples | Sources |
| :--- | :---: | :---: |
| TUTA(Wang et al., 2021) | $58 \mathrm{M}$ | WikiTable,WDC,web |
| TAPAS(Herzig et al., 2020) | $6.2 \mathrm{M}$ | WikiTable |
| TaBERT(Yin et al., 2020b) | $26.6 \mathrm{M}$ | WikiTable, WDC |
| XTab(Zhu et al., 2023) | 52Tasks | OpenML-AutoML |
| Ours | $13 \mathrm{~B}$ | UCI,Kaggle (300 domains) |

as descriptions, textual columns and labels. This blend not only enriches the model's comprehension of natural language content but also ensures a balanced dataset that isn't overwhelmed by numerical data alone.

Furthermore, we supplement our dataset with data aimed at adapting our LLM into downstream tabular tasks. This includes 12 classification datasets and 12 regression datasets sourced from the UCI Machine Learning Repository. ${ }^{1}$ These datasets are equipped with task-specific instructions. The list of datasets used to construct this corpus is detailed in the Appendix B. Table 1 presents the comparative statistics of our constructed dataset relative to those utilized in previous research. Our dataset encompasses a wide range of domains, featuring an extensive collection of examples.

### 3.4. Applications in Downstream Tasks

This section explores the application of our trained model to various downstream tasks, such as filling in missing table values, performing classification and regression, and executing broader tasks like zero-shot and in context learning. To prepare the model input, we insert task-specific descriptions and instructions into the unified prompt template. This enables the model to engage in reasoning between the provided instructions and tables, leading to accurate prediction of the desired output. Note that for these tasks, the "Answer" placeholder, as shown in the referenced figure of the unified prompt template, remains unfilled.[^1]

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-06.jpg?height=477&width=765&top_left_y=233&top_left_x=211)

Figure 6. An illustration of our approach to learning in contexts of extreme length, with each example being sequentially organized using the uniform prompt template before being concatenated into the sequence of texts for model input.

Finetuning for Classification. Similar to traditional finetuing LLM for classification tasks, an additional classification head is integrated into our trained model. The model is optimized to minimize the cross-entropy loss, ensuring a more accurate alignment with the ground truth data. For the few-shot prediction, our trained model is finetuned with limited training examples or data points.

Finetuning for Regression. In a manner akin to classification, the model is augmented with an additional regression head for this task. The focus of optimization shifts to reducing the mean squared error (MSE) between the model's predictions and the actual values.

Finetuning for Missing Values Prediction. Addressing missing values within datasets is a common yet critical challenge in real-world applications. By employing the same methodology as in our mask-then-predict training, the model is adept at predicting missing values for every designated sentinel position.

In Context Learning Prior to making predictions on a target example, the model is presented with several contextual examples as depicted in Figure 6. These examples are structured using the unified prompt template, ensuring consistency in the model's input. The assembled texts from both context and target examples are concatenated into a singular input sequence, guiding the model to derive the target prediction from the provided context.

Zero-shot Prediction From a general perspective, the zeroshot prediction can be regarded as a special case of incontext learning that contains zero demonstration examples, where the example to be predicted is serialized and fed into the model without finetuning. For classification tasks, the model can also perform constrained decoding on specified tokens of options, enabling it to predict a class without prior explicit training on those categories.

## 4. Experiments

This section presents a comprehensive examination of our model's performance across various tasks, highlighting the experimental setup $\S 4.1$, overall results $\S 4.2$, and in-depth analyses $\S 4.3$ to elucidate the model's capabilities and limitations.

### 4.1. Experimental Setup

Implementation Details We employ the Llama-2 7B as the foundational architecture for our model, utilizing a highperformance computing cluster with NVIDIA A100 GPUs for efficient and capable training. We initiate training with a learning rate of $2 e-5$, balancing convergence speed with model stability. To accommodate large batch sizes, we use gradient accumulation with a step size of 4 . The Adam optimizer, with hyperparameters $\beta_{1}=0.9, \beta_{2}=0.95$, and $\epsilon=10^{-8}$, is adopted to ensure smooth and stable training progression. Following the masking recipe of BERT, a masking ratio of 0.15 is applied, randomly selecting cells for masking to bolster the model's competence with incomplete data. A warm-up ratio of 0.05 during the initial training phase helps prevent early instability by gradually adjusting the learning rate. In addition, numerical values are standardized to a precision of five decimal places to prevent excessively long numerical tokens. Tabular data can contain a wide range of information across multiple rows and columns, leading to the long sequence of model input. The context length determines how much of this data can be considered in a single model prediction. Inspired by recent research (Xiong et al., 2023; Fu et al., 2024), we have adjusted the base of RoPE (Rotary Positional Embedding) to enhance the model's ability to manage longer contextual dependencies.

Baselines In this work, we adopt the XGBoost as the representative baseline for traditional tree-based methods. The configuration for XGBoost adheres to the default settings of the xgboost package. ${ }^{2}$ For preprocessing textual data for XGBoost, we employed one-hot encoding through the scikitlearn library. ${ }^{3}$ We also compare with GANDALF (Joseph \& Raj, 2023) that builds upon a tailored tabular processing unit combined with a gating mechanism and in-built feature selection. Furthermore, our comparative analysis incorporates a comprehensive range of Transformer-based models and pre-trained models, including Tapas (Herzig et al., 2020), TaBERT (Yin et al., 2020a), TabTransformer (Huang et al., 2020), TabPFN (Hollmann et al., 2022), TUTA (Wang et al., 2021), TabLLM (Hegselmann et al., 2023), and XTab (Collins et al., 2022), among others. Throughout the training of these models on downstream tasks, we follow the official hyperparameter settings to ensure a consistent[^2]

Table 2. Evaluation results with ROC-AUC on classification tasks from Kaggle (left section) and public tabular benchmarks (right section). A higher score reflects superior results. The Best resutls in the table are denoted by bold formatting. The task name of each public benchmark starting with " $\mathrm{n}$ " represents the dataset only contains numerical features, while the task name starting with " $\mathrm{c}$ " denotes its dataset has both textual and numerical features. Left section demonstrates the results of tabular tasks from Kaggle.

| Method/Dataset | loan | heart | health | diabetes | cAlbe | cCTY | $\mathrm{cDCCC}$ | cElec | $\mathrm{cRS}$ | nDiab | nMT | nBM | $\mathrm{nCT}$ | nCred | $\mathrm{nDCCC}$ | nElec | nHelo |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| XGBoost | 0.733 | 0.829 | 0.854 | 0.793 | 0.700 | 0.674 | 0.753 | 0.963 | 0.879 | 0.631 | 0.936 | 0.846 | 0.935 | 0.840 | 0.751 | 0.952 | 0.764 |
| NODE | 0.712 | 0.789 | 0.845 | 0.821 | 0.705 | 0.711 | 0.758 | 0.868 | 0.812 | 0.634 | 0.925 | 0.845 | 0.827 | 0.807 | 0.764 | 0.855 | 0.766 |
| AutoInt | 0.663 | 0.801 | 0.846 | 0.814 | 0.689 | 0.710 | 0.463 | 0.585 | 0.501 | 0.499 | 0.895 | 0.854 | 0.502 | 0.758 | 0.773 | 0.838 | 0.500 |
| Tapas | 0.710 | 0.829 | 0.825 | 0.788 | 0.685 | 0.702 | 0.723 | 0.973 | 0.867 | 0.618 | 0.931 | 0.853 | 0.938 | 0.811 | .724 | 0.959 | 0.744 |
| TaBERT | 0.666 | 0.741 | 0.819 | 0.788 | 0.704 | 0.692 | 0.763 | 0.965 | 0.519 | 0.627 | 0.928 | 0.857 | 0.955 | 0.823 | 0.730 | 0.952 | 0.763 |
| TabTransformer | 0.580 | 0.811 | 0.838 | 0.806 | 0.441 | 0.697 | 0.722 | 0.821 | 0.733 | 0.623 | 0.852 | 0.821 | 0.654 | 0.740 | 0.431 | 0.819 | 0.505 |
| FT-Transformer | 0.488 | 0.794 | 0.831 | 0.805 | 0.654 | 0.535 | 0.497 | 0.887 | 0.844 | 0.640 | 0.932 | 0.836 | 0.913 | 0.815 | 0.778 | 0.879 | 0.538 |
| TabNet | 0.711 | 0.684 | 0.841 | 0.781 | 0.501 | 0.607 | 0.419 | 0.830 | 0.497 | 0.533 | 0.547 | 0.759 | 0.903 | 0.815 | 0.480 | 0.852 | 0.770 |
| TUTA | 0.728 | 0.695 | 0.836 | 0.824 | 0.696 | 0.614 | 0.748 | 0.487 | 0.571 | 0.633 | 0.898 | 0.814 | 0.737 | 0.734 | 0.756 | 0.518 | 0.617 |
| TabPFN | 0.710 | 0.787 | 0.800 | 0.821 | 0.703 | 0.697 | 0.762 | 0.859 | 0.782 | 0.632 | 0.923 | 0.849 | 0.846 | 0.838 | 0.767 | 0.858 | 0.721 |
| $\mathrm{XTab}$ | 0.722 | 0.824 | 0.854 | 0.827 | 0.708 | 0.704 | 0.761 | 0.902 | 0.881 | 0.641 | 0.928 | 0.858 | 0.954 | 0.825 | 0.762 | 0.886 | 0.784 |
| GANDALF | 0.646 | 0.796 | 0.822 | 0.819 | 0.704 | 0.699 | 0.693 | 0.820 | 0.822 | 0.635 | 0.924 | 0.847 | 0.828 | 0.792 | 0.496 | 0.847 | 0.775 |
| TabLLM | 0.732 | 0.783 | 0.836 | 0.790 | 0.650 | 0.691 | 0.719 | 0.861 | 0.849 | 0.622 | 0.799 | 0.839 | 0.790 | 0.788 | 0.713 | 0.858 | 0.762 |
| Llama2 7B | 0.706 | 0.774 | 0.841 | 0.817 | 0.687 | 0.683 | 0.711 | 0.962 | 0.883 | 0.573 | 0.893 | 0.815 | 0.954 | 0.802 | 0.736 | 0.964 | 0.764 |
| Our Method | 0.780 | 0.841 | 0.868 | 0.854 | 0.724 | 0.715 | 0.781 | 0.986 | 0.921 | 0.655 | 0.954 | 0.873 | 0.982 | 0.851 | 0.791 | 0.985 | 0.793 |

Table 3. Comparison results of regression tasks with R2 on Kaggle datasets (left section) and public tabular datasets (right section).

| Method/Dataset | $\mathbf{L C}$ | $\mathbf{H P}$ | PMI | cAbal | cAS | $\mathrm{cHS}$ | cNTGD | $\mathbf{c P M}$ | cSeat | nAbal | nElev | nH1 | nHS |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| XGBoost | 0.981 | 0.868 | 0.823 | 0.535 | 0.964 | 0.896 | 0.601 | 0.716 | 0.174 | 0.492 | 0.873 | 0.508 | 0.887 |
| NODE | 0.967 | 0.883 | 0.856 | 0.523 | 0.938 | 0.803 | 0.464 | 0.641 | 0.074 | 0.491 | 0.862 | 0.404 | 0.802 |
| AutoInt | 0.956 | 0.851 | 0.847 | 0.534 | 0.926 | 0.859 | 0.406 | 0.640 | 0.137 | 0.513 | 0.796 | 0.416 | 0.849 |
| TaBERT | 0.880 | 0.808 | 0.784 | 0.418 | 0.915 | 0.607 | 0.665 | 0.667 | 0.122 | 0.447 | 0.839 | 0.419 | 0.527 |
| TabTransformer | 0.974 | 0.847 | 0.668 | 0.517 | 0.427 | 0.745 | 0.328 | 0.496 | 0.126 | 0.504 | 0.691 | 0.185 | 0.717 |
| FT-Transformer | 0.981 | 0.590 | 0.691 | 0.513 | 0.928 | 0.874 | 0.404 | 0.669 | 0.107 | 0.516 | 0.447 | 0.448 | 0.867 |
| TabNet | 0.967 | 0.763 | 0.527 | 0.504 | 0.964 | 0.830 | 0.403 | 0.618 | 0.161 | 0.505 | 0.360 | 0.304 | 0.709 |
| TUTA | 0.956 | 0.805 | 0.854 | 0.304 | 0.871 | 0.619 | 0.620 | 0.569 | 0.173 | 0.244 | 0.625 | 0.299 | 0.606 |
| GANDALF | 0.992 | 0.864 | 0.845 | 0.521 | 0.944 | 0.878 | 0.331 | 0.636 | 0.157 | 0.513 | 0.856 | 0.291 | 0.869 |
| Llama2 7B | 0.967 | 0.854 | 0.816 | 0.363 | 0.965 | 0.846 | 0.658 | 0.708 | 0.162 | 0.460 | 0.865 | 0.458 | 0.860 |
| Our Method | 0.985 | 0.890 | 0.874 | 0.552 | 0.981 | 0.901 | 0.745 | 0.721 | 0.182 | 0.532 | 0.895 | 0.530 | 0.892 |

and fair comparison. Note that models initially not designed to support regression tasks in their official code, such as TUTA, are adapted by just modifying the output layer to produce a single numerical output.

Metrics The primary aim of this study is to further pretrain LLMs on tabular data, with an emphasis on applying these models to classification, regression, and filling missing values in the realm of data science. To assess the model's discriminative capacity and its effectiveness in distinguishing among different classes in classification tasks, we employ the ROC-AUC metric. For regression tasks, we utilize the coefficient of determination, $R^{2}$, as the evaluative metric. Additionally, to evaluate the model's proficiency in predicting missing values, both textual and numerical, we consider these values as text and apply the ROUGE-L metric (Lin, 2004) to compare the performance of various methods.

Benchmarks We have curated a collection of datasets to thoroughly evaluate our proposed method against existing approaches. The collection includes four classification and three regression tasks, all derived from Kaggle. Additionally, we have incorporated tasks from the publicly available tabular benchmarks (Grinsztajn et al., 2022). ${ }^{4}$ Within this subset of benchmarks, we drop tasks that are easy to ensure that our assessment accurately reflects the model's capability across a spectrum of challenges. For those tasks within the public tabular benchmarks, the abbreviated task name prefixed with " $n$ " indicates its dataset comprised solely of numerical features, whereas prefix of "c" signifies its dataset containing both textual and numerical features, thus offering a more complex evaluation scenario. This differentiation allows for an in-depth analysis of different models' performance across diverse data compositions prevalent in real-world applications.

### 4.2. Downstream Task Evaluation

Classification Table 2 presents the comparative performance of various methods on classification tasks, illustrating that our approach outperforms XGBoost, a traditionally prevalent method for tabular data analysis. XTab, employing pretraining techniques, emerges as a strong competitor to[^3]

XGBoost, underscoring the advantage of pretraining mechanism over conventional tree-based methods. In comparison to the Llama2 7B model, our method registers significant enhancements, evidencing the efficacy of our pretraining approach. Against a spectrum of pretrained models tailored for tabular data (such as TaBERT, TUTA, XTab, TabLLM, and others), our approach consistently delivers superior performance, indicating its practicality for real-world applications.

To extend the evaluation of our model's performance across a broader domain spectrum, we also engaged in comparative analyses with diverse methods on public tabular benchmarks. As depicted on the right part of Table 2, across 13 tasks, our model prevails as the leading performer, affirming its robust predictive modeling capability for datasets comprising numerical as well as mixed features. This reinforces the potential of our method as a versatile tool for various realworld scenarios involving composite tabular data. Moreover, Table 2 reveals a general trend where approaches exhibit diminished performance on mixed-feature tasks relative to purely numerical tasks. This performance disparity is particularly noticeable in models like TUTA. Nonetheless, our approach consistently achieves high ROC-AUC scores across different tasks, showcasing the robustness of our pretraining strategy that equitably accommodates numerical and textual data, backed by our training dataset rich in both data types.

Regression In the realm of regression, Table 3 presents the $R^{2}$ metrics across various tasks, conclusively demonstrating our method's superiority in regression analysis over a diverse dataset ensemble, sourced both from Kaggle and public domains. The uniformly high $R^{2}$ scores attest to our methodology's adeptness at discerning intricate patterns and relationships within tabular data, resulting in precise regression prediction. Overall, our model achieves an average performance improvement of $8.9 \%$ in classification tasks and $10.7 \%$ in regression tasks.

Filling in Missing Values Additionally, we evaluate the effectiveness of our method in filling in missing values. By simulating missing data through the random removal of cell content in tables, we tasked the model with predicting these absent values under varying conditions of data sparsity. Our model's performance is benchmarked against TableLlama (Zhang et al., 2023), Llama-2, and GPT-4. Despite TableLlama being an extension of Llama-2 and trained specifically on several tabular tasks (e.g. tableto-text, TableQA), its incremental performance gain over Llama-2 in handling missing values is modest. In contrast, our model demonstrates a significant improvement in performance, particularly noteworthy as the number of missing values increases, exhibiting a more resilient performance compared to GPT-4 with an overall improvement of around $27 \%$. This improvement in performance provides additional experimental support for the effectiveness of our pretrained

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-08.jpg?height=567&width=748&top_left_y=275&top_left_x=1098)

Figure 7. Comparison of prediction results for missing values: the number of missing values ranges from 1 to 4 . This range reflects the scenarios encountered in real-world applications, where a table may contain multiple missing entries.

model in addressing missing values, thereby affirming its potential utility in applications related to data completion, data recovery and tabular data synthesis tasks.

Extremely Long Context Learning In the realm of tabular data tasks, the challenge of modeling long sequences is significant. The primary hurdles involve improving the Large Language Model's (LLM) ability to handle the wide-ranging complexity of such data. This includes overcoming issues like data sparsity and decoding the non-linear relationships within tables. To navigate these challenges, models must be adept at processing lengthy sequences and precisely interpreting the dynamic nature of tabular datasets. To this end, we have adjusted the base of RoPE to bolster long sequence modeling capabilities during the pretraining phase.

We further conduct the experiments under the scenario of extremely long context learning. For each test sample, we select k-nearest examples from training set as its context. We leverage sentence-transformers to convert each example into a vector representation based on natural language text. This conversion follows the format: "column-name-0 is cell-value- 0 , column-name- 1 is cell-value- $1, \ldots$ columnname- $\{\mathrm{N}-1\}$ is cell-value- $\{\mathrm{N}-1\}$ ". Such a conversion aids the LLM, particularly sentence-transformers, in discerning subtle distinctions among examples, more so than if the original table format were used directly. To maintain label balance, an equal number of examples from each class are selected.

Figure 9 presents the comparative performance of our model against the Llama-2 7 b $80 \mathrm{~K}$ model that supports up to $80 \mathrm{~K}$ tokens. The clear performance enhancement, quantified as an average improvement of $18.8 \%$, reveals that our model not only achieves higher scores, but also consistently surpasses the Llama-2 80K model as the context size expands.

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-09.jpg?height=437&width=420&top_left_y=215&top_left_x=213)

(a) loan

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-09.jpg?height=437&width=423&top_left_y=215&top_left_x=615)

(b) heart

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-09.jpg?height=437&width=420&top_left_y=215&top_left_x=1015)

(c) health

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-09.jpg?height=439&width=439&top_left_y=214&top_left_x=1426)

(d) diabetes

Figure 8. Radar chart illustrating the performance of few-shot prediction in 4 classification tasks. The evaluation metric is ROC-AUC. Our method demonstrates superior performance, achieving higher scores in most of the directions (number of shots) on the chart, showing its effectiveness and competitiveness.

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-09.jpg?height=602&width=805&top_left_y=908&top_left_x=194)

Figure 9. Analysis of extremely Long context learning. We adopt the Llama-2 7B $80 \mathrm{~K}$ here as a good comparison that is capable of processing $80 \mathrm{~K}$ tokens as context. The $\mathrm{x}$-axis represents the number of examples included in the context, ranging from 0 to 48 .

This demonstrates our model's proficiency in mastering extremely long context learning.

Zero-shot Prediction The results of zero-shot prediction are also demonstrated in Figure 9. Our method achieves a ROC-AUC score of 0.54 and an accuracy rate of $68 \%$. The significant performance improvement against baseline model indicates the effectiveness of our proposed method.

Few-shot Prediction To evaluate the few-shot prediction capabilities of our model and to understand its efficacy and potential in scenarios characterized by scarce or costly data acquisition, we conducted few-shot prediction experiments. These experiments, detailed in Figure 8, illustrates the model's performance on classification tasks with a varying number of training examples (shots), which are selected randomly. The experimental results reveal that our method obtains a average performance leap of $28.8 \%$ in extremefew-shot (4-shot) predictions across various dataset against baselines. The findings suggest that an increase in the num-
Table 4. Ablation analysis in both classification (nDCCC) and regression (cHS) tasks. Removing mask-then-predict objective, downstream task customized objective, and removing both objectives separately.

| Method/Task | Classification | Regression |
| :--- | :---: | :---: |
| Our Method | 0.791 | 0.901 |
| - w/o Mask-then-Predict | 0.754 | 0.865 |
| - w/o Customized Tuning | 0.773 | 0.888 |
| - w/o both objectives | 0.736 | 0.846 |

ber of shots generally tends to enhance performance across different methods and datasets, albeit to varying extents. Analysis of Figure 8 reveals that in scenarios with as few as four training examples, such as in the loan eligibility prediction task, most methods, including XGBoost, exhibit evaluation scores around 0.5 . Notably, methods based on pretraining surpass XGBoost in the 4 -shot scenario, underscoring the advantages of pretraining in leveraging knowledge from tabular data. Our approach, in particular, outperforms other methods significantly in scenarios with very limited training examples, like 4 or 8 shots, demonstrating its superior efficacy and advantage in the few-shot learning context against competitors such as XGBoost, TabPFN, XTab, and TabLLM. This demonstrates that our model excels in adapting to a new target domain by just using a small dataset. Generally, the performance differences between methods begin to converge as the number of training examples increases beyond 8 .

### 4.3. Analysis

Ablation Study We want to examine the individual contributions of our proposed pretraining objectives. Results from the ablation study are presented in Table 4. The removal of the Mask-Then-Predict objective results in a significant decrease in performance, underscoring its vital role in enabling effective learning from tabular data. Conversely, omitting the objective of adapting to downstream tasks leads to a lesser decline in performance, suggesting that while it
contributes value to the model, its impact is comparatively modest against the Mask-Then-Predict objective. The combined omission of both pretraining objectives results in a marked deterioration in performance, highlighting the synergistic benefit of these objectives in bolstering the model's overall capabilities.

Predicting as Imputing Missing Value \& CoT Prompting We are curious about the feasibility of predicting the target value in the way of filling missing value. An additional column, which represents the predicted target for classification task and whose values are designated as missing with the sentinel token, has been incorporated into the original table. Consequently, the model is tasked with predicting the missing value within the example. The results measured with ROC-AUC are demonstrated in Figure 10. Furthermore, we analyze the effect of combining our trained model with CoT (Chain-of-Thought) prompting (Wei et al., 2022). We supplement the original instruction with "Let's think step by step. You need to first give the predicted value in the placeholder of $<$ missing_value_ $0>$, and then explain your reasons or thoughts." The performance gain of our method against Llama-2 is clear as our model has been trained with the self-supervised training of Mask-then-Predict task. This reveals that our trained model copes well with learning the intrinsic relation within the given table and carrying out reasoning over the tabular contents before predicting the missing value. Compared with the baseline, we notice that our model obtains a consistent performance improvement while combining with CoT prompting indicating that our method has the potential of utilizing properties of LLM (e.g. integrating with CoT) while excelling in understanding tabular data.

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-10.jpg?height=586&width=808&top_left_y=1577&top_left_x=192)

Figure 10. Analysis of predicting target value in the manner of filling in missing value. The CoT (Chain-of-Thought) prompting method is also integrated into models to provide detailed reasoning or explanations for each step. Our model demonstrates the consistent performance improvement with CoT across all tasks.

Performance Analysis of Label Imbalance This analysis further investigates the impact of imbalanced class distribu-

![](https://cdn.mathpix.com/cropped/2024_06_04_6300df0419c2b0808299g-10.jpg?height=588&width=794&top_left_y=275&top_left_x=1072)

Figure 11. Analysis of the impact to performance with varied label imbalance. The class imbalance is measured with Gini Index.

tions on the performance of the proposed model, employing the Gini Index to quantify the extent of inequality in class distributions. Datasets are categorized into three distinct groups based on their Gini Index values, with the average ROC-AUC score computed for each method within these categories. The findings, depicted in Figure 11, indicate that while label imbalance constitutes a significant challenge for all algorithms, the method developed in this work experiences a relatively minor performance decline in such scenarios. This suggests its enhanced robustness and effectiveness in addressing the challenges posed by uneven class distributions.

## 5. Conclusion

This study embarked on bridging the gap between Large Language Model (LLMs) and its application in processing structured tabular data, a staple in data science yet underexplored in LLM research. Through the pretraining of the Llama-2 model on a curated dataset from Kaggle and other tabular-focused sources, which includes approximately 13 billion examples across 300 domains, we have achieved substantial improvements in classification, regression, and missing value imputation tasks. The enhanced Llama-2 model demonstrates superior performance, with an average increase of $8.9 \%$ in classification and $10.7 \%$ in regression tasks, and a $27 \%$ improvement in missing value prediction accuracy over GPT-4. Moreover, the application of our method extends to few-shot prediction and extremely long context learning, further illustrating its versatility and effectiveness. These results underscore the effectiveness of our approach and the significant potential of well-pretrained LLMs for structured data analysis. Our work lays a foundational step for future research in applying LLMs to data science, aiming for improved analytical and predictive modeling capabilities.

## References

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33: $1877-1901,2020$.

Chen, T. and Guestrin, C. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pp. 785-794, 2016.

Collins, L., Hassani, H., Mokhtari, A., and Shakkottai, S. Fedavg with fine tuning: Local updates lead to representation learning. Advances in Neural Information Processing Systems, 35:10572-10586, 2022.

Fu, Y., Panda, R., Niu, X., Yue, X., Hajishirzi, H., Kim, Y., and Peng, H. Data engineering for scaling language models to $128 \mathrm{k}$ context. arXiv preprint arXiv:2402.10171, 2024.

Gong, H., Sun, Y., Feng, X., Qin, B., Bi, W., Liu, X., and Liu, T. Tablegpt: Few-shot table-to-text generation with table structure reconstruction and content matching. In Proceedings of the 28th International Conference on Computational Linguistics, pp. 1978-1988, 2020.

Gorishniy, Y., Rubachev, I., Khrulkov, V., and Babenko, A. Revisiting deep learning models for tabular data. Advances in Neural Information Processing Systems, 34: 18932-18943, 2021.

Gorishniy, Y., Rubachev, I., and Babenko, A. On embeddings for numerical features in tabular deep learning. Advances in Neural Information Processing Systems, 35: 24991-25004, 2022.

Grinsztajn, L., Oyallon, E., and Varoquaux, G. Why do treebased models still outperform deep learning on typical tabular data? Advances in Neural Information Processing Systems, 35:507-520, 2022.

Gu, Z., Fan, J., Tang, N., Nakov, P., Zhao, X., and Du, X. Pasta: table-operations aware fact verification via sentence-table cloze pre-training. arXiv preprint arXiv:2211.02816, 2022.

Hegselmann, S., Buendia, A., Lang, H., Agrawal, M., Jiang, X., and Sontag, D. Tabllm: Few-shot classification of tabular data with large language models. In International Conference on Artificial Intelligence and Statistics, pp. 5549-5581. PMLR, 2023.

Herzig, J., Nowak, P. K., MÃ¼ller, T., Piccinno, F., and Eisenschlos, J. M. Tapas: Weakly supervised table parsing via pre-training. arXiv preprint arXiv:2004.02349, 2020.
Hollmann, N., MÃ¼ller, S., Eggensperger, K., and Hutter, F. Tabpfn: A transformer that solves small tabular classification problems in a second. arXiv preprint arXiv:2207.01848, 2022.

Huang, X., Khetan, A., Cvitkovic, M., and Karnin, Z. Tabtransformer: Tabular data modeling using contextual embeddings. arXiv preprint arXiv:2012.06678, 2020.

Joseph, M. and Raj, H. Gandalf: Gated adaptive network for deep automated learning of features, 2023.

Li, P., He, Y., Yashar, D., Cui, W., Ge, S., Zhang, H., Fainman, D. R., Zhang, D., and Chaudhuri, S. Table-gpt: Table-tuned gpt for diverse table tasks. arXiv preprint arXiv:2310.09263, 2023.

Lin, C.-Y. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pp. $74-81,2004$.

Liu, G., Yang, J., and Wu, L. Ptab: Using the pre-trained language model for modeling tabular data. arXiv preprint arXiv:2209.08060, 2022.

Popov, S., Morozov, S., and Babenko, A. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019.

Shin, G., Xie, W., and Albanie, S. arxiveri: Automatic table verification with gpt. arXiv preprint arXiv:2306.07968, 2023.

Slack, D. and Singh, S. Tablet: Learning from instructions for tabular data. arXiv preprint arXiv:2304.13188, 2023.

Wang, Z. and Sun, J. Transtab: Learning transferable tabular transformers across tables. arXiv preprint arXiv:2205.09328, 2022.

Wang, Z., Dong, H., Jia, R., Li, J., Fu, Z., Han, S., and Zhang, D. Tuta: tree-based transformers for generally structured table pre-training. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining, pp. 1780-1790, 2021.

Wang, Z., Zhang, H., Li, C.-L., Eisenschlos, J. M., Perot, V., Wang, Z., Miculicich, L., Fujii, Y., Shang, J., Lee, C.-Y., et al. Chain-of-table: Evolving tables in the reasoning chain for table understanding. arXiv preprint arXiv:2401.04398, 2024.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.

Xiong, W., Liu, J., Molybog, I., Zhang, H., Bhargava, P., Hou, R., Martin, L., Rungta, R., Sankararaman, K. A., Oguz, B., et al. Effective long-context scaling of foundation models. arXiv preprint arXiv:2309.16039, 2023.

Yang, Y., Wang, Y., Liu, G., Wu, L., and Liu, Q. Unitabe: A universal pretraining protocol for tabular foundation model in data science. In The Twelfth International Conference on Learning Representations, 2024.

Yin, P., Neubig, G., tau Yih, W., and Riedel, S. TaBERT: Pretraining for joint understanding of textual and tabular data. In Annual Conference of the Association for Computational Linguistics (ACL), July 2020a.

Yin, P., Neubig, G., Yih, W.-t., and Riedel, S. Tabert: Pretraining for joint understanding of textual and tabular data. arXiv preprint arXiv:2005.08314, 2020b.

Zhang, T., Yue, X., Li, Y., and Sun, H. Tablellama: Towards open large generalist models for tables. arXiv preprint arXiv:2311.09206, 2023.

Zhao, Y., Zhang, H., Si, S., Nan, L., Tang, X., and Cohan, A. Investigating table-to-text generation capabilities of large language models in real-world information seeking scenarios. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Industry Track, pp. 160-175, 2023.

Zhu, B., Shi, X., Erickson, N., Li, M., Karypis, G., and Shoaran, M. Xtab: Cross-table pretraining for tabular transformers. arXiv preprint arXiv:2305.06090, 2023.

Table 5. Statistics of datasets used in multi-task training.

| Dataset | Link | \# Columns | \# Examples |
| :--- | :---: | :---: | :---: |
| Dry Beans | [url] | 16 | 13611 |
| PriceRunner Product | $[u r l]$ | 7 | 35311 |
| Auction Verification | $[\mathrm{url}]$ | 7 | 2043 |
| Mushroom | $[\mathrm{url}]$ | 22 | 8124 |
| Bank Marketing | $[\mathrm{url}]$ | 16 | 45211 |
| Credit Approval | $[\mathrm{url}]$ | 15 | 690 |
| Online Shopping Purchase Intent | $[\mathrm{url}]$ | 17 | 12330 |
| Banknote Authentication | $[\mathrm{url}]$ | 4 | 1372 |
| Early Stage Diabetes Prediction | $[\mathrm{url}]$ | 16 | 520 |
| Spambase | $[\mathrm{url}]$ | 57 | 4601 |
| Letter Recognition | $[\mathrm{url}]$ | 16 | 20000 |
| Soybean Cultivation | $[\mathrm{url}]$ | 11 | 320 |
| Seoul Bike Sharing Demand | $[\mathrm{url}]$ | 13 | 8760 |
| Wine Quality | $[\mathrm{url}]$ | 11 | 4898 |
| Servo System | $[\mathrm{url}]$ | 4 | 167 |
| Appliances Energy Prediction | $[\mathrm{url}]$ | 29 | 19735 |
| Energy Efficiency | $[\mathrm{url}]$ | 8 | 768 |
| Computer Hardware | $[\mathrm{url}]$ | 10 | 209 |
| Gas Turbine CO and NOx Emission | $[\mathrm{url}]$ | 12 | 36733 |
| Forest Fire | $[\mathrm{url}]$ | 12 | 517 |
| Temperature Forecast | $[\mathrm{url}]$ | 7 | 7750 |
| Infrared Thermography Temperature | $[\mathrm{url}]$ | 33 | 1020 |
| Large-scale Wave Energy Farm | $[\mathrm{url}]$ | 149 | 63600 |
| Parkinsons Telemonitoring | [url] | 19 | 5875 |
