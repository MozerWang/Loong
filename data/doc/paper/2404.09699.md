# Generative AI for Game Theory-based Mobile Networking 

Long He, Geng Sun, Dusit Niyato, Fellow, IEEE, Hongyang Du, Fang Mei, Jiawen Kang,<br>MÃ©rouane Debbah, Fellow, IEEE, and Zhu Han, Fellow, IEEE


#### Abstract

With the continuous advancement of network technology, various emerging complex networking optimization problems opened up a wide range of applications utilizating of game theory. However, since game theory is a mathematical framework, game theory-based solutions often require the experience and knowledge of human experts. Recently, the remarkable advantages exhibited by generative artificial intelligence (GAI) have gained widespread attention. In this article, we propose a novel GAI-enabled game theory solution that combines the powerful reasoning and generation capabilities of GAI to the design and optimization of mobile networking. Specifically, we first outline the game theory and key technologies of GAI, and then explore the advantages of combining GAI with game theory. Then, we briefly review the advantages and limitations of existing research and demonstrate the potential application values of GAI applied to game theory in mobile networking. Subsequently, we develop a game theory framework enabled by large language models (LLMs) to realize this combination, and demonstrate the effectiveness of the proposed framework through a case study in secured UAV networks. Finally, we provide several directions for future extensions.


Index Terms-GAI agent, pluggable LLM module, RAG, game theory, Nash equilibrium.

## I. INTRODUCTION

Game theory studies mathematical models of strategic interactions among interdependent rational participants (referred to as players), who make decisions based on their self-interests while their actions influence one another. Given its highly abstract representation of real-life situations, game theory has emerged as a standard analytical tool in various fields to model and comprehend complex systems involving multiple interacting agents. Employing game theory in the real world requires both constructing a suitable abstract game model (i.e., a binding from the cases to game-theoretic language) and solving the game (i.e., running an algorithm on the constructed model to extract the Nash equilibrium). Moreover, analyzing complex game scenarios with numerous players and[^0]

intricate strategic interactions typically entails high computational complexity and communication costs among players. Additionally, game theory models often oversimplify realworld complexities for analytical convenience. However, this simplification may result in a model that fails to adequately capture all relevant factors in practical scenarios, thus affecting the accuracy and applicability of the model.

Solving the aforementioned issues can be challenging since it traditionally requires a deep understanding of game theory and solution algorithms, particularly for the newcomers or those with interdisciplinary backgrounds. Therefore, exploring the formulation of game-theoretic models from human language and obtaining a Nash equilibrium holds tremendous research potential, despite facing the following challenges.

1) Human language is not explicitly built into the foundations of game theory.
2) Human language often contains incomplete or vague information, making it difficult to precisely define all the necessary parameters of a game-theoretic model.

In particular, with the development of mobile networking, game theory plays an increasingly important role in network optimization, network configuration and management, as well as network security and privacy. For example, a game theorybased method [1] was proposed to optimize user allocation and transmission power to improve the performance of mobile edge computing networks. Therefore, exploring solutions to formulate game-theoretic models from human language and obtain their Nash equilibrium is also crucial to improve network performance and facilitate network management.

Fortunately, generative artificial intelligence (GAI) techniques, such as large language models (LLMs) combined with retrieval-augmented generation (RAG), offer a promising solution to address the aforementioned challenges. LLMs, such as GPT-41. have demonstrated remarkable capabilities in understanding and generating human-like text. For example, the authors in [2] proposed a systematic simulation framework utilizing LLM agents for game theory research, and the simulation results demonstrated that the LLMs have the ability to imitate complex human strategic behaviors in socio-economic contexts. Furthermore, RAG models are able to enhance the reasoning capabilities of LLMs and provide more contextaware solutions by leveraging external knowledge sources, such as online encyclopedias or databases. Specifically, the advantages of using GAI in solving the challenges of formulating game models from human language and to obtain its Nash equilibrium in networking are as follows:
- Learning from Data: Generative AI techniques allow for a data-driven approach to game model formulation.[^1]

Specifically, LLMs can be trained on large-scale datasets, enabling them to learn from a wide range of game descriptions and strategies. This data-driven learning can help in capturing the patterns, common behaviors, and rationality assumptions exhibited by game players, their strategies and payoffs, enhancing the accuracy and realism of the formulated game models [3].

- Incorporating External Knowledge: RAG models, which combine LLMs with retrieval-based methods, can leverage external knowledge sources to augment the generation process. This is particularly useful when dealing with incomplete or vague language descriptions. Furthermore, possessing the ability to learn from and access external data sources enhances adaptability. For example, we can leverage game-theoretic models derived from economics and effectively apply them to resource allocation in networking. By accessing relevant information from databases, RAG models can enhance the accuracy, context relevance, and credibility of game model formulation and solution. Moreover, they also improve the trustworthiness and interpretability of the formulated model.
- Scalability and Computational Efficiency: LLMs and RAG models are designed with parallel processing capabilities, making them computationally efficient for handling large-scale game models. This is crucial when dealing with complex games involving numerous players and intricate interactions. Moreover, the efficiency of these models enables faster analysis and optimization, while reducing the computational burden associated with obtaining Nash equilibrium.

Motivated by these, this paper attempts to provide a forward-looking research that delves into the integration of GAI and game theory for networking optimization. To the best of the authors' knowledge, the synergy between GAI and game theory for networking optimization has still been an open issue thus far. The contributions of this paper are summarized as follows:

1) We overview the game theory and introduce different types of GAI models. Building on this, we provide comprehensive insights into the integration of GAI and game theory.
2) We explore a few seminal applications of LLMs and game theory in networking from different perspectives, providing the guideline on how to integrated these three important technologies to solve practical problems.
3) We propose an LLM combined with RAG framework for networking optimization. Simulation results based on a real-world networking optimization case study validate the effectiveness of the proposed framework.

## II. Overview of Game Theory and Generative AI

In this section, we first introduces the basics of game theory and several typical AI technologies that forming the foundation of GAI. Following that, we generally explain the potential support of GAI for game theory.

## A. Game Theory

1) What is game theory about? Game theory is a mathematical model and theoretical tool that studies the interaction of rational decision-makers (called players) in the presence of conflicts of interest. For example, the time required for a car driver to get home typically depends not only on the route they choose but also on the decisions made by other drivers. For such scenarios, game theory provides a framework for analyzing the strategic behavior of rational decision-makers and predicting the outcomes of their decisions. In game theory, non-cooperative game theory (NGT) is one of the most elemental and important branches, which has been widely applied in various fields. Specifically, it typically implies a competitive nature where players are not allowed to engage in enforced cooperation. Therefore, in this brief exposition, this paper focuses on a review of NGT.
2) How to present a game? The representation of game theory typically involves mapping a real-world game problem or scenario into a mathematical model. For NGT, as shown in Fig. 1, the strategic form is the most basic form, which typically consists of three fundamental elements that are players, strategies and payoffs.

- Players: Players are the participants or decision-makers involved in the game. A player can be a person, a machine, or more generally, any decision-making entity. Each player has a distinct set of preferences and objectives, and their choices or actions impact the outcomes of the game.
- Strategies: Strategies represent the available choices or actions that players can take in the game. A strategy of the player is their plan of action, which determines how they will act or respond to the actions of other players.
- Payoffs: Payoffs in game theory represent the objectives or utilities that players receive based on the strategies they choose and the actions taken by other players. The payoffs determine the desirability of different outcomes for each player, influencing their decisions and strategies.

3) How to analyze the outcome of a game? For NGT, the Nash equilibrium is a fundamental solution concept for predicting the outcome of the game. Specifically, it represents a strategy profile in which no player can improve their own payoff by changing their strategy while keeping the strategies of the other players unchanged. In other words, Nash equilibrium is a stable state where the players lack the incentive to actively change their strategies.

## B. Generative AI Models

GAI is a collection of various AI technologies and models that can learn patterns and regularities from data and then generate new data. The foundation of GAI mainly includes the following key technologies.

LLMs: LLMs are AI models based on Transformers, which can understand and generate human language through training of large-scale text data. Due to their versatility and robust generalization capabilities, LLMs can undertake diverse tasks, including text classification, question answering systems, and text generation, etc.

![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-3.jpg?height=1157&width=1759&top_left_y=186&top_left_x=172)

Fig. 1. The non-cooperative game framework contains multiple players and an environment in which players interact. Each player has a strategy space that represents the available actions and a utility function that evaluates the player's payoff from taking a certain action. Additionally, the objective of each player is to take actions that maximize their own payoff. The environment represents the medium through which players interact, that matches an action profile to a payoff profile. The flow of player interaction is as follows: in the first interaction (Step 1), each player takes an action from their strategy space and receives the corresponding payoff. In subsequent interactions (Step i), each player updates their action based on the observed strategies of other players to improve their own payoff. When the actions of all players no longer change, a Nash equilibrium is obtained.

RAG: RAG is an advanced natural language processing technique that integrates information retrieval and generative models to enhance the quality and relevance of generated text. Furthermore, when combined with RAG, LLMs can better understand user queries and generate text results that more accurately fulfill user needs by accessing external databases.

Generative Adversarial Networks (GANs): GANs are a type of neural network architecture with custom adversarial learning objectives, and they consists of two main parts that are the generator and discriminator. The goal of GANs is to train a generator network to generate samples that are similar to real data, and to train a discriminator network to distinguish between samples generated by the generator and real samples. Therefore, GANs have high performance in generating high-quality multi-modal content, which has led to a large number of applications such as 3D object generation, and image processing.

Generative Diffusion Models (GDMs): Inspired by nonequilibrium thermodynamics, GDMs comprise of two interconnected processes, i.e., a predefined forward process that transforms the data distribution into a more simplistic prior distribution (typically a Gaussian distribution), and a corresponding reverse process that employs a trained neural network to gradually reverse the effects of the forward process.
Due to the ability to generate high-quality data and the advantage of modeling complex data distributions, GDMs have been employed in material design, time series forecasting, and text-to-image generation, etc.

## C. GAI for Game Theory

Traditional AI technologies such as deep learning and reinforcement learning, have been applied in various successful cases in the context of game theory. For example, in [9], the authors formulated the task offloading problem in vehicular edge computing networks as an exact potential game and utilized a multi-agent distributed distributional deep deterministic policy gradient approach to attain the Nash equilibrium. In [10], the authors investigated the dynamic resource trading problem of multi-UAV-assisted industrial IoT networks, which is modeled as an extended stochastic game. Then, the authors proposed a multi-agent deep reinforcement learning algorithm to solve the formulated stochastic game. In [11], a Stackelberg game was employed to model real-time UAV twin migration for the emerging UAV metaverse system. The authors designed a tiny multi-agent deep reinforcement learning algorithm to approximate the game equilibrium. However, traditional AI techniques applied in the context of game theory still encounter the following challenges:

TABLE I

OVERVIEW OF SURVEY PAPERS ON THE INTEGRATION OF LLMS AND GAME THEORY

| Survey | Contributions | Emphasis |
| :--- | :--- | :--- |

- Need for Formal Formulation: Traditional AI techniques typically require a formal formulation of a gametheoretic scenario, i.e., mathematical representations, including the definition of players, actions, and payoffs. However, this formalization process can be challenging, especially for complex and real-world games where the rules may not be explicitly defined or known.
- Limited Information and Communication: In certain games, players may lack complete information about the game state or the strategies of other players. Traditional AI techniques may struggle to handle such incomplete or asymmetric information settings, as they rely on the assumption of complete information in their learning and decision-making processes.
- Computational Complexity: Obtaining Nash equilibrium for large games can incur significant computational costs. The search space for Nash equilibrium exponentially increases exponentially with the number of players and strategies [12]. Traditional AI techniques may struggle to efficiently explore the strategy space and converge to a Nash equilibrium in such cases.

LLMs combined with RAG provide a promising solution for addressing the abovementioned challenges faced by traditional AI. In the following, we elaborate on the advantages of LLMs combined with RAG in game scenarios from three perspectives, focusing on game scenario recognition, game theoretic model formulation, and Nash equilibrium search.

- Game Scenario Recognition: Game theory has been widely used in various fields to analyze complex real-life situations. Applying game theory to case studies involves initially identifying and extracting key game theoryrelated concepts from the context of these cases, including decision-makers, their strategies, and their payoffs. LLMs, trained on large amounts of textual data, possess the capability to comprehend natural language, thereby accurately identifying game theory-related concepts from natural language descriptions of real-life cases.
- Game Theoretic Model Formulation: Game theoretic model formulation involves mapping a game scenario to a mathematical model to facilitate theoretical analysis. Due to the diversity and complexity of game scenarios, it is challenging to formulate suitable mathematical models, requiring a broad and in-depth understanding of game theory and mathematical method. LLMs combined with RAG has powerful learning and generation capabilities, which can formulate accurate mathematical models that are suitable for gaming scenarios through extensive learning of knowledge in related fields.
- Nash Equilibrium Search: Obtaining the outcomes of game theoretic models, i.e., the Nash equilibrium, is often computationally complex. LLMs combined with RAG can extensively explore the strategy space in game theory and infer possible Nash equilibrium points. Moreover, LLM can enhance reasoning capabilities by learning existing methods, which makes obtaining Nash equilibrium more effective.

Lesson Learned: The exploration of LLMs combined with RAG in game theory underscores the critical role of rich knowledge base and powerful reasoning abilities in simplifying the utilization of game theory. Specifically, traditional game theory typically demands researchers to possess extensive experience and a deep understanding of game theory to provide effective insights into various complex game scenarios. By engaging in self-learning from large-scale data, LLM-based game theory successfully encapsulates the aforementioned complex process, thereby effectively reducing the challenges faced in the applications of traditional game theory. For example, in the social sciences domain, the integration of LLMs with game theory provides a valuable tool for experimental research and social simulations [5]. In the field of economics, LLMs have the potential to revolutionize microeconomic analysis by simulating strategic interactions among economic agents, which can lead to a better understanding of market behaviors and policy impacts [4].

## III. LLMS-ENABLED GAME THEORY IN NETWORKING

In this section, we first provide a comprehensive review of the existing literature on the integration of LLMs and game theory, and analyze the contributions and limitations of the current works. Subsequently, we present some applications of LLMs-enabled game theory in networking and analyze the combination of LLM and game theory for multi-agent network design .

## A. Overview of Survey Papers

Several studies have explored the integration of LLMs and game theory, as shown by Table I. However, these studies
exhibit certain limitations. First, existing research mainly focuses on exploring the reasoning capabilities of LLMs in the context of game theory. However, the potential advantages of applying LLMs to game theory scenarios have not been well studied. Second, existing research is mainly based on typical game theory cases with pre-defined game theory models. However, in various application fields of game theory such as the networking, it is challenging to map actual game scenarios into appropriate game theory models. Given the potent natural language understanding and generation capabilities of LLMs, leveraging them to map game scenarios to game models is a great value topic, which is still lacking research. Finally, existing studies do not consider the combination of LLMs with RAG. However, RAG is crucial to improving the capabilities of LLMs. Therefore, the combination of LLMs and RAG needs further exploration. To this end, this paper proposes a framework that applies LLMs combined with RAG to game theory scenarios in networking to make up for the shortcomings of existing research.

## B. Potential Applications of LLMs-enabled Game Theory in Networking

Spectrum and Interference Management: Spectrum and interference management are important issues in the field of wireless communication networks, involving the effective use of limited spectrum resources and power control to reduce wireless interference and improve network performance. Unlike traditional centralized management solutions with high computing load, game theory can be used to formulate distributed management solutions to effectively alleviate the computing load. However, traditional game theory approaches require frequent information interactions between the service users and central controller to obtain real-time complete information, which results in not only substantial time taken by users but also heavy computation and communication overhead. In this case, the LLMs-enabled game theory approach can use pre-trained models to approximate and learn strategic interaction behaviors in games to predict user decisions, which supplements the integrity of information to reduce the communication overhead.

Resource Allocation: Resource allocation involves the effective allocation and management of limited network resources, such as communication resources, computing resources, and storage resources, to meet the needs of network users. The limited nature of network resources usually leads to competition among network users, while game theory provides an analytical framework to understand the decisionmaking and strategy selection process among users to obtain effective resource allocation solutions. However, traditional game theory approaches to evaluate user satisfaction usually rely on pre-defined models, which are inflexible and inaccurate in practical scenarios. LLMs-enabled game theory approaches can develop a more accurate model for evaluating the user satisfaction by combining historical information and user feedback, which can improve the effectiveness of decisionmaking.

Network Security: Security constitutes a critical aspect of network management, which involves various security con- trols and protocols to ensure the confidentiality of network resources. Game theory can be used to analyze the interaction between cyber attacks and defense strategies. By modeling the game between attackers and defenders, optimal defense strategies can be derived, thereby improving the network security performance. Traditional game theory approaches typically formulate optimal defense strategies based on the static network environments. However, in dynamic network environments, the strategies and behaviors of attackers may evolve over time, which is challenging for dealing with. In this case, LLM-based game theory can monitor the changing network security threats in order to adjust decision-making strategies to deal with the new attacks.

## C. Combining LLM and Game Theory for Multi-Agent Network Design

The convergence of LLM, mobile networks, and multi-agent systems represents groundbreaking synergies that are leading to the emergence of multi-agent LLM network architectures, bringing huge potential for the design of future mobile networks [6]. This integration harnesses the power of collective intelligence and paves the way for self-managing networks. However, in a multi-agent LLM network, each LLM agent not only needs to pursue its individual objectives but also collaborate with other agents to achieve the collective goals of the entire network. This balance is crucial in designing efficient multi-agent LLM networks. In this context, game theory can be used to model and analyze the behavior of multi-agent LLM systems. This includes finding equilibria among agents, enabling them to serve individual objectives while effectively collaborating to achieve network-level goals. Furthermore, multi-agent reinforcement learning (RL) can further model the interactions among agents to learn optimal collaborative strategies and communication protocols among distributed LLM agents. In doing this, the communication costs among agents can be reduced.

## IV. LLMs-ENABLED GAME THEORY FRAMEWORK AUGMENTED BY RAG FOR MOBILE NETWORK OPTIMIZATION

In the section, we first propose an LLM-enabled game theory framework supported by RAG for network optimization. Then, we conduct a case study on UAV secure communication optimization to demonstrate the effectiveness of the proposed framework.

## A. Motivations

Network optimization is crucial for enhancing the performance, efficiency, and user experience of mobile networks. Given the complexity of network optimization problems, game theory has been adopted and has played a significant role in analyzing various network optimization issues. Nevertheless, for network designers, employing game theory to analyze networking optimization problems pose challenges that typically necessitate a solid grasp of mathematical theory and a profound comprehension of game theory principles.

![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-6.jpg?height=1084&width=1749&top_left_y=190&top_left_x=188)

Fig. 2. The LLM-enabled game theory framework. The framework is based on a layered architecture consisting of an input layer, an augmented layer, a decision layer, and an output layer. The input layer captures user input queries. The augmented layer employs RAG technology to enhance user queries. The decision layer utilizes a pluggable LLM to generate responses. The output layer returns the generated results to the user.

Inspired by LLM's outstanding capabilities, we propose an LLM-enabled game theory framework to address the abovementioned challenges. The proposed framework automates the mathematical formulation and game theory analysis of networking optimization problems through simple interactions with network designers, which effectively addresses the challenges of applying game theory and enhances the process of networking optimization. In addition, the framework can improve the accuracy of model formulation by incorporating relevant domain knowledge learned from a comprehensive knowledge base.

## B. Proposed Framework

As shown in Fig. 2, our proposed framework follows a layered architecture, which consists of four layers that are the input layer, augmented layer, decision layer, and output layer.

- Input Layer: The input layer receives requests from users, where multi-modal input allows the users to use different types of data as input, such as text, image, voice, and video. After receiving a request of the user, prompt engineering guides the system to generate the desired output by designing and constructing appropriate input prompts. Then, the input request of the user is transformed into a dense vector representation that the system can understand and process through embedding to facilitate downstream model processing. Furthermore, through embedding, the system can learn semantic similarities and correlations between inputs.
- Augmented Layer: The augmented layer is primarily implemented through the RAG technique, which is shown in detail in Part A of Fig. 3. The RAG can improve the quality, accuracy, and relevance of the generated answers of the system by providing relevant information related to the user requests [13]. The augmented layer contains a large-scale knowledge base to store rich material information, such as academic papers from IEEE Xplore. Specifically, RAG first acquires rich knowledge by loading the knowledge base, and then divides the knowledge into knowledge chunks that are suitable for embedded search. These knowledge chunks are then transformed into dense vector representations by using embedding techniques and stored in a vector database. Upon receiving the vector representation of the user request, RAG retrieves relevant information from the vector database and combines it with the user requests to form prompts, which are then sent to the decision-making layer for inference and decision-making execution.
- Decision Layer: The decision layer adopts a plugin architecture to select the appropriate LLMs such as New bing, Bard, and GPT4, to formulate decisions. As shown in Part B of Fig. 3. LLM formulates a response based on the query and the selected chunks from the augmented layer. The decision layer mainly relies on the reasoning and

![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-7.jpg?height=1065&width=1783&top_left_y=183&top_left_x=171)

Fig. 3. The operation flow of RAG and LLM. In Part A, documents are loaded from the knowledge base, segmented into chunks, encoded into vectors, and stored in the vector database. Then, RAG retrieves the $K$ most relevant chunks to the query of user based on semantic relevance from the vector database. In Part B, the original query and the retrieved chunks are inputted together into LLM to generate the final response.

decision-making capabilities of LLMs based on largescale data training.

- Output Layer: The output layer presents the decision results given by the decision layer to the users.


## C. Case Study: UAV Secure Communication Optimization

In the section, we use a UAV secure communication optimization case to demonstrate the proposed framework.

Scenario Description: As shown in Fig. 4, consider a UAV communication network consisting of $N$ legitimate UAV users, a destination ground base station, a friendly UAV jammer, and a malicious ground eavesdropper. These legitimate UAV users communicate with the destination base station through $N$ orthogonal channels while facing the risk of eavesdropping by the eavesdropper. The friendly UAV jammer has the capability to transmit cooperative jamming signals simultaneously over these channels to enhance the overall secrecy rate against the eavesdropper. The optimization objective is to maximize the aggregate security rate of all legitimate users through optimal power allocation of the friendly jammer across each channel.

Framework Configuration: In the framework configuration, we call the ChatGPT 4 model through the OpenAI API to implement the pluggable LLM module. Furthermore, the RAG module is built based on the LangChain.

Framework Operation Flow: The LLM interactive module in Fig. 4 shows the optimization flow of the proposed framework to solve the UAV secure communication optimization problem. In traditional optimization process, a network designer needs to formulate a mathematical optimization problem, use an appropriate game theory model to analyze the problem, and design effective algorithms to solve it, which relies on rich professional knowledge. With the help of the proposed framework, the optimization process can be automatically implemented through three rounds of interaction between the network designer and the GAI agent. Therefore, the proposed framework can effectively solve the challenge faced by the traditional optimization process.

Evaluation Results: The evaluation result module (a) of Fig. 4 shows the convergence of the algorithm generated by the proposed framework (i.e., GAI algorithm). From this figure, we can see that the GAI algorithm reaches a stable state, i.e., Nash equilibrium, after five iterations. The simulation results illustrate that the proposed framework can obtain a Nash equilibrium solution to the game theory problem. Moreover, the evaluation result module (b) of Fig. 4 shows the performance of the GAI algorithm with respect to different number of channels, where the expert algorithm indicates that the algorithm designed by network experts can be regarded as the optimal algorithm, and the EPR algorithm indicates that the average power allocation strategy is a benchmark algorithm. Correspondingly, we can observe that the GAI algorithm has the same performance as the expert algorithm. The evaluation results demonstrate the effectiveness of the proposed framework.

## V. Future DireCTIONS

In this section, we present three major future directions for the enhancement and extension of GAI-enabled game theory.
![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-8.jpg?height=856&width=522&top_left_y=192&top_left_x=172)

(b) System sum secrecy rate with respect to number of channels.
LLM Interaction

![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-8.jpg?height=902&width=795&top_left_y=205&top_left_x=730)

![](https://cdn.mathpix.com/cropped/2024_06_04_ab183e6f989419f0e57eg-8.jpg?height=919&width=312&top_left_y=188&top_left_x=1619)

Fig. 4. The experiment results of the wireless secure communication optimization case. The scenario module presents a system model of the considered scenario. The interaction module showcases the functionality of the proposed framework. The RAG augmentation module emphasizes the operational mechanism of RAG. The evaluation results module demonstrate the effectiveness of the proposed framework.

## A. GDM-enhanced Non-Cooperative Game

For non-cooperative game scenarios in networking with numerous players and complex decision spaces, obtaining a Nash equilibrium is often challenging computationally due to the need to search through a high-dimensional, exponentially large space. GDM has outstanding capabilities in modeling complex data distribution and data generation [14]. With the help of GDM, it is possible to enhance the search efficiency for Nash equilibrium and greatly reduce the computational complexity of complex non-cooperative games.

## B. Performance Evaluation of GAI-enabled Game Theory

It is crucial to design a comprehensive performance evaluation model to evaluate the performance of GAI combined with game theory. This is because effective evaluation models can provide directions for guiding and improving the GAI-enabled game theory framework. Furthermore, intelligent evaluation criteria should be designed to evaluate GAI-enabled game theory instead of human evaluation in the future.

## C. GAI-enabled Game Theory for Future Networks

As a key technology for future $6 \mathrm{G}$ wireless communications, the space-air-ground integrated network (SAGIN) has been proposed to provide seamless communication coverage and high-speed connections [15]. Due to the inclusion of heterogeneous network technologies, i.e., ground-based network, airbased network, and space-based network, the deployment and network management of SAGIN becomes more challenging. The vast potential of GAI-enabled game theory in networking is anticipated to synergize with the emerging SAGIN technology, catalyzing the advancement of SAGIN.

## VI. CONCLUSION

In this article, we explored the integration of LLMs with game theory, and concluded the advantages of LLM for game theory. Following this, we presented the potential applications of LLM combined with game theory in networking. Based on these, we proposed a framework that utilized RAG to combine LLM with game theory, aiming to achieve the intelligence of game theory in network applications. We conducted a case study on UAV secure communication optimization to validate the effectiveness of the proposed framework. Finally, we discussed several potential research directions for future extensions.

## REFERENCES

[1] P. Lai, Q. He, F. Chen, M. Abdelrazek, J. Hosking, J. Grundy, and Y. Yang, "Online user and power allocation in dynamic NOMA-based mobile edge computing," IEEE Trans. Mob. Comput., vol. 22, no. 11, pp. 6676-6689, November 2023.

[2] S. Mao, Y. Cai, Y. Xia, W. Wu, X. Wang, F. Wang, T. Ge, and F. Wei, "Alympics: LLM agents meet game theory - Exploring strategic decision-making with AI agents," arXiv preprint arXiv:2311.03220, 2023.

[3] C. Fan, J. Chen, Y. Jin, and H. He, "Can large language models serve as rational players in game theory? A systematic analysis," in Proc. AAAI Conf. Artif. Intell., vol. 38, no. 16, March 2024, pp. 17 960-17967.

[4] J. Duan, R. Zhang, J. Diffenderfer, B. Kailkhura, L. Sun, E. StengelEskin, M. Bansal, T. Chen, and K. Xu, "Gtbench: Uncovering the strategic reasoning limitations of LLMs via game-theoretic evaluations," arXiv preprint arXiv:2402.12348, 2024.

[5] F. Guo, "GPT agents in game theory experiments," arXiv preprint arXiv:2305.05516, 2023.

[6] H. Zou, Q. Zhao, L. Bariah, M. Bennis, and M. Debbah, "Wireless multi-agent generative AI: From connected intelligence to collective intelligence," arXiv preprint arXiv:2307.02757, 2023.

[7] Z. Wu, S. Zheng, Q. Liu, X. Han, B. I. Kwon, M. Onizuka, S. Tang, R. Peng, and C. Xiao, "Shall we talk: Exploring spontaneous collaborations of competing LLM agents," arXiv preprint arXiv:2402.12327, 2024.

[8] I. Gemp, Y. Bachrach, M. Lanctot, R. Patel, V. Dasagi, L. Marris, G. Piliouras, and K. Tuyls, "States as strings as strategies: Steering language models with game-theoretic solvers," arXiv preprint arXiv:2402.01704, 2024.

[9] X. Xu, K. Liu, P. Dai, F. Jin, H. Ren, C. Zhan, and S. Guo, "Joint task offloading and resource optimization in NOMA-based vehicular edge computing: A game-theoretic DRL approach," J. Syst. Archit., vol. 134, p. 102780, January 2023.

[10] M. S. Abegaz, H. N. Abishu, Y. H. Yacob, T. A. Ayall, A. Erbad, and M. Guizani, "Blockchain-based resource trading in multi-UAV-assisted industrial IoT networks: A multi-agent DRL approach," IEEE Trans. Netw. Serv. Manag., vol. 20, no. 1, pp. 166-181, March 2023.

[11] J. Kang, Y. Zhong, M. Xu, J. Nie, J. Wen, H. Du, D. Ye, X. Huang, D. Niyato, and S. Xie, "Tiny multi-agent DRL for twins migration in UAV metaverses: A multi-leader multi-follower Stackelberg game approach," IEEE Internet Things J., pp. 1-1, 2024.

[12] Y. Babichenko, S. Barman, and R. Peretz, "Simple approximate equilibria in large games," in Proc. ACM EC, 2014, pp. 753-770.

[13] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, "Self-RAG: Learning to retrieve, generate, and critique through self-reflection," arXiv preprint arXiv:2310.11511, 2023.

[14] H. Cao, C. Tan, Z. Gao, Y. Xu, G. Chen, P.-A. Heng, and S. Z. Li, "A survey on generative diffusion models," IEEE Trans. on Knowl. Data Eng., pp. 1-20, 2024

[15] J. Liu, Y. Shi, Z. M. Fadlullah, and N. Kato, "Space-air-ground integrated network: A survey," IEEE Commun. Surv. Tutorials, vol. 20, no. 4, pp. 2714-2741, Fourthquarter 2018.


[^0]:    L. He and F. Mei is with the College of Computer Science and Technology, Jilin University, Changchun 130012, China (e-mail: helong0517@foxmail.com, meifang@jlu.edu.cn).

    G. Sun is with the College of Computer Science and Technology, Jilin University, Changchun 130012, China, and also with the College of Computing and Data Science, Nanyang Technological University, Singapore 639798 (email: sungeng @ jlu.edu.cn).

    D. Niyato and H. Du are with the College of Computing and Data Science, Nanyang Technological University, Singapore 639798 (e-mail: hongyang001@e.ntu.edu.sg, dniyato@ntu.edu.sg).

    J. Kang is with the School of Automation, Guangdong University of Technology, Guangzhou, China (e-mail: kavinkang @ gdut.edu.cn).

    M. Debbah is with Khalifa University of Science and Technology, P O Box 127788, Abu Dhabi, UAE (e-mail: merouane.debbah@ku.ac.ae).

    Z. Han is with the University of Houston, Houston TX 77004, USA, and also with the Department of Computer Science and Engineering, Kyung Hee University, Seoul 446701, South Korea (e-mail: zhan2@uh.edu).

[^1]:    ${ }^{1}$ https://openai.com/blog/chatgpt/

