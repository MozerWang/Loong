# Lens functions for exploring UMAP Projections with Domain Knowledge 

Daniël Bot ${ }^{1}$ and Jan Aerts ${ }^{2}$<br>${ }^{1}$ UHasselt, Data Science Institute (DSI) (e-mail: jelmer.bot@uhasselt.be)<br>${ }^{2} \mathrm{KU}$ Leuven, Augmented Intelligence for Data Analytics Lab, Department of Biosystems (e-mail:<br>jan.aerts@kuleuven.be)


#### Abstract

Dimensionality reduction algorithms are often used to visualise high-dimensional data. Previously, studies have used prior information to enhance or suppress expected patterns in projections. In this paper, we adapt such techniques for domain knowledge guided interactive exploration. Inspired by Mapper and STAD, we present three types of lens functions for UMAP, a state-of-the-art dimensionality reduction algorithm. Lens functions enable analysts to adapt projections to their questions, revealing otherwise hidden patterns. They filter the modelled connectivity to explore the interaction between manually selected features and the data's structure, creating configurable perspectives each potentially revealing new insights. The effectiveness of the lens functions is demonstrated in two use cases and their computational cost is analysed in a synthetic benchmark. Our implementation is available in an open-source Python package: https://github.com/vda-lab/lensed_umap.


Keywords: Constraint dimensionality reduction, interactive data exploration, prior knowledge inclusion, topological data analysis, UMAP, visual analytics.

口

## 1 INTRODUCTION

Dimensionality reduction (DR) techniques are commonly used to visualise complex, high-dimensional data in two or three dimensions [1]. While these visualisations provide a good overview, they may not contain all the patterns an analyst expects to find. Patterns may not be visible due to errors and distortions [2] or can be hidden by a few influential data attributes [3]. Prior information and domain knowledge have been incorporated in DR algorithms as constraints to make embeddings better reflect analysts' expectations [4]. Generally, these techniques aim to emphasise or suppress known structures in the embeddings.

In this paper, we use such constraints for domainknowledge-guided exploration instead. Our primary inspiration comes from topological data analysis algorithms Mapper [5] and STAD [6]. Both algorithms support lens functions that highlight how particular features behave in different parts of the data. Their key benefit is that they create configurable perspectives, each potentially uncovering different insights. For example, lens functions can be used to emphasise a feature of interest or to incorporate additional signals.

The idea underpinning lens functions can be traced back to classical Morse theory, which studies shape with a function that identifies points of interest (e.g., [7]). The Mapper algorithm is based closely on these ideas, as it detects clusters in (overlapping) lens level sets and connects them across level set boundaries to construct a network that approximates a Reeb Graph [5]. The resulting structure summarises the relation be- tween the data's shape and the chosen lens function.

Lens functions can also be applied to modulate manifolds that describe point-to-point connectivity. For example, STAD removes edges between points in different lens level sets from a graph connecting all points closer than a particular distance threshold [6]. The resulting network does not have the same formal properties as a Reeb graph but can be used to visualise the same relations. In general, lens functions have three related effects: 1) they separate similar observations with different lens values; thereby 2) revealing distinct sub-populations with similar lens values; and 3) uncovering how these sub-populations evolve over the lens function.

Visually, lens functions are particularly effective because they express patterns by changing network connectivity and layout (i.e., position of the data points on the screen). They modulate data point positions and change which data points are pre-attentively perceived as a single group by the proximity Gestalt law [8]. Strictly speaking, many of the same patterns can also be visualised by colouring data points. However, as the visual variable of colour is less accurately perceived than position [9] they are not as easy to recognise that way. This is also corroborated by the discovery of novel patterns in older datasets using Mapper (e.g., [10, 11]).

The present paper proposes lens functions for UMAP, a state-of-the-art dimensionality reduction algorithm [12]. We present three lens types for UMAP models (see Fig. 1), bringing lens functionality to UMAP in an accessible manner. Two case studies demonstrate the added value lenses have for exploration[^0]workflows with UMAP: exploring data from multiple perspectives, leading to different insights. In addition, we show the computation scalability of these lens types by reporting compute times and presenting a synthetic benchmark.

In summary, we make the following contributions:

- Three lens types for UMAP models that adapt embeddings for answering questions using domain knowledge.
- Two use cases demonstrating exploration workflows using the lens types, and explaining in which scenarios each lens type is appropriate.
- A ready-to-use, open-source Python package $\rrbracket^{1}$ implementing the proposed functionality and the demonstrated use cases.


## 2 RELATED WORK

Our work has similarities to several other research topics. In this section, we first describe three related research fields to contextualise our work: graph signal processing, constraint dimensionality reduction, and visual analytics for dimensionality reduction. Then, we introduce UMAP, the dimensionality reduction algorithm on which we build.

### 2.1 Graph Signal Processing

Lens values can be interpreted as a signal defined on a graph. The Graph Signal Processing (GSP) field studies how such signals on graphs can be analysed (e.g., [13, 14]). It provides tools that describe how signals interact with the structure of a graph. In that sense, the field is related to lens functions. However, where lens functions use a signal to change the graph, GSP typically uses the graph to change or process the signal. For example, GSP adapts the Fourier transform for signals on graphs, enabling frequency-based transformations such as high-pass [15] and low-pass filtering [16], translation [17], and denoising [18]. The principles from GSP have also been used to infer connectivity within graphs from the attributes present on the nodes [19]. In addition, frequency and wavelet coefficients can be used to detect interesting patterns within a graph [20], which could identify interesting lens dimensions.

### 2.2 Constraint Dimensionality Reduction

Prior information and domain knowledge are typically incorporated in dimensionality reduction algorithms as constraints [4]. Several types of constraints are distinguished. Instance-level constraints apply to individual points or relations between points. This type of constraint is used to manipulate an embedding's layout [21] or describe which points should or should not be considered similar [22]. Dataset-level constraints apply to datasets as a whole. For instance, to adapt feature priorities [23] or to incorporate class labels [24], the data's hierarchy [25], or cluster shapes [26]. Recently, studies have also applied constraints on the embedding's topological structure [27] to recover patterns that are known to be in a dataset [28, 29].

Generally, these techniques aim to make the embedding reflect a known structure. Prior information can also suppress known patterns to reveal other unexplained patterns [30, 31]. Lens functions have a different purpose. They use prior information to explore datasets. They can, however, be explained in terms of constraints as a method that introduces "cannot-link" relations between points that differ in lens value. There is also a connection with multiview constraints that restrict embeddings to the variation shared between different views of the same data items [4], as lens functions may originate from such different views.

### 2.3 Visual Analytics for Dimensionality Reduction

Integrating dimensionality reduction algorithms in effective visual interfaces for human analysts is an active research topic in the visual analytics field (e.g., [1, 2]). We restrict our overview to one broad task: interpreting patterns present in an embedding. Several studies have designed visualisation systems for this purpose. For example, t-viSNE explains patterns through data features that correlate most with manually drawn polylines [32]. Colour has been used to summarise which features are most stable or most extreme in value across a projection [33, 34]. The manifold's orientation around data points has been visualised by drawing elliptical glyphs indicating each point's local linearised variance [35]. Sequences, groups, and hierarchies have been visualised directly in embeddings to let analysts summarise their data in these terms and explain the structures in terms of the high-dimensional data [36].

Lens functions have a similar goal to these techniques: they attempt to uncover and explain patterns within a dataset that remain hidden when only a dimensionality reduction's layout is shown. They differ from these techniques because lens functions change the modelled structure-and thereby the produced layout-rather than how the layout is shown. Lens functions can, therefore, be combined with visualisation techniques that present additional information or explain the patterns present within a layout.

A recent technique by Fujiwara et al [3] is perhaps the most related to our work. They generate multiple maximally distinct projections from linear subspaces of a dataset to reveal patterns that are unrecognisable when all features are projected. Our approach differs from theirs by its human steerability and by the way the global structure is retained. Using our method, analysts can target which features to inspect in the context of the entire feature space rather than as a subspace.

### 2.4 UMAP

Uniform Manifold Approximation and Projection (UMAP) is a state-of-the-art dimensionality reduction algorithm [12, 37]. Together with t-SNE [38], PBC [39], and IDMAP [40], UMAP produced the highest-rated embeddings in a benchmark comparison considering multiple datasets and quality metrics [41]. Several studies have built upon UMAP since it was first published, for example, to improve density preservation [42], cluster separation [43], and to embed multiple (overlapping) datasets in an aligned manner [44]. In addition, a specialised GPU implementation reaching interactive embedding speeds on large datasets has been created [45]. To our knowledge, the lens functions we present here have not been implemented for UMAP before.[^1]

Global Lens

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-03.jpg?height=185&width=564&top_left_y=165&top_left_x=173)

(2)
![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-03.jpg?height=288&width=428&top_left_y=402&top_left_x=166)

(4) $\downarrow$

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-03.jpg?height=385&width=545&top_left_y=705&top_left_x=172)

(a)
Global Mask
![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-03.jpg?height=928&width=582&top_left_y=164&top_left_x=774)

(b)
Local Mask

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-03.jpg?height=937&width=559&top_left_y=160&top_left_x=1398)

(c)

Figure 1. Overview of the three lens types. All three lens types operate on an initial UMAP model, in this case constructed from a dataset with two spatial variables (1). The initial model does not reveal local lens extrema in its connectivity or layout, i.e., observations with low lens values (red) are connected and located near observations with high lens values (blue). The lens types filter the initial model's edges to separate observations that differ in the lens dimension. In the visualisations, edges that are kept are shown in black and edges that are removed are shown in red. How the lens types update the initial model differs: (a) The global lens divides a single lens dimension-shown by horizontally ordered data points-into non-overlapping segments (2) and only keeps the initial model's edges between points in the same or neighbouring segments (3). (b) The global mask constructs a $k_{\text {mask }}$-nearest neighbour network over one or more lens dimensions (2) and only keeps the initial model's edges that also exist in the mask network (3). (c) The local mask computes the distance in one or more lens dimensions between points connected in the initial model (2) and only keeps the $k_{\text {mask }}$ shortest ones for each point (3). All three lens types compute a layout for their updated model using the initial model's layout as starting point (4). The resulting embeddings reveal local extrema in the lens dimension.

Because our work builds upon UMAP, explaining how the algorithm works is relevant. Therefore, the remainder of this section presents a high-level overview of the algorithm summarised from [12]. For a thorough theoretical treatment of UMAP, we refer the reader to [12].

### 2.4.1 Approximating the Manifold

As its name suggests, UMAP works in two stages. The first approximates a manifold along which the data is distributed uniformly. Let $X=\left\{\boldsymbol{x}_{1}, \ldots, \boldsymbol{x}_{N}\right\}$ be the dataset and $d: X \times X \rightarrow \mathbb{R}_{\geq 0}$ a distance metric or dissimilarity function. Let $i_{k}$ indicate the index of $\boldsymbol{x}_{i}$ 's $k$-th nearest neighbour. Then, the manifold is computed from a directed $k$-nearest neighbour graph $G=(V, E, w)$, where denotes $V$ the set of vertices, $E=\left\{\left(i, i_{j}\right) \mid\right.$ $1 \leq j \leq k, 1 \leq i \leq N\}$ is the set of edges, and $w\left(i, i_{j}\right)$ expresses the similarity between $\boldsymbol{x}_{i_{j}}$ and $\boldsymbol{x}_{i}$ from $\boldsymbol{x}_{i}$ 's perspective, accounting for varying densities and ensuring each point is at least fully connected to its closest neighbour. Finally, $G$ is symmetrised in a union operation that combines the points' perspectives, interpreting $w(i, j)$ as the probability of the edge existing in $E$.

### 2.4.2 Projecting the Manifold

UMAP's second stage typically functions as a graph layout algorithm for the manifold graph. Formally, UMAP optimises an embedding into a user-defined space to minimise the crossentropy between the uncovered manifold $G$ and the embedded points' manifold. Practically, UMAP employs a sampling-based stochastic gradient descent strategy. The algorithm iterates for a pre-specified number of epochs, sampling edges $(i, j)$ with a probability $w(i, j)$ to apply an attraction force that increases the embedding similarity $v(i, j)$. The high-dimensional similarity $w(i, j)$ is not used in the force computation once an edge is selected. Similarly, a repulsion force decreases $v(i, k)$ for $m$ randomly selected vertices $k$. This negative sampling scheme assumes $w(i, k)=0$, basing the applied force only on $v(i, k)$. These forces are applied using a configurable learn-rate parameter that decays linearly to 0 to improve convergence.

This minimisation process is sensitive to the initialisation. Using an initialisation that provides global structural information is essential to preserve that information in the final embedding [46]. The implementation's default spectral initialisation performs that role but is negatively affected by disconnected components and vertices [12].

## 3 LENSED UMAP

We present three types of lens functions for UMAP models that let analysts adapt their projections to their questions. This section describes how they work in detail. Table 1 summarises their overall properties. All lens three types operate on a UMAP manifold $G=(V, E, w)$, where $V$ is the set of vertices, $E$ is the set of edges, and $w(i, j)$ is the edge weight acting as the probability data points $\boldsymbol{x}_{i}$ and $\boldsymbol{x}_{j}$ are connected. The lens functions filter edges based on the lens dimensions and (re-)project the manifold.

### 3.1 Global Lens

The global lens (Fig. 1a) is most similar to the approaches used by Mapper [5] and STAD [6]. Like in STAD, the global lens first divides a single lens dimension $(f: X \rightarrow \mathbb{R})$ into $k_{\text {lens }}$ nonoverlapping segments. Our implementation supports creating regularly spaced or balanced segments encapsulating approximately the same number of points. Let $s_{i}$ be a positive integer indicating point $\boldsymbol{x}_{i}$ 's segment number (between 0 and $k_{\text {lens }}$ ). Then, edges are filtered, keeping only the edges between points within the same or neighbouring segments:

$$
\begin{equation*}
E_{\text {global lens }}=\left\{(i, j) \mid(i, j) \in E, a b s\left(s_{i}-s_{j}\right) \leq 1\right\} \tag{1}
\end{equation*}
$$

Extending this approach to circular lens domains is trivial by also allowing edges between segments 0 and $k_{\text {lens }}$. Multiple lens dimensions can be combined by applying them in sequence.

This filtering approach differs from STAD in two ways. First, we keep empty lens segments that reflect gaps in the lens dimension, which splits connected components in the filtered graph. Second, we avoid needing a community-detection-based post-processing step to maintain connectivity across segment boundaries by allowing one boundary crossing.

The global lens can also be interpreted as a global lens distance threshold on the edges in $E$. When regularly spaced segments are used, all edges with a lens distance larger than one segment width are removed. With balanced segments, the threshold varies with the lens distribution's density: for uncommon lens values, the threshold is higher, and for common lens values, the threshold is lower.

The computational complexity of this lens type depends on the chosen discretisation strategy. Computing regularly spaced segments has a complexity linear with the number of points. The balanced segments require sorting the points by their lens value. Filtering the edges has a complexity linear in the number of edges.

### 3.2 Global Mask

The global mask (Fig. 1b) is similar to UMAP's intersection functionality [12, 37]. The global mask first computes a UMAP manifold $G_{\text {mask }}=\left(V, E_{\text {mask }}, w_{\text {mask }}\right)$ over one or more lens dimensions $\left(f: X \rightarrow \mathbb{R}^{m}\right)$ using distance metric $d_{\text {mask }}$ : $f(X) \times f(X) \rightarrow \mathbb{R}_{\geq 0}$.

Table 1. Summary of the lens types' properties. Effect indicates whether the lens type applies a global threshold or operates on the manifold locally. The other columns rank the lens types: Tearing indicates their tendency to split connected components, Cost indicates their computational cost, Difficulty indicates the intuitiveness of their parameters.

| Lens type | Effect | Tearing | Cost | Difficulty |
| :---: | :---: | :---: | :---: | :---: |
| Global Lens | Global | Medium | Low | Medium |
| Global Mask | Global | High | High | High |
| Local Mask | Local | Low | Medium | Low |

Then, the initial model's edges are filtered, keeping only the edges that also occur in $G_{\text {mask }}$ :

$$
\begin{equation*}
E_{\text {global mask }}=\left\{(i, j) \mid(i, j) \in E,(i, j) \in E_{\text {mask }}\right\} \tag{2}
\end{equation*}
$$

The resulting graph is symmetrised, as the edges are undirected. Unlike UMAP's intersection functionality, our filter does not adapt the edge weights $w(i, j)$; it only removes edges that do not occur in the lens' manifold.

Like the global lens with balanced segments, the global mask can be interpreted as a global lens distance threshold that varies with the lens distribution's density. Here, that threshold is expressed as the number of neighbours in the lens dimensions to keep. This number may need to be high when similar lens values occur in multiple places along the manifold. Consequently, constructing the lens manifold for large datasets can be quite expensive. The filter operation is implemented like an elementwise sparse matrix multiplication, which requires iterating over the edge union between $G$ and $G_{\text {mask }}$.

### 3.3 Local Mask

The local mask (Fig. 1c) is most similar to a UMAP manifold computed over the lens dimensions $\left(f: X \rightarrow \mathbb{R}^{n}\right.$ ), where the initial manifold $G$ prescribes the allowed edges. The local mask first computes the lens dimension distance ( $d_{\text {mask }}$ : $\left.f(X) \times f(X) \rightarrow \mathbb{R}_{\geq 0}\right)$ for each edge in $G$. Then, let $r_{i}(\cdot)$ rank all edges connected to $\boldsymbol{x}_{i}$ in $G$ by their (increasing) lens dimension distance, such that $r_{i}(j)$ indicates edge $(i, j)$ 's rank from $\boldsymbol{x}_{i}$ 's perspective. Then, the $k_{\text {mask }}$ shortest edges are kept for each point:

$$
\begin{equation*}
E_{\text {local mask }}=\left\{(i, j) \mid(i, j) \in E, r_{i}(j)<k_{\text {mask }}\right\} \tag{3}
\end{equation*}
$$

The resulting graph is symmetrised because the edges are undirected. As with the previous lens types, the initial edge weights $w(i, j)$ are retained, distinguishing this lens type from the previously mentioned UMAP manifold.

Unlike the global lens and global mask, this lens type cannot be reduced to a global threshold. Instead, it operates in the context of each point, which provides several benefits. Firstly, the number of neighbours parameter $k_{\text {mask }}$ directly specifies how many edges should be kept for each point. Secondly, the local lens is less likely to split connected components. Neither gaps in the lens dimensions nor large lens value differences along the manifold $G$ directly result in a tear, as each point is guaranteed to keep $k$ edges. On the other hand, this also means that the local lens is less consistent in removing large lens distance edges when few short lens distance edges connected to a data point.

The computational complexity of this lens type depends on the initial manifold's number of neighbours $k$ and the mask number of neighbours $k_{\text {mask }}$. Computing each edge's lens distance has a linear complexity with the number of edges. Then, finding each point's $k_{\text {mask }}$ closest lens-neighbours is, at worst,

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-05.jpg?height=398&width=548&top_left_y=83&top_left_x=149)

(a)
Default UMAP

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-05.jpg?height=352&width=642&top_left_y=138&top_left_x=709)

(b)
Survival lens

ESR1

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-05.jpg?height=341&width=626&top_left_y=144&top_left_x=1335)

(c)

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-05.jpg?height=450&width=1808&top_left_y=558&top_left_x=164)

Figure 2. (Lensed) UMAP embeddings for the NKI dataset 47. (a) UMAP embedding (correlation distance, 30 nearest neighbours) coloured by survival. Contrasting patients within the grey dotted ellipse identifies the ESR1 gene (b). (c) A global lens with three segments separates patients by their survival state, indicated by the coloured rectangles. Contrasting patients by survival state within the low ESR1 community identifies the CSTA gene. A local mask (10 neighbours) over CSTA reveals how CSTA varies over the manifold (d) coloured by survival state, (e) coloured by ESR1, (f) coloured by CSTA. The grey dotted ellipse indicates a low ESR1, high CSTA region with an abundance of 'relapse free' patients.

as expensive as sorting each point's $k$ edge distances. Finally, constructing the resulting graph has a complexity linear in the number of remaining edges.

## 4 USE CASES

Lens functions help generating insights in exploratory data analyses by adapting UMAP projections for particular questions. We present two use cases that demonstrate the lens function in action and highlight how they provide benefits. The first use case exhibits the similarities and differences with Mapper. The second use case applies lensed UMAP to a larger dataset, and reports compute times in a realistic setting. In addition, we present a synthetic benchmark to investigates how the lens types' computational costs scale and are influenced by their parameters. All timings were recorded on a computer with an AMD R7 7700 CPU and 32GB RAM.

### 4.1 Breast Cancer Gene Expression

This use case demonstrates the role of lens functions in an exploratory data analysis using UMAP. We adapt a Mapper analysis [10] of the NKI breast cancer dataset [47] that identified several interesting genes in the Chemokine KEGG pathway. These genes distinguish patients with low oestrogen receptor gene (ESR1) levels that relapse from those who remain relapsefree. The strength of this exploration is that these genes can be discovered without prior motivation to investigate low ESR1 patients. Instead, visualising the networks raises the question of why particular sub-groups differ, leading to the insights.

### 4.1.1 Data and Pre-Processing

The data (obtained from [48]) was pre-processed following [10]. Specifically, we removed the rows and columns with the $5 \%$ most missing values. The remaining missing values were imputed using their observation's 5-nearest neighbours. Finally, we extracted the 1553 genes with the highest variance.

### 4.1.2 Exploration Steps

The exploration starts by constructing a UMAP model using the correlation distance and 30 nearest neighbours, shown in Fig. 2a. The resulting embedding contains one larger and one smaller community connected by a few data points, raising the question of which genes differ between these communities. A Kolmogorov-Smirnov test comparing expression values between the selected small community (grey-dotted ellipse) and the other non-selected data points identified the ESR1 gene as significantly different ( $\mathrm{p}<0.01, \mathrm{D}=0.90$ ) (Fig. 2b). This gene is relevant to a domain expert because low ESR1 expression has been linked to poor prognoses (as cited in [10]).

At this point, a domain expert might wonder why there does not appear to be an abundance of patients who relapse in this low ESR1 community. One way to explore this question is to visually separate the patients by their survival state. A global lens with three regular segments removes all connections between the two groups. Fig. $2 \mathrm{c}$ shows the resulting embedding, where the two disconnected components were positioned below each other in a post-processing step. The orange and blue rectangles indicate the 'relapse-free' and 'with relapse' patients, respectively. This new embedding makes it easier to see colour differences between the two groups.

The low ESR1 community can also be explored by comparing gene expressions between its 'relapse-free' and 'with relapse' patients. The CSTA gene (among others) was significantly different in a Kolmogorov-Smirnov test comparing these groups ( $\mathrm{p}<0.01, \mathrm{D}=0.51$ ). A local mask over CSTA reducing the model's connectivity to 10 nearest neighbours was applied to the original UMAP model to investigate how CSTA behaves across the model. Fig. $2 \mathrm{~d}$ 2f show the resulting embedding coloured by survival state, ESR1, and CSTA. In these figures, the low ESR1 community is transformed into a loop along which CSTA increases from the lower left to the upper right. A grey-dotted ellipse indicates a region with many 'relapsefree' patients. Patients in this region have low ESR1 but high CSTA expressions, indicating CSTA expression correlates with survival state for patients with low ESR1 expression.

The Chemokine genes identified by [10] also differed significantly in the Kolmogorov-Smirnov test comparing survival state within the low ESR1 community ( $\mathrm{p}<0.05, \mathrm{D}=0.36$ ). This finding indicates that these genes could be discovered using lensed UMAP. We chose to illustrate the local mask with CSTA because its effect was stronger with our selections and preprocessing. Also, note that we did not need an eccentricity lens to explore the data in this use case. It is, however, possible to re-create the Y-shape found by [10] with lensed UMAP using such a lens.

### 4.2 Air-Quality

This use case demonstrates lensed UMAP's ability to deal with a larger dataset. We adapt an exploratory analysis [6] of an air quality dataset [49] that described several patterns in air quality changes over time by aggregating the data per week. This preprocessing step effectively averaged out measurement locations. Here, we show how lensed UMAP explores the dataset and detects similar patterns while keeping measurement locations separate.

### 4.2.1 Data and Pre-Processing

The dataset [49] contains daily compound concentration measurements for several years and locations. Two features with more than $40 \%$ missing values were removed. Observation with missing values in features with at least $10 \%$ missing values were also removed. This action reduced the number of data points from 446.014 to 181.368 , removing some locations entirely and consecutive periods from others. The remaining missing values were imputed using their observation's 5-nearest neighbours. Finally, a robust z-score was applied to make the features comparable.

### 4.2.2 Exploration Steps

The first exploration step constructed a UMAP model (cosine metric, 50 nearest neighbours) in $17 \mathrm{~s}$ and computed the embedding in $111 \mathrm{~s}$. The embedding is shown by its edges (Fig. 3a), data points coloured by year (Fig. 3b), and data points coloured by features (Fig. 3c). An equal histogram normalisation was applied when mapping the features to colours. This technique preserves value orders but not their magnitudes and avoids outlier values dominating the colour range [50]. These figures highlight two main patterns: 1) time appears correlated with the embedding-older observations appear towards the right side, more recent observations are contained in three structures on the left and bottom-and 2) three recent structures differ most in their $\mathrm{SO}_{2}$ values.

A global lens over the observation year was applied to reveal which states exist each year and how those states progress across years. The lens was configured with 24 regular segments to retain the edges between equal or consecutive years. Applying the lens took $29 \mu \mathrm{s}$, and updating the embedding required $56 \mathrm{~s}$. The lens effect is visible in Fig. 3e. There appear to be four periods with distinct structures. Several additional interesting patterns are visible in Fig. 3d and 3f:

- PM10 started decreasing from 2003 onward, which may be related to vehicle regulations introduced around that time (as cited in [6]).
- Observations before 2008 appear more densely connected, which suggests larger differences between nonconsecutive years in that period.
- The lower and higher $\mathrm{NO}_{2}$ states after 2008 appear connected through two arms: one with low and one with high $\mathrm{O}_{3}$ and $\mathrm{PM} 10$.
- Between 2008 and 2015, the connectivity to previous years occurs through observations with relatively high $\mathrm{NO}_{2}$ values. Similar states that occur later and states with lower $\mathrm{NO}_{2}$ are located separately.

A local mask over the $\mathrm{SO}_{2}$ values (20 neighbours) was applied to inspect that feature's interaction with the manifold. Applying the mask took $1.0 \mathrm{~s}$, and the embedding was updated in 49 s. The resulting embedding is shown in Fig. 3g 3i. These figures highlight one main pattern: there appear to be multiple slices with different $\mathrm{SO}_{2}$ values, hinting at some discrete process. Further inspection of the $\mathrm{SO}_{2}$ values reveals that they are measured in whole $\mu \mathrm{g} / \mathrm{m}^{3}$, and their distribution is right-tailed. This finding explains explains the slices, as low $\mathrm{SO}_{2}$ values occur often, and data points with such values are likely to have 20 neighbours with the same value, resulting in few connections to other $\mathrm{SO}_{2}$ values.

A colouring technique that reveals which feature has the highest value along the manifolds is applied to demonstrate that such visualisation techniques can be combined with lenses. Our approach approximates the "value explanation" from [33, 34] using Datashader's categorical shading that blends hues for each pixel by the features means within that pixel [50]. Fig. 4] shows the resulting visualisations that summarise feature behaviour along the manifold.

### 4.2.3 Discussion

The observed lack of connectivity between states after applying a lens can be caused either by a sufficient change in state or a lack of similar observations nearby in the lens dimension. Our removal of observations with missing values contributes to this lack of connectivity because it introduced measurement time gaps at several locations. The changes in measurement locations over time also contribute to changes in the observed state. Both factors should be considered when interpreting the discovered patterns.

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-07.jpg?height=1476&width=1828&top_left_y=80&top_left_x=148)

(a) (b)

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-07.jpg?height=388&width=661&top_left_y=126&top_left_x=1296)

(c) (d) (e) (f) (g) (h) (i)

Figure 3. (Lensed) UMAP embeddings for the Air Quality dataset 49. (a)-(c) Default UMAP embedding (cosine distance, 50-nearest neighbours) shown by the model's edges and points coloured by year and features, respectively. (d)-(f) The embedding after applying a global lens over the year dimensions (24 regular segments), drawn as before. (g-i) The embedding after applying a local mask ( 20 neighbours) over the $\mathrm{SO}_{2}$ dimension, drawn as before.

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-07.jpg?height=417&width=594&top_left_y=1708&top_left_x=164)

(a)

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-07.jpg?height=420&width=599&top_left_y=1709&top_left_x=758)

(b)

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-07.jpg?height=417&width=594&top_left_y=1708&top_left_x=1359)

(c)

Figure 4. (Lensed) UMAP embeddings for the Air Quality dataset [49] coloured to summarise the highest feature over the manifold inspired by [33] Default UMAP (cosine distance 50-nearest-neighbors), (b) a global lens over the year dimensions (24 regular segments), and (c) a local mask (20 neighbours) over the $\mathrm{SO}_{2}$ dimension. Feature values were normalised with a robust z-score enabling direct comparison of their values. The figures were created using Datashader's categorical shading that blends hues depending on the category values in each pixel [50].

While there appear to be spherical structures that reflect seasonal patterns, they do not correspond to time directly. A location's consecutive measurements do not move smoothly over the manifold. Instead, day-to-day variations can jump

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-08.jpg?height=564&width=1808&top_left_y=81&top_left_x=148)

Figure 5. Benchmark compute times ( $\mu \mathrm{s}$ ) excluding the embedding step and mask model computation. A linear regression line with its $95 \%$ interval—relating compute time to the initial UMAP model's edge count-is shown for each dataset size (100, 1000, 10.000, 100.000 points), lens types, and lens parameter value. (a) The global lens with varied discretisation strategy over $3,6,12$, and 24 segments. (b) The global mask with 20, 40, 80, and 160 mask neighbours. (c) The local mask with $5,10,20$, and 40 mask neighbours.

across the manifold quite wildly. These spherical structures are natural for a cosine distance metric, as that metric measures the angles between observations and is sensitive to the relative feature-value compositions.

### 4.3 Benchmark

Updating the embedding is lensed UMAP's main computational bottleneck, as shown in Section 4.2.2 This step's cost depends only on the number and weight of the edges being embedded. The local mask's retained number of edges follows from the specified mask neighbours and the number of data points. The other two lens types retain more edges as the input model contains more edges. In our experience, updating an embedding after applying a lens takes the same order of magnitude time as computing the initial embedding. Removing too many edgeswhich would speed up the process-also removes structure, thereby hindering interpretability. It is possible to accelerate this step with GPUs, bringing the cost down to seconds for millions of data points [45].

The global mask has an additional bottleneck: computing the mask model. Generally, this step tends to be more expensive than computing the original UMAP model, as more neighbours are needed to balance the mask's strength. As shown in Section 4.2.2, computing a UMAP model on roughly 180.000 data points with 50 neighbours took $12 \mathrm{~s}$. Consequently, this step will be a noticeable part of the compute time.

Both of these points aside, in this section, we demonstrate the lens types' computational scaling, excluding both previously mentioned bottlenecks. This benchmark is not intended to reflect realistic data. Instead, we are interested in general scaling trends. The benchmark used randomly generated datasets containing a varying number of points forming 10 clusters around the vertices of a 10-dimensional hypercube. Then, a UMAP model was computed given a varying number of neighbours $k$, and the lens types were applied given their parameter values. All selected parameter values (see Fig. 5) were evaluated on five datasets.

We measured the time required to apply the lenses to the UMAP model, i.e. the steps described in Section 3. For the global mask, constructing the mask model is excluded from the timing. Fig. 5 shows linear regression lines with their $95 \%$ interval for the compute time ( $\mu \mathrm{s}$ ) over the initial UMAP model's edge count, computed separately for each dataset size, lens type, and indicated lens parameters.

The global lens' compute time scales linearly with the original model's edge count, with the balanced strategy being faster at smaller sizes (Fig. 5a. This difference diminishes as the number of edges increases. The global mask also scales with the edge count; with a stronger effect, the more mask neighbours are considered and an additional effect for the dataset size (Fig. 5b]. This pattern matches the lens type's workload: iterating over the mask and the initial model's edge union. The local mask appears to scale more with the dataset size than the initial model's edge count (Fig. 5c). An increase in edges to process is primarily visible in its interaction with the number of mask neighbours: the more edges, the stronger the effect of mask neighbours.

## 5 DISCUSSION

The use cases (Section 4) demonstrated how lens functions enable analysts to use their domain knowledge in exploring data from multiple perspectives, leading to different insights. They also demonstrate which lens type is appropriate for different scenarios:

- The global lens is most applicable for separating binary or ordinal values, such as the survival state in Section 4.1 and the year in Section 4.2. It can also be used for numerical values but is limited to one dimension per lens and may split connected components.
- The local mask works well on numerical variables, such as CSTA expression in Section 4.1 and $\mathrm{SO}_{2}$ values in Section 4.2. Its parameters are easy to set, and the mask is unlikely to separate connected components.
- The global mask is most useful when two related manifolds are available. In other cases, the mask manifold's
compute cost and indirect nature of the parameters limits usability.

The computational costs were reported in the air quality use case (Section 4.2) and investigated in a synthetic benchmark (Section 4.3). Generally, updating the embedding coordinates is the computational bottleneck. In our use cases, this step took roughly half the time spent computing the initial embedding. Consequently, applying lenses to larger datasets is not feasible at interactive speeds but will be quicker than computing the initial model. GPU acceleration can alleviate this problem [45]. Filtering the modelled connectivity-i.e., applying the lensesis much less expensive. The benchmark confirmed this step's computational cost scales as described in Section 3 .

### 5.1 Validity

UMAP is based on solid mathematical theory, which gives it credibility [12]. Lenses break some of the properties UMAP is designed to maintain by changing what is being modelled from the data's manifold to the interaction of that manifold and a signal defined on it. While we do not provide an elaborate theoretical description, we argue that breaking these properties is justified because lenses uncover the connectivity which a Reeb graph uses to determine whether two points in a level set are equivalent (i.e., in the same connected components). In this interpretation, UMAP provides the manifold, and the lens types specify how the level sets are defined.

In practice, breaking these properties has consequences in UMAP's sampling-based embedding process and can reduce the embedding's quality after applying a lens. For example, the spectral initialisation expects the manifold to contain few connected connected components and deteriorates when many separate components are present. In addition, every data point is given at least one attraction force in every epoch by ensuring it is fully connected to its nearest neighbour.

Lenses can break both properties by splitting connected components into smaller pieces and removing edges between nearest neighbours. The quality of the resulting embedding is maintained by using the initial model's layout as initialisation. A reduced attraction force is typically counteracted by decreasing the repulsion strength. Alternatively, the edge weights can be normalised after applying a lens-increasing the modelled similarity—or the lens's strength can be reduced to remove fewer edges.

We recommend visualising model edges to judge the embedding quality. Long and overlapping edges indicate too much repulsion and too little attraction. Other (force-directed) graph layout algorithms can also be used to embed the model (f.i., $[51,52,53]$ ).

### 5.2 Alternatives

Several alternative data exploration techniques have been mentioned in the present paper. This section compares these approaches to the proposed lens types, describing their differences and highlighting how the techniques can be combined.

The first alternative technique uses colour to summarise feature distributions across embeddings [33, 34] (Section 2.3). This approach is not a direct alternative for lens functions. Instead, it visualises regions where particular (combinations of) features have stable or extreme values, providing a figure explaining how regions in the manifold differ. The approach can be applied with a lens, which we demonstrate in Fig. 4

The second alternative technique is Mapper, a source of inspiration for our work. Mapper uses lens functions to visualise a dataset's structure from configurable perspectives, raising questions to explore and leading to insights. We attempted to bring this functionality to UMAP in an accessible manner, where UMAP provides a starting point without needing a lens. The main difference between both approaches is that Mapper uses clusters while UMAP works with individual data points. Consequently, it can be easier to estimate how many points are part of a pattern in a lensed UMAP projection compared to a Mapper graph. Furthermore, there is no need to inspect and tune clustering behaviours when using lensed UMAP. Instead, UMAP's $k$-nearest neighbours determine whether data points are connected.

Finally, we discuss two alternative ways to integrate information with UMAP. Firstly, some lens dimensions can be added to UMAP's distance metric. Secondly, lens dimensions can be used to pre-compute a sparse distance matrix, prescribing which edges UMAP may use. Like lens functions, both approaches increase the separation between data points that differ in the lens dimensions. Unlike lens functions, they also decrease the separation between data points with similar lens values. Computationally, both approaches are more expensive in interactive exploration workflows as they require recomputing the nearest neighbours for every lens.

## 6 CONCLUSION

The present paper proposed three types of lens functions for UMAP models. Two use cases demonstrated how the lens types can be use to explore data from different perspectives, leading to new hypotheses and insights. Lenses are particularly effective in discovering patterns in a subset of the data, as these may not be obvious from individual distributions. In addition, lenses can be based on metadata-i.e., features not included in the distance metric-providing additional exploration flexibility.

## ACKNOWLEDGMENT

This work was supported by Hasselt University BOF grant [BOF20OWB33] and KU Leuven grant STG/23/040.

## DATA AVAILABILITY

Data is available on-line at https://doi.org/10.5281/ zenodo.11193167.

## REFERENCES

[1] D. Sacha, L. Zhang, M. Sedlmair, J. A. Lee, J. Peltonen, D. Weiskopf, S. C. North, and D. A. Keim, "Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis," IEEE Trans. Vis. Comput. Graph., vol. 23, no. 1, pp. 241-250, 2017.

[2] L. G. Nonato and M. Aupetit, "Multidimensional Projection for Visual Analytics: Linking Techniques with Distortions,

Tasks, and Layout Enrichment," IEEE Trans. Vis. Comput. Graph., vol. 25, no. 8, pp. 2650-2673, 2019.

[3] T. Fujiwara, Y. H. Kuo, A. Ynnerman, and K. L. Ma, "Feature Learning for Nonlinear Dimensionality Reduction toward Maximal Extraction of Hidden Patterns," IEEE Pacific Vis. Symp., vol. 2023-April, pp. 122-131, 2023.

[4] V. M. Vu, A. Bibal, and B. Frenay, "Integrating Constraints Into Dimensionality Reduction for Visualization: A Survey," IEEE Trans. Artif. Intell., vol. 3, no. 6, pp. 944-962, $\operatorname{dec} 2022$.

[5] G. Singh, F. Mémoli, and G. Carlsson, "Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition," PGB@ Eurographics, vol. 2, pp. 91-100, sep 2007.

[6] D. Alcaide and J. Aerts, "Spanning Trees as Approximation of Data Structures," IEEE Trans. Vis. Comput. Graph., vol. 27, no. 10, pp. 3994-4008, 2021.

[7] S. Biasotti, D. Giorgi, M. Spagnuolo, and B. Falcidieno, "Reeb graphs for shape analysis and applications," Theor. Comput. Sci., vol. 392, no. 1-3, pp. 5-22, 2008.

[8] C. Ware, Information Visualization: Perception for Design. San Francisco: Morgan Kaufmann Publishers Inc, 2004.

[9] J. Mackinlay, "Automating the design of graphical presentations of relational information," ACM Trans. Graph., vol. 5, no. 2, pp. 110-141, apr 1986.

[10] P. Y. Lum, G. Singh, A. Lehman, T. Ishkanov, M. VejdemoJohansson, M. Alagappan, J. Carlsson, and G. Carlsson, "Extracting insights from the shape of complex data using topology," Sci. Rep., vol. 3, no. 1, p. 1236, feb 2013.

[11] J. L. Nielson, J. Paquette, A. W. Liu, C. F. Guandique, C. A. Tovar, T. Inoue, K.-A. Irvine, J. C. Gensel, J. Kloke, T. C. Petrossian, P. Y. Lum, G. E. Carlsson, G. T. Manley, W. Young, M. S. Beattie, J. C. Bresnahan, and A. R. Ferguson, "Topological data analysis for discovery in preclinical spinal cord injury and traumatic brain injury," Nat. Commun., vol. 6, no. 1, pp. 1--12, 2015.

[12] L. McInnes, J. Healy, and J. Melville, "UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction," feb 2018.

[13] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst, "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains," IEEE Signal Process. Mag., vol. 30, no. 3, pp. 83-98, may 2013.

[14] A. Ortega, P. Frossard, J. Kovacevic, J. M. Moura, and P. Vandergheynst, "Graph Signal Processing: Overview, Challenges, and Applications," Proc. IEEE, vol. 106, no. 5, pp. 808-828, 2018.

[15] A. Sandryhaila and J. M. F. Moura, "Discrete Signal Processing on Graphs: Frequency Analysis," IEEE Trans. Signal Process., vol. 62, no. 12, pp. 3042-3054, jun 2014.

[16] X. Zhu and M. Rabbat, "Graph spectral compressed sensing for sensor networks," ICASSP, IEEE Int. Conf. Acoust. Speech Signal Process. - Proc., pp. 2865-2868, 2012.

[17] B. Girault, P. Goncalves, and E. Fleury, "Translation on Graphs: An Isometric Shift Operator," IEEE Signal Process. Lett., vol. 22, no. 12, pp. 2416-2420, 2015.

[18] J. Pang, G. Cheung, A. Ortega, and O. C. Au, "Optimal graph laplacian regularization for natural image denoising," ICASSP, IEEE Int. Conf. Acoust. Speech Signal Process. Proc., vol. 2015-August, pp. 2294-2298, 2015.

[19] X. Dong, D. Thanou, P. Frossard, and P. Vandergheynst, "Learning Laplacian Matrix in Smooth Graph Signal Representations," IEEE Trans. Signal Process., vol. 64, no. 23, pp. 6160-6173, dec 2016.

[20] D. M. Mohan, M. T. Asif, N. Mitrovic, J. Dauwels, and P. Jaillet, "Wavelets on graphs with application to transportation networks," 2014 17th IEEE Int. Conf. Intell. Transp. Syst. ITSC 2014, pp. 1707-1712, 2014.

[21] X. Yang, H. Fu, H. Zha, and J. Barlow, "Semi-supervised nonlinear dimensionality reduction," ACM Int. Conf. Proceeding Ser., vol. 148, pp. 1065-1072, 2006.

[22] H. Cevikalp, J. Verbeek, F. Jurie, and A. Klaser, "Semisupervised dimensionality reduction using pairwise equivalence constraints." in VISAPP '08 - 3rd Int. Conf. Comput. Vis. Theory Appl., A. Ranchordas and H. Araújo, Eds. Funchal, Portugal: INSTICC, 2008, pp. 489-496.

[23] D. H. Jeong, C. Ziemkiewicz, B. Fisher, W. Ribarsky, and R. Chang, "iPCA: An Interactive System for PCA-based Visual Analytics," Comput. Graph. Forum, vol. 28, no. 3, pp. 767-774, jun 2009.

[24] M. Sugiyama, "Local Fisher discriminant analysis for supervised dimensionality reduction," in Proc. 23rd Int. Conf. Mach. Learn. - ICML '06, vol. 148. New York, New York, USA: ACM Press, 2006, pp. 905-912.

[25] T. Höllt, A. Vilanova, N. Pezzotti, B. P. Lelieveldt, and H. Hauser, "Focus+context exploration of hierarchical embeddings," Comput. Graph. Forum, vol. 38, no. 3, pp. 569$579,2019$.

[26] A. Machado, A. Telea, and M. Behrisch, "ShaRP: ShapeRegularized Multidimensional Projections," in EuroVis Workshop on Visual Analytics (EuroVA), M. Angelini and M. El-Assady, Eds. The Eurographics Association, 2023.

[27] M. Moor, M. Horn, B. Rieck, and K. Borgwardt, "Topological autoencoders," in Proceedings of the 37th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, H. D. III and A. Singh, Eds., vol. 119. PMLR, 1318 Jul 2020, pp. 7045-7054. [Online]. Available: https://proceedings.mlr.press/v119/moor20a.html

[28] R. Vandaele, B. Kang, J. Lijffijt, T. De Bie, and Y. Saeys, "Topologically Regularized Data Embeddings," ICLR 2022 - 10th Int. Conf. Learn. Represent., pp. 1-26, oct 2021.

[29] E. Heiter, R. Vandaele, T. De Bie, Y. Saeys, and J. Lijffijt, "Topologically Regularized Data Embeddings," jan 2023.

[30] B. Kang, D. García García, J. Lijffijt, R. Santos-Rodríguez, and T. De Bie, "Conditional t-SNE: more informative tSNE embeddings," Mach. Learn., vol. 110, no. 10, pp. 2905-2940, oct 2021.

[31] E. Heiter, B. Kang, R. Seurinck, and J. Lijffijt, "Revised Conditional t-SNE: Looking Beyond the Nearest Neighbors," in Adv. Intell. Data Anal. XXI, B. Rémilleux, S. Hess, and S. Nijssen, Eds. Cham: Springer Nature Switzerland, 2023, pp. 169-181.

[32] A. Chatzimparmpas, R. M. Martins, and A. Kerren, "tviSNE: Interactive Assessment and Interpretation of t-SNE

Projections," IEEE Trans. Vis. Comput. Graph., vol. 26, no. 8, pp. 2696-2714, aug 2020.

[33] R. R. O. Silva, P. E. Rauber, R. M. Martins, R. Minghim, and A. C. Telea, "Attribute-based Visual Explanation of Multidimensional Projections," in EuroVis Work. Vis. Anal., 2015.

[34] J. Thijssen, Z. Tian, and A. Telea, "Scaling Up the Explanation of Multidimensional Projections," in Int. Work. Vis. Anal., vol. 2023-June, 2023, pp. 61-66.

[35] R. Bian, Y. Xue, L. Zhou, J. Zhang, B. Chen, D. Weiskopf, and Y. Wang, "Implicit Multidimensional Projection of Local Subspaces," IEEE Trans. Vis. Comput. Graph., no. c, pp. 1-1, 2020.

[36] K. Eckelt, A. Hinterreiter, P. Adelberger, C. Walchshofer, V. Dhanoa, C. Humer, M. Heckmann, C. Steinparz, and M. Streit, "Visual Exploration of Relationships and Structure in Low-Dimensional Embeddings," IEEE Trans. Vis. Comput. Graph., vol. 29, no. 7, pp. 3312-3326, jul 2023.

[37] L. McInnes, J. Healy, N. Saul, and L. Grossberger, "Umap: Uniform manifold approximation and projection," The Journal of Open Source Software, vol. 3, no. 29, p. 861, 2018.

[38] L. van der Maaten and G. Hinton, "Visualizing data using t-SNE," J. Mach. Learn. Res., vol. 9, pp. 2579-2625, nov 2008.

[39] F. V. Paulovich and R. Minghim, "Text Map Explorer: A tool to create and explore document maps," Proc. Int. Conf. Inf. Vis., pp. 245-251, 2006.

[40] R. Minghim, F. V. Paulovich, and A. de Andrade Lopes, "Content-based text mapping using multi-dimensional projections for exploration of document collections," Vis. Data Anal. 2006, vol. 6060, no. 0, p. 60600S, 2006.

[41] M. Espadoto, R. M. Martins, A. Kerren, N. S. T. Hirata, and A. C. Telea, "Toward a Quantitative Survey of Dimension Reduction Techniques," IEEE Trans. Vis. Comput. Graph., vol. 27, no. 3, pp. 2153-2173, mar 2021.

[42] A. Narayan, B. Berger, and H. Cho, "Assessing single-cell transcriptomic variability through density-preserving data visualization," Nat. Biotechnol., vol. 39, no. 6, pp. 765-774, jun 2021.

[43] A. Dalmia and S. Sia, "Clustering with UMAP: Why and How Connectivity Matters," 2021.

[44] M. Tariqul Islam and J. W. Fleischer, "Manifold- aligned Neighbor Embedding," arXiv e-prints, no. 0, p. arXiv:2205.11257, 2022.

[45] C. J. Nolet, V. Lafargue, E. Raff, T. Nanditale, T. Oates, J. Zedlewski, and J. Patterson, "Bringing UMAP Closer to the Speed of Light with GPU Acceleration," 35th AAAI Conf. Artif. Intell. AAAI 2021, vol. 1, pp. 418-426, 2021.

[46] D. Kobak and G. C. Linderman, "Initialization is critical for preserving global data structure in both t-SNE and UMAP," Nat. Biotechnol., vol. 39, no. 2, pp. 156-157, 2021.

${ }^{[47]}$ L. J. van 't Veer, H. Dai, M. J. van de Vijver, Y. D. He, A. A. M. Hart, M. Mao, H. L. Peterse, K. van der Kooy, M. J. Marton, A. T. Witteveen, G. J. Schreiber, R. M. Kerkhoven, C. Roberts, P. S. Linsley, R. Bernards, and S. H. Friend, "Gene expression profiling predicts clinical outcome of breast cancer," Nature, vol. 415, no. 6871, pp. 530-536, jan 2002.

[48] M. Schroeder, B. Haibe-Kains, A. Culhane, C. Sotiriou, G. Bontempi, and J. Quackenbush, breastCancerNKI: Genexpression dataset published by van't Veer et al. [2002] and van de Vijver et al. [2002] (NKI)., 2023, r package version 1.40.0.

[49] Datos Abiertos de Castilla y León, "CALIDAD DEL AIRE (POR DÍAS)," https://datosabiertos.jcyl.es/web/jcyl/set/es/ medio-ambiente/calidad_aire_historico/1284212629698. 2012, accessed: 2024-01-22.

[50] J. A. Bednar, J. Crail, I. Thomas, J. Crist-Harif, P. Rudiger, G. Brener, C. B, J. Mease, J. Signell, M. Liquet, J.-L. Stevens, B. Collins, S. H. Hansen, thuydotm, A. Thorve, esc, kbowen, N. Abdennur, O. Smirnov, maihde, A. Hawley, A. Oriekhov, A. Ahmadia, B. A. B. Jr, C. H. Brandt, C. Tolboom, E. G., E. Welch, J. Bourbeau, and J. J. Schmidt, "holoviz/datashader: Version 0.16.0," Oct. 2023. [Online]. Available: https://doi.org/10.5281/zenodo. 10044690

[51] Y. W. R. I. Hu, "Efficient and High Quality Force-Directed Graph Drawing," Math. J., vol. 10, no. 1, pp. 37-71, 2005.

![](https://cdn.mathpix.com/cropped/2024_06_04_818d5e913e5689f4a34ag-11.jpg?height=57&width=884&top_left_y=1538&top_left_x=1084)
"DRGraph: An Efficient Graph Layout Algorithm for Largescale Graphs by Dimensionality Reduction," aug 2020.

[53] F. Zhong, M. Xue, J. Zhang, F. Zhang, R. Ban, O. Deussen, and Y. Wang, "Force-Directed Graph Layouts Revisited: A New Force Based on the T-Distribution," IEEE Trans. Vis. Comput. Graph., pp. 1-14, 2023.


[^0]:    This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.

[^1]:    ${ }^{1}$ https://github.com/vda-lab/lensed_umap

