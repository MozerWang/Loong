# Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning 

Atharva Gundawar ${ }^{* 1}$ Mudit Verma ${ }^{* 1}$ Lin Guan ${ }^{1}$ Karthik Valmeekam ${ }^{1}$ Siddhant Bhambri ${ }^{1}$<br>Subbarao Kambhampati ${ }^{1}$

## 1. Introduction

As the applicability of Large Language Models (LLMs) extends beyond traditional text processing tasks, there is a burgeoning interest in their potential to excel in planning and reasoning assignments, realms traditionally reserved for System 2 cognitive competencies (Kahneman, 2011). Despite their perceived versatility, the research community is still unraveling effective strategies to harness these models in such complex domains. While there are studies showing LLMs are not able to support robust planning (Verma et al., 2024a; Stechly et al., 2024a; Valmeekam et al., 2022; Verma et al., 2024b), there is some consensus that they can help planning in a more integrated architecture (Kambhampati et al., 2024). The recent discourse introduced by the paper on LLM Modulo (Kambhampati et al., 2024) marks a significant stride, proposing a conceptual framework that enhances the integration of LLMs into diverse planning and reasoning activities. Of interest to this paper is to realize the LLM Modulo Framework for a Planning problem. As motivated by (Xie et al., 2024) Travel planning remains a complex domain, involving choices on destinations, accommodations, transport, and activities, which necessitates managing longterm dependencies and logical reasoning. This complexity makes travel planning an ideal domain to assess the reasoning abilities of planners. Utilizing the Travel Planning Benchmark (Xie et al., 2024), we aim to determine if language agents can handle realistic scenarios akin to human operations. Despite advanced techniques like ReAct(Yao et al., 2022) and Chain of Thought(Wei et al., 2022), these models achieve less than $1 \%$ accuracy, compared to humans who score $100 \%$.

The benchmark provides user queries in nautral langauge and an evaluation methodology for validating solution plans / itineraries obtained via LLM agents. In this paper, we will revisit the various abstract components suggested in the LLM-Modulo framework and realize it for the TravelPlanning domain. In this generate-test planning paradigm, the LLMs play several helpful roles such as the generator (to[^0]

generate the plan or travel itinerary), reformulator (or translator, for converting natural language queries to structured output parseable by other components) and critic extraction (to implement model based critics responsible for testing the LLM generated plan and backprompting the LLM for fixing known issues).

While popular methods of enhancing reasoning abilities of LLMs such as Chain of Thought, ReAct, and Reflexion achieve a meager $0 \%, 0.6 \%$, and $0 \%$ with GPT3.5Turbo(OpenAI, 2022) respectively , our operationalization of the LLM-Modulo framework for TravelPlanning domain provides a remarkable improvement, enhancing baseline performances by 4.6x for GPT4-Turbo(OpenAI, 2023) and even more for older models like GPT3.5-Turbo from $0 \%$ to $5 \%$. Furthermore, we highlight the other useful roles of LLMs in the planning pipeline, as suggested in LLMModulo, can be reliably operationalized such as extraction of useful critics and reformulator for critics.

## 2. Background and Setup

### 2.1. Travel Planning domain

The domain provides a sandboxed environment to generate itineraries for travel plan queries simulated using various datasets such as flights, restaurants, distances between locations, available transport options, accommodation choices to name a few. The TravelPlanning domain evaluates generated plans based on hard constraints and commonsense constraints. We use the recommended dataset (validation dataset) with 180 queries for all our experiments. Use of test set requires an official submission to TravelPlanning leaderboard which is left for future work. Furthermore, as a first investigation of LLM-Modulo for TravelPlanning we restrict our discussion to the sole-planning mode which simplifies the objective for the LLMs. In this setting, the domain provides necessary context (that would otherwise be obtained by querying the various datasets) to the LLM instead of expecting the LLM to perform Tool Use (Schick et al., 2024; Paranjape et al., 2023; Hsieh et al., 2023). The top performing models in this simplified mode achieves 4.4\% (GPT-4Turbo) and $0.6 \%$ (across various prompt-engineering tricks with GPT-3.5-Turbo).

Example : A query can be for a 3-day trip from

![](https://cdn.mathpix.com/cropped/2024_06_04_e181bac35ef37e7b8778g-2.jpg?height=632&width=1273&top_left_y=229&top_left_x=383)

Figure 1. LLM Modulo Framework for Travel Planning

Washington to Myrtle Beach for one traveler with a $\$ 1,400$ budget, running from March 13th to 15th, 2022. There are no specific preferences regarding accommodation, cuisine, room type, or transport method. Key attributes captured in each query include the origin city (org: Washington), destination city (dest: Myrtle Beach), trip duration (days: 3), number of cities visited (visiting_city_number: 1), number of travelers (people_number: 1), and no local constraints (local_constraint: none). The (budget: $\$ 1,400$ ) is set to cover all travel expenses, ensuring accurate and efficient travel planning within financial limits.

### 2.2. LLM Modulo

The LLM-Modulo framework introduced by (Kambhampati et al., 2024) establishes a robust iterative interaction between a base generative model, specifically a large language model (LLM), and a suite of external verifiers. These verifiers critically assess the LLM's outputs. Should the output not meet predefined criteria, these external critics provide feedback to the LLM, prompting necessary adjustments. Essentially, the work provides various uses of LLMs in the planning pipeline such as idea-generators, translators, problem specification enrichment, critic/model acquisition to name a few. This work instantiates several abstract roles of LLMs as presented in LLM-Modulo framework specific to the TravelPlanning (Xie et al., 2024) domain.

## 3. Instantiating LLM Modulo for Travel Planning

Our implementation follows the LLM-Modulo architecture presented in (Kambhampati et al., 2024) and the LLMModulo for TravelPlanning can be seen in Fig. 1.

Problem Specification By design the TravelPlanning do- main presents queries that contains all information which maybe required to generate a feasible travel plan, however, the query is in natural language which is a popular mode of interacting with LLMs.

Prompt Generator Consistent with use of LLMs as agents (Wang et al., 2024; Xi et al., 2023; Chang et al., 2024), we provide an instruction prompt the LLM along with the context information about flights, hotels etc. We also provide instructions on the output format of the generated plan and present few shot example. This is directly inherited from the implementation of (Xie et al., 2024).

Plan Backboard and Reformatter We transform the LLM generated natural language travel plan into a valid JSON format and store it in the plan blackboard. This translation is done through the use of LLM as a reformulator and we reuse it for our model based critics which require structured parseable plans.

Crtics All of the critics that we use are binary critics paired with a backprompt describing the issue should the critic detect one. The Format critics ensures the syntactic validity of the plan such as validating the JSON and eliminating any missing key-values which is a precondition for all other critics, therefore takes precedence. We repurpose the commonsense constraints as style critics that provide information about missing implicit preference considerations and finally use the hard-constraints as the remainder of the critics.

Metacontroller All of the critics evaluate a generated plan and incase any of the critics find issues with the generated plan the metacontroller takes on the control flow. It contains the decision-making logic to stich together the critic responses, choose which backprompts to allow for (if a certain pedagogical prompting is in effect) or other consolidation of various backprompts. The metacontroller interfaces with the LLM and makes use of the Prompt Generator to contain

| Model | Delivery <br> Rate | Commonsense <br> Pass Rate |  | Hard <br> Pass Rate |  | Final Pass <br> Rate |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  | Micro | Macro | Micro | Macro |  |
| Direct $\mathrm{GPT}-3.5-$ Turbo | 99.4 | 61.5 | 3.9 | 11.2 | 2.8 | 0.0 |
| Direct GPT-4-Turbo | 100 | 84.9 | 25.6 | 51.9 | 24.4 | 4.4 |
| CoT $_{\text {GPT-3.5-Turbo }}$ | 100 | 66.3 | 3.3 | 11.9 | 5 | 0 |
| $\operatorname{ReAct}_{\mathrm{GPT}-3.5-\text { Turbo }}$ | 82.2 | 47.6 | 3.9 | 11.4 | 6.7 | 0.6 |
| ![](https://cdn.mathpix.com/cropped/2024_06_04_e181bac35ef37e7b8778g-3.jpg?height=50&width=586&top_left_y=545&top_left_x=293) | 93.9 | 53.8 | 2.8 | 11 | 2.8 | 0 |
| LLM Modulo $[\text { All] }]_{\mathrm{GPT}-3.5-\text { Turbo }}$ | 97.8 | 59.8 | 13.3 | 14 | 6.7 | 5 |
| LLM Modulo $[\text { Common }]_{\mathrm{GPT}-3.5-\text { Turbo }}$ | 100 | 67.9 | 16.7 | 14 | 5 | 2.8 |
| LLM Modulo $[\text { Hard }]_{\mathrm{GPT}-3.5-\text { Turbo }}$ | 100 | 61.3 | 4.4 | 10.7 | 5.6 | 1.6 |
| LLM Modulo $[\text { Json }]_{\mathrm{GPT}}-3.5$-Turbo | 100 | 61.3 | 4.4 | 10.2 | 3.9 | 1.1 |
| LLM Modulo $[\text { All }]_{\mathrm{GPT}-4-\text { Turbo }}$ | 100 | 89.2 | 40.6 | 62.1 | 39.4 | 20.6 |

Table 1. We report the results on TravelPlanning Validation set following (Xie et al., 2024). Grayed out results on CoT / ReAct / Reflexion

![](https://cdn.mathpix.com/cropped/2024_06_04_e181bac35ef37e7b8778g-3.jpg?height=35&width=1697&top_left_y=882&top_left_x=187)
LLM Modulo $[\mathrm{Crtic}]_{\mathcal{M}}$ represents the critics used during the LLM-Modulo planning with model $\mathcal{M}$. Values are percentages of delivery rate, micro and macro commonsense and hard constraints and finally, success rate defined as Final Pass Rate as in (Xie et al., 2024).

other information such as instructions, database context, formatting and few shot examples along with the compiled backprompt. In this work we concatenate the backprompts from all the critics and add it to the initial prompt and provide it to the LLM.

The interaction loop in LLM Modulo continues uptill a specificed maximum budget (set to 10 iterations) or until all of the critics agree to the generated plan. Building on this integration, the use of critics within the Modulo framework illustrates that similar evaluative mechanisms can be effectively utilized across different datasets by converting traditional evaluation constraints into critics, enhancing output precision and adaptability. Moreover, the employment of a rudimentary metacontroller highlights the substantial potential for advancement. The current approach, which aggregates and reiterates critic responses, is simple yet effective. Future enhancements could include strategically ordering constraints or providing more targeted and relevant feedback in critic responses, improving the system's efficacy and responsiveness.

## 4. Experiments and Results

The baseline results with GPT-3.5 Turbo model showed a final pass rate of $0 \%$, for both micro and macro pass rates in commonsense and hard constraints being low across 180 queries, indicating that none of the generated plans fully met all constraints. Surprisingly, methods such as Chain of Thought(Wei et al., 2022), ReAct (Yao et al., 2022) and Reflexion(Shinn et al., 2024) provides no improvement. When used with GPT-3.5 Turbo, Chain of Thought and Reflexion exhibit a final pass rate of $0 \%$, while Chain of Thought alone achieves a slightly higher pass rate of $0.6 \%$, indicating suboptimal performance. While improvements from prompt engineering often remain unexplained, the LLM-Modulo framework promises soundness of produced plans consistent with the critics used. Indeed, we find that our LLM Modulo planner with GPT3.5-Turbo (older model) surpasses GPT4Turbo baseline performance (newer model). Consequently we see improved micro/macro pass rates along commonsense and hard constraints. LLM Modulo GPT4-Turbo achieves state of the art performance on TravelPlanning benchmark under the agentic LLM paradigm of using LLMs to generate final plans. We achieve $20.6 \%$ final pass rate compared to $4.4 \%$ baseline. Moreover, such gains are wellfounded and the source of improvement can be attributed to the presence of reliable critics in the planning pipeline.

### 4.1. Ablations

We categorized the critics into three subgroups: Format (which includes checks for valid JSON and the presence of all key-value pairs), Hard (hard constraints), and Commonsense (commonsense constraints). We study the impact of each class of critics on the final performance and other fine-grained metrics such as micro/macro rates. Note that choosing a subset of critics implies that we prevent the LLM from getting pointed feedback on issues in the generated plan as well as allow for suboptimal plans (in that they are guarateed to satisfy only the subset of critics) as final result.

As anticipated, LLM Modulo with a subset of critics underperforms relative to the model that uses all critic types, yet they demonstrated improvements over baselines (Direct ${ }_{\text {Model }}$ ) and CoT/ReAct/Reflexion variants. Utilizing solely the commonsense critics resulted in a final pass rate of $2.8 \%$, while employing just the hard constraints as critics achieved a final pass rate of $1.6 \%$. Solely ensuring the correct format yielded a $1.1 \%$ final pass rate.

We note our results demonstrate the composability of the critics. Compared to [Hard], [Common], or [JSON] variants, the LLM Modulo [All] result is higher micro/macro pass rates across common-sense and hard constraints (with exceptions for delivery rate and common-sense micro pass rate). While providing just the Commonsense critics gave the most improvement, composing it with other critics (Hard, JSON) yields a much higher performance rate. Finally, we see that even thought Direct $_{\text {GPT-4-Turbo }}$ has higher micro/macro pass rates even comparable to LLM Modulo[All] $]_{\text {GPT-4-Turbo }}$, the final pass rate in the case of LLM Modulo is 4.6x higher.

### 4.2. Frequency analysis of Critics

LLMs are known for capturing common-sense information about real world tasks (Stechly et al., 2024a;b; Guan et al., 2024; Kambhampati, 2024; Verma et al., 2024a). Figure 2 shows the number of times a critic was fired (or detected an issue with a generated plan) across all 180 validation set instances and iteration steps in LLM Modulo for GPT3.5-Turbo and GPT4-Turbo models. We find that certain critics more frequent than others since the corresponding issues occur more often. We also find that the format critic (for ensuring JSON correctness) is required more often by GPT3.5-Turbo over GPT4-Turbo and that the LLM Modulo planner is able to resolve format issues in the first few iterations of the budget. The critics that often disagree with the plan are valid_cost, is_valid_accommodation, and is_valid_information, which are generated respectively by Budget, Room Type, and Validate Itinerary. With the knowledge that critics maybe correlated (such as change in accommodation impacts transport and budget) and that only a few critics are the flagged most of the times, future work may take such statistics into account when designing an advanced Metacontroller and identification of points of failure for LLM generated plans.

### 4.3. Recovering critics from LLMs

Previous subsection highlights that only a few critics are flagged most of the times during the LLM Modulo interaction. We argue that LLMs may indeed be useful for extracting the implementation for such critics. This is akin to teasing out the model based critics in the LLM-Modulo frameworks. We prompt the GPT-4-Turbo model to obtain the implementation of the critics by providing it contextual information such as the objective of the critic, available tools or databases with corresponding function declaration (such as flights, etc.) and the input plan as JSON (along with the JSON schema). We do so for common-sense and hard constraint critics. We then compared the generated critics code implementation with the existing ones to evaluate their correctness. Typically, we observe that only minimal modifications were necessary (such as fixing function call signature and syntax which itself can be automated via crit- ics such as compilers and parsers) for the generated critics to match the efficacy of the pre-existing ones. The generated hard critics included: Room Type, Cuisines, Budget, and Transportation. The generated commonsense critics encompassed: Complete Information, Diverse Restaurants, Diverse Attractions, and Validate Itinerary.

![](https://cdn.mathpix.com/cropped/2024_06_04_e181bac35ef37e7b8778g-4.jpg?height=384&width=724&top_left_y=529&top_left_x=1096)

Figure 2. Comparison of Critic Values for GPT 3.5 Turbo and GPT 4 Turbo

![](https://cdn.mathpix.com/cropped/2024_06_04_e181bac35ef37e7b8778g-4.jpg?height=426&width=729&top_left_y=1077&top_left_x=1099)

Figure 3. Final Pass rates of models across LLM Modulo Iterations

## 5. Conclusion

We demonstrate the effective application of the LLM modulo framework within the TravelPlanning domain showcasing a remarkable 4.6x improvement performance for GPT4Turbo achieveing new state of the art on TravelPlanning domain under the agentic LLM paradigm. Our work also validates the framework's robustness in real-world scenarios such as Travel Planning as motivated by (Xie et al., 2024). We showcase that such performance boost is well-founded and easily surpasses predominant ways of enhacing agentic abilities of LLMs such as CoT / ReAct and Reflexion. We do so by allowing critics to be part of the LLM-Modulo based planning pipeline. We also showcase that such critics may also be extracted through the LLMs (LLMs working towards teasing out model-based critics / verifiers). Finally, we showcase the LLMs use as a reformualor to translate natural language plans to a structured representation (JSON) that can be easily used by the critics. Along our discussion, we also point out potential next steps beyond our first investigation to further improve agentic LLM performance.

## References

Chang, Y., Wang, X., Wang, J., Wu, Y., Yang, L., Zhu, K., Chen, H., Yi, X., Wang, C., Wang, Y., et al. A survey on evaluation of large language models. ACM Transactions on Intelligent Systems and Technology, 15(3):1-45, 2024.

Guan, L., Zhou, Y., Liu, D., Zha, Y., Amor, H. B., and Kambhampati, S. "task success" is not enough: Investigating the use of video-language models as behavior critics for catching undesirable agent behaviors, 2024.

Hsieh, C.-Y., Chen, S.-A., Li, C.-L., Fujii, Y., Ratner, A., Lee, C.-Y., Krishna, R., and Pfister, T. Tool documentation enables zero-shot tool-usage with large language models. arXiv preprint arXiv:2308.00675, 2023.

Kahneman, D. Thinking, fast and slow. macmillan, 2011.

Kambhampati, S. Can large language models reason and plan? Annals of the New York Academy of Sciences, 1534 (1):15-18, 2024.

Kambhampati, S., Valmeekam, K., Guan, L., Stechly, K., Verma, M., Bhambri, S., Saldyt, L., and Murthy, A. Llms can't plan, but can help planning in llm-modulo frameworks, 2024.

OpenAI. Gpt-3.5: Language model, 2022. https : / / www . openai.com.

OpenAI. Gpt-4: Language model, 2023. https: / /www . openai.com.

Paranjape, B., Lundberg, S., Singh, S., Hajishirzi, H., Zettlemoyer, L., and Ribeiro, M. T. Art: Automatic multi-step reasoning and tool-use for large language models. arXiv preprint arXiv:2303.09014, 2023.

Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Hambro, E., Zettlemoyer, L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems, 36, 2024.

Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and Yao, S. Reflexion: Language agents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.

Stechly, K., Valmeekam, K., and Kambhampati, S. Chain of thoughtlessness: An analysis of cot in planning, 2024a.

Stechly, K., Valmeekam, K., and Kambhampati, S. On the self-verification limitations of large language models on reasoning and planning tasks, 2024b.
Valmeekam, K., Olmo, A., Sreedharan, S., and Kambhampati, S. Large language models still can't plan (a benchmark for llms on planning and reasoning about change). arXiv preprint arXiv:2206.10498, 2022.

Verma, M., Bhambri, S., and Kambhampati, S. Theory of mind abilities of large language models in human-robot interaction: An illusion? In Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction, HRI '24. ACM, March 2024a. doi: 10.1145/ 3610978.3640767. URL http://dx.doi.org/10. $1145 / 3610978.3640767$.

Verma, M., Bhambri, S., and Kambhampati, S. Theory of mind abilities of large language models in human-robot interaction: An illusion? In Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction, pp. 36-45, 2024b.

Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et al. A survey on large language model based autonomous agents. Frontiers of Computer Science, 18(6):1-26, 2024.

Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824-24837, 2022.

Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., Zhou, E., et al. The rise and potential of large language model based agents: A survey. arXiv preprint arXiv:2309.07864, 2023.

Xie, J., Zhang, K., Chen, J., Zhu, T., Lou, R., Tian, Y., Xiao, Y., and Su, Y. Travelplanner: A benchmark for real-world planning with language agents. arXiv preprint arXiv:2402.01622, 2024.

Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022.
