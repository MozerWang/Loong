# Efficient Algorithms for Densest Subgraph Discovery 

\author{
Yixiang Fang ${ }^{\circledR \dagger \star}$, Kaiqiang Yu ${ }^{\ddagger}$, Reynold Cheng ${ }^{\ddagger}$, Laks V.S. Lakshmanan ${ }^{\S}$, Xuemin Lin ${ }^{\dagger \star}$ <br> ${ }^{9}$ Guangzhou University, China, ${ }^{\dagger}$ The University of New South Wales, Australia, *Zhejiang Lab, China,

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-01.jpg?height=49&width=1266&top_left_y=474&top_left_x=424)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-01.jpg?height=62&width=1589&top_left_y=522&top_left_x=260)


#### Abstract

Densest subgraph discovery (DSD) is a fundamental problem in graph mining. It has been studied for decades, and is widely used in various areas, including network science, biological analysis, and graph databases. Given a graph $G$, DSD aims to find a subgraph $D$ of $G$ with the highest density (e.g., the number of edges over the number of vertices in $D$ ). Because DSD is difficult to solve, we propose a new solution paradigm in this paper. Our main observation is that the densest subgraph can be accurately found through a $k$-core (a kind of dense subgraph of $G$ ), with theoretical guarantees. Based on this intuition, we develop efficient exact and approximation solutions for DSD. Moreover, our solutions are able to find the densest subgraphs for a wide range of graph density definitions, including clique-based- and general pattern-based density. We have performed extensive experimental evaluation on both real and synthetic datasets. Our results show that our algorithms are up to four orders of magnitude faster than existing approaches.


## PVLDB Reference Format:

Yixiang Fang, Kaiqiang Yu, Reynold Cheng, Laks V.S. Lakshmanan, Xuemin Lin. Efficient Algorithms for Densest Subgraph Discovery. PVLDB, 12(11): 1719 - 1732, 2019

DOI: https://doi.org/10.14778/3342263.3342645

## 1. INTRODUCTION

Given a graph $G$ with $n$ vertices and $m$ edges, the densest subgraph discovery (DSD) is the problem of discovering a "dense" subgraph from $G$ 11 66 28 14]. For example, the densest subgraph of Figure 1 a) is $S_{1}$, because its edge-density, or the average number of edges over the number of vertices in $S_{1}$, is the highest among all possible subgraphs of $G$. The DSD problem is fundamental to graph mining [31], and is widely used in network science, biological analysis, graph databases, and system optimization. In network science, for instance, the densest subgroups discovered can be used to find "cohesive groups" in social networks, for purposes of community detection [11 66. In biology, as another example, bioinformatics researchers have studied the use of DSD in identifying regulatory motifs in genomic DNA [28] and gene annotation graphs [55]. In graph databases, the DSD is a building block for many graph algorithms, such as creating elegant index structures for reachability and distance queries [14 41] and supporting graph visualization [71 72]. In system optimization, DSD has been used

This work is licensed under the Creative Commons AttributionNonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For any use beyond those covered by this license, obtain permission by emailing info@ vldb.org. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment.

Proceedings of the VLDB Endowment, Vol. 12, No. 11

ISSN 2150-8097.

DOI: https://doi.org/10.14778/3342263.3342645

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-01.jpg?height=228&width=463&top_left_y=702&top_left_x=1102)

(a) An example graph

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-01.jpg?height=211&width=206&top_left_y=716&top_left_x=1643)

(b) Cliques and pattern
Figure 1: Illustrating the densest subgraphs.

in social piggybacking [30 31], which can be used to improve the throughput of social networking systems (e.g., Facebook).

At present, two variants of DSD have been proposed. The first problem is to find the subgraph with the highest edge-density in $G$. In Figure 1 a), for example, $S_{1}$ has the highest edge-density of 11/7 among all possible subgraphs of $G$. Recently, researchers have studied DSD by defining density based on $h$-clique, which is a complete graph of $h$ vertices, with $h \geq 2$. Figure 1 (b) shows a 3-clique (or "triangle") and a 4-clique. The goal of DSD is then to find the subgraph of $G$ that has the highest $h$-clique-density [65, 49], or the average number of $h$-cliques that a vertex participates in. In Figure 1)a), subgraph $S_{2}$ has the highest "3-clique-density", in terms of number of triangles. The DSD problem, based on clique-density, can be used for detecting larger near-cliques [65, 49] (which can be used for communication network analysis and automatic test pattern generation [1]). The triangle-based densest subgraphs are useful for finding research groups in the DBLP network and clusters in senators' network on US bill voting [65], and discovering compact dense subgraphs from networks [57]. Note that an edge is a 2-clique, so edge-density is the 2-clique-density.

Our main goal is to solve the DSD problem with respect to edgeand clique- densities. This problem is technically challenging 32 65. 10. 72]. Existing DSD solutions, which often involve solving the maximum flow problem, are computationally expensive. For example, given a graph $G$ with $n$ vertices and $m$ edges, a wellknown algorithm based on edge-density $[32]$ may incur a time complexity of $\mathcal{O}\left(\left(m n+m^{3}\right) \log n\right)$, and is thus impractical for very large graphs. The $h$-clique-based DSD problem is even more complex [65 49]. Moreover, our experiments show that existing DSD solutions cannot handle large graphs very well, and there is considerable room for developing faster solutions.

In this paper, our goal is to develop efficient algorithms for finding the subgraph with the highest edge- and $h$-clique-density. We leverage the $k$-core [62], or the largest subgraph of graph $G$, where each vertex has at least $k$ neighbors. We show that the densest subgraph (in terms of edge-density) is located in some $k$-cores, which are often much smaller than the entire graph $G$. For example, in Figure 1 a), the subgraph $S_{1}$ is the 3 -core, which is also the densest subgraph of $G$, w.r.t. edge-density. To solve DSD w.r.t. $h$-cliquedensity, we extend the $k$-core to the $k$-clique-core, or $(k, \Psi)$-core, which incorporates an $h$-clique $\Psi$ into the $k$-core definition. Based
on the cores, we develop efficient exact and approximation algorithms for finding the subgraphs with the highest edge-density and $h$-clique-density. Notably, this "core-based solution" achieves the same approximation ratio as the current state-of-the-art.

It is non-trivial to use $(k, \Psi)$-core to solve the DSD problem. Here we give an outline of this process. We denote by $k$ the core number. We first derive the lower and upper bounds on the $h$ clique-density for each $(k, \Psi)$-core. Based on these tight bounds, we can compute the upper and lower bounds of $\rho_{o p t}$, which is the density of the densest subgraph, and further locate the densest subgraph w.r.t. an $h$-clique in some specific $(k, \Psi)$-cores. These ( $k$, $\Psi)$-cores are often much smaller than the entire graph $G$, and thus we can directly compute the densest subgraph from these small cores, resulting in high efficiency.

Specifically, to compute the exact densest subgraph $D$, we first locate $D$ in a specific ( $k, \Psi)$-core. Then, we build a flow network on this core, and find $D$ by solving the maximum flow problem using binary search. During the binary search, whenever we obtain a larger lower bound of $\rho_{\text {opt }}$, we can further locate $D$ in another core with higher core number and build an even smaller flow network to compute $D$. The binary search process stops when we have found $D$. We further show that the $\left(k_{\max }, \Psi\right)$-core, which is a $(k, \Psi)$-core with $k$ attaining the maximum value, is a good approximation to the densest subgraph, with theoretical guarantees. To find the $\left(k_{\max }, \Psi\right)$-core, a straightforward method is to perform core decomposition, which computes all the $(k, \Psi)$-cores in an incremental manner. This is costly and unnecessary because we only need the $\left(k_{\max }, \Psi\right)$-core, rather than all the $(k, \Psi)$-cores. We thus develop another efficient method that extracts the $\left(k_{\max }, \Psi\right)$-core without computing all the $(k, \Psi)$-cores. This solution finds the ( $\left.k_{\max }, \Psi\right)$-core from a set of small subgraphs induced by vertices with high degrees, and thus yields better performance.

In addition, we generalize the notion of density to allow arbitrary "pattern graphs" (e.g., the diamond pattern in Figure 1.b)), and propose pattern-density to measure the average number of patterns in which a vertex participates. We further extend $k$-clique-core to $k$ pattern-core, and show that our solutions above can be smoothly adapted to finding the densest subgraph w.r.t. pattern-density.

We have performed extensive experiments to evaluate our approaches. On both real and synthetic graph datasets ranging from a few thousand to millions of vertices and edges, our new solutions show high efficiency. For example, our core-based exact algorithm, namely CoreExact, is up to four orders of magnitude faster than the state-of-the-art exact DSD solution. Our best approximation algorithm, called CoreApp, is up to two orders of magnitude faster than the existing approximation solution. We further perform experiments to find pattern-based densest subgraphs and our results again confirm the superiority of our core-based approaches.

Contributions. In summary, our main contributions are:

- We present a new perspective on solving the DSD problem. Particularly, we propose the $(k, \Psi)$-core by incorporating an $h$-clique $\Psi$ where $h \geq 2$ (Section 5). We further establish the lower and upper bounds of densities for $(k, \Psi)$-cores.
- Based on the $(k, \Psi)$-cores, we develop fast exact and approximation DSD algorithms w.r.t. $h$-clique-density (Section 6.
- We generalize $h$-clique-density to pattern-density and adapt our solutions to solving DSD w.r.t. pattern-density (Section 7 .
- We conduct extensive experiments on ten real datasets and three synthetic datasets to evaluate our algorithms. The results reveal that our proposed DSD algorithms are several orders of magnitude faster than existing ones (Section 8 .

Organization. We review the related work in Section 2 The DSD problem is stated in Section 3 In Sections 4-6 we present different DSD solutions. In Section 7, we extend our algorithms for finding densest subgraphs for general patterns. We report experimental results in Section 8 and conclude in Section 9 Due to space limitation, for some lemmas, we do not show the complete proof in this paper; instead, we give the proof sketch and show the complete proof in the technical report 27 .

## 2. RELATED WORK

The problem of dense subgraph computation has been extensively studied [31, 56, 11, 66]. In the following, we review existing works that are highly related to our DSD problem.

Edge-based Densest Subgraph (EDS). The edge-density of an undirected graph $G(V, E)$ is defined as $\frac{m}{n}$ with $n=|V|$ and $m=|E|$. The EDS problem aims to find a subgraph such that its edge-density is the highest among all subgraphs. This problem can be addressed by solving a parametric maximum-flow problem [32. 29]. A typical variant of EDS is to impose a size restriction on the returned subgraph, i.e., finding a subgraph of up to a given number of vertices whose density is the highest. This problem is NP-hard [5, 4]. Another version of EDS, called optimal quasi-clique [66], extracts a subgraph, which is more compact, with a smaller diameter than the EDS. Again, this variant is NP-hard [9]. Qin et al. developed solutions for finding the top- $k$ locally densest subgraphs [54]. The EDS problem on evolving graphs is studied in [19|. In [64 18], the edgedensity-based graph decomposition is extensively studied. Kannan and Vinay [43] modeled the density on directed graphs, and then studied the $\widehat{\mathrm{DSD}}$ problem on directed graphs [10].

In general, exact EDS solutions work well for small graphs, but they perform poorly for large graphs. Thus, researchers have developed approximation algorithms, in order to achieve higher efficiency. In [10], Charikar et al. proposed a greedy 0.5 -approximation algorithm for solving the EDS problem. Bahmani et al. [6] devised a $1 /(2+2 \varepsilon)$-approximation algorithm under the streaming model, which takes $\mathcal{O}\left(m \frac{\log (n)}{\varepsilon}\right)$ time. The densest subgraph on directed graphs can also be computed by an approximation algorithm [44].

Our solution is based on computing $k$-cores, which can then be used to find the EDS. Based on this intuition, we have developed exact and approximation algorithms, and show using extensive experiments that they are much faster than existing EDS solutions.

$h$-clique Densest Subgraph (CDS). In [65, 49], Tsourakakis et al. modeled graph density based on $h$-cliques, and studied the $h$ clique densest subgraph (CDS) problem. It generalizes the EDS problem, which is a special case of CDS for $h=2$. They found that the 3-clique densest subgraphs (a 3-clique is a triangle) help identify cohesive researcher groups in a bibliographical network, as well as clusters of republicans in the network of US senators. Recently, a variant based on the 3-clique, called top- $k$ local triangledensest subgraphs discovery, has been investigated [57].

There are four key differences between existing works [65, 49] and our work. (1) Our algorithms, based on $(k, \Psi)$-cores where $\Psi$ is an $h$-clique, are substantially different from existing CDS solutions. (2) Whereas [65, 49] can only handle $h$-cliques, our work supports any general pattern (e.g., 4-vertex subgraph [40, 68]). (3) The approximation algorithm in [49] is a randomized algorithm which has a failure probability to obtain an approximation solution, while our core-based approximation algorithms are deterministic algorithms. (4) Our empirical evaluation shows that our algorithms significantly outperform previous exact algorithms [65, 49] and deterministic approximation algorithm [65].

Other Dense Subgraphs. Recently, many other dense subgraph models [24], such as $k$-core [7, 47, 51, 23, 22, 20, 25, 26, 67 12], $k$-truss [15, 37, 69, 39, 38, $k$ - $(r, s)$ nucleus [60, 58, 61, 59] (a generalization of $k$-core and $k$-truss), $k$-clique [16 34], $k$-edge connected components [35, 36]. and $k$-plexes |63|, have also been explored. However, these dense subgraphs are different from EDS and CDS, which attain the highest edge-density and clique-density.

## 3. PROBLEM DEFINITION

Data model. In this paper, we consider an undirected, unweighted, and simple graph $G(V, E)$ with vertex set $V$ and edge set $E$, where $n=|V|$ and $m=|E|$. The degree of a vertex $v$ in $G$, denoted by $\operatorname{deg}_{G}(v)$, is the number of its neighbors, and we denote the maximum degree by $d$. Table 1 summarizes all the notations frequently used in this paper. Next, we first introduce two prominent notions of density that were employed in the DSD literature, namely edgedensity and $h$-clique-density.

DEFinition 1 (Edge-dENSity [32, 29]). Given a graph $G$ $(V, E)$, its edge-density is $\tau(G)=\frac{|E|}{|V|}$.

Definition 2 (CliQue instance). Given a graph $G(V, E)$ and an integer $h \geq 2$, we say a set of $h$ vertices, $S \in V$, is an $h$-clique instance, if each pair of vertices $u, v \in S$ is connected by an edge.

Definition 3 (CliQue-DEGREE). Given a graph $G(V, E)$ and an $h$-clique $\Psi$, the clique-degree of a vertex $v$ in $G$, or $\operatorname{deg}_{G}(v$, $\Psi)$, is the number of clique instances containing $v$.

Note that for each of these instances, we do not consider permutations of vertices. For example, let $\Psi$ be the triangle (i.e., 3clique). Then in Figure 1 a), the subgraph $S_{2}$ contains two clique instances of $\Psi$, which share an edge. The clique-degrees of vertices $A, B$, and $C$ are 2,1 , and 2 respectively.

DEFINITION 4 ( $h$-CLIQUE-DENSITY [65]). Given a graph $G$ ( $V, E)$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$ with $h \geq 2$, the $h$-clique-density of $G$ w.r.t. $\Psi$ is

$$
\begin{equation*}
\rho(G, \Psi)=\frac{\mu(G, \Psi)}{|V|} \tag{1}
\end{equation*}
$$

where $\mu(G, \Psi)$ is the number of clique instances of $\Psi$ in $G$.

The densest subgraph of $G$ w.r.t. edge-density (resp., $h$-cliquedensity), i.e., $E D S$ [32] (resp., $C D S$ [65, 49]), is the subgraph $D=$ ( $V_{D}, E_{D}$ ) of $G$ whose edge-density (resp., $h$-clique-density) is the highest. Clearly, if the $h$-clique is a single edge (i.e., $h=2$ ), the $h$ clique-density reduces to edge-density. For ease of exposition, in the following we simply focus on the $h$-clique-density with $h \geq 2$. We use the term CDS when we refer to the DSD problem using the edge-, or $h$-clique-based density. Where necessary, we make the distinction between EDS and CDS.

Now we formally introduce the problem studied in this paper.

PRoblem 1 (CDS PRoblem [65, 49]). Given a graph $G(V$ $, E)$ and an h-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)(h \geq 2)$, return the subgraph $D$ of $G(V, E)$, whose $h$-clique-density $\rho(D, \Psi)$ is the highest.

We denote the $h$-clique-density of $D$ by $\rho_{o p t}$, i.e., $\rho_{\text {opt }}=\rho(D, \Psi)$, where $D$ is the CDS. For the graph $G$ of Figure 1 (a), if we let $\Psi$ be the single edge, we will return $S_{1}$ as the densest subgraph; if we let $\Psi$ be the 3 -clique (i.e., triangle), then, $S_{2}$ is the subgraph with the highest 3-clique-density.

## 4. EXISTING APPROACHES

In this section, we review existing algorithms for the EDS and CDS problems, and then discuss their limitations.

### 4.1 The Exact Method

Generally, the algorithms for finding exact EDS and CDS [32. 65. 49] follow the same framework by solving a maximum flow problem using binary search. A flow network [33] is a directed graph $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$, where there is a source node $s$, a sink node[^0]

Table 1: Notations and meanings.

| Notation | Meaning |
| :---: | :--- |
| $G(V, E)$ | a graph with vertex set $V$ and edge set $E$ |
| $n, m$ | $n=\|V\|, m=\|E\|$ |
| $d e g_{G}(v)$ | (classical edge-based) degree of vertex $v$ in $G$ |
| $d$ | the maximum (classical edge-based) degree of $G$ |
| $G[T]$ | a subgraph of $G$ induced by vertex set $T$ |
| $\Psi\left(V_{\Psi}, E_{\Psi}\right)$ | an $h$-clique (vertex set: $V_{\Psi}$, edge set $\left.E_{\Psi}\right)$ |
| $d e g_{G}(v, \Psi)$ | clique-degree of vertex $v$ in $G$ w.r.t. $\Psi$ |
| $\mu(S, \Psi)$ | number of clique instances of $\Psi$ in the graph $S$ |
| $\rho(G, \Psi)$ | $h$-clique-density of graph $G$ w.r.t. an $h$-clique $\Psi$ |
| $D\left(V_{D}, E_{D}\right)$ | the CDS whose $h$-clique-density is $\rho_{o p t}$ |
| $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$ | a flow network with node set $V_{\mathcal{F}}$ and edge set $E_{\mathcal{F}}$ |

$t$, and some intermediate nodes; each edge has a capacity and the amount of flow on an edge cannot exceed the capacity of the edge. The maximum flow of a flow network equals the capacity of its minimum st-cut, $(\mathcal{S}, \mathcal{T})$, which partitions the node set $V_{\mathcal{F}}$ into two disjoint sets, $\mathcal{S}$ and $\mathcal{T}$, such that $s \in \mathcal{S}$ and $t \in \mathcal{T}$.

```
Algorithm 1: The algorithm: Exact.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: The $\operatorname{CDS} D\left(V_{D}, E_{D}\right)$;
    initialize $l \leftarrow 0, u \leftarrow \max _{v \in V} \operatorname{deg}_{G}(v, \Psi)$;
    initialize $\Lambda \leftarrow$ all the instances of $(h-1)$-clique in $G, D \leftarrow \emptyset$;
    while $u-l \geq \frac{1}{n(n-1)}$ do
        $\alpha \leftarrow \frac{l+u}{2} ;$
        $V_{\mathcal{F}} \leftarrow\{s\} \cup V \cup \Lambda \cup\{t\} ; \quad / /$ build a flow network
        for each vertex $v \in V$ do
            add an edge $s \rightarrow v$ with capacity $\operatorname{deg}_{G}(v, \Psi)$;
            add an edge $v \rightarrow t$ with capacity $\alpha\left|V_{\Psi}\right|$;
        for each ( $h-1$ )-clique $\psi \in \Lambda$ do
            for each vertex $v \in \psi$ do
                add an edge $\psi \rightarrow v$ with capacity $+\infty$;
        for each (h-1)-clique $\psi \in \Lambda$ do
            for each vertex $v \in V$ do
                    if $\psi$ and $v$ form an $h$-clique then
                        $L$ add an edge $v \rightarrow \psi$ with capacity 1 ;
        find minimum st-cut $(\mathcal{S}, \mathcal{T})$ from the flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
        if $\mathcal{S}=\{s\}$ then $u \leftarrow \alpha$
        else $\quad l \leftarrow \alpha, D \leftarrow$ the subgraph induced by $\mathcal{S} \backslash\{s\}$;
    return $D$
```

We present the state-of-the-art algorithm from [49] in Algorithm 1 where the input is a graph $G$ and an $h$-clique $\Psi$. First, it initializes lower and upper bounds of $\rho_{\text {opt }}$ and collects all the instances of ( $h-1$ )-clique (lines 1-2). Then, it finds $D$ by using binary search (lines 3-18). Specifically, in each binary search (lines 4-18), it tries to find a subgraph with density larger than a guessed value $\alpha$, by computing the minimum st-cut using Gusfield's algorithm [2] in a flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$. To build $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$, it first creates a node set $V_{\mathcal{F}}$ (line 5 ), and then links its nodes by directed edges with different capacities (lines 6-15). The binary search stops when the gap between the upper and lower bounds of $\alpha$ is less than $\frac{1}{n(n-1)}$. We denote this algorithm by Exact.

Note that if $\Psi$ is the single edge, the flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$ can be simplified such that |32|: $V_{\mathcal{F}}=\{s\} \cup V \cup\{t\}$, and for each vertex $v \in G$, there is a directed edge from $s$ to $v$ with capacity $m$ and a directed edge from $v$ to $t$ with capacity $m+2 \alpha$-degG $(v)$; for each edge $(v, u) \in G$, there is a directed edge from $u$ to $v$ with capacity 1 and a directed edge from $v$ to $u$ with capacity 1 .

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-04.jpg?height=193&width=177&top_left_y=169&top_left_x=234)

(a) graph

$\Psi_{1} \mathrm{~A} \bullet \mathrm{B}$
$\Psi_{2} \mathrm{~B} \longrightarrow \mathrm{C}$
$\Psi_{3} \mathrm{~B} \longrightarrow \longrightarrow$

(b) 2-cliques

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-04.jpg?height=399&width=751&top_left_y=169&top_left_x=226)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-04.jpg?height=364&width=482&top_left_y=173&top_left_x=491)

(c) the flow network
Figure 2: Illustrating the flow network ( $\Psi$ is a triangle).

EXAMPLE 1. Let $\Psi$ be the triangle and $G$ be the graph in Figure 2.a). The graph contains 4 edges (see Figure 2b)). By Algorithm1. we construct the flow network, as depicted in Figure 2.c), where the value on each edge denotes its capacity.

LEMMA 1. Given a graph $G(V, E)$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, Exact takes $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}+\left(n|\Lambda|+\min (n,|\Lambda|)^{3}\right) \log n\right)$ time and $\mathcal{O}(n+|\Lambda|)$ space, where $\Lambda$ is set of $(h-1)$-clique instances in $G[65$.

PROOF SKETCH: In the worst case, we will consider $n \cdot\binom{d-1}{h-1}$ $h$-clique instances, and each binary search of Exact takes $\mathcal{O}(n$. $\left.|\Lambda|+\min (n,|\Lambda|)^{3}\right)$ time. These are the main cost of Exact.

In practice, $h$ is often small and the number of clique instances, $|\Lambda|$, is often much larger than the number $n$ of vertices, so the second summand dominates the overall computational cost.

### 4.2 The Approximation Method

The approximation method of computing the EDS [10] and CDS [65] follows the peeling paradigm and achieves an approximation ratio of $\frac{1}{\left|V_{\Psi}\right|}$. Here, the approximation ratio is the ratio of the $h$ clique-density of subgraph returned, over $\rho_{\text {opt }}$, which is at most 1.0. Specifically, given a graph $G$ of $n$ vertices, it works in $n$ rounds. In each round, it removes the vertex that participates in the minimum number of $h$-cliques, and recomputes the density of the residual graph. Finally, the subgraph of the largest $h$-cliquedensity is returned. Algorithm 2 outlines the steps. Because the algorithm removes vertices one by one, we call it PeelApp.

```
Algorithm 2: The algorithm: PeelApp.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: A subgraph $S^{*}$;
    initialize $S \leftarrow G, S^{*} \leftarrow \emptyset$;
    compute the clique-degree for each vertex of $G$;
    while $S \neq \emptyset$ do
        $v \leftarrow$ the vertex with the minimum clique-degree in $S$;
        $S \leftarrow$ remove the vertex $v$ from $S$;
        if $\rho(S, \Psi)>\rho\left(S^{*}, \Psi\right)$ then $S^{*} \leftarrow S$;
    return $S^{*}$;
```

LEMMA 2. Given a graph $G$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, then PeelApp takes $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}\right)$ time and $\mathcal{O}(m)$ space [65].

PROOF SKETCH: The main time cost comes from enumerating clique instances, whose number is $n \cdot\binom{d-1}{h-1}$ in the worst case.

### 4.3 Limitations of Existing Methods

From the above lemmas, we see that while PeelApp is faster than Exact, it also sacrifices some accuracy. For example, when $\Psi$ is an edge, Exact finds the exact EDS in $\mathcal{O}\left(\left(m n+m^{3}\right) \log n\right)$ time, while PeelApp returns a subgraph with 0.5 -approximation ratio in linear time, i.e., $\mathcal{O}(m)$. Both solutions can be inefficient on larger graphs with more complex cliques. We found that Exact suffers from several problems: (1) the initial lower and upper bounds of $\alpha$ are not very tight; (2) the size of the flow network can be large when the graph is large and there are many clique instances of $\Psi$; and (3) the flow network $\mathcal{F}$ is always built on the entire graph $G$ in each iteration, while the CDS is often in a small subgraph of $G$. The PeelApp algorithm also involves a lot of unnecessary computation: for the first few iterations, the graph contains many vertices with lower clique-degrees, which are unlikely to be in the CDS, but PeelApp still computes the $h$-clique-density. As shown in our experiments later, on a moderate-size graph ( $n \approx 26 \mathrm{~K}$ and $m \approx 100 \mathrm{~K})$, Exact takes more than 5 days to find the densest subgraphs for 6-clique; on a million-scale graph ( $n \approx 19 \mathrm{M}$ and $m \approx 298 \mathrm{M})$, PeelApp takes more than 2 days to find the CDS for 6-clique. Thus, there is room for improving their efficiency.

We next propose a core-based approach for locating a CDS, by quickly converging on smaller dense subgraphs that contain the CDS. To make our approach applicable for processing all the $h$ clique-density definitions $(h \geq 2)$, we lift the notion of $k$-cores to $k$ clique-cores and study how to exploit them in the DSD solution.

## 5. THE CLIQUE-BASED CORES

We now study the $k$-clique-core, or $(k, \Psi)$-core, which is a generalization of the classical $k$-core 62 7] for an $h$-clique $\Psi$ (Section 5.1). As we will show, $(k, \Psi)$-cores are useful in locating the CDS in both exact and approximation algorithms. We then establish upper and lower bounds on the clique-density of $(k, \Psi)$-cores (Section 5.2, present efficient algorithms for decomposing $(k, \Psi)$ cores (Section 5.3, and give some discussions (Section 5.4) .

## $5.1 k$-core and $(k, \Psi)$-core

We first review the definition of $k$-core.

DEFINITION 5 ( $k$-CORE [62, 7]). Given a graph $G$ and an integer $k(k \geq 0)$, the $k$-core, denoted by $\mathcal{H}_{k}$, is the largest subgraph of $G$, such that $\forall v \in \mathcal{H}_{k}$, $\operatorname{deg}_{\mathcal{H}_{k}}(v) \geq k$.

We say that $\mathcal{H}_{k}$ has order $k$. The core number of a vertex $v \in$ $V$ is defined as the highest order of a $k$-core that contains $v$. In other words, a $k$-core is the largest subgraph induced by vertices whose core numbers are at least $k$. A $k$-core has some interesting properties |7]: (1) $k$-cores are "nested": given two nonnegative integers $i$ and $j$, if $i<j$, then $\mathcal{H}_{j} \subseteq \mathcal{H}_{i}$; (2) a $k$-core may not be connected; and (3) computing core numbers of all the vertices in a graph, known as $k$-core decomposition, can be done in linear time.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-04.jpg?height=266&width=352&top_left_y=1797&top_left_x=1144)

(a) $k$-cores

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-04.jpg?height=279&width=355&top_left_y=1796&top_left_x=1514)

(b) $(k, \Psi)$-cores
Figure 3: $k$-core, and $(k, \Psi)$-core ( $\Psi$ is a triangle).

EXAMPLE 2. Figure 3. a) depicts a graph of 8 vertices and its $k$ cores. The number $k$ in each ellipse indicates the $k$-core contained in that ellipse. For instance, the subgraph induced by $\{A, B, C$, $D\}$ is the 3 -core, and the entire graph is both the 0 -core and 1-core, which consist of two connected components.

DEFINITION $6 \quad((k, \Psi)$-CORE $)$. Given a graph $G$, an integer $k(k \geq 0)$, and an $h$-clique $\Psi$, the $(k, \Psi)$-core, denoted by $\mathcal{R}_{k}$, is the largest subgraph of $G$ such that $\forall v \in \mathcal{R}_{k}$, $\operatorname{deg}_{\mathcal{R}_{k}}(v, \Psi) \geq k$.

Similar to $k$-cores, we say that $\mathcal{R}_{k}$ has order $k$. The clique-core number of a vertex $v \in V$, core ${ }_{G}(v, \Psi)$, is then the highest order of a $(k, \Psi)$-core containing $v$. We denote the maximum clique-core number by $k_{\max }$, where the underlying clique $\Psi$ is understood from the context. Given a clique $\Psi, \mathrm{a}(k, \Psi)$-core also has the following properties: (1) $(k, \Psi)$-cores are "nested": given two nonnegative integers $i$ and $j$, if $i<j$, then $\mathcal{R}_{j} \subseteq \mathcal{R}_{i}$; (2) a ( $\left.k, \Psi\right)$-core may not be connected; and (3) $\operatorname{core}_{G}(v, \Psi) \leq \operatorname{deg}_{G}(v, \Psi)$.

Example 3. Let $\Psi$ be the triangle. Figure 3 b) shows all ( $k$, $\Psi)$-cores of the graph. The number $k$ in each circle indicates the $(k, \Psi)$-core contained in that ellipse. For instance, the subgraph of $\{A, B, C, D\}$ is the $(3, \Psi)$-core as the 4 -clique contains 4 triangle instances, and each vertex participates in 3 of them. Observe that $k$ cores and $(k, \Psi)$-cores are different between Figures 3 a) and 3 b), for $k=1,2$. Also, the entire graph is a $(0, \Psi)$-core.

### 5.2 Density Bounds of $(k, \Psi)$-core

The main result of this section is on the lower and upper bounds on the density of a $(k, \Psi)$-core.

THEOREM 1. Given a graph $G$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, let $\mathcal{R}_{k}$ be a $(k, \Psi)$-core of $G$. Then, the $h$-clique-density of $\mathcal{R}_{k}$ satisfies

$$
\begin{equation*}
\frac{k}{\left|V_{\Psi}\right|} \leq \rho\left(\mathcal{R}_{k}, \Psi\right) \leq k_{\max } \tag{2}
\end{equation*}
$$

To prove this theorem, we develop the following lemmas.

LEMMA 3. Given a graph $G$ and an $h$-clique $\Psi$, the connected components of CDS D have the same clique-density.

PRoof SKETCH. The lemma can be proved by contradiction.

LemmA 4. Given a graph $G(V, E)$, an h-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, and the CDS $D\left(V_{D}, E_{D}\right)$, for any subset $U$ of $V_{D}$, removing $U$ from $D$ will result in the removal of at least $\rho_{\text {opt }} \times|U|$ clique instances from $D$.

Proof. We prove the lemma by contradiction. Assume that $D$ is the CDS and the removal of $U$ results in removing less than $\rho_{\text {opt }} \times|U|$ clique instances. Then, after removing $U$ from $V_{D}$, the clique-density of the residual graph (denoted by $D \backslash U$ ) becomes:

$$
\begin{equation*}
\rho(D \backslash U, \Psi)=\frac{\mu(D \backslash U, \Psi)}{\left|V_{D}\right|-|U|}>\frac{\rho_{o p t}\left|V_{D}\right|-\rho_{o p t}|U|}{\left|V_{D}\right|-|U|}=\rho_{o p t} \tag{3}
\end{equation*}
$$

However, this contradicts the assumption that $D$ is the CDS. Hence, the lemma holds.

Based on the lemma above, we show an upper bound of $\rho_{\text {opt }}$.

LEMMA 5. Given a graph $G$, an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, and its maximum clique-core number $k_{\max }$, we have:

$$
\begin{equation*}
\rho_{o p t} \leq k_{\max } \tag{4}
\end{equation*}
$$

Proof. We prove the lemma by contradiction. Suppose that we have $\rho_{o p t}>k_{\max }$. From Lemma 4 we know that removing any vertex of $D$ will result in the removal of at least $\rho_{\text {opt }}$ clique instances, or more than $k_{\max }$ clique instances from $D$. In other words, each vertex of $D$ participates in at least $k_{\text {max }}+1$ clique instances. This contradicts the fact that $k_{\max }$ is the maximum clique-core number. Hence, the value of $\rho_{\text {opt }}$ is at most $k_{\max }$.

Proof of Theorem 1 The upper bound follows by Lemma 5 Let us focus on the lower bound. Let $r_{k}$ be the number of vertices in $\mathcal{R}_{k}$. By Definition 6, since $\mathcal{R}_{k}$ is a $(k, \Psi)$-core, each vertex $v$ of $\mathcal{R}_{k}$ participates in at least $k$ clique instances. Meanwhile, each clique instance involves $\left|V_{\Psi}\right|$ vertices. As a result, there are at least $\frac{k \times r_{k}}{\left|V_{\Psi}\right|}$ clique instances in $\mathcal{R}_{k}$. Thus, we have $\rho\left(\mathcal{R}_{k}, \Psi\right) \geq \frac{k}{\left|V_{\Psi}\right|}$.

To further illustrate Theorem 1 we give Example 4

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-05.jpg?height=125&width=672&top_left_y=173&top_left_x=1171)

(b)

Figure 4: Illustrating the lower and upper bounds.

ExAmple 4. Let $\Psi$ be an edge and consider the $k_{\text {max }}$-core with $k_{\max }=2$. By Theorem 1 the lower and upper bounds of the density of $k_{\max }$-core are 1 and 2 respectively. These bounds are attained by graphs in Figures 4 a) and 4 (b) respectively. In Figure 4) a), the density of the $k_{\max }$-core is $4 / 4=1$. In Figure 4 (b), there is a list of graphs with $k_{\max }=2$, and the density values of $k_{\max }$-cores in the 1 st, 2 nd, $\cdots, x$-th graphs are $\frac{1+4}{2+2}, \frac{1+8}{2+4}, \cdots, \frac{1+4 x}{2+2 x}$, respectively. Clearly, when $x \rightarrow \infty$, the density converges to 2 .

## $5.3(k, \Psi)$-core Decomposition

Inspired by the $k$-core decomposition algorithm [7], we develop an efficient $(k, \Psi)$-core decomposition algorithm for computing the clique-core number of each vertex. The algorithm exploits a key observation that, if we recursively remove vertices whose cliquedegrees are less than a non-negative integer $k$, then the remaining graph, if non-empty, must be the $(k, \Psi)$-core.

Specifically, we first compute the clique-degree of each vertex, and sort vertices in increasing order of their clique-degrees. Then, we iteratively remove the vertex $v$ whose clique-degree is the smallest in each iteration, until the graph is empty. In each iteration, after removing $v$, we need to decrease the clique-degrees of vertices, which share clique instances with $v$, and re-sort the vertices. Notice that by using the bin-sort technique [7], sorting all the vertices takes linear time and re-sorting can also be done efficiently.

```
Algorithm 3: $(k, \Psi)$-core decomposition.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: The clique-core number of each vertex;
    1 initialize core []$\leftarrow$ an array with $n$ entries;
    2 for each vertex $v \in V$ do compute its clique-degree $\operatorname{deg}_{G}(v, \Psi)$;
    sort vertices of $V$ in increasing order of their clique-degrees;
    while $V$ is not empty do
        core $[v] \leftarrow \operatorname{deg}_{G}(v, \Psi)$ where $v$ has the minimum clique-degree;
        for each clique instance $\psi$ containing $v$ do
            for each vertex $u$ in $\psi$ do
                if $\operatorname{deg}_{G}(u, \Psi)>\operatorname{deg}_{G}(v, \Psi)$ then
            $L$ decrease $u$ 's clique-degree;
        update $G$ by removing $v$ and its incident edges;
        resort the vertices in $V$;
    return the array core $[$;
```

Algorithm 3 presents the core decomposition algorithm. First, we initialize an array core [ ] and compute the clique-degree of each vertex (lines 1-2). Then, we sort all the vertices in increasing order (line 3). Next, we recursively remove the vertex $v$ whose cliquedegree is the smallest (lines 4-11). In each iteration, we record $v$ 's clique-core number (line 5), decrease the clique-degrees of vertices in $v$ 's clique instances as removing $v$ causes the deletion of some clique instances (lines 6-9), update $G$, and resort vertices (lines 1011). Finally, we return core[] (line 12).

To compute the clique-degrees of all the vertices, we can first run an $h$-clique enumeration algorithm, and then compute the cliquedegree of each vertex by listing all the $h$-cliques. During the core decomposition process, after removing a vertex $v$, we can first locate the subgraph induced by $v$ and its neighbors, then enumerate all the $h$-cliques in this subgraph, and finally decrease the cliquedegrees of the vertices involved. In this paper, we use the state-ofthe-art $h$-clique enumeration algorithm [17].

LEMMA 6. Given a graph $G$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the core decomposition algorithm above completes in $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}\right)$ time and $\mathcal{O}(m)$ space.

Proof. For each vertex $v$, we need to compute the number of clique instances it involves, i.e., $\operatorname{deg}_{G}(v, \Psi)$. In the worst case, any $h-1$ neighbors of $v$ can form an $h$-clique with $v$, so $\operatorname{deg}_{G}(v, \Psi)$ is up to $\binom{d-1}{h-1}$. By using the bin-sort technique in [7], we can sort vertices of $V$ in linear time cost, and resorting after removing a vertex takes linear time cost to the clique-degree. In addition, computing $\operatorname{deg}_{G}(v, \Psi)$ takes $\mathcal{O}(m)$ space as we can compute the clique instances sequentially. Hence, Lemma 6 holds.

### 5.4 Extension and Discussion

The $k$-clique-core can be extended to $k$-pattern-core by incorporating a general pattern (e.g., star, loop, etc.). Let $\Psi$ be a pattern. Then, the $(k, \Psi)$-core is the largest subgraph of $G$, in which each vertex participates in at least $k$ instances of $\Psi$. The properties of $k$-clique-cores also hold for $k$-pattern-core. Besides, for any two patterns $\Psi$ and $\Psi^{\prime}$, if $\left|V_{\Psi}\right|=\left|V_{\Psi^{\prime}}\right|$ and $\Psi \subseteq \Psi^{\prime}$, i.e., $\Psi$ is a subpattern of $\Psi^{\prime}$, then the $\left(k, \Psi^{\prime}\right)$-core is a subgraph of the $(k, \Psi)$-core. Algorithm 3 can also be extended for decomposing $k$-pattern-cores. We skip the details due to the space limitation.

Recently, Sariy√ºce et al. studied the $k-(r, s)$ nucleus [60 58 59], which is the maximal connected subgraph of the $r$-cliques where each $r$-clique is contained in at least $k s$-cliques $(r<s)$. When $\Psi$ is an $h$-clique, our $(k, \Psi)$-core can be considered as a special case of $k-(r, s)$ nucleus, i.e., $k$ - $(1, h)$ nucleus, in terms of clique-degree (or $\mathcal{S}$-degree in [59]). However, when $\Psi$ is a non-clique, $(k, \Psi)$ core is different with the $k-(r, s)$ nucleus, because in our $(k, \Psi)$ core, $\Psi$ can be an arbitrary pattern, such as clique, star, loop, etc., while $k-(r, s)$ nucleus is defined purely based on cliques. In other words, our $(k, \Psi)$-core can capture pattern-based dense subgraphs. A second difference is that a $k-(r, s)$ nucleus requires that any two $r$-cliques $R$ and $R^{\prime}$ are $\mathcal{S}$-connected: i.e., there exists a sequence of $r$-cliques $R=R_{1}, R_{2}, \cdots, R_{l}=R^{\prime}$, such that $R_{i}, R_{i+1}$ are both contained by a specific $s$-clique ( $i \in[1, l-1]$ ). In addition, when $\Psi$ is an $h$-clique, the nucleus decomposition algorithm [59] can be applied to decomposing $(k, \Psi)$-cores. We will experimentally compare this method with ours in Section 8.1

## 6. CORE-BASED APPROACHES

Based on $(k, \Psi)$-cores, we develop efficient exact and approximation DSD algorithms. While our exact algorithm, CoreExact, is significantly faster than the state-of-the-art algorithm (Exact), we can speed it up further by trading accuracy: we develop an efficient approximation algorithm, namely CoreApp, which has an approximation ratio of $\frac{1}{\left|V_{\Psi}\right|}$.

### 6.1 The Core-Based Exact Method

As shown in Lemma 1 the major limitation of Algorithm Exact is its high computational cost. To address this, in this section we exploit the $k$-clique-cores and propose the following three optimization techniques for boosting the efficiency.

1 Tighter bounds on $\alpha$. In Exact, the value of $\alpha$ is within the range $\left[0, \max _{v \in V} \operatorname{deg}_{G}(v, \Psi)\right]$. As discussed in Section 5.2 by using the $(k, \Psi)$-cores, we can derive a tighter bound on $\alpha$. Specifically, consider a $\left(k_{\max }, \Psi\right)$-core $\mathcal{R}_{k_{\max }}$. By Theorem 1 we can see that $\rho\left(\mathcal{R}_{k_{\max }}, \Psi\right) \geq \frac{k_{\max }}{\left|V_{\Psi}\right|}$, which implies that $\rho_{o p t} \geq \frac{k_{\max }}{\left|V_{\Psi}\right|}$, so the lower bound of $\alpha$ is $\frac{k_{\max }}{\left|V_{\Psi}\right|}$. On the other hand, by Lemma 5e have $\rho_{\text {opt }} \leq k_{\max }$ and thus the upper bound of $\alpha$ is $k_{\max }$. In practice, since $\frac{k_{\max }}{\left|V_{\Psi}\right|}$ is larger than 0 and $k_{\max }$ is smaller than the maximum clique-degree, the number of binary searches can be greatly reduced by using the tighter bounds.
2 Locating the CDS in a core. Recall that in each binary search of the algorithm Exact, the flow network is reconstructed based on the entire graph $G$. This, however, is unnecessary, since the CDS is often in some $(k, \Psi)$-cores which could be much smaller than $G$.

LemmA 7. Given a graph $G$ and an h-clique $\Psi$, the CDS is contained in the $(k, \Psi)$-core, where $k=\left\lceil\rho_{\text {opt }}\right\rceil$.

Proof. By Lemma 4 deleting any single vertex from CDS will result in the removal of $\left\lceil\rho_{o p t}\right\rceil$ clique instances in CDS. In other words, each vertex of the CDS has participated in $\left\lceil\rho_{o p t}\right\rceil$ clique instances. By the definition of $(k, \Psi)$-core, we conclude that the CDS is in the $(k, \Psi)$-core, where $k=\left\lceil\rho_{o p t}\right\rceil$.

As the value of $\rho_{\text {opt }}$ may not be known in advance, we can only locate it in the cores using the lower bounds of $\rho_{\text {opt }}$, by exploiting the nested property of cores. For example, by Theorem 1 we have $\rho_{\text {opt }} \geq \frac{k_{\max }}{\left|V_{\Psi}\right|}$, which implies that the CDS must be in the $(k$, $\Psi)$-core, where $k=\left\lceil\frac{k_{\max }}{\left|V_{\Psi}\right|}\right]$. Recall that in the core decomposition process, we delete vertices iteratively and obtain a residual subgraph after removing a vertex. In order to get a tighter lower bound on $\rho_{\text {opt }}$, we can compute the densities of these residual subgraphs.

- Pruning1: The CDS is in the $\left(k^{\prime}, \Psi\right)$-core, where $k^{\prime}=\left\lceil\rho^{\prime}\right\rceil$ and $\rho^{\prime}$ is the highest $h$-clique-density of all residual graphs. The correctness directly follows Lemma 7 . since $\rho^{\prime} \leq \rho_{\text {opt }}$.

Since the $\left(k^{\prime}, \Psi\right)$-core may be disconnected and some connected components may be denser than others, we can further locate the CDS in a core with a larger core number, using Pruning2.

- Pruning2: For each connected component of the $\left(k^{\prime}, \Psi\right)$-core, we compute its $h$-clique-density. Let $\rho^{\prime \prime}$ be the maximum $h$-cliquedensity of these connected components. If $\left\lceil\rho^{\prime \prime}\right\rceil>k^{\prime}$, we increase $k^{\prime}$ to $k^{\prime \prime}=\left\lceil\rho^{\prime \prime}\right\rceil$ and the CDS is in the $\left(k^{\prime \prime}, \Psi\right)$-core. The correctness holds by Lemma 7 since $\rho^{\prime} \leq \rho^{\prime \prime} \leq \rho_{\text {opt }}$.
- Pruning3: After locating the CDS in a connected component $C\left(V_{C}, E_{C}\right)$, we can change the stopping criterion of binary search to " $u-l<\frac{1}{\left|V_{C}\right|\left(\left|V_{C}\right|-1\right)}$ ". Since $C\left(V_{C}, E_{C}\right)$ contains the CDS and the flow network is built using $C\left(V_{C}, E_{C}\right)$, the pruning is correct by following Algorithm 1 .

3 The flow network gradually becomes smaller. During the binary search, since the lower bound $l$ of $\alpha$ is gradually enlarged, we can locate the CDS in cores with larger clique-core numbers. As clique-core numbers increase, the sizes of cores become smaller, so the flow networks constructed become smaller gradually, and the cost of computing the minimum st-cut is greatly reduced.

Combining the three optimization techniques above, we develop an advanced exact algorithm, called CoreExact, as presented in Algorithm 4 We first perform core decomposition and locate the CDS in the ( $\left.k^{\prime \prime}, \Psi\right)$-core (lines 1-2). Then, we put the connected components of $\left(k^{\prime \prime}, \Psi\right)$-core into a set $\mathcal{C}$, and initialize some variables including the lower and upper bounds of $\alpha$ (lines 3-4). Next, in the loop (lines 5-20), we consider the connected components one by one. Note that the lower bound $l$ is never decreased during the iterations. If the current lower bound $l>k^{\prime \prime}$, we replace $C$ by the core which has higher clique-core number and is contained by $C$ (line 6). Intuitively, if $l$ is too large, then $C$ may not contain a subgraph with density $l$ and thus we skip it. Consequently, we build a flow network (line 7), and check whether $l$ is a feasible lower bound (line 8), i.e., whether there exists a subgraph with density at least $l$.

If $C$ cannot be skipped, we use binary search to find the CDS (lines 10-19). Each time we set a guess value of $\rho_{\text {opt }}$, namely $\alpha$, and check whether there is a subgraph with density of $\alpha$ or more. Once we get a larger lower bound (line 16), we locate the CDS in the core with a larger clique-core number, so the network based on $C$ is even smaller. In other words, during the binary search, as the value of $\alpha$ approaches the true value of $\rho_{o p t}$, the flow networks

```
Algorithm 4: The algorithm: CoreExact.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: The CDS $D\left(V_{D}, E_{D}\right)$;
    perform core decomposition using Algorithm 3
    locate the $\left(k^{\prime \prime}, \Psi\right)$-core using pruning criteria;
    $\mathcal{C} \leftarrow$ all the connected components of $\left(k^{\prime \prime}, \Psi\right)$-core;
    initialize $D \leftarrow \emptyset, U \leftarrow \emptyset, l \leftarrow \rho^{\prime \prime}, u \leftarrow k_{\max }$;
    for each connected component $C\left(V_{C}, E_{C}\right) \in \mathcal{C}$ do
        if $l>k^{\prime \prime}$ then $C\left(V_{C}, E_{C}\right) \leftarrow C \cap(\lceil l\rceil, \Psi)$-core;
        build a flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$ by lines 5-15 of Algorithm 1
        find minimum st-cut $(\mathcal{S}, \mathcal{T})$ from $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
        if $\mathcal{S}=\emptyset$ then continue;
        while $u-l \geq \frac{1}{\left|V_{C}\right|\left(\left|V_{C}\right|-1\right)}$ do
            $\alpha \leftarrow \frac{l+u}{2}$;
            build $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$ by lines $5-15$ of Algorithm 1
            find minimum st-cut $(\mathcal{S}, \mathcal{T})$ from $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
            if $\mathcal{S}=\{s\}$ then
                $u \leftarrow \alpha$;
            else
                if $\alpha>\lceil l\rceil$ then remove some vertices from $C$;
                $l \leftarrow \alpha$;
                $U \leftarrow \mathcal{S} \backslash\{s\}$
        if $\rho(G[U], \Psi)>\rho(D, \Psi)$ then $D \leftarrow G[U]$;
    return $D$;
```

constructed become smaller. Finally, we get the CDS (line 21). We further illustrate CoreExact by Example 5

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-07.jpg?height=220&width=618&top_left_y=1142&top_left_x=293)

Figure 5: Illustrating the core-based algorithms.

EXAMPLE 5. Let $\Psi$ be a single edge and consider the graph in Figure 5, where $k_{\max }=4$. During core decomposition, we track densities of residual graphs and obtain $\rho^{\prime}=25 / 12 \approx 2.08$ (i.e., density of subgraph $S_{3}$ ). Thus, we get $\left\lceil\rho^{\prime}\right\rceil=3$ and locate the EDS in the 3-core (i.e., subgraph $S_{3}$ ). The EDS (i.e., subgraph $S_{1}$ with density $15 / 7 \approx 2.14$ ) can be computed by conducting binary search using the flow networks built on the two connected components $S_{1}$ and $S_{2}$ of $S_{3}$, rather than the entire graph, respectively.

### 6.2 The Core-Based Approximation Methods

Recall that Theorem 1 gives the lower and upper bounds of density of a $(k, \Psi)$-core. Moreover, for a specific clique $\Psi$, the larger the value of $k$, the higher the lower bound on the density of the corresponding $(k, \Psi)$-core. Using Theorem 1 we can show:

LEMMA 8. Given a graph $G$ and an h-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the $\left(k_{\max }, \Psi\right)$-core is a $\frac{1}{\left|V_{\Psi}\right|}$-approximation solution to CDS problem.

PROOF. By Theorem 1 we have $\frac{k_{\max }}{\left|V_{\Psi}\right|} \leq \rho\left(\mathcal{R}_{k_{\max }}, \Psi\right) \leq k_{\max }$. Using the fact that $\rho_{\text {opt }} \leq k_{\max }$, we have

$$
\begin{equation*}
\frac{\rho\left(\mathcal{R}_{k_{\max }}, \Psi\right)}{\rho_{\text {opt }}} \geq \frac{k_{\max } /\left|V_{\Psi}\right|}{k_{\max }}=\frac{1}{\left|V_{\Psi}\right|} \tag{5}
\end{equation*}
$$

The lemma follows.

To compute the $\left(k_{\max }, \Psi\right)$-core, we can use the core decomposition method discussed in Section 5.3 which computes all the cores in an incremental manner. We denote this approximation algorithm by IncApp (see Algorithm55. Clearly, it has the same time complexity as the core decomposition algorithm.
Algorithm 5: The algorithm: IncApp.

Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;

Output: The $\left(k_{\max }, \Psi\right)$-core;

1 run $(k, \Psi)$-core decomposition algorithm (Section 5.3);

2 return the $\left(k_{\max }, \Psi\right)$-core;

A subtle point is that although the $\left(k_{\max }, \Psi\right)$-core is dense and provides an approximation solution, the CDS may not be in the $\left(k_{\max }, \Psi\right)$-core or even share some vertices with it. For example, in Figure 5 let $\Psi$ be a single edge. Then, the subgraph $S_{2}$ is the $k_{\max }$-core $\left(k_{\max }=4\right)$, but the EDS is the subgraph $S_{1}$.

To further improve efficiency, we propose another method, called CoreApp. Unlike IncApp which computes all the cores, it focuses on computing the $\left(k_{\max }, \Psi\right)$-core directly. It relies on a key observation that the $\left(k_{\max }, \Psi\right)$-core often tends to be a subgraph of vertices with higher clique-degrees. We thus propose to discover the CDS from a sequence of subgraphs induced by vertices, whose clique-degrees are the largest. Moreover, once we find a core with higher clique-core number, we can prune some subgraphs, whose vertices' clique-degrees are too small. Thus, the CDS can be discovered efficiently. We remark that for $h$-cliques where $h \geq 3$, computing the clique-degree $\operatorname{deg}_{G}(v, \Psi)$ may be costly. Instead, we replace it by an upper bound $\gamma(v, \Psi)$, which can be computed more efficiently. Specifically, we run the $k$-core decomposition algorithm [7], and for each vertex $v$ in an $x$-core, we set $\gamma(v, \Psi)=\binom{x}{h-1}$.

```
Algorithm 6: The algorithm: CoreApp.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: The $\left(k_{\max }, \Psi\right)$-core;
    for $\forall v \in V$ do compute $\gamma(v, \Psi)$ of $\operatorname{deg}_{G}(v, \Psi)$;
    sort vertices of $V$ in decreasing order of their $\gamma(v, \Psi)$ values;
    initialize $W, k_{\max } \leftarrow 0, S^{*} \leftarrow \emptyset$;
    while $\max _{v \in V \backslash W} \gamma(v, \Psi) \geq k_{\max }$ do
        for $\forall v \in W$ do compute $\operatorname{deg}_{G[W]}(v, \Psi)$;
        $k_{l} \leftarrow \min _{v \in W} \operatorname{deg} g_{G[W]}(v, \Psi), k_{u} \leftarrow \max _{v \in W} \operatorname{deg}_{G[W]}(v, \Psi)$;
        $k \leftarrow \max \left\{k_{l}, k_{\max }+1\right\}$;
        while $k \leq k_{u}$ and $|W|>0$ do
            while $\left(\exists v \in W, \operatorname{deg}_{G[W]}<k\right)$ do
                delete $v$ from $W$ and decrease clique-degrees;
            if $|W|>0$ then
                if $k>k_{\max }$ then
                $\left\lfloor k_{\max } \leftarrow k, S^{*} \leftarrow G[W]\right.$;
                $k \leftarrow k+1 ;$
        $W \leftarrow$ top- $(2 \times|W|)$ vertices in $V$
    return $S^{*}$
```

Algorithm 6 presents CoreApp. First, we compute $\gamma(v)$ for each vertex, and sort vertices based on their $\gamma(v)$ values (lines 1 2). Then, we initialize three variables $W, k_{\max }$, and $S^{*}$, where $W$ keeps a set of vertices whose clique-degrees are the largest, and $S^{*}$ is used to track the $\left(k_{\max }, \Psi\right)$-core (line 3 ), which is computed from the vertex-induced subgraph $G[W]$. Next, we compute the $\left(k_{\max }, \Psi\right)$-core in $G$, by using a while loop (lines 4-15). Specifically, we first compute the exact clique-degree for each vertex in $G[W]$, and record the minimum and maximum clique-degrees (lines 6-7). Then, we perform core decomposition for $G[W]$ with clique-core numbers in $\left[k_{l}, k_{u}\right]$ (lines 8-15), during which the maximum clique-core number $k_{\max }$ and $\left(k_{\max }, \Psi\right)$-core are kept (lines 13-14). After that, we double the size of $W$ for the next iteration (line 15). The loop can be stopped safely by using the stopping criterion (line 4). Finally, we get $\left(k_{\max }, \Psi\right)$-core (line 16). Note that $k_{\max }$ tracks the maximum clique-core number during the iterations, and for each subgraph $G[W]$, we focus on finding cores with core numbers larger than the previous $k_{\max }$ (line 7).

Correctness. Essentially, CoreApp finds the $\left(k_{\max }, \Psi\right)$-core from a sequence of subgraphs induced by vertices in $W$ which have the largest clique-degrees. For each small subgraph $G[W]$, it computes the core with the highest core number by running core decomposition steps (lines 7-14). The stopping criterion (line 4) ensures that the $\left(k_{\max }, \Psi\right)$-core is correctly computed, i.e., since the maximum clique-degree of all the remaining vertices (in the set $V \backslash W$ ) is less than $k_{\max }$, their clique-core numbers must be less than $k_{\max }$.

LEMMA 9. The time and space complexities of CoreApp are $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}\right)$ and $\mathcal{O}(m)$ respectively.

Proof. Let the number of iterations be $t$. Since we adopt the exponential growth strategy, the numbers of vertices involved in these iterations are at most $\left(\frac{1}{2}\right)^{t-1} \cdot n,\left(\frac{1}{2}\right)^{t-2} \cdot n, \cdots, n$ respectively, which form a geometric sequence. In the $i$-th iteration $i \in[1$, $t$ ], it takes $\mathcal{O}\left(\left(\frac{1}{2}\right)^{t-i} \cdot n \cdot\binom{d-1}{h-1}\right)$ time and $\mathcal{O}(m)$ space, as it performs core decomposition. By summarizing the time cost of all iterations, we obtain $\mathcal{O}\left(2 \cdot n \cdot\binom{d-1}{h-1}\right)=\mathcal{O}\left(n \cdot\binom{d-1}{h-1}\right)$. The space cost is $\mathcal{O}(m)$, since the iterations are sequentially executed.

Although, CoreApp has almost the same worst-case cost as PeelApp and IncApp, it performs much faster in practice, because the CDS is often much smaller than $G$ and thus only a few subgraphs are examined in the iterations. As shown by our experiments next, CoreApp is up to two orders of magnitude faster than PeelApp and IncApp. Moreover, the approximation algorithms generate high-quality solutions - their actual approximation ratios are often much higher than their theoretical approximation ratios.

Remark. In [13], Cheng et al. present an external-memory core decomposition algorithm, called EMcore, which also works in a top-down manner. However, there are four differences between CoreApp and EMcore: (1) CoreApp can handle any $h$-cliqueand pattern-cores, while EMcore is developed for processing the classical (edge-based) $k$-cores. (2) CoreApp focuses on computing the $\left(k_{\max }, \Psi\right)$-core while EMcore decomposes all $k$-cores. (3) The methods of estimating upper bounds of core numbers are different. (4) In the worst case, for classical $k$-cores, CoreApp takes $\mathcal{O}(n+m)$ time while EMcore takes $\mathcal{O}\left(k_{\max }(n+m)\right)$ time, since both of them conduct core decomposition for a sequence of subgraphs, but the strategies of considering subgraphs are different. Our later experiments show that for computing the $k_{\max }$-core, CoreApp is faster than EMcore.

### 6.3 Discussions

Below, we discuss the parallelizability of our algorithms and show that our algorithms can solve a variant of the CDS problem. Parallelizability. The existing parallel $k$-core decomposition algorithms [50 48, 59] can be easily extended for decomposing ( $k$, $\Psi)$-cores, so our approximation solutions, which rely on the ( $k_{\max }$, $\Psi)$-core, can be computed in parallel. Moreover, for the exact solution CoreExact, the main overhead comes from the step of computing the minimum st-cut. The parallel algorithms of computing the minimum st-cut have been studied extensively [42, 52], so our exact algorithm can also be easily parallelized.

A variant of CDS problem. In [65], Tsourakakis et al. studied a variant of the densest $k$ subgraph problem [8, 3], which aims to find a subgraph that contains a given set $Q$ of $k$ query vertices $(|Q|=k)$ with the highest density, and its exact solution follows the framework of the exact solution of CDS problem by solving a maximum flow problem. To solve this problem with edge-density, we can first decompose $k$-cores and get the minimum core number $x$ of these $k$ vertices. Then, then lower bound of the edge-density of $x$-core is $\frac{x}{2}$ by Theorem 1 Since $x$-core contains $Q$, we get a lower bound of $\rho_{\text {opt }}$ which is $\frac{x}{2}$. As a result, we can locate the densest subgraph in $\frac{x}{2}$-core, so we can build a flow network on $\frac{x}{2}$-core, rather than the entire graph, resulting in higher efficiency.

## 7. THE PDS PROBLEM AND SOLUTIONS

A pattern (a.k.a. motif or higher-order structure) is a small graph containing a few vertices (e.g., a diamond in Figure 1.b)). These patterns can be considered as building blocks of knowledge graphs or biological databases [70, 34, 21]. Compared to graph edges, they can better capture the intricate relationship among vertices, as well as the underlying rich semantics. For example, in a protein interaction network, proteins are often organized in cohesive patterns of interactions, each of which represents some particular functions [70]. We now study the discovery of pattern-aware densest subgraphs, i.e., subgraphs that are "dense" in terms of the number of patterns. We term this pattern densest subgraph (PDS) problem and show how our previous CDS solutions can be adapted.

### 7.1 The PDS Problem

We generalize the $h$-clique to a general pattern, which is a connected simple graph $\Psi\left(V_{\Psi}, E_{\Psi}\right)$. We formally introduce definitions of pattern instance and pattern-density below.

DEFINITION 7 (SUbGRAPH ISOMORPHISM). A graph $G(V$, $E)$ is subgraph isomorphic to a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$ if there exists an injection $\phi: V_{\Psi} \rightarrow V$, such that for all $v, v^{\prime} \in V_{\Psi}$, if $\left(v, v^{\prime}\right) \in$ $E_{\Psi}$, then $\left(\phi(v), \phi\left(v^{\prime}\right)\right) \in E$.

Definition 8 (PATTERn INSTANCE). Given a graph $G(V$, $E)$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, a subgraph $S\left(V_{S}, E_{S}\right) \subseteq G$ is a pattern instance of $\Psi$, if $S$ is isomorphic to $\Psi$.

DEFinition 9 (PATTERN-DEGREE). Given a graph $G(V, E)$ and a pattern $\Psi$, the pattern-degree of a vertex $v$, or $\operatorname{deg}_{G}(v, \Psi)$, is the number of pattern instances of $\Psi$ containing $v$.

Clearly, $G$ is subgraph isomorphic to $\Psi$ iff it has a subgraph $S\left(V_{S}, E_{S}\right)$ that is isomorphic to $\Psi$. Note that $S$ may not be a vertex-induced subgraph, although we note that our algorithms can be easily adapted for the vertex-induced case. Due to symmetry, for a single subgraph $S$ of $G$, there may be multiple mappings witnessing that $\Psi$ is isomorphic to $S$, which are automorphisms, but in this case we do not distinguish between different automorphisms of $S$ and instead count instances based on the edge set.

Definition 10 (PAtTERn-density). Given a graph $G(V$, $E)$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the pattern-density of $G$ w.r.t. $\Psi$ is $\rho(G, \Psi)=\frac{\mu(G, \Psi)}{|V|}$, where $\mu(G, \Psi)$ is the number of pattern instances of $\Psi$ in $G$.

Problem 2 (PDS PRoblem). Given a graph $G(V, E)$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, return the subgraph $D$ of $G(V, E)$, whose pattern-density $\rho(D, \Psi)$ is the highest.

For example, consider the graph in Figure 6 (a) and let $\Psi$ be the diamond pattern (Figure 1 b)). Then, the subgraph of $\{A, D, E, F\}$ is the densest subgraph, which contains three pattern instances (Figure 6 (c)) and has the highest pattern-density.

### 7.2 Algorithms for PDS Problem

Approximation methods. To compute the approximate PDS's, we can directly adapt algorithm PeelApp by replacing the steps of computing clique instances (clique-degrees) by pattern instances (pattern-degrees). The correctness is guaranteed by Lemma 10 Similarly, IncApp and CoreApp can be adapted.

LemmA 10. Given a graph $G$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the subgraph $S^{*}$ returned by PeelApp is a $\frac{1}{\left|V_{\Psi}\right|}$-approximation solution to the PDS problem w.r.t. pattern-density for pattern $\Psi$.

PRoOF SKETCH. We can prove the lemma by generalizing Lemma 8 and Theorem 1 for supporting an arbitrary pattern.

Exact methods. The algorithm Exact in Section 4.1 cannot be trivially extended for computing the exact PDS's since it relies on ( $h-1$ )-cliques. Nevertheless, we can adapt the exact CDS algorithm in [65], which follows the framework of Exact but introduces a different flow network construction method, for computing the exact PDS's by replacing the steps of computing clique instances (clique-degrees) by pattern instances (pattern-degrees). We denote this algorithm by PExact, and its pseudocodes are presented in the technical report [27]. Theorem 2 shows its correctness.

THEOREM 2. Given a graph $G$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the algorithm PExact correctly finds the PDS of $G$ w.r.t. patterndensity of $\Psi$.

PRoof. Please refer to the technical report [27].

Our core-based techniques can be used for improving PExact. Specifically, we adopt the $k$-pattern-core in Section 5.4 and use the three optimization techniques in Section 6.1 In addition, we propose a new optimization strategy, which relies on the following key observation: for a general pattern $\Psi$, different pattern instances may share the same set of vertices, but PExact creates a node for each of them when building the flow network. For example, consider the graph in Figure 6 a). If the pattern is a diamond, then the three pattern instances in Figure 6.c) share the same set of vertices.

```
Algorithm 7: construct $+(G, \Psi, \alpha)$.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right), \alpha$;
    Output: The flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
$1 \Lambda \leftarrow$ all the pattern instances of $\Psi$ in $G$;
$2 \Lambda^{\prime}=\left\{g_{1}, g_{2}, \cdots, g_{\left|\Lambda^{\prime}\right|}\right\} \leftarrow$ group the pattern instances in $\Lambda$;
$3 V_{\mathcal{F}} \leftarrow\{s\} \cup V \cup \Lambda^{\prime} \cup\{t\}$
$4 \forall v \in V$, add an edge $s \rightarrow v$ with capacity $\operatorname{deg}_{G}(v, \Psi)$;
$5 \forall v \in V$, add an edge $v \rightarrow t$ with capacity $\alpha\left|V_{\Psi}\right|$;
$6 \forall v \in V$, if it appears in a group $g \in \Lambda^{\prime}$, add an edge $v \rightarrow g$ with
    capacity $|g|$
$7 \forall g \in \Lambda^{\prime}$, if it contains a vertex $v$, add an edge $g \rightarrow v$ with capacity
    $|g|\left(\left|V_{\Psi}\right|-1\right)$;
8 return $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
```

Based on the observation above, we propose a new flow network construction method construct + , by grouping nodes of pattern instances having same set of vertices. Algorithm 7 shows construct+. First, a set $\Lambda^{\prime}=\left\{g_{1}, g_{2}, \cdots, g_{\left|\Lambda^{\prime}\right|}\right\}$ is collected, where each $g_{i}$ denotes a group of pattern instances sharing the same set of vertices. Second, for each vertex $v \in V$, we set the capacities of edges $(s, v)$ and $(v, t)$ similarly with that in PExact. Third, for each vertex $v \in V$, if it appears in a group $g \in \Lambda^{\prime}$, the capacity of edge $(v, g)$ is set to $|g|$; for each group $g \in \Lambda^{\prime}$, the capacity of edge $(g, v)$ is set to $|g|\left(\left|V_{\Psi}\right|-1\right)$. Here, we define the capacties based on the intuition that the densest subgraph $D$ is obtained by computing the minimum st-cut $(\mathcal{S}, \mathcal{T})$, and vertices of $D$ must be in one partition $\mathcal{S}$. This implies that nodes of all the pattern instances in $D$ should be in $\mathcal{S}$, and thus we can accumulate their capacities by using the term $|g|$ when computing the maximum flow from $\mathcal{S}$ to $\mathcal{T}$. Note that if $\Psi$ is a clique, then $|g|=1$. The correctness is stated by Lemma 11 We illustrate construct + by Example 6 We denote the above core-based exact PDS algorithm by CorePExact.

LEMMA 11. Given a graph $G$, a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the flow networks built by PExact (lines 5-12) and construct+ have the same capacity for their minimum st-cut.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-09.jpg?height=382&width=354&top_left_y=178&top_left_x=1122)

(c) group $g_{2}$

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-09.jpg?height=363&width=396&top_left_y=176&top_left_x=1493)

(d) the flow network
Figure 6: Illustrating the flow network in CorePExact.

PRoof. Please refer to the technical report 27.

Example 6. Let $\Psi$ be the diamond pattern. The graph in Figure 6 a) has 4 pattern instances, which are grouped into 2 groups as shown in Figures 6 (b) and 6.c). Clearly, we can locate the PDS in $(1, \Psi)$-core, in which the vertex set is $\{A, B, \cdots, F\}$ and $\Lambda^{\prime}=$ $\left\{g_{1}, g_{2}\right\}$. To build $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$, we first collect the set $V_{\mathcal{F}}$, then create 10 nodes, and finally add edges. For example, for group $g_{2}$, we link it to all its vertices with capacities $\left|g_{2}\right|\left(\left|V_{\Psi}\right|-1\right)=9$ and their reversed edges are with capacities 3. Figure 6 d) shows $\mathcal{F}$.

Remark. CorePExact relies on the core decomposition. For some special patterns such as stars and loops, the core decomposition algorithm in Algorithm 3 can be performed faster by optimizing the steps of computing pattern-degrees and decreasing the vertices' pattern-degrees. For details, please refer to the technical report [27]. For general patterns, we use the state-of-the-art pattern enumeration algorithm [53] for computing the pattern-degrees.

## 8. EXPERIMENTS

We have performed experiments on ten real graphs ${ }^{2}$ (see Table 2. These graphs cover various domains, such as biological networks (e.g., Yeast), collaboration networks (e.g., Ca-HepTh), autonomous system graphs (e.g., As-Caida), bibliographical graphs (e.g., DBLP), web graphs (e.g., UK-2002), citation networks (e.g., Cit-Patents), social networks (e.g., Friendster), etc.

Table 2: Datasets used in our experiments.

| Graph | Name | Vertices | Edges |
| :---: | :---: | ---: | ---: |
| Real small graphs <br> (all algo.) | Yeast | 1,116 | 2,148 |
|  | Netscience | 1,589 | 2,742 |
|  | As-733 | 1,486 | 3,172 |
|  | Ca-HepTh | 9,877 | 25,998 |
|  | As-Caida | 26,475 | 106,762 |
| Real large graphs <br> (approx. algo.) | DBLP | 425,957 | $1,049,866$ |
|  | Cit-Patents | $3,774,768$ | $16,518,948$ |
|  | Friendster | $20,145,325$ | $106,570,765$ |
|  | Enwiki-2017 | $5,409,498$ | $122,008,994$ |
| Synthetic <br> random graphs | UK-2002 | $18,520,486$ | $298,113,762$ |
|  | SSCA | 100,000 | $3,405,676$ |
|  | ER | 100,000 | $4,837,534$ |

Besides, as shown in Table 2. we have used three synthetic random graphs (SSCA, ER, and R-MAT) generated by GTgraph ${ }^{3}$ These three graphs follow three representative distributions: SSCA

${ }^{2}$ The datasets are: Yeast (https://dip.doe-mbi. ucla.edu/dip/Stat.cqil; Netscience (http: //www-personal.umich.edu/ mejn/netdata/); DBLP (http://dblp.uni-trier.de/xml/); and Enwiki2017 and UK-2002 (http://law.di.unimi.it/). Others are found athttps://snap. stanford.edu/data/

${ }^{3}$ GTgraph random graph generator: http://www.cse.psu. edu/ kxm85/software/GTgraph/
is made by random-sized cliques, ER follows the random distribution, and R-MAT follows the power-law distribution. Note that for SSCA and R-MAT, we set default parameters of their generators; for ER, we set the probability of an edge between any pair of vertices to 0.0005 , which is also the chance that an edge exists in the real graph Cap-HepTh. A more detailed analysis of the characteristics of these datasets is in the technical report [27], which we omit here due to lack of space.

We considered two groups of patterns: (1) $h$-cliques (with $h \in$ $[2,6]$ ); and (2) seven other patterns (Figure 7) studied in 170,46 . 45], each of which is associated with an ID (e.g., $4=$ diamond).

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-10.jpg?height=131&width=762&top_left_y=585&top_left_x=215)

Figure 7: Patterns used in evaluation of PDS.

For CDS problem, we tested 2 exact algorithms (Exact and CoreExact) and 5 approximation algorithms (Nucleus [59], EMcore [13], PeelApp, IncApp, and CoreApp). Nucleus is applied for decomposing the $(k, \Psi)$-core where $\Psi$ is an $h$-clique. For fair comparison, we implement the the faster nucleus decomposition algorithm AND [59] on a single core. We also adapt EMcore such that it works in main memory and stops when the $k_{\text {max }}$-core is computed. For PDS problem, we tested both exact algorithms (PExact, CorePExact) and approximation algorithms (PeelApp, IncApp, CoreApp). For special patterns marked $*$ in Figure 7 . we have implemented optimizations discussed in the technical report [27|, for all algorithms. Note that CoreExact, IncApp, CoreApp, and CorePExact are our core-based approaches. All these solutions are implemented in Java, and executed on a machine having an $\operatorname{Intel}(\mathrm{R}) \mathrm{Xeon}(\mathrm{R}) 3.40 \mathrm{GHz}$ processor, 16 cores, and $125 \mathrm{~GB}$ of memory, with Ubuntu installed.

### 8.1 DSD for Edge- and $h$-Clique-Densities

$\mathbf{1}$ Exact algorithms. Figures 8 a)-(e) show the performance of exact algorithms on five small datasets. (As these solutions cannot finish in a reasonable time on larger datasets, we do not report their results here.) We see that the time costs of all the algorithms increase with the $h$-clique size. Moreover, CoreExact is at least $4.5 \times$ and up to four orders of magnitude faster than the existing algorithm Exact ${ }^{4}$ This is because CoreExact employs the $k$ clique-cores, or $(k, \Psi)$-cores, which not only effectively locate the CDS in some smaller subgraphs, but also significantly reduce the flow network sizes in the binary search process. In contrast, the flow network of Exact is built on the entire graph in each iteration, and the sizes of the flow networks remain unchanged in all the iterations. Hence, CoreExact is faster than Exact.

We now investigate how the flow network size (number of nodes) changes in the first six iterations of CoreExact, on Ca-HepTh and As-Caida (Figure 9). In the $x$-axis, " -1 " denotes that the flow network is constructed for the entire graph $G$, instead of a subgraph located by the $(k, \Psi)$-cores (Section 4.1 ; " 0 " means that the flow network is built on the subgraph located by the clique-cores. The $(k, \Psi)$-cores are indeed effective for locating the CDS, as it greatly prunes vertices and clique instances. The flow networks shrink, as the number of iterations increases. After an iteration of the binary search is completed, a tighter lower bound of $\rho_{\text {opt }}$ is obtained, which can then be used to locate the CDS in a smaller subgraph with a larger core number, resulting in a smaller flow network. For example, for the triangle on the $\mathrm{Ca}$-HepTh dataset, over $95 \%$ of the nodes in the flow network is pruned after six iterations. As the flow network is smaller, the minimum st-cut can be computed faster,[^1]

thus yielding a better performance. As the clique size (i.e., $h$ ) increases, the proportion of cliques instances in the densest subgraph becomes larger, so the degree of pruning gets smaller.

Next, we evaluate the individual effect of the three pruning criteria in CoreExact. We create three variants of CoreExact, namely $P 1, P 2$, and $P 3$, which only include Pruning1, Pruning2, and Pruning3 respectively, while other steps are the same as those of CoreExact. Our experimental results (Figure 10) confirm that each of the pruning strategies makes a contribution to the efficiency of CoreApp. Most of the savings come from Pruningl; however, while the contribution of other pruning strategies is small on the As-733 and Ca-HepTh, Pruning2 and Pruning3 still make a nontrivial contribution on $\mathrm{Ca}-\mathrm{HepTh}$.

Finally, we examine the percentage of time cost of core decomposition in CoreExact. As shown in Table 3, the percentage is small and decreases with the $h$-clique size. Besides, cores are effective for locating the CDS in some small subgraphs. Thus, CoreExact achieves high efficiency, while incurring negligible overhead from core decomposition.

Table 3: \% of time cost of core decomposition.

| Dataset | edge | triangle | 4-clique | 5-clique | 6-clique |
| :---: | :---: | :---: | :---: | :---: | :---: |
| As-733 | $57.14 \%$ | $8.28 \%$ | $0.31 \%$ | $0.09 \%$ | $0.04 \%$ |
| Ca-HepTh | $69.74 \%$ | $6.01 \%$ | $2.32 \%$ | $0.87 \%$ | $0.65 \%$ |

2 Approximation algorithms. We next report the efficiency results of approximation solutions on the five largest datasets. From Figures 8 f)-(j), we observe that core-based approximation algorithms (IncApp and CoreApp) are consistently faster than Nucleus and PeelApp ${ }^{5}$ This implies that for decomposing cores, our algorithm (Algorithm 3) which is almost the same as IncApp is faster than the nucleus decomposition algorithm. The average running time of IncApp is only $90 \%$ of that of PeelApp. Both algorithms iteratively remove vertices from the graph $G$. Particularly, PeelApp computes the density after removing each vertex, and only stops after $G$ has no more vertices. However, IncApp does not compute the density, and stops after the ( $k_{\max }, \Psi$ )-core is discovered. CoreApp performs the best, as it finds the ( $k_{\max }$, $\Psi)$-core in a top-down manner, and skips the computation of cores with smaller clique-core numbers. In our experiments, CoreApp is up to three and two orders of magnitude faster than Nucleus and PeelApp respectively.

As the clique size $(h)$ increases, the speedup of CoreApp over PeelApp decreases, because the proportion of clique instances in the densest subgraph becomes larger, increasing the time cost of computing $\left(k_{\max }, \Psi\right)$-core. Meanwhile, the running time generally grows as the clique size $(h)$ increases, except for the Cit-Patents dataset. This is because on Cit-Patents, the numbers of 5 -cliques and 6 -cliques are less than the number of 4 -cliques. In addition, we compare CoreApp with EMcore for computing approximate EDS's on five largest datasets. As reported in Table 4, EMcore is slower than CoreApp, because it differs with CoreApp on four aspects as discussed in Section 6.2

Table 4: Efficiency of EMcore and CoreApp (seconds).

| Algo. | DBLP | CitPatents | FriendSter | Enwiki-2017 | UK-2002 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| EMcore | 0.091 | 1.132 | 3.143 | 8.543 | 7.543 |
| CoreApp | 0.077 | 1.021 | 2.986 | 8.139 | 5.825 |

We next report the theoretical ratio $T$ (i.e., $\frac{1}{\left|V_{\Psi}\right|}$ ) and actual approximation ratios $R$ of approximation methods. Since Nucleus, IncApp and CoreApp return the same ( $k_{\max }, \Psi$ )-core, their $R$ values are the same, so we only show results for CoreApp. As[^2]

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=510&width=1832&top_left_y=176&top_left_x=141)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=195&width=355&top_left_y=214&top_left_x=145)

(a) Yeast (exact)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=195&width=361&top_left_y=445&top_left_x=145)

(f) DBLP (app.)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=219&width=360&top_left_y=194&top_left_x=514)

(b) Netscience (exact)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=206&width=358&top_left_y=442&top_left_x=512)

(g) Cit-Patents (app.)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=198&width=369&top_left_y=213&top_left_x=867)

(c) As-733 (exact)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=225&width=374&top_left_y=440&top_left_x=865)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=201&width=371&top_left_y=211&top_left_x=1235)

(d) Ca-HepTh (exact)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=198&width=363&top_left_y=215&top_left_x=1594)

(e) As-Caida (exact)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=225&width=358&top_left_y=446&top_left_x=1596)

Figure 8: Efficiency of exact and approximation CDS algorithms.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=304&width=769&top_left_y=783&top_left_x=209)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=252&width=366&top_left_y=798&top_left_x=215)

(a) $\mathrm{Ca}-\mathrm{HepTh}$

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=271&width=372&top_left_y=786&top_left_x=600)

(b) As-Caida

Figure 9: Flow network sizes in CoreExact.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=276&width=786&top_left_y=1174&top_left_x=211)

Figure 10: The effect of pruning criteria in CoreExact.

shown in Figure 11. $R$ is often larger than $T$. Although CoreApp is slightly worse than PeelApp on 6/10 instances (the average ratio of CoreApp is 0.956 times that of PeelApp), they have the same theoretical guarantee and their actual ratios are close to 1.0 in most cases, so CoreApp produces high-quality results in practice.

In addition, we compare the efficiency of core-based exact and approximation approaches on two datasets. As shown in Figure 12 . CoreApp is much faster than CoreExact. The reason is that CoreExact relies on not only core decomposition, but also computing the minimum st-cut from flow networks using binary search, whereas CoreApp just computes the $\left(k_{\max }, \Psi\right)$-core directly.

Remark. For small-to-moderate-sized graphs (e.g., Ca-HepTh), CoreExact is the best choice, as it computes an exact result in a reasonable time. For larger graphs (e.g., UK-2002), CoreApp is a much better option since it achieves high accuracy and efficiency. 3 Random graphs. As depicted in Figures 13 and 14 for SSCA and R-MAT, the performance of our proposed solution is generally satisfactory. For example, the running time of CoreApp is 20

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=217&width=393&top_left_y=2201&top_left_x=215)

(a) Netscience

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=206&width=379&top_left_y=2220&top_left_x=602)

(b) As-Caida
Figure 11: Approximation ratio.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-11.jpg?height=260&width=768&top_left_y=781&top_left_x=1123)

Figure 12: CoreExact and CoreApp.

(resp., 201) times faster than PeelApp in SSCA (resp., R-MAT) when $\Psi$ is the triangle. For ER, the degree values of vertices are almost the same, and the $k_{\text {max }}$-core contains $96.8 \%$ of the vertices in the graph. This affects the pruning effectiveness of CoreApp, rendering a lower performance gain. All in all, our core-based algorithms favor real-world graphs.

4 Densities of CDS's. We next show the clique-densities of CDS's for different $h$-cliques $(h \geq 3)$. Specifically, for each dataset, we first use CoreExact to compute its exact CDS's for different cliques, then compute the $h$-clique-densities of its EDS, and finally report the $h$-clique-densities of its EDS and CDS's in Table 5 Due to the space limitation, we only show the results on four small datasets (where S-DBLP is a sub-graph of the DBLP dataset used in Section 8.2. . We remark that for Yeast dataset, the EDS does not contain any $4,5,6$-clique, so its $h$-clique-density is 0.0 $(h \geq 4)$. As we can see, for S-DBLP and Netscience, their CDS's are exactly the same as EDS. In fact, they are the maximal clique in the graph, which confirms the conclusion that CDS's can be used for identifying large near-cliques 65. For Yeast and As-733, the clique-density values of CDS's are higher than those on the EDS.

### 8.2 DSD for Pattern-Densities

Next, we present the results for general patterns in Figure 7 For lack of space, we only report results on a subset of datasets. In addition, we perform case studies on real datasets for these patterns. 1 Exact algorithms. In Figure 15. we present the efficiency results of exact algorithms on two small datasets As-733 and CaHepTh. The bars touching the top of the figures mean that the corresponding algorithms cannot find densest subgraphs within 3 days, at which point we time them out. We can see that CorePExact is up to four orders of magnitude faster than PExact. For different patterns, their running times vary, because the number of pattern instances in the underlying graph for each pattern can be very different. For any two patterns $\Psi_{1}$ and $\Psi_{2}$ which are not "special patterns" (e.g., star and loop), we observe that if $\left|V_{\Psi_{1}}\right|=\left|V_{\Psi_{2}}\right|$ and $\Psi_{1} \subseteq \Psi_{2}$, then it takes longer to find the densest subgraph w.r.t. $\Psi_{1}$ than w.r.t. $\Psi_{2}$. This is because the number of pattern instances of $\Psi_{1}$ is more than that of $\Psi_{2}$. For example, c3-star is a subgraph of 2-triangle (with 4 vertices) and it takes more time to find the

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=272&width=1825&top_left_y=173&top_left_x=150)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=209&width=355&top_left_y=199&top_left_x=164)

(a) SSCA

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=217&width=355&top_left_y=192&top_left_x=516)

(b) ER

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=198&width=353&top_left_y=210&top_left_x=886)

(c) R-MAT

Figure 13: Efficiency of exact CDS algorithms on random graphs.

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=195&width=355&top_left_y=518&top_left_x=164)

(a) SSCA

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=214&width=352&top_left_y=500&top_left_x=518)

(b) ER

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=220&width=356&top_left_y=494&top_left_x=882)

(c) R-MAT

Figure 14: Efficiency of approximation CDS algorithms on random graphs.

Table 5: The edge-densities and clique-densities (pattern-densities) of CDS's (PDS's).

| Dataset | edge <br> $\rho_{o p t}$ | triangle |  | 4-clique |  | 5-clique |  | 6-clique |  | 2-star |  | diamond |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ | $\rho_{o p t}$ | $\rho(\mathrm{EDS}, \Psi)$ |
| S-DBLP | $\overline{6}$ | 22 | $\overline{22}$ | $\overline{55}$ | $\overline{55}$ | $\overline{99}$ | 99 | 132 | 132 | 73.5 | 66 | 165 | 165 |
| Yeast | 3.13 | 2.11 | 0.467 | 0.67 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 111.3 | 18.13 | 20 | 19.2 |
| Netscience | 9.50 | 57.25 | 57.25 | 242.3 | 242.3 | 775.2 | 775.2 | 1938 | 1938 | 171 | 171 | 726.8 | 726.8 |
| As-733 | 8.19 | 31.43 | 31.35 | 68.67 | 67.94 | 92.78 | 90.23 | 79.37 | 75.13 | 826.3 | 153.8 | 3376 | 437.7 |

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-12.jpg?height=353&width=769&top_left_y=1103&top_left_x=209)

Figure 17: The densest subgraphs found in DBLP network, based on triangle and 2-star patterns.

densest subgraph w.r.t. c3-star than 2-triangle. 2 Approximation algorithms. As shown in Figure 16 the running time of an approximation algorithm increases with the graph size in general. This is because computing the cores is more expensive for a larger graph. Again, CoreApp performs the fastest, and it is up to two orders of magnitude faster than PeelApp. For special patterns (star and diamond), we use optimized algorithms (details are in [27]) for core decomposition. Hence, they need less time cost than other more complicated patterns (e.g., 2-triangle).

3 Case studies. We use two real graphs, namely $S-D B L P$ and Yeast. S-DBLP $(|V|=478,|E|=1,086)$ is a sub-graph of the DBLP dataset. It is the co-authorship network of authors who published at least two DB/DM papers between 2013 and 2015. We consider two 3vertex patterns, i.e., triangle and 2-star (Figure 7). We use the exact algorithm to compute their PDS's, as depicted in Figure 17 . In a triangle pattern, every pair of vertices is connected, so the PDS tends to be a near-clique [65]. The researchers involved in this PDS possess a close collaboration relationship: any two researchers have published papers together. The PDS for 2-star is quite different from that of triangle. Particularly, researchers in the "central" part of the PDS formed by 2-star tend to be group directors or senior researchers (e.g., Profs. Jiawei Han and Chengxiang Zhai), who are linked to their former students or postdocs. For this PDS, over half of the researchers worked in Prof. Han's lab before. Similarly, for Yeast, different PDS's can capture different semantics [27.
4 Densities of PDS's. In this experiment, we analyze the patterndensities of PDS's for different patterns. Again, for each dataset, we first compute its exact EDS and PDS's for all patterns, and then report the pattern-densities of its EDS and PDS's in Table 5 Due to the space limitation, we only show results of 2-star and diamond. As we can observe, for most of the datasets, the pattern-density values of PDS's are higher than those on the EDS.

## 9. CONCLUSIONS

The densest subgraph discovery (DSD) problem is fundamental to many graph applications. In this paper, we develop new algorithms to discover edge- and $h$-clique-based densest subgraphs, which are well studied in the literature. Our main observation is that densest subgraphs can be derived efficiently from $k$-cores. We extend $k$-core to $(k, \Psi)$-core by incorporating an $h$-clique $\Psi$. Based on $(k, \Psi)$-cores, we develop core-based exact and approximation solutions to the DSD problem. Moreover, we generalize the edgeand $h$-clique-density to pattern-density and show that our solutions can be easily adapted for finding pattern-density-based densest subgraphs. Extensive experiments show that our exact (resp., approximation) "core-based solutions" outperform existing algorithms by up to four orders (resp., two orders) of magnitude.

In the future, we will attempt to derive even tighter bounds for densities of $(k, \Psi)$-cores. We will also extend our core-based algorithms for finding densest subgraphs with size constraints. Another interesting research direction is to exploit our core-based techniques to speed up the randomized approximation algorithm in [49].

## Acknowledgments

Reynold Cheng was supported by the Research Grants Council of Hong Kong (RGC Projects HKU 17229116, 106150091, and 17205115) and the University of Hong Kong (Projects 104004572, 102009508, and 104004129), and the Innovation and Technology Commission of Hong Kong (ITF project MRP/029/18). Lakshmanan's research was supported in part by a discovery grant and a discovery accelerator supplement grant from NSERC (Canada). Xuemin Lin was supported by 2019DH0ZX01, 2018YFB1003504, NSFC61232006, DP180103096, and DP170101628. We would
like to thank Dr. Charalampos E. Tsourakakis for bringing his KDD'15 paper to our attention.

## 10. REFERENCES

[1] https://en.wikipedia.org/wiki/Clique_(graph_theory).

[2] R. K. Ahuja, J. B. Orlin, C. Stein, and R. E. Tarjan. Improved algorithms for bipartite network flow. SIAM Journal on Computing, 23(5):906-933, 1994.

[3] R. Andersen and K. Chellapilla. Finding dense subgraphs with size bounds. In International Workshop on Algorithms and Models for the Web-Graph, pages 25-37, 2009.

[4] Y. Asahiro, R. Hassin, and K. Iwama. Complexity of finding dense subgraphs. Discrete Applied Mathematics, 121(1):15-26, 2002.

[5] Y. Asahiro, K. Iwama, H. Tamaki, and T. Tokuyama. Greedily finding a dense subgraph. Journal of Algorithms, 34(2):203-221, 2000.

[6] B. Bahmani, R. Kumar, and S. Vassilvitskii. Densest subgraph in streaming and mapreduce. $P V L D B$, 5(5):454-465, 2012.

[7] V. Batagelj and M. Zaversnik. An o(m) algorithm for cores decomposition of networks. arXiv preprint cs/0310049, 2003.

[8] A. Bhaskara, M. Charikar, E. Chlamtac, U. Feige, and A. Vijayaraghavan. Detecting high log-densities: an o (n $1 / 4)$ approximation for densest k-subgraph. In STOC, pages 201-210, 2010.

[9] E. T. Charalampos. Mathematical and Algorithmic Analysis of Network and Biological Data. PhD thesis, Carnegie Mellon University, 2013. 2.1.

[10] M. Charikar. Greedy approximation algorithms for finding dense components in a graph. In APPROX, pages 84-95. Springer, 2000.

[11] J. Chen and Y. Saad. Dense subgraph extraction with application to community detection. TKDE, 24(7):1216-1230, 2012.

[12] Y. Chen, Y. Fang, R. Cheng, Y. Li, X. Chen, and J. Zhang. Exploring communities in large profiled graphs. IEEE Transactions on Knowledge and Data Engineering, 31(8):1624-1629, 2019.

[13] J. Cheng, Y. Ke, S. Chu, and M. T. √ñzsu. Efficient core decomposition in massive networks. In ICDE, pages 51-62, 2011.

[14] E. Cohen, E. Halperin, H. Kaplan, and U. Zwick. Reachability and distance queries via 2-hop labels. SIAM Journal on Computing, 32(5):1338-1355, 2003.

[15] J. Cohen. Trusses: Cohesive subgraphs for social network analysis. National Security Agency Technical Report, 16, 2008.

[16] W. Cui, Y. Xiao, H. Wang, Y. Lu, and W. Wang. Online search of overlapping communities. In SIGMOD, pages 277-288. ACM, 2013.

[17] M. Danisch, O. Balalau, and M. Sozio. Listing k-cliques in sparse real-world graphs. In $W W W$, pages 589-598, 2018.

[18] M. Danisch, T.-H. H. Chan, and M. Sozio. Large scale density-friendly graph decomposition via convex programming. In Proceedings of the 26th International Conference on World Wide Web, pages 233-242, 2017.

[19] A. Epasto, S. Lattanzi, and M. Sozio. Efficient densest subgraph computation in evolving graphs. In $W W W$, pages 300-310, 2015.

[20] Y. Fang, R. Cheng, Y. Chen, S. Luo, and J. Hu. Effective and efficient attributed community search. The VLDB Journal, 26(6):803-828, 2017.

[21] Y. Fang, R. Cheng, G. Cong, N. Mamoulis, and Y. Li. On spatial pattern matching. In IEEE International Conference on Data Engineering (ICDE), pages 293-304. IEEE, 2018.

[22] Y. Fang, R. Cheng, X. Li, S. Luo, and J. Hu. Effective community search over large spatial graphs. $P V L D B$, 10(6):709-720, 2017.

[23] Y. Fang, R. Cheng, S. Luo, and J. Hu. Effective community search for large attributed graphs. PVLDB, 9(12):1233-1244, 2016.

[24] Y. Fang, X. Huang, L. Qin, Y. Zhang, W. Zhang, R. Cheng, and X. Lin. A survey of community search over big graphs. The VLDB Journal, 2019.

[25] Y. Fang, Z. Wang, R. Cheng, X. Li, S. Luo, J. Hu, and X. Chen. On spatial-aware community search. IEEE Transactions on Knowledge and Data Engineering, 31(4):783-798, 2018.

[26] Y. Fang, Z. Wang, R. Cheng, H. Wang, and J. Hu. Effective and efficient community search over large directed graphs. IEEE Transactions on Knowledge and Data Engineering (TKDE), 2018.

[27] Y. Fang, K. Yu, R. Cheng, L. V. S. Lakshmanan, and X. Lin. Efficient algorithms for densest subgraph discovery (technical report). arXiv, 2019. https://arxiv.org/abs/1906.00341.

[28] E. Fratkin, B. T. Naughton, D. L. Brutlag, and S. Batzoglou. Motifcut: regulatory motifs finding with maximum density subgraphs. Bioinformatics, 22(14):e150-e157, 2006.

[29] G. Gallo, M. D. Grigoriadis, and R. E. Tarjan. A fast parametric maximum flow algorithm and applications. SIAM Journal on Computing, 18(1):30-55, 1989.

[30] A. Gionis, F. Junqueira, V. Leroy, M. Serafini, and I. Weber. Piggybacking on social networks. PVLDB, 6(6):409-420, 2013.

[31] A. Gionis and C. E. Tsourakakis. Dense subgraph discovery: Kdd 2015 tutorial. In SIGKDD, pages 2313-2314, NY, USA, 2015. ACM.

[32] A. V. Goldberg. Finding a maximum density subgraph. UC Berkeley, 1984.

[33] G. T. Heineman, G. Pollice, and S. Selkow. Chapter 8: Network flow algorithms. Algorithms in a Nutshell, pages 226-250, 2008 .

[34] J. Hu, R. Cheng, K. C.-C. Chang, A. Sankar, Y. Fang, and B. Y. Lam. Discovering maximal motif cliques in large heterogeneous information networks. In IEEE International Conference on Data Engineering (ICDE), pages 746-757. IEEE, 2019.

[35] J. Hu, X. Wu, R. Cheng, S. Luo, and Y. Fang. Querying minimal steiner maximum-connected subgraphs in large graphs. In International on Conference on Information and Knowledge Management (CIKM), pages 1241-1250. ACM, 2016.

[36] J. Hu, X. Wu, R. Cheng, S. Luo, and Y. Fang. On minimal steiner maximum-connected subgraph queries. IEEE Transactions on Knowledge and Data Engineering, 29(11):2455-2469, 2017.

[37] X. Huang, H. Cheng, L. Qin, W. Tian, and J. X. Yu. Querying k-truss community in large and dynamic graphs. In SIGMOD, pages 1311-1322. ACM, 2014.

[38] X. Huang and L. V. Lakshmanan. Attribute-driven community search. $P V L D B, 10(9): 949-960,2017$.

[39] X. Huang, W. Lu, and L. V. Lakshmanan. Truss decomposition of probabilistic graphs: Semantics and algorithms. In Proceedings of the 2016 International Conference on Management of Data, pages 77-90. ACM, 2016.

[40] M. Jha, C. Seshadhri, and A. Pinar. Path sampling: A fast and provable method for estimating 4-vertex subgraph counts. In $W W W$, pages 495-505, 2015.

[41] R. Jin, Y. Xiang, N. Ruan, and D. Fuhry. 3-hop: a high-compression indexing scheme for reachability query. In SIGMOD, pages 813-826. ACM, 2009.

[42] D. B. Johnson. Parallel algorithms for minimum cuts and maximum flows in planar networks. Journal of the ACM (JACM), 34(4):950-967, 1987.

[43] R. Kannan and V. Vinay. Analyzing the structure of large graphs. Rheinische Friedrich-Wilhelms-Universit√§t Bonn, 1999 .

[44] S. Khuller and B. Saha. On finding dense subgraphs. Automata, Languages and Programming, pages 597-608, 2009 .

[45] L. Lai, L. Qin, X. Lin, Y. Zhang, L. Chang, and S. Yang. Scalable distributed subgraph enumeration. $P V L D B$, $10(3): 217-228,2016$.

[46] J. Leskovec, A. Singh, and J. Kleinberg. Patterns of influence in a recommendation network. In $P A K D D$, pages 380-389. Springer, 2006.

[47] L. L√º, T. Zhou, Q.-M. Zhang, and H. E. Stanley. The h-index of a network node and its relation to degree and coreness. Nature communications, 7:10168, 2016.

[48] A. Mandal and M. Al Hasan. A distributed k-core decomposition algorithm on spark. In International Conference on Big Data, pages 976-981. IEEE, 2017.

[49] M. Mitzenmacher, J. Pachocki, R. Peng, C. Tsourakakis, and S. C. Xu. Scalable large near-clique detection in large-scale networks via sampling. In International Conference on Knowledge Discovery and Data Mining (SIGKDD), pages 815-824. ACM, 2015.

[50] A. Montresor, F. De Pellegrini, and D. Miorandi. Distributed $\mathrm{k}$-core decomposition. IEEE Transactions on parallel and distributed systems, 24(2):288-300, 2013.

[51] Y. Peng, Y. Zhang, W. Zhang, X. Lin, and L. Qin. Efficient probabilistic k-core computation on uncertain graphs. In International Conference on Data Engineering (ICDE), pages 1192-1203. IEEE, 2018.

[52] T. L. Pham, I. Lavallee, M. Bui, and S. H. Do. A distributed algorithm for the maximum flow problem. In International Symposium on Parallel and Distributed Computing (ISPDC), pages 131-138. IEEE, 2005.

[53] M. Qiao, H. Zhang, and H. Cheng. Subgraph matching: on compression and computation. $P V L D B, 11(2): 176-188$, 2017.

[54] L. Qin, R.-H. Li, L. Chang, and C. Zhang. Locally densest subgraph discovery. In $K D D$, pages 965-974. ACM, 2015.

[55] B. Saha, A. Hoch, S. Khuller, L. Raschid, and X.-N. Zhang. Dense subgraphs with restrictions and applications to gene annotation graphs. In RECOMB, volume 6044, pages 456-472, 2010.

[56] S. Sahu, A. Mhedhbi, S. Salihoglu, J. Lin, and M. T. √ñzsu. The ubiquity of large graphs and surprising challenges of graph processing. $P V L D B, 11(4): 420-431,2017$.

[57] R. Samusevich, M. Danisch, and M. Sozio. Local triangle-densest subgraphs. In International Conference on Advances in Social Networks Analysis and Mining (ASONAM), pages 33-40. IEEE, 2016.

[58] A. E. Sariy√ºce and A. Pinar. Fast hierarchy construction for dense subgraphs. PVLDB, 10(3):97-108, 2016.

[59] A. E. Sariy√ºce, C. Seshadhri, and A. Pinar. Local algorithms for hierarchical dense subgraph discovery. $P V L D B$,
12(1):43-56, 2018

[60] A. E. Sariy√ºce, C. Seshadhri, A. Pinar, and U. V. Catalyurek. Finding the hierarchy of dense subgraphs using nucleus decompositions. In $W W W$, pages 927-937, 2015.

[61] A. E. Sariy√ºce, C. Seshadhri, A. Pinar, and √ú. V. √áataly√ºrek. Nucleus decompositions for identifying hierarchy of dense subgraphs. ACM Transactions on the Web (TWEB), 11(3):16, 2017.

[62] S. B. Seidman. Network structure and minimum degree. Social networks, 1983.

[63] S. B. Seidman and B. L. Foster. A graph-theoretic generalization of the clique concept. Journal of Mathematical sociology, 6(1):139-154, 1978.

[64] N. Tatti and A. Gionis. Density-friendly graph decomposition. In Proceedings of the 24th International Conference on World Wide Web, pages 1089-1099, 2015.

[65] C. Tsourakakis. The k-clique densest subgraph problem. In $W W W$, pages $1122-1132,2015$.

[66] C. Tsourakakis, F. Bonchi, A. Gionis, F. Gullo, and M. Tsiarli. Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees. In $K D D$, pages 104-112. ACM, 2013.

[67] K. Wang, X. Cao, X. Lin, W. Zhang, and L. Qin. Efficient computing of radius-bounded k-cores. In IEEE International Conference on Data Engineering (ICDE), pages 233-244. IEEE, 2018.

[68] K. Wang, X. Lin, L. Qin, W. Zhang, and Y. Zhang. Vertex priority based butterfly counting for large-scale bipartite networks. $P V L D B, 12(10): 1139-1152,2019$.

[69] Y. Wu, R. Jin, J. Li, and X. Zhang. Robust local community detection: on free rider effect and its elimination. $P V L D B$, 8(7):798-809, 2015.

[70] S. Wuchty, Z. N. Oltvai, and A.-L. Barab√°si. Evolutionary conservation of motif constituents within the yeast protein interaction network. Nature Genetics, 35:176-179, 2003.

[71] Y. Zhang and S. Parthasarathy. Extracting analyzing and visualizing triangle k-core motifs within networks. In ICDE, pages 1049-1060, 2012.

[72] F. Zhao and A. K. Tung. Large scale cohesive subgraphs discovery for social network visual analysis. $P V L D B$, 6(2):85-96, 2012.

## APPENDIX

## A. DATASET STATISTICS

| Dataset | \# of <br> vertices | \# of <br> edges | \# of CCs | maximum <br> diameter | Power <br> -law $\boldsymbol{\alpha})$ | $\mathbf{k}_{\text {max }}$ | $\left(\mathbf{k}_{\text {max }} \boldsymbol{\Psi}\right)$ <br> -core size |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Yeast | 1,116 | 2,148 | 23 | 3 | 2.9769 | 3 | 10 |
| Netscience | 1,589 | 2,742 | 396 | 34 | 2.4053 | 171 | 20 |
| As-733 | 1,486 | 3,172 | 1 | 13 | 2.7204 | 39 | 30 |
| Ca-HepTh | 9,877 | 25,998 | 429 | 17 | 2.6472 | 456 | 32 |
| As-Caida | 26,475 | 106,762 | 1 | 23 | 2.7898 | 154 | 68 |
| DBLP | 425,957 | $1,049,866$ | 108878 | 21 | 2.3457 | 4175 | 117 |
| Cit-Patents | $3,774,768$ | $16,518,948$ | 3267 | 22 | 2.284 | 1465 | 145 |
| Friendster | $20,145,325$ | $106,570,765$ | 16342 | 28 | 2.4466 | 224532 | 707 |
| Enwiki-2017 | $5,409,498$ | $122,008,994$ | 4054 | 8 | 2.4443 | 13435 | 614 |
| UK-2002 | $18,520,486$ | $298,113,762$ | 3887634 | 24 | 2.4967 | 444153 | 944 |
| SSCA | 100,000 | $3,405,676$ | 2 | 135 | 7.2754 | 4950 | 685 |
| R-MAT | 100,000 | $2,571,986$ | 34465 | 105 | 24.653 | 2964 | 1224 |
| ER | 100,000 | $4,837,534$ | 1 | 12 | 63.6944 | 3 | 75874 |

Figure 18: Characteristics of the networks in our experiments.

In this section, we analyze the properties of the graph datasets used, according to their number of vertices and edges, the number of connected components (\# of CCs), diameter, decay factor $\alpha$ of the power law distribution (where $\alpha$ in $f(x)=x^{-\alpha}$ ), $k_{\text {max }}$, and size of $\left(k_{\max }, \Psi\right)$-core (where $\Psi$ is triangle). Fig. 18 shows these statistics. We can see that the networks have a variety of characteristics. For example, the number of $\mathrm{CCs}$ ranges from 1 to $3.8 \mathrm{M}$; the diameter varies from 3 to 135 ; the value of $\alpha$ is between 2.28 and 63.7. To conclude, the graphs we used exhibit a wide range of characteristics.

## B. ADDITIONAL PROOFS

## B. 1 Proofs for Section 4

LemmA 1 Given a graph $G(V, E)$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, Exact takes $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}+\left(n|\Lambda|+\min (n,|\Lambda|)^{3}\right) \log n\right)$ time and $\mathcal{O}(n+|\Lambda|)$ space, where $\Lambda$ is set of ( $h-1)$-clique instances in $G$ 65].

Proof. To collect the $h$-clique instances, for each vertex $v$, we compute the number of clique instances it involves. In the worst case, any $h-1$ neighbors of $v$ can form an $h$-clique with $v$, so the maximum number of clique instances it involves is $\binom{d-1}{h-1}$. As a result, collecting all the instances of the $h$-clique and building the flow network takes $O\left(n \cdot\binom{d-1}{h-1}\right)$. The number of binary search queries can be bound by $\mathcal{O}\left(\left\lceil\log \left(n^{\left|V_{\Psi}\right|} \cdot n \cdot(n-1)\right)\right]\right)=\mathcal{O}(\log n)$. In each binary search query, we adopt the Gusfield's algorithm [2] to compute the minimum st-cut of the flow network and its time cost is $\mathcal{O}\left(n \cdot|\Lambda|+\min (n,|\Lambda|)^{3}\right)$, where $|\Lambda|$ denotes the number of clique instances. In addition, to compute the minimum st-cut, the space cost of is linear to the size of flow network, i.e., $\mathcal{O}(n+|\Lambda|)$. Therefore, the lemma holds.

Lemma 2 Given a graph $G$ and an $h$-clique $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, then PeelApp takes $\mathcal{O}\left(n \cdot\binom{d-1}{h-1}\right)$ time and $\mathcal{O}(m)$ space 65 .

Proof. For each vertex, computing its clique-degree can be completed in $\mathcal{O}\left(\binom{d-1}{h-1}\right)$ time. After removing a vertex $v$, we need to update the clique-degrees of vertices which share at least one clique instance with $v$, which can be completed in $\mathcal{O}\left(\binom{d-1}{h-1}\right)$ time. After computing the clique-degrees, the clique-density of each residual subgraph can be updated in constant time. Note that computing the clique-degree of $v$ takes $m$ space as we sequentially compute the clique instances. Hence, the lemma holds.

## B. 2 Proofs for Section 5.2

Lemma 3 Given a graph $G$ and an $h$-clique $\Psi$, the connected components of CDS D have the same clique-density.
Proof. We first consider the case that $D$ has two connected components $C_{1}\left(V_{C_{1}}, E_{C_{1}}\right)$ and $C_{2}\left(V_{C_{2}}, E_{C_{2}}\right)$, and assume that their clique-densities are not the same. Then, we can easily conclude

$$
\begin{equation*}
\rho_{\text {opt }}=\frac{\mu\left(C_{1}, \Psi\right)+\mu\left(C_{2}, \Psi\right)}{\left|V_{C_{1}}\right|+\left|V_{C_{2}}\right|} \tag{6}
\end{equation*}
$$

Since $\left|V_{C_{1}}\right|$ and $\left|V_{C_{2}}\right|$ are non-negative, we can derive

$\min \left\{\frac{\mu\left(C_{1}, \Psi\right)}{\left|V_{C_{1}}\right|}, \frac{\mu\left(C_{2}, \Psi\right)}{\left|V_{C_{2}}\right|}\right\} \leq \rho_{o p t} \leq \max \left\{\frac{\mu\left(C_{1}, \Psi\right)}{\left|V_{C_{1}}\right|}, \frac{\mu\left(C_{2}, \Psi\right)}{\left|V_{C_{2}}\right|}\right\}$.

Notice that, $\rho\left(C_{1}, \Psi\right)=\frac{\mu\left(C_{1}, \Psi\right)}{\left|V_{C_{1}}\right|}$ and $\rho\left(C_{2}, \Psi\right)=\frac{\mu\left(C_{2}, \Psi\right)}{\left|V_{C_{2}}\right|}$. Therefore, if $\rho\left(C_{1}, \Psi\right) \neq \rho\left(C_{2}, \Psi\right)$, we can obtain a denser subgraph by removing the one with smaller density. This, however, contradicts the fact that $D$ is the CDS. Hence, $C_{1}$ and $C_{2}$ must be of the same density. The proof for the case where $D$ consists of more than two connected components is a straightforward extension, and is omitted here.

## B. 3 Proofs for Section 7.2

LEMMA 10 Given a graph $G$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the subgraph $S^{*}$ returned by PeelApp is a $\frac{1}{\left|V_{\Psi}\right|}$-approximation solution to the PDS problem.

Proof. Consider the PDS $D\left(V_{D}, E_{D}\right)$. After removing any vertex $v$ from $D$, the density will decrease, so we get

$$
\begin{equation*}
\rho(D, \Psi) \geq \frac{\mu(D, \Psi)-\operatorname{deg}_{D}(v, \Psi)}{\left|V_{D}\right|-1} \Leftrightarrow \operatorname{deg}_{D}(v, \Psi) \geq \rho(D, \Psi) \tag{8}
\end{equation*}
$$

Let us consider the iteration before PeelApp removes the first vertex $v$ which is in $D$. We denote the subgraph in this iteration by $O\left(V_{O}, E_{O}\right)(D \subseteq O)$. Since PeelApp works in a greedy manner, we can conclude that, for each vertex $u \in O, \operatorname{deg}_{O}(u, \Psi) \geq$ $\operatorname{deg}_{O}(v, \Psi) \geq \operatorname{deg}_{D}(v, \Psi) \geq \rho(D, \Psi)$. As a result, we have $\mu(O, \Psi)=\frac{1}{\left|V_{\Psi}\right|} \sum_{u \in O} \operatorname{deg}_{G}(u, \Psi) \geq \frac{1}{\left|V_{\Psi}\right|} \cdot\left|V_{O}\right| \cdot \rho(D, \Psi)$. Then, the density of $O$ is

$$
\begin{equation*}
\rho(O, \Psi)=\frac{\mu(O, \Psi)}{\left|V_{O}\right|} \geq \frac{1}{\left|V_{\Psi}\right|} \cdot \rho(D, \Psi)=\frac{\rho_{o p t}}{\left|V_{\Psi}\right|} \tag{9}
\end{equation*}
$$

Since $O$ is one of the $n$ residual subgraphs and $S^{*}$ is the densest one, we have $\rho\left(S^{*}, \Psi\right) \geq \rho(D, \Psi) \geq \frac{\rho_{o p t}}{\left|V_{\Psi}\right|}$.

THEOREM 2 Given a graph $G$ and a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the algorithm PExact correctly finds the PDS of $G$ w.r.t. patterndensity of $\Psi$.

We first prove the correctness of the criterion for deciding when to stop the binary search. Let $\rho\left(G\left[\Gamma_{1}\right], \Psi\right)$ and $\rho\left(G\left[\Gamma_{2}\right], \Psi\right)$ be the pattern-density of any two arbitrary subgraphs $G\left[\Gamma_{1}\right]$ and $G\left[\Gamma_{2}\right]$ of $G$, where $\Gamma_{1}$ and $\Gamma_{1}$ represent their vertex sets, respectively. We show that if their density values are different, their difference cannot be arbitrary small.

LemmA 12. For any two sets of vertices $\Gamma_{1}$ and $\Gamma_{2} \subseteq V$, if $\rho\left(G\left[\Gamma_{1}\right], \Psi\right) \neq \rho\left(G\left[\Gamma_{2}\right], \Psi\right)$, then their difference is at least $\frac{1}{n(n-1)}$.

Proof. For any two non-empty sets of vertices $\Gamma_{1}, \Gamma_{2} \subseteq V$, their pattern-density difference is

$$
\begin{align*}
& \Delta=\left|\rho\left(G\left[\Gamma_{1}\right], \Psi\right)-\rho\left(G\left[\Gamma_{2}\right], \Psi\right)\right|=\left|\frac{\mu\left(G\left[\Gamma_{1}\right], \Psi\right)}{\left|\Gamma_{1}\right|}-\frac{\mu\left(G\left[\Gamma_{2}\right], \Psi\right)}{\left|\Gamma_{2}\right|}\right| \\
& =\left|\frac{\mu\left(G\left[\Gamma_{1}\right], \Psi\right)\left|\Gamma_{2}\right|-\mu\left(G\left[\Gamma_{2}\right], \Psi\right)\left|\Gamma_{1}\right|}{\left|\Gamma_{1}\right|\left|\Gamma_{2}\right|}\right| \tag{10}
\end{align*}
$$

, which is larger than 0 , since $\rho\left(G\left[\Gamma_{1}\right], \Psi\right) \neq \rho\left(G\left[\Gamma_{2}\right], \Psi\right)$.

If $\left|\Gamma_{1}\right|=\left|\Gamma_{2}\right|$, then $\Delta \geq \frac{1}{n}$; otherwise, since $0<\left|\Gamma_{1}\right|\left|\Gamma_{2}\right| \leq$ $n(n-1)$, we have $\Delta \geq \frac{1}{n(n-1)}$. Hence, the lemma holds.

The lemma above implies that, during the binary search process, if the distance between the lower and upper bounds is at most $\frac{1}{n(n-1)}$, then we can stop the binary search.

Next, we discuss the capacity of the minimum st-cut. For ease of presentation, we introduce a notation, $\Psi[R, i]$, to indicate the number of pattern instances that involve exactly $i\left(1 \leq i \leq\left|V_{\Psi}\right|\right)$ vertices from a given set $R$ of vertices.

LemmA 13. Given a flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$ constructed by construct+, let $\left(\mathcal{S}, \mathcal{T}\right.$ ) denote its minimum st-cut, $\mathcal{A}_{1}=\mathcal{S} \bigcap \mathcal{A}$, $\mathcal{B}_{1}=\mathcal{S} \cap \mathcal{B}, \mathcal{A}_{2}=\mathcal{T} \cap \mathcal{A}$, and $\mathcal{B}_{2}=\mathcal{T} \cap \mathcal{B}$. Then, the capacity of the minimum st-cut is

$$
\begin{equation*}
\Phi+\alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right|+\Pi \tag{11}
\end{equation*}
$$

where $\Phi=\sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)$, and $\Pi=\sum_{i=1}^{\left|V_{\Psi}\right|-1} i \cdot \Psi\left[\mathcal{A}_{1}, i\right]$.

Proof. We consider two different cases as follows.

i) $\mathcal{A}_{1}=\emptyset$ : In this case, $\mathcal{B}_{1}$ must be empty. This is because, if $\mathcal{B}_{1} \neq$ $\bar{\emptyset}$, the capacity of the st-cut must be larger than the situation when both $\mathcal{A}_{1}$ and $\mathcal{B}_{1}$ are empty sets, so we have $\mathcal{B}_{1}=\emptyset$. In other words, $\mathcal{S}=\{s\}, \mathcal{T}=\mathcal{A} \cup \mathcal{B} \cup\{t\}$. It is easy to conclude that the lemma holds, as the capacity of the st-cut is $\sum_{v \in \mathcal{A}_{2}} \operatorname{deg}_{G}(v, \Psi)=\sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)=\Phi$. ii) $\mathcal{A}_{1} \neq \emptyset$ : In this case, we need to consider four possible parts of the overall st-cut capacity:

(1) the capacity of the edges from the source node $s$ to nodes in $\mathcal{A}_{2}$, which is $\sum_{v \in \mathcal{A}_{2}} \operatorname{deg}_{G}(v, \Psi)=\sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)=\Phi$.

(2) the capacity of the edges from nodes in $\mathcal{A}_{1}$ to the sink node $t$, which is $\alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right|$.

(3) the capacity of edges from nodes in $\mathcal{B}_{1}$ to nodes in $\mathcal{A}_{2}$. Consider a specific node (i.e., a pattern instance) in $\mathcal{B}_{1}$ and let $X$ ( $|X|=\left|V_{\Psi}\right|$ ) be the set of its vertices. If $X \subseteq \mathcal{A}_{1}$, then this node and its vertices are in the same partition $\mathcal{S}$ and thus we skip it directly. If $\left|X \cap \mathcal{A}_{1}\right|=i\left(1 \leq i \leq\left|V_{\Psi}\right|-1\right)$,then the capacity of all the patterns, whose vertex sets are $X$, is $\mu(G[X], \Psi)\left(\left|V_{\Psi}\right|-1\right)\left(\left|V_{\Psi}\right|-i\right)$, where $\mu(G[X], \Psi)$ equals to the size of this group.

(4) the capacity of edges from nodes in $\mathcal{A}_{1}$ to nodes in $\mathcal{B}_{2}$. Consider a specific node (i.e., a pattern instance) in $\mathcal{B}_{2}$ and let $X$ ( $|X|=\left|V_{\Psi}\right|$ ) be the set of its vertices. Again, if $X \subseteq \mathcal{A}_{2}$, then this node and its vertices are in the same partition $\mathcal{T}$ and thus we skip it directly. If $\left|X \cap \mathcal{A}_{2}\right|=\left|V_{\Psi}\right|-i\left(1 \leq i \leq\left|V_{\Psi}\right|-1\right)$, then $\left|X \cap \mathcal{A}_{1}\right|=i$ and the capacity is $i \cdot \mu(G[X], \Psi)$, where $\mu(G[X], \Psi)$ equals to the size of this group.

Notice that, for each node of $\mathcal{B}$, if its vertices come from both $\mathcal{A}_{1}$ and $\mathcal{A}_{2}$, it will be considered by both parts (3) and (4). However, since $1 \leq i \leq\left|V_{\Psi}\right|-1$, we always have $\mu(G[X], \Psi)\left(\left|V_{\Psi}\right|-\right.$ $1)\left(\left|V_{\Psi}\right|-i\right) \geq i \cdot \mu(G[X], \Psi)$. As a result, for any node with vertex set $X$ in part (3), if it shares at least one vertex with $\mathcal{A}_{2}$, we can move the node of $X$ into $\mathcal{B}_{2}$ to reduce the capacity, so we do not need to consider the capacity from part (3).

By summing up the capacity from parts (1), (2), and (3), we get the overall capacity as shown in Eq 11). Hence, the lemma holds for these two cases.

We further present another lemma, which theoretically shows the correctness of the binary search in CoreExact.

LemmA 14. Consider a flow network $\mathcal{F}$ built on $G$,

1. if there is a subgraph with vertex set $Y$ s.t. $\rho(G[Y], \Psi)>\alpha$, then any minimum st-cut $(\mathcal{S}, \mathcal{T}$ ) of $\mathcal{F}$ has $\mathcal{S} \backslash\{s\} \neq \emptyset$;
2. if there does not exist a subgraph with vertex set $Y$ such that $\rho(G[Y], \Psi)>\alpha$, then the minimum st-cut satisfies that $\mathcal{S}=\{s\}$ and $\mathcal{T}=\mathcal{A} \cup \mathcal{B} \cup\{t\}$.
Proof. We sequentially prove these two cases.

First case: We prove it by contradiction. Suppose that there is a subgraph with vertex set $Y$ such that $\rho(G[Y], \Psi)>\alpha$ and the minimum st-cut is achieved by $(\{s\}, \mathcal{A} \cup \mathcal{B} \cup\{t\})$. In this case the capacity of the minimum st-cut is

$$
\begin{equation*}
\sum_{v \in \mathcal{A}} \operatorname{deg}_{G}(v, \Psi)=\left|V_{\Psi}\right| \mu(G, \Psi) \tag{12}
\end{equation*}
$$

We now consider another different st-cut $(\mathcal{S}, \mathcal{T})$, where $\mathcal{S}=\{s\} \cup \mathcal{A}_{1} \cup$ $\mathcal{B}_{1}, \mathcal{A}_{1}=Y, \mathcal{B}_{1}$ is the set of groups of pattern instances formed by vertices in $\mathcal{A}_{1}$, and $\mathcal{T}$ contains the rest nodes in the network $\mathcal{F}$. Then, the capacity of this st-cut is exactly Eq (11).

Since we assume that the minimum st-cut is achieved by $(\{s\}, \mathcal{A} \cup$ $\mathcal{B} \cup\{t\})$, the relationship between Eqs 11 and $\sqrt{12}$ can be represented as

$\sum_{v \in \mathcal{A}} \operatorname{deg}_{G}(v, \Psi) \leq \sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)+\alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right|+\sum_{i=1}^{\left|V_{\Psi}\right|-1} i \cdot \Psi\left[\mathcal{A}_{1}, i\right]$.

The left part of $\mathrm{Eq}$ 133 can be rewritten as

$$
\sum_{v \in \mathcal{A}} d e g_{G}(v, \Psi)=\sum_{v \in \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)+\sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)
$$

Notice that the first term of the right part of $\mathrm{Eq} 14$ is

$$
\begin{equation*}
\sum_{v \in \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)=\sum_{i=1}^{\left|V_{\Psi}\right|-1} i \cdot \Psi\left[\mathcal{A}_{1}, i\right]+\left|V_{\Psi}\right| \cdot \Psi\left[\mathcal{A}_{1},\left|V_{\Psi}\right|\right] \tag{15}
\end{equation*}
$$

By considering the two equations above, we can simplify the inequation of $\mathrm{Eq}$ (13) as

$$
\begin{equation*}
\left|V_{\Psi}\right| \cdot \Psi\left[\mathcal{A}_{1},\left|V_{\Psi}\right|\right] \leq \alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right| \tag{16}
\end{equation*}
$$

Since $\left|V_{\Psi}\right| \geq 1,\left|V_{\Psi}\right| \cdot \Psi\left[\mathcal{A}_{1},\left|V_{\Psi}\right|\right]=\mu(G[Y], \Psi)$, and $\left|\mathcal{A}_{1}\right|=|Y|$, we can conclude that $\rho(G[Y], \Psi)=\frac{\mu(G[Y], \Psi)}{|Y|} \leq \alpha$, which contradicts the assumption. Hence the first case holds.

Second case: We also prove by contradiction. Suppose that there does not exist a subgraph with vertex set $Y$ such that $\rho(G[Y], \Psi)>\alpha$, and the st-cut $(\{s\}, \mathcal{A} \cup \mathcal{B} \cup\{t\})$ is not the minimum st-cut. Notice that the capacity of this st-cut is $\sum_{v \in \mathcal{A}} \operatorname{deg}_{G}(v, \Psi)$.

By Lemma 13, for any minimum st-cut $(\mathcal{S}, \mathcal{T})$, its capacity is $\sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)+\alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right|+\sum_{i=1}^{\left|V_{\Psi}\right|-1} i \cdot \Psi\left[\mathcal{A}_{1}, i\right]$.

As a result, we have

$\sum_{v \in \mathcal{A}} \operatorname{deg}_{G}(v, \Psi) \geq \sum_{v \notin \mathcal{A}_{1}} \operatorname{deg}_{G}(v, \Psi)+\alpha \cdot\left|V_{\Psi}\right| \cdot\left|\mathcal{A}_{1}\right|+\sum_{i=1}^{\left|V_{\Psi}\right|-1} i \cdot \Psi\left[\mathcal{A}_{1}, i\right]$.

We notice that $\mathrm{Eq} 17$ is very similar to Eq 13), so we can further analyze it using the similar analysis above and finally derive that $\mu(G[Y], \Psi)>\alpha|Y|$. This contradicts the assumption. Hence, the second case holds.

Therefore, Theorem 2 is proved.

LEMMA 11 Given a graph $G$, a pattern $\Psi\left(V_{\Psi}, E_{\Psi}\right)$, the flow networks built by PExact (lines 5-12) and construct+ have the same capacity for their minimum st-cut.

Proof. To prove the lemma, let us revisit the proof of Lemma 13 which considers two cases. Let the flow networks built by PExact (lines 5-12) and construct + be $\mathcal{F}$ and $\mathcal{F}+$ respectively. We show that, for each case, the minimum st-cuts of $\mathcal{F}$ and $\mathcal{F}+$ are the same. The case " $\mathcal{A}_{1}=\emptyset$ " obviously holds as all the pattern groups are in the same partition $\mathcal{T}$.

For the other case " $\mathcal{A}_{1} \neq \emptyset$ ", the capacity consists of four parts. The first two parts holds as they do not consider the patterns. For part (3), in the proof of Lemma 13 when considering a specific pattern instance with vertex set $X$, we have considered all the patterns which share the set of vertices. Let $g$ be the group of pattern instances with vertex set $X$. Then, we can observe that $\mu(G[X], \Psi)=|g|$. Thus, after grouping these pattern instances and increasing the capacity of the edges by $|g|$ times, the capacity of part (3) does not change. Similarly, we can prove that the capacity in part (4) remains unchanged. Hence, the lemma holds.

## C. PSEUDOCODES OF PEXACT

Algorithm 8 presents the detailed pseudocodes of PExact.

```
Algorithm 8: The algorithm: PExact.
    Input: $G(V, E), \Psi\left(V_{\Psi}, E_{\Psi}\right)$;
    Output: The PDS $D\left(V_{D}, E_{D}\right)$;
    initialize $l \leftarrow 0, u \leftarrow \max _{v \in V} \operatorname{deg}_{G}(v, \Psi)$;
    initialize $\Lambda \leftarrow$ all the pattern instances of $\Psi$ in $G, D \leftarrow \emptyset$.
    while $u-l \geq \frac{1}{n(n-1)}$ do
        $\alpha \leftarrow \frac{l+u}{2} ;$
        $V_{\mathcal{F}} \leftarrow\{s\} \cup V \cup \Lambda \cup\{t\} ; \quad / /$ build a flow network
        for each vertex $v \in V$ do
            add an edge $s \rightarrow v$ with capacity $\operatorname{deg}_{G}(v, \Psi)$;
            add an edge $v \rightarrow t$ with capacity $\alpha\left|V_{\Psi}\right|$;
        for each pattern $\psi \in \Lambda$ do
            for each vertex $v \in \psi$ do
                add an edge $v \rightarrow \psi$ with capacity 1 ;
                add an edge $\psi \rightarrow v$ with capacity $\left(\left|V_{\Psi}\right|-1\right)$;
        find minimum st-cut $(\mathcal{S}, \mathcal{T})$ from the flow network $\mathcal{F}\left(V_{\mathcal{F}}, E_{\mathcal{F}}\right)$;
        if $\mathcal{S}=\{s\}$ then $u \leftarrow \alpha$;
        else $\quad l \leftarrow \alpha, D \leftarrow$ the subgraph induced by $\mathcal{S} \backslash\{s\}$;
    return $D$;
```


## D. OPTIMIZING CORE DECOMPOSITION FOR SPECIAL PATTERNS

The core decomposition algorithm in Section 5.3 can be extended for a general pattern $\Psi$. For particular patterns, such as stars, and loops, the decomposition process above can be performed faster, because the two key steps - computing the pattern-degrees and decreasing the vertices' pattern-degrees, can be done more efficiently. In the following, we illustrate this for two kinds of commonly encountered patterns, namely star, and loop.

<img class="imgSvg" id = "lx1b0hg29xxjm0pifbr" src="data:image/svg+xml;base64,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"/>

(a) 3-star

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-18.jpg?height=149&width=158&top_left_y=1839&top_left_x=558)

(b) $(3, \Psi)$-core $(\Psi=3$-star $)$

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-18.jpg?height=149&width=154&top_left_y=1842&top_left_x=823)

(c) diamond
Figure 19: Illustrating the special patterns.

1 Star Patterns. The star pattern has been widely investigated 77 . 46]. Specifically, a star pattern consists of a star-vertex (center) with a few tail-vertices (spokes). We call a star pattern with $x$ $(x>1)$ tail-vertices an $x$-star pattern. In Figure 19(a), we depict the 3-star pattern $\Psi$. The whole graph in Figure 19. b) is an example $(3, \Psi)$-core: each vertex participates in at least three 3 -star pattern instances.

Given an $x$-star pattern, we now discuss how to efficiently perform these two key steps for a vertex $v$ during the decomposition process. Assume that $v$ has $y$ neighbors, and let $v$ 's $i$-th $(1 \leq i \leq y)$ neighbor be $u$.
1.1 Computing $v$ 's pattern-degree. There are two disjoint cases: (1) $v$ is the star-vertex and (2) $v$ is a tail-vertex. For case (1), the number of pattern instances is $\binom{y}{x}$, since any $x$ neighbors of $v$ can form a $x$-star with $v$. For case (2), the number of pattern instances is $\left.\sum \begin{array}{c}z_{i}-1 \\ x-1\end{array}\right)$, where $z_{i}$ is $u$ 's degree, since $v$ and any other $1 \leq i \leq y \wedge x \leq z_{i}$ $x-1$ neighbors of $u$ can form a $x$-star with $u$. Therefore, we have

$$
\begin{equation*}
\operatorname{deg}_{G}(v, \Psi)=\binom{y}{x}+\sum_{1 \leq i \leq y \wedge x \leq z_{i}}\binom{z_{i}-1}{x-1} \tag{18}
\end{equation*}
$$

Here, we adopt the convention that $\binom{y}{x}=0$, whenever $y<x$.

1.2 Decreasing pattern-degrees. After removing $v$, we also have two disjoint cases: (1) decreasing the pattern-degrees of $v$ 's 1hop neighbors, and (2) decreasing the pattern-degrees of $v$ 's 2-hop neighbors. Let us denote $v$ 's $i$-th $(1 \leq i \leq y)$ neighbor by $u$. For case (1), we have to compute the number of pattern instances that include both $v$ and $u$. When $v$ is the star-vertex, the number of $x$ stars that have a tail-vertex $u$ is $\binom{y-1}{x-1}$, since $u$ and any other $x-1$ neighbors of $v$ can form a $x$-star with $v$; when $v$ is the tail-vertex, the number of $x$-stars that have a star-vertex $u$ is $\binom{z_{i}-1}{x-1}$, since $v$ and any other $x-1$ neighbors of $u$ can form a $x$-star with $u$. Therefore, we decrease $u$ 's pattern-degree by $\binom{y-1}{x-1}+\binom{z_{i}-1}{x-1}$.

In case (2), $u$ must be a star-vertex and $v$ is a tail-vertex. For each neighbor $w$ of $u(w \neq v)$, we need to decrease $w$ 's patterndegree by $\binom{z_{i}-2}{x-2}$, because $v, w$, and any other $x-2$ neighbors of $u$ can form an $x$-star with $u$.

From the discussions above, we can easily conclude that, the first and second steps can be completed in $\mathcal{O}(d)$ and $\mathcal{O}\left(d^{2}\right)$ time respectively, because we only need to enumerate their 1-hop and 2-hop neighbors. Note that the values of different $\binom{y}{x}(x \leq y \leq d)$ can be precomputed in advance. Therefore, for any $x$-star pattern, the time cost of performing $k$-pattern-core decomposition can be reduced from $\mathcal{O}\left(n \cdot d^{x}\right)$ to $\mathcal{O}\left(n \cdot d^{2}\right)$.

2 Loop Patterns. For ease of exposition, we take the diamond pattern (see Figure 19.(c)) as an example to illustrate the details of these two steps. The diamond pattern has also been used in many real applications $[70,46$.

2.1 Computing $v$ 's pattern-degree. We first enumerate all the paths from $v$ to its 2-hop neighbors, and then organize these paths into $h$ groups, each of which share the same 2-hop neighbor. Then, for each group, any pair of paths can form an instance of the diamond pattern. Let the size of the $i$-th group be $y_{i}(1 \leq i \leq h)$. We thus have $\operatorname{deg}_{G}(v, \Psi)=\sum_{1<i<h \wedge y_{i}>2}\binom{y_{i}}{2}$.

2.2 Decreasing pattern-degrees. We handle the groups one by one. Consider the specific group $h_{i}$, which only has one 2-hop neighbor of $v$. If $y_{i}=1$, we skip this group as there is not any pattern instance. If $y_{i} \geq 2$, we decrease the pattern-degree of the 2-hop neighbor by $\binom{\overline{y_{i}}}{2}$. For each 1-hop neighbor in $g_{i}$, we decrease its pattern-degree by $y_{i}-1$, because each path participates in $y_{i}-1$ pattern instances.

Clearly, the time complexity of performing the two steps above is $\mathcal{O}\left(d^{2}\right)$. Hence, the time cost of performing core decomposition is reduced from $\mathcal{O}\left(n \cdot d^{3}\right)$ to $\mathcal{O}\left(n \cdot d^{2}\right)$.

## E. RESULTS ON ADDITIONAL DATASETS

Table 6 shows the additional three real datasets used in our experiments. The efficiency results are presented in Figure 20 We can observe that the results are highly similar to those presented in the main paper, so we skip the detailed description.

## F. MORE CASE STUDIES

Yeast. As [70] pointed out, the conservation of biological cellular functions across species during the evolution process is often

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=282&width=1176&top_left_y=176&top_left_x=469)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=195&width=374&top_left_y=217&top_left_x=474)

(a) Flickr

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=220&width=374&top_left_y=188&top_left_x=867)

(b) Google

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=244&width=374&top_left_y=198&top_left_x=1255)

(c) Foursquare

Figure 20: Efficiency of approximation CDS algorihms.

| Pattern | Functional classes |
| :---: | :---: |
| edge | subcellular localization |
| c3-star | cell cycle, cellular transport, <br> protein synthesis |
| 2-triangle | subcellular localization, <br> cell cycle, <br> protein synthesis |
| 4-clique | subcellular localization, <br> cellular transport, <br> protein synthesis |

(a) Functional classes $|70|$

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=339&width=293&top_left_y=524&top_left_x=623)

(b) edge (red)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=342&width=314&top_left_y=520&top_left_x=946)

(c) c3-star (blue)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=339&width=312&top_left_y=524&top_left_x=1275)

(d) 2-triangle (green)

![](https://cdn.mathpix.com/cropped/2024_06_04_52e40598569c96515525g-19.jpg?height=334&width=307&top_left_y=527&top_left_x=1619)

(e) 4-clique (cyan)

Figure 21: PDS's (vertices in colored triangles) in the yeast PPI network.

Table 6: Additional Datasets.

| Name | Vertices | Edges |
| :---: | ---: | ---: |
| Flickr | 214,698 | $2,096,306$ |
| Google | 875,713 | $4,322,051$ |
| Foursquare | $2,127,093$ | $8,640,352$ |

carried out by integrated activities of various patterns. A protein can belong to more than one functional class, and a pattern corresponds to multiple classes. Figure 21 a) shows four patterns and their corresponding functional classes for yeast proteins [70]. We studied a yeast PPI network ${ }^{6}(|V|=1,116,|E|=2,148)$, where vertices represent proteins and edges represent interactions. For each pattern, we compute the PDS, as highlighted in Figure 21 which also shows the subnetwork induced by the vertices in the union of all the PDS's, for convenience. Notice that the PDS's corresponding to different patterns have distinct shapes. Each PDS could represent a subnetwork with a specific function. Tasks such as analyzing the conservation and evolution of cellular components [70] can then be performed on these subnetworks.[^3]


[^0]:    ${ }^{1}$ We use "node" to mean "flow network node" in this paper.

[^1]:    ${ }^{4}$ For exact algorithms, bars touching the upper boundaries mean that the corresponding algorithms cannot finish within 5 days.

[^2]:    ${ }^{5}$ For approximation algorithms, bars touching the upper boundaries mean that the corresponding algorithms cannot finish within 2 days.

[^3]:    ${ }^{6}$ DIP: http://dip.doe-mbi.ucla.edu/dip/Stat.cgi

