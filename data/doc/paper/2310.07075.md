# Don't Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding 

\author{
Kexun Zhang * <br> Carnegie Mellon University <br> kexun@cmu.edu

## Lei Li

 <br> Carnegie Mellon University <br> leili@cs.cmu.edu}

Hongqiao Chen *<br>California Institute of Technology<br>harrychen@caltech.edu<br>William Yang Wang<br>UC Santa Barbara<br>william@cs.ucsb.edu


#### Abstract

Instruction-tuned large language models (LLMs) excel at many tasks but often fail to use external tools due to complicated and unfamiliar syntax constraints. While extensive fine-tuning and prompting can mitigate the issue, these approaches are expensive and hard to generalize. Furthermore, because syntax constraints are only learned implicitly during fine-tuning, models still make frequent syntax errors. Motivated by the fact that these constraints can be better satisfied explicitly with constrained decoding, we propose TOOLDEC, a decoding algorithm using finite state machines to force LLMs to follow tool syntax. Our experiments show that TOOLDEC eliminates all syntax errors, achieving significantly better performance on various base models and benchmarks. More surprisingly, when applied to generalist out-of-the-box LLMs such as Mistral-Instruct, ToolDEC improves its accuracy in tool use from the initial $0 \%$ to an impressive $52 \%$, matching the performance of specialized fine-tuned models such as ToolLLM. We release our code at https://github.com/chenhongqiao/tooldec


![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-01.jpg?height=644&width=1260&top_left_y=1618&top_left_x=430)

Figure 1: On various benchmarks, ToolDEC improves both fine-tuned specialist models (ToolLLM) and generalist models (Mistral-Instruct and Vicuna). Mistral-Instruct is improved from an initial $0 \%$ to be even better than ToolLLM. ToolDEC also eliminates all syntax errors.[^0]

## 1 Introduction

Augmenting large language models (LLMs) with external tools (Mialon et al. 2023) enables them to solve complex problems. Current LLMs can utilize retrievers (Shen et al. ||2023; Gupta \& Kembhavi, 2022, Schick et al., 2023), RESTful APIs (Qin et al., 2023, Song et al. 2023), program interpreters (Chen et al. 2022; Gao et al. 2023), and various other tools. As existing tools are being modified and new tools are being created every day, it is important for LLMs to be able to use unknown tools that are not in the training set.

Out-of-the-box LLMs such as Mistral and Llama, even when instruction-tuned to be very capable on many other tasks (Jiang et al., 2023), can fail in using tools, as demonstrated by its low (and even zero) performance in Figure 1. One major reason for their bad performance is syntax errors. For example, Mistral-Instruct-7B has a syntax error rate of over $90 \%$ when using some unknown tools in ToolEval (Qin et al. 2023), which results in its $0 \%$ accuracy. Even very capable models such as GPT-4 make syntax errors on new tools. Previous approaches use extensive fine-tuning or prompting (Qin et al. 2023, Hao et al. 2023) to teach LLMs tool syntax, which reduces syntax errors but not all of them. In Figure 1, although the fine-tuned ToolLLM makes significantly fewer syntax errors than the general Mistral-Instruct, it still has an over $20 \%$ error rate. We show examples of common modes of failure in Figure 2 .

We argue that fine-tuning or prompting is neither optimal nor enough to enforce syntax constraints, because general instruction-tuned models already have a "rough idea" of what tool to use in different scenarios. Fine-tuning or prompting approaches expect the model to learn and follow syntax constraints from tool use examples in training data or in-context demonstration. However, these constraints can be explicitly modeled with symbolic rules. Directly applying these rules in model generation can be more accurate than either fine-tuning or prompting, as they do not need extra compute or prompting while guaranteeing the model is syntax error-free.

To this end, we propose ToolDEC, a decoding algorithm guided by a finite-state machine (FSM) to ensure LLMs invoke tools properly. We automatically convert tool syntax schemas to an equivalent finite-state machine. During decoding, ToOLDEC transitions from state to state as decoding progresses. At each decoding step, TOOLDEC samples from the valid subset of tokens allowed by the tool syntax. This way, TOOLDEC is able to always generate syntactically correct tool calls. Since syntax constraints are enforced by the FSM, there's no need for them to appear in prompts. We further use an LLM to simplify the tool description prompt by removing the syntax constraints from it. ToolDEC is model-agnostic and can be combined with any base LLM. More examples comparing TOOLDEC and other tool LLMs can be found in Appendix A.1.

![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-02.jpg?height=479&width=1350&top_left_y=1655&top_left_x=385)

Figure 2: Common syntactical modes of failure of tool-use LLMs include reasoning format error, tool name error, and tool argument error. Even fine-tuned models have a significant level of syntax error.

We evaluate ToolDec by applying it to 5 base models and evaluating it on 4 benchmarks. On base models that are specifically fine-tuned for tool use purposes, such as ToolLLM Qin et al. (2023) and ToolkenGPT Hao et al. (2023), ToolDEC significantly improves their accuracy by at most 21 points and greatly reduce the number of tokens in the output. On base models that initially have zero accuracy on ToolBench Qin et al. (2023) such as Mistral Jiang et al. (2023) and Vicuna Chiang et al. (2023), TOOLDEC improves their accuracy from 0 to at most $60 \%$.

Our contributions can be summarized as follows:

- We propose ToolDEC, a constrained decoding algorithm for LLMs to use tools without syntax errors. TOOLDEC can off-load syntax constraints to an FSM, and eliminate all syntax errors.
- We verify ToolDEC's superior performance by combining it with 5 base models and evaluating on 4 benchmarks. Our experiments show TOOLDEC improves all base models significantly.
- We further compare TOOLDEC on generalist models with specialized tool-using models. We find that ToOLDEC, as an alternative, can achieve comparable performance while retaining the model's performance on other reasoning benchmarks.


## 2 Related Work

Fine-tuning language models to use tools. Language models can be fine-tuned to use tools with data that contain interleaving text and tool use. Earlier studies make language models use a single tool like a retrieval module (Borgeaud et al. 2022; Guu et al. 2020) or a search engine (Nakano et al. 2021) by fine-tuning. Recent advances in tool-augmented language models that use multiple tools (Schick et al., 2023, Parisi et al., 2022) also fine-tune language models to use tools including QA models, translation models, calculators, and search engines. ToolkenGPT (Hao et al. 2023) proposes to use several special tokens to represent tools and only tunes the embeddings of the tokens so that new tool adoption can be more efficient. However, fine-tuning approaches cannot adapt to new tools without training data.

In-context learning for tool use. Language models can learn from in-context examples Brown et al. 2020) and follow instructions (Ouyang et al. 2022). This makes it possible to simply put the descriptions of tools in the prompt and ask language models to use them. Recent works put tool documentation and demonstration in the prompt to use neural models (Shen et al., 2023), RESTful APIs (Qin et al., 2023, Song et al. 2023), program interpreters (Chen et al. 2022; Gao et al., 2023) and many other tools to solve problems. In-context learning does not need extra model tuning to use new tools. However, the syntax and semantic constraints of new tools are entangled in the prompts, resulting in longer prompts and syntax errors.

Constrained decoding and finite-state machines. Previous constrained decoding methods reduce the large search space of lexically constrained decoding with finite-state machines (Anderson et al. 2017), grouping together similar candidates (Hokamp \& Liu, 2017), and better search algorithms (Miao et al. 2019, Lu et al. 2021, 2022). However, lexical constraints are not expressive enough to regulate tool calls. While finite-state machines have to be weighted and probabilistic to deal with the soft constraints in natural language (Eisner, 2002; Rastogi et al. 2016), the constraints for syntactic tool calls are hard constraints that are much easier for FSMs. Grammar-constrained decoding has been used for structural NLP tasks such as code generation Yin \& Neubig (2017), semantic parsing Stengel-Eskin et al. (2024), coreference resolution, POS tagging and many others Geng et al. (2023). Using external tools is different from these tasks because the syntax and semantics of tools are unknown to the model until inference time.

## 3 Proposed Method: ToolDEC

To use a tool, an LLM must first refer to an existent tool by its designated name. Then, it needs to generate arguments that adhere to the grammar of that tool (e.g. a JSON Schema). Motivated by the fact that it is easy to verify the syntax of a tool call using a finite-state machine (FSM), we propose ToOLDEC, a LLM tool-use framework that uses an FSM to eliminate syntax errors.During each decoding step, the model samples from a subset of the vocabulary that only contains syntactically correct tokens. This subset is dictated by the current state of the FSM and the sampled token determines the next state to transition to.

We designed an algorithm to automatically construct the described FSM from tool documentation recursively (Section 3.1). It takes advantage of machine-readable endpoint documentation (e.g., OpenAPI), which is very common in software engineering. In addition to constructing an FSM, we use another LLM to remove syntax constraints from the tool documentation (Section 3.2). The goal of this step is to shorten the extensive prompts and demonstrate that FSM on its own is sufficient to guarantee syntactically correct tool calls. An example of constrained decoding with ToolDEC is provided in Section 3.3

![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-04.jpg?height=735&width=1379&top_left_y=245&top_left_x=362)

Figure 3: Converting a tool documentation to a simplified prompt and an FSM. The caption on each state in the FSM denotes the valid token set at that step. FSM will transition to the corresponding state when the token on that edge is generated by the LLM.

### 3.1 Construction of TOOLDEC FSM

Definition of TOolDEC FSM. An FSM is a 5-tuple $\left(S, V, g, s_{0}, R\right)$, consisting of a finite state set $S$, an alphabet $V$, a transition function $g: S \times V \rightarrow S$, an initial state $s_{0}$ and a set of accepting states $R$. In our case, $S$ and $g$ are constructed from the tool documentation. $V$ is the token vocabulary of the language model. $R$ corresponds to pre-defined tokens that can determine the LM has completed the task, like ' $<$ EOS $>$ '.

FSM-constrained decoding. At each decoding step $t$, ToolDEC maintains a current state $s$. The LLM can only sample from the tokens permitted by the FSM, i.e. the tokens for which $g(s, \cdot)$ is defined. These permitted tokens are a subset of $V$ and we denote them as $V_{s}$. After generating one token $a$, ToolDEC transits to another state $g(s, a)$ specified by the FSM transition function. The permitted tokens for each state can be the full vocabulary, or a valid subset corresponding to tool names and argument types. With the next token, we move on to the next decoding step and transition the current state $s$ to the next state $g(s, a)$. The pseudo-code of this algorithm is listed in Algorithm 1

Constructing FSM from Tool Documentation. In this paper, we focus on the automatic construction of guidance FSM for REST APIs and Python functions. With the following algorithm, we were able to cover $16,000+$ tools across 4 different domains, representing various tool-use applications explored in previous studies (Qin et al. 2023, Hao et al. 2023, Yuan et al. 2024). This approach can be extended should future applications emerge because a finite state machine can be algorithmically constructed for any regular grammar. Our FSM construction algorithm assumes that the syntax grammar of a tool is documented in a machine-readable format, for example, in the OpenAPI specification.

In Figure 3, we illustrate an automatically constructed FSM from a JSON Schema. The nodes represent the states. The caption inside a state $s$ illustrates the valid tokens $V_{s}$ and the edges represent possible transitions based on the token sampled. The generation starts at an initial state and stops with an accepting state (the green nodes). For each parameter of a tool, we create a sub-machine for its syntax. For example, the first row with 4 nodes in Figure 3 is the sub-machine for the parameter "from". Each sub-machine has two parts - one for parameter names and one for parameter values. Name sub-machines (with blue backgrounds) only accept one string - the name for a particular parameter. Value sub-machines (with pink backgrounds) accept strings that follow the format of the parameter value. For example, for the parameter "adult", it only accepts digit strings that end with a comma. After generating the name and value of a parameter, an LLM might generate some end-of-generation tokens (with orange backgrounds, such as ', ' or ' \} ') to move on to the next parameter.

For required parameters, their sub-machines must be passed through, while for optional parameters, there's a skip connection that allows the model to go around it without generating an optional parameter (for example, the parameter "type" in Figure 3). Note that this algorithm can also work for nested parameters (parameters that have subfields), because we can just apply the process recursively.

Based on $V_{s}$, we pre-compute the token mask for every $s \in S$ during construction to allow $\mathcal{O}(1)$ filtering during inference. This construction process only needs to be executed once for every tool, and can be cached. The size of the FSM scales linearly as the number of arguments of a tool increases, which is the same as the number of tokens if prompting were used. However, our approach is much more efficient because its computation and memory overhead is negligible (less than $0.1 \%$ ) when compared to the GPU cost of LLMs.

Linking FSMs for Guided Reasoning and Tool Selection. Tool enhanced problem solving involves multiple steps of reasoning and selecting tools for each step. This can be guided by linking multiple FSMs together. For guided tool selection, we tokenized the names of all available tools and constructed a tree structure similar to a trie (Fredkin, 1960). Every leaf node has a $g$ defined to transition to the $s_{0}$ of the FSM for that tool. An example can be seen in Figure 4. As the number of tools increases (for example, in the KAMEL (Kalo \& Fichtel, 2022) benchmark, toolset size reaches 234), the trie could automatically expanded by adding more nodes to the tree. Reasoning syntax, such as ReAct (Yao et al. 2023), can also be incorporated into the FSM as showns in Figure 4

![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-05.jpg?height=363&width=1363&top_left_y=1022&top_left_x=381)

Figure 4: Linking multiple FSMs to guide the LLM through reasoning and tool selection. After a tool is selected, the FSM then transitions to start generating arguments.

### 3.2 Prompt Compression

Since syntax constraints can be effectively handled by our decoding algorithm, we created a prompt compression pipeline to remove these constraints from the tool documentation. For each tool, we prompted an LLM to rewrite the tool documentation while ignoring the hierarchical structure of JSON schema and the typing of each parameter. Resulted was a simple list of parameters with concise descriptions. This list of parameters is necessary for the tool-use LLM to match the context information it has at hand with a tool. We show an example of the compressed prompt in Figure 3 . The prompt we used to rewrite the tool documentation can be found in Appendix A.3.

By removing syntax information from the prompt, we reduce the number of tokens and show that syntax constraints are more efficiently handled by decoding algorithms rather than prompting.

### 3.3 Inferencing with FSM and Compressed Prompt

Inferencing with ToolDec involves using the ToolDec FSM in conjunction with the compressed prompt. First, the compressed prompt, succinct and free of syntax constraints, is provided to the LLM to begin generation. At each step $t$, we do not directly sample from the next token distribution $P\left(x_{t} \mid x_{1 . . t-1}\right)$ calculated by the LLM. Instead, we zero out the probabilities of invalid tokens for which the transition function is undefined, and normalize the probabilities,

$$
\tilde{P}\left(x_{t}=a\right)= \begin{cases}\frac{P\left(x_{t}=a \mid x_{1 . . t-1}\right)}{\sum_{a^{\prime} \in V_{s}} P\left(x_{t}=a^{\prime} \mid x_{1 . . t-1}\right)}, & \exists g(s, a) \\ 0, & \text { otherwise }\end{cases}
$$

The next token $a$ is then sampled from the modified distribution $\tilde{P}\left(x_{t} \mid x_{1 . . t-1}, s\right)$.

We show an example in Figure 5. First, the semantic description of flight_search is provided to the LLM. At step $n$, the current state $s_{n}$ only permits the generation of integers or comma, which corresponds to adult's data type integer. By multiplying the token mask with $P$, we obtain $\tilde{P}$ where the probability of all other tokens are zeroed out. From the shifted probability, we sampled ' , '. As we moves on to step $n+1$, the FSM also transitions to $s_{n+1}$ following $g\left(s_{n},{ }^{\prime}\right.$, ' $)$. Here with the zoom in bubble, we show the actual FSM that accepts the parameter name "child", which only accepts " " as the first token. A similar process repeats until the LLM finishes generating a tool call.

Step N

Step $\mathrm{N}+1$
![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-06.jpg?height=250&width=636&top_left_y=628&top_left_x=384)

Compressed Prompt

flight_search: ...

Generated Output

... \{

"from": "LHR", "to": "DXB", "adult": 2 ,
![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-06.jpg?height=372&width=1270&top_left_y=860&top_left_x=466)

Figure 5: A decoding step using ToolDEC FSM. The invalid tokens at the current FSM state are masked out from the token probabilities.

## 4 Experiment

As a model-agnostic decoding algorithm, ToOLDEC can be applied to any LLM with token logits access. We evaluate ToolDeC by applying it to 5 base LLMs on 4 benchmarks. In this section, we first introduce the base LLMs (Section 4.1) and benchmarks we evaluate ToolDeC on (Section 4.2). Then we report our main results (Section 4.3) and further ablate why ToolDEC can be a good complement/alternative for fine-tuning and prompting (Section 4.4).

### 4.1 Base LLMs

We evaluate how ToolDEC can improve 5 LLMs - ToolLLM (Qin et al., 2023), ToolkenGPT (Hao et al., 2023), RestGPT (Song et al., 2023), Vicuna-7B (Chiang et al., 2023), and Mistral-7B-Instruct (Jiang et al., 2023). The first three are "specialists", particularly designed/fine-tuned for tool-use benchmarks in the same papers that proposed the models. We evaluate them on their specialized benchmarks. Additionally, we evaluate Llama and Mistral-7B, two "generalist" instruction-tuned models to demonstrate that TOOLDEC can also work on base models that are not particularly designed for tool use. These two models are not fine-tuned on the benchmark's training sets. Therefore, their initial performance without the TOOLDEC is very poor compared to their specialist counterparts.

ToolLLM (Qin et al., 2023). ToolLLM is a specialist LLaMA-7B model fine-tuned to use tools on RapidAPI (https://rapidapi.com/). Given each task, ToolLLM is prompted with the documentation of relevant tools. It is then instructed to generate a natural language rationale, a tool to use, and the tool's inputs. This process continues for several iterations until the path of tool calls leads to an answer or the model gives up. ToolLLM can either generate a single path of tool calls (denoted as ToolLLM+ReAct) or run a tree search to find the best path (denoted as ToolLLM+DFSDT). Note that ToolLLM is fine-tuned with the same formatted data synthesized with the same process as its evaluation benchmark, ToolEval.

ToolkenGPT (Hao et al., 2023). ToolkenGPT is a specialist Llama-33B model with an additional vocabulary of tokens learned for tools. The original weights of Llama are frozen while the additional
tokens are learned. These tokens for tools, or toolkens, each correspond to a tool. The text spans of tool use in the training data are replaced with toolkens, so that the model can learn when to start a tool call. Although ToolkenGPT is much more efficient than full fine-tuning a model, it still needs to learn the representations of all tools in the evaluation set.

RestGPT (Song et al. 2023). RestGPT learns to use RESTful APIs from in-context tool documentation. RestGPT utilizes several different LLM-based modules to make natural language plans, select which APIs to use, generate tool calls and parse results from them.

Mistral-Instruct (Jiang et al., 2023) and LLaMA (Touvron et al., 2023). Mistral-Instruct-7B and LLaMA-7B are generalist 7B LLMs tuned without tool-specific fine-tuning. When directly evaluated on ToolEval with syntax constraints in the prompt, Mistral cannot solve any tests. This suggests that Mistral is not able to follow syntax constraints when prompted. The same is true for LLaMA-7B. We choose them as base models to show when syntax constraints are taken care of by TOOLDEC; even a generalist model can perform well on tool-using.

### 4.2 Benchmarks and Metrics

We evaluate the baselines and ToolDEC on four benchmarks - ToolEval (Qin et al., 2023), FuncQA (Hao et al., 2023), KAMEL (Kalo \& Fichtel, 2022), and RestBench (Song et al. 2023). We evaluate the performance of all base models with and without ToolDEC. Other than correctness metrics, we also measure syntax error rate, the proportion of tasks on which the models make syntax errors. Our experiments are conducted on NVIDIA A6000 GPUs within 60 GPU hours.

ToolEval (Qin et al., 2023). ToolEval is a dataset proposed in the ToolLLM paper. Tasks in it involve 10000+ publicly available REST APIs. We use its more complex subsets to evaluate our method I2-Category and I3-Instruction. They contain tasks that need complex and unseen tools from multiple categories to solve. On average, a task in these subsets needs more than 7 tools to solve. ToolEval has two main metrics: pass rate measures the percentage of tasks for which the model reaches an answer within limited reasoning steps. win rate compares the quality and correctness of the models' answers to the reference answers from ChatGPT. Qin et al. (2023) finds that these automatic metrics have a high correlation of $75.8 \%$ with human annotators. Since ToolEval requires extensive prompting of tool documentation, we measure tok / tool, the average number of tokens required for each tool, to see how much TOOLDEC can shorten the prompts.

FuncQA (Hao et al., 2023). FuncQA tests LLMs' ability in numerical reasoning tasks with 68 math problems. LLMs are required to produce a numerical answer using a few of the 13 arithmetic operations as tools (e.g. multiply, power, $1 \mathrm{~cm}$ ). The accuracy is determined by measuring the percentage of problems for which a correct answer is produced, with a $0.1 \%$ error tolerance. On average, a problem in FuncQA requires 2.78 tool calls to solve. Following Hao et al. (2023), we report results of other baselines, including ChatGPT without tools, LLaMA with chain-of-thought and tools, LLaMA with ReAct and tools.

KAMEL (Kalo \& Fichtel, 2022). KAMEL is a question-answering dataset containing a total of 234 knowledge relations that resemble the characteristics of APIs (e.g. number_of_children). The tools in KAMEL are also more complex and diverse because their number of arguments varies from 1 to 3 , and their types include strings, locations, dates, numbers, and other ad-hoc types.

RestBench (Song et al. 2023). RestBench consists of tasks in real-world scenarios, including TMDB, a movie website, and Spotify, an online music player. These tasks directly come from real-user instructions and require multiple tools in the form of RESTful APIs to solve. We use the correct path rate (CP\%) proposed by the original paper as the metric to measure accuracy. Correct path rate is the proportion of outputs that contain the correct tool call path annotated by humans.

### 4.3 Results

We list our main results in Table 1 Each green row contains the performance of TooLDEC applied to the base model in the previous row. Note that on KAMEL, syntax error rate is not available. This is because KAMEL tests the model's ability to select the right tool and does not involve tool arguments and execution. For the same reason, ToolkenGPT + ToolDec is also not available. Also, the win rates on ToolEval are not available for ChatGPT + ReAct, because it is the baseline compared against when computing the win rates. Several observations can be made about the results:

Table 1: When applied to various baselines on different benchmarks, TooLDEC significantly improves the model generations with fewer tokens in the prompt. It also completely eliminates all syntax errors. "err." is short for syntax error rate. "tok" is short for the average number of tokens for each tool.

|  | ToolEval : I2-Category |  |  |  | ToolEval: I3-Instruction |  |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | $\operatorname{win} \% \uparrow$ | pass $\% \uparrow$ | tok $\downarrow$ | err. $\% \downarrow$ | $\operatorname{win} \% \uparrow$ | pass $\% \uparrow$ | tok $\downarrow$ | err. $\% \downarrow$ |
| ToolLLM + ReAct | 36.5 | 30.5 | 827 | 21 | 49 | 22 | 1380 | 32 |
| + TOOLDEC | 46.5 | 47.5 | 397 | 0 | 61 | 48 | 627 | 0 <br> 0 |
| ToolLLM + DFSDT | 40.5 | 64.5 | 827 | 44 | 41 | 58 | 1380 | 49 |
| + TOOLDEC | 50.5 | 69 | 397 | 0 | 49 | 59 | 627 | 0 |
| Mistral + ReAct | 0 | 0  | 827 | 92.5 | 0  | 0 | 1380 | 93 |
| + TOOLDEC | 41 | 26 | 397 | 0 | 53 | 32 | 627 | 0  |
| Mistral + DFSDT | 0  | 0 | 827 | 100 | 0  | 0  | 1380 | 100 |
| + TOOLDEC | 52 | 50.5 | 397 | 0 | 60 | 35 | 627 | 0 |
| ChatGPT + ReAct | n.a. | 39 | 827 | 5 | n.a. | 23 | 1380 | 9 |
| ChatGPT + DFSDT | 63.0 | 64.5 | 827 | 28 | 70 | 60 | 1380 | 47 |
| GPT-4 + ReAct | 53.5 | 67.5 | 827 | ![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-08.jpg?height=43&width=119&top_left_y=838&top_left_x=1077) | 71 | 40 | 1380 | 2 |
| GPT-4 + DFSDT | 57 | 69.5 | 827 | 4 | 73 | 59 | 1380 | 5 |
|  | FuncQA |  |  |  | KAMEL |  |  |  |
|  | accuracy $\% \uparrow$ |  | err. $\% \downarrow$ |  | accuracy $\% \uparrow$ |  | err. $\% \downarrow$ |  |
| LLaMA | 6 |  | 27.9 |  | 8.2 |  | $\overline{\text { n.a. }}$ |  |
| + TOOLDEC |  |  | 27.9 |  |  |  | n.a. |  |
| ToolkenGPT | 10.3 |  |  |  | 25.4 |  | {n.a. <br> n.a.} |  |
| + TOOLDEC | 13.2 |  | 0 |  |  |  |  |  |
|  | RestBench: Spotify |  |  |  | RestBench: TMDB |  |  |  |
|  | correct path $\% \uparrow$ |  | err. $\% \downarrow$ |  | correct path $\% \uparrow$ |  | err. $\% \downarrow$ |  |
| Vicuna + RestGPT | {20.6 <br> 36} |  | 7.4 |  | 15 <br> 23 |  | 23 |  |
| +TOOLDEC |  |  |  | 0 |  |  |  | 0 |
| ChatGPT | 72.3 |  |  | 3.6 |  |  |  | 3 |

TOOLDEC leads to significant improvements of all base models across multiple benchmarks. On ToolEval, ToolDec improves win rates and pass rates substantially on ToolLLM with either the ReAct or DFSDT strategies. The win rate is improved by 10 points, while the pass rate is improved by 12 on average. Particularly noteworthy is the performance of ToolLLM+DFSDT with TOOLDEC, which not only outperforms ChatGPT but also achieves performance on par with GPT-4. Similarly significant improvements are observed across other benchmarks on other base models as well.

TOOLDEC helps generalist models to match or outperform similar-sized specialist models. Without ToOLDEC, Mistral-7B cannot pass a single task on ToolEval, while ToolLLM has an average $>40 \%$ win rate and $>40 \%$ pass rate. With ToolDEC, Mistral-7B's performance on ToolEval is on par with ToolLLM + TOolDEC and even better in several cases and metrics. The same is true for FuncQA and KAMEL. When enhanced with ToolDEC, the generalist, pre-trained LLaMA-7B model's performance gets 2.2x better on FuncQA and 5.1x better on KAMEL, matching or beating the specialist ToolkenGPT.

TOoLDEC gets much better performance with shorter prompts. On ToolEval, the average number of tokens required for each tool is reduced by $58 \%$ and $69 \%$ for I2-Category and I3-Instruction. With shorter prompts, TOOLDEC is able to include more tools in the inventory without exceeding the context limit of LLMs.

All models have syntax errors. Fine-tuning or prompting can't eliminate them, but TOOLDEC can. When evaluating on the ToolEval: I3-Instruction dataset, ToolLLM + DFSDT-despite being fine-tuned with data formatted identically to that of the test data-still produces syntax errors in nearly half $(49 \%)$ of the instances. Mistral is even worse, with syntax errors occurring in over $90 \%$ of its responses. This high error rate probably explains its directly impacted its accuracy being exactly 0 . Even advanced models like ChatGPT and GPT-4, known for their capabilities, were not immune to syntax mistakes during tool interactions. The same is true for other benchmarks and other base models. When ToolDEC is applied, both specialist models like ToolLLM and generalist models stop making syntax errors.

Table 2: While tool-specialized models, such as ToolLLM, can perform as well as generalist models + TOOLDEC $(\dagger)$, their performance on other reasoning benchmarks is much lower (underlined).

|  | ToolEval (I2-Cat) | ToolEval (I2-Ins) | GSM8K | HumanEval | MBPP | BBH |
| ---: | :---: | :---: | :---: | :---: | :---: | :---: |
| ToolLLM-7B | 36.5 | 49.0 | $\mathbf{1 . 2}$ | $\underline{\mathbf{2 . 4}}$ | $\underline{\mathbf{5 . 3}}$ | $\underline{\mathbf{2 8 . 1}}$ |
| Llama-2-chat-7B $\dagger$ | 39.0 | 51.0 | 23.1 | 14.6 | 29.6 | 39.9 |
| Mistral-Ins-7B $\dagger$ | 41.0 | 53.0 | 42.0 | 43.9 | 43.4 | 50.6 |

![](https://cdn.mathpix.com/cropped/2024_06_04_4b31f047d07fc348d505g-09.jpg?height=304&width=1260&top_left_y=561&top_left_x=432)

(a) Win rates of Mistral on I2-Category and I3-(b) Win rates of ToolLLM on I2-Category and I3Instruction under four different settings. Instruction under four different settings.

Figure 6: Win rates of Mistral and ToolLLM under different settings of syntax constraints. Syntax constraints are much more helpful as decoding constraints than in-context descriptions.

### 4.4 Ablation Study

ToolDec v.s. Tool-Specialized Fine-Tuning. We argue that it's more ideal to use ToolDeC on generalist LLMs instead of fine-tuning specialist LLMs to use tools. To demonstrate that, we evaluate both the specialist ToolLLM and the generalist Llama-2-chat and Mistral-Ins on other reasoning and coding benchmarks, including GSM8K (Cobbe et al., 2021), HumanEval (Chen et al. 2021), MBPP (Austin et al. 2021), and BigBenchHard (Suzgun et al., 2022). The details of these evaluations can be found in Appendix A.4. As reported in Table 2, although the specialist ToolLLM can have comparable performance on tool-related benchmarks as ToolDEC on generalist LLMs, its performance on general reasoning or coding benchmarks is unreasonably bad. On GSM8K, it's solving only $1.2 \%$ of the problems, while Llama-2-chat, the generalist model with the same pertaining, solves $23.1 \%$. This suggests that tool-specialized fine-tuning can seriously degrade the model's general ability, probably due to catastrophic forgetting.

TooldeC vs. Prompting Syntax Constraints. We argue that removing syntax constraints in prompts doesn't harm TOOLDEC's performance. We conduct a fine-grained ablation study on two approaches (prompting and decoding) to incorporate syntax constraints with two base models ToolLLM and Mistral. We consider four different settings of syntax constraints: "no prompting, no decoding", "only decoding", "only prompting", "prompting and decoding". We evaluate the win rate of ToolLLM and Mistral under these four settings and report the results in Figure 6. The following observations can be made: 1) Decoding time syntax constraints are much more helpful than in-prompt syntax constraints. For both models, the improvements from constrained decoding are much larger than those from prompting syntax constraints. 2) Using decoding time constraints is mostly enough. Extra in-context constraints offer little help. The gaps between the third setting, decoding constraints, and the fourth setting, both constraints are very small.

## 5 Conclusion

We propose ToolDEC, a constrained decoding algorithm to guide LLMs to use external tools. It guarantees that LLMs do not make syntax errors when generating a tool call. ToolDeC is complementary to existing approaches and improves the performance of all the base LLMs we tested. Surprisingly, ToolDEC can enable generalist LLMs to be as good as or even better than tool-specialized models. Since very capable language models, such as GPT-4, can still make syntax errors, we believe that TOoLDEC can be used in some security-sensitive areas to avoid syntax errors, thus having a positive societal impact. However, we do acknowledge that syntax error-free doesn't mean error-free. LLMs with ToOLDEC can still make mistakes beyond syntax and should be used with care.

## References

Anderson, P., Fernando, B., Johnson, M., and Gould, S. Guided open vocabulary image captioning with constrained beam search. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 936-945, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1098. URL https://aclanthology. org/D17-1098.

Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al. Program synthesis with large language models. arXiv preprint arXiv:2108.07732, 2021.

Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Van Den Driessche, G. B., Lespiau, J.-B., Damoc, B., Clark, A., et al. Improving language models by retrieving from trillions of tokens. In International conference on machine learning, pp. 2206-2240. PMLR, 2022.

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901, 2020.

Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.

Chen, W., Ma, X., Wang, X., and Cohen, W. W. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv e-prints, pp. arXiv-2211, 2022.

Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y., Wu, Z., Zhang, H., Zheng, L., Zhuang, S., Zhuang, Y., Gonzalez, J. E., Stoica, I., and Xing, E. P. Vicuna: An open-source chatbot impressing gpt-4 with $90 \% *$ chatgpt quality, March 2023. URL https://lmsys.org/blog/2023-03-30-vicuna/

Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.

Eisner, J. Parameter estimation for probabilistic finite-state transducers. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pp. 1-8, 2002.

Fredkin, E. Trie memory. Communications of the ACM, 3(9):490-499, 1960.

Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., and Neubig, G. Pal: Programaided language models. In International Conference on Machine Learning, pp. 10764-10799. PMLR, 2023.

Geng, S., Josifoski, M., Peyrard, M., and West, R. Grammar-constrained decoding for structured nlp tasks without finetuning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 10932-10952, 2023.

Gupta, T. and Kembhavi, A. Visual programming: Compositional visual reasoning without training. ArXiv, abs/2211.11559, 2022.

Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. Retrieval augmented language model pre-training. In International conference on machine learning, pp. 3929-3938. PMLR, 2020.

Hao, S., Liu, T., Wang, Z., and Hu, Z. Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings. arXiv preprint arXiv:2305.11554, 2023.

Hokamp, C. and Liu, Q. Lexically constrained decoding for sequence generation using grid beam search. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1535-1546, Vancouver, Canada, July 2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1141. URL https://aclanthology.org/P17-1141

Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock, P., Scao, T. L., Lavril, T., Wang, T., Lacroix, T., and Sayed, W. E. Mistral 7b, 2023.

Kalo, J.-C. and Fichtel, L. Kamel : Knowledge analysis with multitoken entities in language models. Automated Knowledge Base Construction, 2022.

Lu, X., West, P., Zellers, R., Le Bras, R., Bhagavatula, C., and Choi, Y. Neurologic decoding:(un) supervised neural text generation with predicate logic constraints. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4288-4299, 2021.

Lu, X., Welleck, S., West, P., Jiang, L., Kasai, J., Khashabi, D., Le Bras, R., Qin, L., Yu, Y., Zellers, R., et al. Neurologic a* esque decoding: Constrained text generation with lookahead heuristics. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 780-799, 2022.

Mialon, G., Dessì, R., Lomeli, M., Nalmpantis, C., Pasunuru, R., Raileanu, R., Rozière, B., Schick, T., Dwivedi-Yu, J., Celikyilmaz, A., et al. Augmented language models: a survey. arXiv preprint arXiv:2302.07842, 2023.

Miao, N., Zhou, H., Mou, L., Yan, R., and Li, L. Cgmh: Constrained sentence generation by metropolis-hastings sampling. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 6834-6842, 2019.

Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.

Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35:27730-27744, 2022.

Parisi, A., Zhao, Y., and Fiedel, N. Talm: Tool augmented language models. arXiv preprint arXiv:2205.12255, 2022.

Qin, Y., Liang, S., Ye, Y., Zhu, K., Yan, L., Lu, Y., Lin, Y., Cong, X., Tang, X., Qian, B., et al. Toolllm: Facilitating large language models to master $16000+$ real-world apis. arXiv preprint arXiv:2307.16789, 2023.

Rastogi, P., Cotterell, R., and Eisner, J. Weighting finite-state transductions with neural context. In Proceedings of the 2016 conference of the North American chapter of the Association for Computational Linguistics: human language technologies, pp. 623-633, 2016.

Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use tools. arXiv preprint arXiv:2302.04761, 2023.

Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face, 2023.

Song, Y., Xiong, W., Zhu, D., Wu, W., Qian, H., Song, M., Huang, H., Li, C., Wang, K., Yao, R., Tian, Y., and Li, S. Restgpt: Connecting large language models with real-world restful apis, 2023.

Stengel-Eskin, E., Rawlins, K., and Durme, B. V. Zero and few-shot semantic parsing with ambiguous inputs, 2024.

Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D., , and Wei, J. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022.

Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lample, G. Llama: Open and efficient foundation language models, 2023.

Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models, 2023.

Yin, P. and Neubig, G. A syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 440-450, 2017.

Yuan, S., Song, K., Chen, J., Tan, X., Shen, Y., Kan, R., Li, D., and Yang, D. EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction, January 2024. URL http://arxiv.org/ $\mathrm{abs} / 2401.06201$. arXiv:2401.06201 [cs].
