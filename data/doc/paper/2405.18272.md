# Metaheuristics and Large Language Models Join Forces: Towards an Integrated Optimization Approach 

Camilo Chacón Sartori ${ }^{1}$, Christian Blum ${ }^{1}$, Filippo Bistaffa ${ }^{1}$, and Guillem Rodríguez<br>Corominas ${ }^{1,2}$<br>${ }^{1}$ Artificial Intelligence Research Institute (IIIA-CSIC), Bellaterra, Spain<br>${ }^{2}$ Universitat Politècnica de Catalunya (UPC - BarcelonaTech), Barcelona, Spain<br>\{cchacon,christian.blum, filippo.bistaffa\} @iiia.csic.es,<br>guillem.rodriguez.corominas@upc.edu

May 29, 2024


#### Abstract

Since the rise of Large Language Models (LLMs) a couple of years ago, researchers in metaheuristics (MHs) have wondered how to use their power in a beneficial way within their algorithms. This paper introduces a novel approach that leverages LLMs as pattern recognition tools to improve MHs. The resulting hybrid method, tested in the context of a social network-based combinatorial optimization problem, outperforms existing stateof-the-art approaches that combine machine learning with MHs regarding the obtained solution quality. By carefully designing prompts, we demonstrate that the output obtained from LLMs can be used as problem knowledge, leading to improved results. Lastly, we acknowledge LLMs' potential drawbacks and limitations and consider it essential to examine them to advance this type of research further.


## 1 Introduction

The advent of Large Language Models (LLMs) has altered the Natural Language Processing (NLP) landscape, empowering professionals across diverse disciplines with their remarkable ability to generate human-like text. Models like OpenAI's GPT [44, Meta's Llama [45], and Anthropic's Claude 3 [4] have become indispensable collaborators in many peoples' daily lives; giving rise to innovative products such as ChatGPT for general use, GitHub Copilot for code generation, DALL-E 2 for image creation, and a multitude of voice generators, including OpenAI's text-to-speech API and ElevenLabs's Generative Voice AI. Currently, LLMs are being experimentally applied across various fields, yielding mixed results 3. While some applications seem questionable, others exhibit spectacular outcomes. One of the most contentious applications is using LLMs for tasks necessitating mathematical reasoning. Given LLMs' inherently probabilistic nature, this application was once deemed implausible. However, recent findings suggest a shift in perspective, particularly with LLMs boasting vast parameter counts 1. As LLMs continue to scale, new capabilities emerge 48. Crucially, these opportunities are contingent upon the thoughtful design of prompts, which helps mitigate the risk of LLMs providing irrelevant or inaccurate responses 47 .

Whenever a new technology emerges, it is natural to wonder if it might enhance an existing one. In combinatorial optimization, metaheuristics (MHs) [21] have been established as effective approximate algorithms for tackling complex, NP-hard problems. While they excel in rapidly providing good-enough solutions, they depend heavily on domain-specific knowledge. To address this limitation, researchers have explored the integration of MHs with other approaches, including exact algorithms and Machine Learning (ML). While combining MHs with exact algorithms has shown promise [10], a successful integration demands significant technical expertise. Alternatively, incorporating ML techniques within MHs can provide valuable problem insights [26], but these approaches often require specialized know-how or, in the case of Deep Learning (DL), substantial datasets and computational resources for training [5]. This paper seeks another direction. We delve into the potential of LLMs to create a novel hybrid approach that combines the strengths of MHs and LLMs.

### 1.1 Our contribution

We introduce a novel approach to enhance the performance of MHs by using LLMs' output. While existing research has already started to explore the integration of LLMs within MHs, our strategy takes a distinct pattern recognition approach. Unlike previous methods that

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-02.jpg?height=45&width=1536&top_left_y=1211&top_left_x=274)
lems through natural language descriptions [51, our approach focuses on designing prompts that include problem instance metrics, graph metrics in our application example. Thus, we employ LLMs not as an oracle providing final answers (i.e., it is not an end-to-end approach according to the classification by Bengio et al. $\sqrt{9}$ ) but as an intermediate step, assisting in pattern detection within the metrics' values (see Figure 2), i.e., it is an hybrid one.

We validate our proposed MH+LLM integration using the Multi-Hop Influence Maximization in Social Networks problem, demonstrating improved performance over the current state-ofthe-art approach, which combines MH with deep learning (DL) 12. Therefore, we believe this approach can unlock new possibilities for improving MHs by leveraging generative AI to tackle complex pattern recognition tasks.

The paper is organized as follows. Section 2 examines existing approaches for integrating ML into MHs and provides an overview of existing research on applying LLMs in optimization. Section 3 formally defines the NP-Hard combinatorial optimization problem that serves as an example for our study. Our proposed integration strategy for combining MH and LLMs is presented in Section 4. The empirical evaluation of our hybrid approach is detailed in Section 5, where we introduce a comprehensive three-dimensional framework for assessment and provide a visual analysis of the algorithm's performance. Section 6 identifies remaining open research questions and discusses the current limitations of LLMs. Finally, Section 7 concludes the paper by summarizing our key findings. Moreover, future research directions are mentioned.

## 2 Background

### 2.1 Machine Learning for Enhancing Metaheuristics in Combinatorial Optimization

Metaheuristics (MHs) are approximate algorithms that have proven effective in solving complex optimization problems, especially combinatorial optimization problems (COPs). COPs
are characterized by discrete variables and a finite search space. Although MHs have been shown to deliver good results in reduced computation times, they do not guarantee finding the optimal solution. Moreover, their success often hinges on the availability of problem-specific knowledge. Each problem instance is treated similarly, applying problem-specific heuristics and (generally) relying on a stochastic behavior. Along these lines, the community aims to innovate by integrating techniques from various domains to improve MHs' performance and address the limitations of MH techniques. In particular, hybrid approaches based on the com-

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-03.jpg?height=48&width=1536&top_left_y=707&top_left_x=274)
Currently, the primary focus has shifted towards the second option. Especially the integration of machine learning (ML) techniques has recently resulted in a multitude of different hybrid approaches. Researchers have explored various strategies to integrate ML into MHs 26. In particular, ML might be used for the following purposes in MHs: algorithm selection (determining the best $\mathrm{MH}$ for a given problem), fast approximate fitness evaluation in the presence of costly objective functions, initialization (generating high-quality initial solutions), and parameter configuration (optimizing the numerous parameters of an $\mathrm{MH}$, which is crucial for its performance). These strategies utilize learning techniques to analyze numerous cases and scenarios, uncovering hidden patterns in the data. By identifying these patterns, MHs can extract general principles that apply to a broad range of situations. This enhances MH's decision-making process, increasing their performance and adaptability \$\$

Beyond classical ML methods (supervised learning: logistic regression, decision trees, support vector machines; unsupervised learning: k-means clustering, principal component analysis), there are approaches from several research subfields within the discipline that have been leveraged and tailored for their use in MHs. Each subfield is characterized by its unique methods, strategies, and possibilities. For instance, deep learning (DL) and reinforcement learning (RL) are two areas that have proven particularly promising for their integration with MHs.

DL employs many-layered artificial neural networks to automatically learn complex data representations, whereas RL focuses on sequential decision-making to achieve good results using a trial-and-error learning process. Methods from both fields have found valuable applications in the realm of MHs, enhancing their ability to find high-quality solutions. In fact, a growing body of research demonstrates this hybrid approach's success. In the following, we provide short descriptions of exemplary hybridization approaches from three different categories:
- MH+ML: In a study by Sun et al. [42, ML techniques were incorporated into the metaheuristic Ant Colony Optimization (ACO) to address the orienteering problem. The authors improved the solution construction process of ACO by utilizing guided predictions based on engineered features. In 31, the authors developed a novel algorithm that combines a metaheuristic with decision trees to address the classic vehicle routing problem.
- MH+DL: Examples of this type of hybridization can be found abundantly in the literature of recent years. For instance, in [12, the authors presented a novel approach that uses a Graph Neural Network (GNN) for learning heuristic information that is then used by a Biased Random Key Genetic Algorithm (BRKGA) to translate random keys into[^0]solutions to the tackled problem. Another example concerns [28] where the authors apply different GNN architectures for parametrizing the neighbor selection strategy in Tabu Search (TS) and in Large Neighborhood Search (LNS).
- MH+RL: RL has recently been used in numerous hybrid approaches. For instance, in 24, the authors devised a method for learning the heuristic function of beam search in the context of two variants of the Longest Common Subsequence (LCS) problems. In 18, the authors proposed a hybrid approach comprised of an attention-based model trained with RL and combined with a more classical optimization method for the formation of collectives of agents in real-world scenarios, showing that it reaches the performance of state-of-the-art solutions while being more general. Furthermore, a variable neighborhood search (VNS) based on Q-learning was devised for a machine scheduling problem in [2]. Finally, we also mention [14], where RL is used for adapting the parameters of a BRKGA during the evolutionary process.

While these hybridization strategies offer potential solutions, they each come with their own set of drawbacks. For instance, the manual feature selection process in many MH+ML approaches relies heavily on the expertise of a specialist. Concerning MH+DL approaches, the system's generalization ability might be hindered by lacking a large and diverse enough dataset. As for MH+RL hybrids, the complexity lies in defining the action space, rewards, and learning policies in a clear and effective manner. Moreover, all three approaches share similar technical challenges: the complexity of replicating models, the time-consuming process of data collection and preparation, and the computational demands of generalization, especially for large-scale problems or complex optimization tasks 5 .

To explore innovative methods for enhancing the performance of $\mathrm{MHs}$ and considering the usefulness and potential of LLMs, which will be discussed in the following subsection, in this paper, we explore a novel hybrid approach: MH+LLM (see Section 4). Utilizing the capabilities of LLMs-while being aware of their limitations-we aim to enhance the problem-solving capabilities of MHs and open up new avenues for tackling complex optimization problems.

### 2.2 LLMs as Pattern Recognition Engines

LLMs have breathed new life into the field of NLP. These high-level language models employ billions of parameters and exhibit an outstanding ability to learn from data. Models like GPT-4o (OpenAI) 2 . Claude-3-Opus (Anthropic) $\sqrt{3}$. Gemini 1.5 (Google) $\sqrt{4}$. Mixtral 8x22b (Mistral AI) $\sqrt{5}$, and Command-R+ (Cohere) $)^{6}$, as well as tools built on top of them-such as ChatGPT, GitHub Copilot, and Bing Chat-have demonstrated that we are in the presence of a groundbreaking technology. Unlike previous advancements, this new wave of AI is no longer limited to experts; instead, it is accessible to anyone who can grasp its benefits.

LLMs are generative AI models that produce text sequentially, predicting each token based on the previous ones. This is made possible by the Transformer, a groundbreaking DL architecture that revolutionized the field of NLP. Proposed by Vaswani et al. 46, it introduces the concept of self-attention, allowing the model to contextually select the most suitable[^1]words. The Transformer derives its name from its ability to transform a set of vectors in a given representation space to a new set of vectors with identical dimensions but in a different space. By assigning varying weight values to each input, the attention mechanism leverages inductive biases related to sequential data 32 . This architecture also takes advantage of the capabilities of high-performance hardware due to its parallelizable nature. As a result, the Transformer generates words that seamlessly fit the context-although it lacks factual verification-marking a significant advancement in NLP tasks.

LLMs have found uses in various domains, including the interpretation of complex results like chemical compounds or images $[41$, where they provide insights and explanations. Additionally, LLMs are being applied as autonomous agents that leverage external tools and resources to accomplish tasks 22 . Furthermore, these models demonstrate progress in domains once thought to be out of the reach of their capabilities, including mathematical reasoning and optimization tasks [51]. While there are still numerous obstacles to overcome [1], these advancements showcase the potential of these models to address intricate cognitive problems.

Recent research on leveraging LLMs for optimization has primarily explored two paths: first, formulating optimization problems within the prompt and requesting the LLM to solve the described problem, typically for straightforward optimization tasks [51] and second, automating code generation to enhance optimization algorithms [33, 39]. Nevertheless, a method that harnesses LLMs as pattern recognition engines in combinatorial optimization problems has not yet been developed, even though a recent study has demonstrated the ability of LLMs to find patterns in various tasks 34 . Our proposal introduces an integration that enhances the effectiveness of the metaheuristic search process by utilizing LLMs, marking a step forward in that direction. While acknowledging the challenges associated with LLMs (discussed in the subsequent Section 2.2.1), we identify numerous opportunities for progress in this area (see Section 4 ).

### 2.2.1 Obstacles and Opportunities

LLMs are an emerging technology that is still evolving. Despite demonstrating usefulness across various applications, as seen above, we believe that our research has mitigated two key risks associated with LLMs:

1. Training these models requires an immense amount of diverse data, from social media posts to books, and an equally vast amount of computing power. As a result, the leaders in the LLM industry tend to be well-funded private companies with significant resources and high valuations. This creates a high barrier to entry for startups or under-funded research centers, which often lack the necessary infrastructure to compete directly with these powerful players. To reduce these risks, a dual strategy can be implemented. On one side, this involves using more compact, open-source LLMs, which may, however, result in lower-quality outputs. On the other side, this entails using proprietary LLMs as software-as-a-service to end-users, which incurs financial expenses. For this research, we employed a mix of both strategies, highlighting their respective benefits and drawbacks.
2. LLMs have no built-in understanding of the world, as they cannot directly experience or "simulate" our environment. This is unlike humans, who constantly perceive information, be it sensory, visual, or auditory. In contrast, LLM operation depends on the data with which they are trained. Consequently, if the data is not meticulously selected by humans, the model's predictions may be unreliable or even generate false information, a
phenomenon known as "hallucinations" in AI discourse 7 We mitigated the problem of hallucinations with a special focus on prompt design. It has been observed that ambiguous prompts can lead to inconsistent results, with the same prompt potentially yielding different responses each time it is executed. As LLMs have evolved and increased in size, it has become evident that altering the prompt strategy can significantly improve the quality of the responses. This discovery has opened up new possibilities, enabling LLMs to tackle tasks that previously yielded negative or untested results. Carefully designing and adjusting prompts can improve the reliability and performance of LLMs 40. This article focuses on creating prompts that produce desired outcomes.

## 3 Problem Definition

In this section, we provide the definition of the optimization problem we consider as an example in this paper, while in Section 4, we present our hybrid optimization approach. The considered optimization problem is from the realm of social networks. In fact, social network problems often serve as an interesting experimental laboratory for testing optimization techniques since they can be modeled as combinatorial problems based on directed graphs that become highly complex as the instance size grows.

Specifically, we consider Multi-Hop Influence Maximization, a social network problem proven NP-hard by Ni et al. [37] and Basuchowdhuri et al. [6]. In the literature, this problem has been studied using both metaheuristics and a state-of-the-art combination of a BRKGA

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-06.jpg?height=51&width=1122&top_left_y=1382&top_left_x=273)

### 3.1 Multi-Hop Influence Maximization in Social Networks

Many optimization problems in social networks can be formalized by modeling the social network as a directed graph $G=(V, A)$, where $V$ represents the set of nodes and $A$ represents the set of directed arcs. This is also the case of the specific multi-hop influence maximization problem addressed in this paper, referred to as the $k$ - $d$-Dominating Set Problem ( $k$ - $d \mathrm{DSP}$ ).

The most crucial concept in this context is the influence $I_{d}(u) \subseteq V$ of a node $u \in V$, which is determined by two factors:

1. Parameter $d \geq 1$, which is an input to the problem and represents the maximum distance of influence.
2. A distance measure $\operatorname{dist}(u, v)$ between nodes $u$ and $v$. In this paper, $\operatorname{dist}(u, v)$ is defined as the length (in terms of the number of arcs) of the shortest directed path from $u$ to $v$ in $G$.

Based on these factors, we can define the influence of a node $u$ as follows:

$$
\begin{equation*}
I_{d}(u):=\{v \in V \mid \operatorname{dist}(u, v) \leq d\} \tag{1}
\end{equation*}
$$[^2]

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-07.jpg?height=309&width=531&top_left_y=371&top_left_x=451)

Input graph

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-07.jpg?height=394&width=511&top_left_y=854&top_left_x=453)

(b) $\mathrm{d}=2$

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-07.jpg?height=294&width=514&top_left_y=384&top_left_x=1116)

(a) $d=1$

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-07.jpg?height=483&width=531&top_left_y=815&top_left_x=1114)

(c) $\mathrm{d}=3$

Figure 1: Multi-hop influence process. The given directed graph consists of 11 nodes and 12 arcs, and the task is to solve the $k$ - $d \mathrm{DSP}$ with $k=2$. The example solution $U$ consists of two nodes: $v_{4}$ and $v_{5}$ (colored in green). The bottom row illustrates the concept of $d$-hop coverage: when $d=1$, nodes $v_{3}, v_{7}, v_{6}$ are 1 -hop covered by $U$; when $d=2$, nodes $v_{2}, v_{3}, v_{7}, v_{8}, v_{6}, v_{11}$ are 2-hop covered by $U$; and when $d=3$, all remaining nodes in the graph are 3 -hop covered by $U$.

In other words, $I_{d}(u)$ represents the set of all nodes in $G$ that can be reached from $u$ via a directed path with at most $d$ arcs. We say that $u$ influences (or covers) all nodes in $I_{d}(u)$. This definition can be naturally extended to sets of nodes as follows:

$$
\begin{equation*}
I_{d}(U):=\bigcup_{u \in U} I_{d}(u) \quad \forall U \subseteq V \tag{2}
\end{equation*}
$$

That is, $I_{d}(U)$ represents the set of all nodes in $G$ that are influenced by at least one node from the set $U$.

Valid solutions to the $k-d \mathrm{DSP}$ are all sets $U \subseteq V$ such that $|U| \leq k$, meaning that any valid solution can contain at most $k$ nodes. The objective of the $k$ - $d \mathrm{DSP}$ is to find a valid solution $U^{*} \subseteq V$ such that $\left|I_{d}\left(U^{*}\right)\right| \geq\left|I_{d}(U)\right|$ for all valid solutions $U$ to the problem. In other words, the objective function value of a valid solution $U$ is $\left|I_{d}(U)\right|$. Formally, the $k$ - $d \mathrm{DSP}$ can be stated as follows:

$$
\begin{align*}
\max _{U \subseteq V} & \left|I_{d}(U)\right|  \tag{3}\\
\text { s.t. } & |U| \leq k
\end{align*}
$$

For an intuitive explanation of $k$ - $d \mathrm{DSP}$, see the toy example in Figure 1 .

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-08.jpg?height=634&width=1537&top_left_y=374&top_left_x=271)

Figure 2: An overview of our approach to integrating MHs and LLMs: We employ LLMs to analyze problem instances and uncover hidden patterns. The patterns are then converted into useful information that guides the MH in its search for high-quality solutions.

## 4 Integration of LLM Output into a Metaheuristic

Figure 2 depicts the framework of our proposed MH+LLM integration, comprising three automatic sequential steps:

1. Prompt generation and execution by an LLM. We begin by phrasing the $k$ $d \mathrm{DSP}$ in natural text and creating a small random graph with a high-quality solution. Next, we calculate five key metrics for each node of the graph, which enables the LLM to determine the most relevant metrics for this problem. We then compute the same metrics for a second (larger) graph in which we want to solve the $k$-dDSP problem. This graph is henceforth called the evaluation graph. Using the generated data, we design a prompt and ask the LLM to provide parameters for calculating the importance of each node in the evaluation graph. In essence, we leverage the LLM as a pattern recognition engine to identify correlations between node metrics and node importance in the context of the $k-d \mathrm{DSP}$.
2. Calculate probabilities for each node of the evaluation graph. As explained in detail below, the LLM provides values for ten parameters that can be used to compute the probability of each node of the evaluation graph to form part of an optimal $k-d \mathrm{DSP}$ solution. We expect this information to offer excellent guidance to a MH.
3. Utilizing the probabilities (guidance) within a MH. Since the MH we use in this work is a BRKGA, we incorporate the probabilities calculated based on the LLM output into the decoder that translates random keys into valid solutions to the tackled optimization problem.

In what follows, these three steps are detailed in corresponding subsections.

### 4.1 Prompt Engineering

A prompt is an instruction provided as input to an LLM. The design of a prompt can greatly influence the quality of the LLMs' responses [48, 47. Also, the specific response can vary depending on the LLM used. From the available prompt design techniques, we have opted for one-shot learning 11, also sometimes called few(1)-shot learning. According to Chen's findings [16], tabular data reasoning can achieve good results with a single example, eliminating the need for additional examples or fine-tuning. This method involves furnishing the LLM with an example to facilitate pattern recognition in the response instructions that are to be requested.

### 4.1.1 Definition

The prompt we have designed consists of four tags, defined as follows:

$$
\begin{equation*}
P:=\operatorname{PROMPT}(\operatorname{Tag} 1, \operatorname{Tag} 2, \operatorname{Tag} 3, \operatorname{Tag} 4) \tag{4}
\end{equation*}
$$

where

- Tag1 is the [PROBLEM] tag,
- Tag2 is the [EXAMPLE GRAPH] tag,
- Tag3 is the [EVALUATION GRAPH] tag, and
- Tag4 is the [RULES ANSWERING] tag.

Hereby, the [PROBLEM] tag contains the description of the $k$ - $d \mathrm{DSP}$. Moreover, the example graph information is provided in the [EXAMPLE GRAPH] tag. Hereby, the example graph consists of 100 nodes, each characterized by the values of five metrics: in-degree, out-degree, closeness, betweenness, and pagerank. In particular, these values are henceforth denoted by

$$
\begin{equation*}
m_{i, 1}^{e x}, m_{i, 2}^{e x}, m_{i, 3}^{e x}, m_{i, 4}^{e x}, m_{i, 5}^{e x} \quad \text { for all } v_{i} \text { of the example graph. } \tag{5}
\end{equation*}
$$

Hereby, $m_{i, 1}^{e x}$ is the value corresponding to metric in-degree, $m_{i, 2}^{e x}$ corresponds to out-degree, etc. Note also that the metric values are normalized to the range $[0,1]$. Furthermore, the high-quality $k-d \mathrm{DSP}$ solution of the example graph is computed using the pure BRKGA algorithm, which we adopted from our earlier work 12 . The solution is encoded as a vector of 32 nodes, separated by commas, corresponding to the $k$ - $d \mathrm{DSP}$ parameter $k=32$.

Next, the [EVALUATION GRAPH] tag contains the evaluation graph for which the $k$ - $d$ DSP must be solved. Each node of this graph is described by the values of the same five metrics described above. These evaluation graph values are henceforth denoted by

$$
\begin{equation*}
m_{i, 1}^{\text {eval }}, m_{i, 2}^{\text {eval }}, m_{i, 3}^{\text {eval }}, m_{i, 4}^{\text {eval }}, m_{i, 5}^{\text {eval }} \text { for all } v_{i} \text { of the evaluation graph. } \tag{6}
\end{equation*}
$$

Finally, the [RULES ANSWERING] tag specifies the details of the request to the LLM, which will be elaborated on in Section 4.1.2.

After the prompt $P$ is formulated, it is utilized by invoking the EXECUTE function, which takes three parameters: the prompt $P$, the selected $L L M$, and $\Theta$, representing a set of values for the configuration parameters of the $L L M$. This results in the corresponding LLM output:

$$
\begin{equation*}
\text { Output }:=\operatorname{EXECUTE}(P, L L M, \Theta) \tag{7}
\end{equation*}
$$

Specifically, $\Theta$ contains values for exactly two parameters, regardless of the utilized LLM. The first, known as temperature, is a value between 0 and 1 that measures the model's response uncertainty, with lower values indicating a more deterministic output. Since a more deterministic response is desirable when searching for patterns in data, we set the temperature to $0 .{ }^{8}$ The second parameter is the maximum number of output tokens, which we have set to a moderate 1000 tokens. This choice is based on the prompt design, which consistently yields relevant outputs regardless of the evaluation graph's size, ensuring that the quality of the results is not compromised by a smaller token limit.

### 4.1.2 Prompt Structure

Effective prompts are generally those with few language ambiguities. To achieve this, the four unique opening and closing tags mentioned in the previous section provide structure and coherence. We will now clarify the syntactic structure of each of these tags. A complete example of a prompt, along with each tag, can be found in Figure 3

1. Problem description. The prompt starts by providing a concise definition of the $k$ $d$ DSP utilizing LaTeX notation within the [PROBLEM] tag; see the top right of Figure 3
2. Example Graph. The [EXAMPLE GRAPH] tag, as the name suggests, provides information about the example graph. Nestled within this tag are two additional tags: [DATA], encompassing the metric values of each node of the example graph, and [ANSWER], which provides a high-quality solution for the given graph.
- [DATA] tag: A (directed) random graph with 100 nodes produced with the ErdösRényi model [38 was chosen as an example graph. The edge probability of the graph was 0.05. Subsequently, five before-mentioned metrics were calculated for each of the 100 nodes and incorporated into the prompt in a tabular data format, with rows and columns separated by commas. Each row corresponds to a node ID, while the columns represent the respective metric values for that particular node. The metric values are presented in scientific numerical notation to minimize token usage. The rationale behind this decision is discussed in the context of the empirical results; see Section 5.
- [ANSWER] tag: The solution to the example graph is computed using the BRKGA algorithm from [12]. However, note that this solution (which is not necessarily optimal) could potentially have been achieved through alternative means, such as employing a different metaheuristic or solving the problem via an exact method. The rationale behind including a high-quality solution is our expectation thatgiven the nodes belonging to a presumably high-quality solution-the LLM will be able to discern which metrics are more crucial than others and how the metric values of selected nodes interrelate.[^3]

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-11.jpg?height=1690&width=1519&top_left_y=494&top_left_x=286)

Figure 3: An example of a prompt and the corresponding LLM response. The prompt includes the problem definition, a graph example with node metrics and a high-quality solution, an evaluation graph, and instructions for the LLM for producing the output. Based on the patterns identified in the evaluation graph, the LLM provides the importance of each metric, represented by the set of alpha and beta values.

3. Evaluation Graph. The [EVALUATION GRAPH] tag, much like the [EXAMPLE GRAPH] tag, utilizes a nested [DATA] tag to store the values of the five metrics for every node. However, we obviously do not provide any solution for the evaluation graph. This is because the objective is to request information from the LLM on the probability of nodes from the evaluation graph to pertain to an optimal solution.
4. Rules Answering. The [RULES ANSWERING] tag is crucial as it ties together all the information provided in the previous tags. In this part of the prompt, an equation is presented to the LLM to calculate the probability of each node of the evaluation graph to form part of an optimal solution. The equation requires 10 parameters: 5 alpha parameters and 5 beta parameters, which will be explained in more detail in Section 4.2. These parameters serve to assign weights to the metrics and correct potential errors. The LLM infers the values of these parameters by analyzing the metrics in the [EVALUATION GRAPH] tag and using the metrics and the solution from the [EXAMPLE GRAPH] tag as a guide.

### 4.2 LLM Output

As described before, a prompt $P$ provides the values of the following five metrics for each node of the example graph and the evaluation graph: in-degree, out-degree, closeness, betweenness, and pagerank. It is assumed that the most important metric for addressing the $k$ - $d \mathrm{DSP}$ is the out-degree, that is, the number of neighbors that can be reached from a node via directed arcs. A node with a higher out-degree is generally more likely to form part of high-quality solutions. However, we assume that there are additional metrics (among the other four metrics) that might contribute valuable information. Consequently, we anticipate that the LLM will be able to identify this. To identify patterns in the values provided by the metrics, the LLM is requested (by means of the [RULES ANSWERING] tag) to return values for two sets of five parameters (one for each metric, in the order as given above), resulting in ten values. More specifically, upon executing a prompt $P$, the chosen LLM produces a set Output (see Eq. (7)) which is as follows:

$$
\begin{equation*}
\text { Output }=\left\{\alpha_{1}, \ldots, \alpha_{5}, \beta_{1}, \ldots, \beta_{5}\right\} \tag{8}
\end{equation*}
$$

The first five of these values are henceforth called alpha values, while the last five values are named beta values. The heart concept of the proposed prompt is centered on the meaning of these values and how they are utilized.

- alpha values: These are weights that indicate the influence of each metric. The total sum of all alpha values should be equal to one $\left(\sum_{i=1}^{5} \alpha_{i}=1\right.$ ), and each alpha value can be unique. In other words, the alpha value $0<\alpha_{i}<1$ reflects the relative significance of the $i$-th metric (in the order as mentioned above).
- beta values: These five values are adjustment (or correction) parameters. Unlike the alpha values, beta values $0<\beta_{i}<1$ are independent of each other. Moreover, beta values do not represent relative weights among the metrics. They rather indicate the best possible value of a node regarding a metric. This allows the LLM to identify where the best values are found with respect to their range $[0,1]$.

Based on these values from the LLM output, the probability for a node $v_{j}$ of the evaluation graph is determined using the following formula:

$$
\begin{equation*}
\mathbf{p}^{\mathrm{LLM}}\left(v_{j}\right):=\sigma\left(\sum_{i=1}^{5} \alpha_{i} \cdot\left(1-\left(\beta_{i}-m_{j, i}^{e v a l}\right)\right)\right) \tag{9}
\end{equation*}
$$

Note that this formula introduces non-linearity into the node probabilities by applying the sigmoid function $\sigma$, which enables a more nuanced representation of the probability space 9

As shown in Figure 3, our proposed prompt thoroughly explains the alpha and beta values to the LLM, along with Eq. 9. By giving the LLM a clear understanding of the context surrounding the alpha and beta values, we simply ask the LLM to provide the corresponding values for the evaluation graph.

### 4.3 Using LLM Output to Guide a Metaheuristic

In this section, we first describe the metaheuristic considered to test the quality of the LLM output. Subsequently, the way of incorporating the probability values into the metaheuristic is outlined.

### 4.3.1 The Considered Metaheuristic: A BRKGA

The chosen metaheuristic is a so-called Biased Random Key Genetic Algorithm (BRKGA) designed for solving the $k$ - $d \mathrm{DSP}$ in 12 In fact, two algorithm variants were proposed in [12]: (1) a pure BRKGA variant and (2) an algorithm variant that makes use of a handdesigned deep learning framework for biasing the BRKGA. This will allow us to compare our proposal properly to existing algorithm versions.

In general, a BRKGA is problem-independent because it works with populations of individuals that are vectors of real numbers (random keys). The problem-dependent part of each BRKGA deals with how individuals are translated into solutions to the tackled problem. The problem-independent pseudocode of BRKGA is provided in Algorithm 1

The algorithm begins by calling GenerateInitialPopulation $\left(p_{\text {size }}\right.$, seed $)$ to create a population $P$ of $p_{\text {size }}$ individuals. If seed $=0$, all individuals are randomly generated, with each $\pi \in P$ being a vector of length $|V|$ (where $V$ is the set of nodes from the input graph). The value at position $i$ of $\pi, \pi(i)$, is randomly chosen from $[0,1]$ for all $i=1, \ldots,|V|$. If seed $=1, p_{\text {size }}-1$ individuals are randomly generated, and the last individual is obtained by setting $\pi(i):=0.5$ for all $i=1, \ldots,|V|$. The initial population's individuals are then evaluated by transforming each individual $\pi \in P$ into a valid solution $U_{\pi} \subset V$ to the $k$ - $d \mathrm{DSP}$, with the value $f(\pi)$ defined as $f(\pi):=\left|U_{\pi}\right|$. The transformation process is discussed later.

At each iteration, the algorithm performs the following operations:

1. The best $\max \left\{\left\lfloor p_{e} \cdot p_{\text {size }}\right\rfloor, 1\right\}$ individuals are copied from $P$ to $P_{e}$ using EliteSolU$\operatorname{TIONS}\left(P, p_{e}\right)$.
2. A set of $\max \left\{\left\lfloor p_{m} \cdot p_{\text {size }}\right\rfloor, 1\right\}$ mutants are generated by function $\operatorname{Mutants}\left(P, p_{m}\right)$ and stored in $P_{m}$. These mutants are random individuals generated the same way as those from the initial population.[^4]
```
Algorithm 1 The pseudocode of BRKGA
Require: a directed graph $G=(V, E)$
Ensure: values for parameters $p_{\text {size }}, p_{e}, p_{m}$, prob $_{\text {elite }}$, seed
    $P \leftarrow \operatorname{GenERATEInitiaLPopULATION}\left(p_{\text {size }}\right.$, seed $)$
    $\operatorname{Evaluate}(P) \quad \triangleright$ problem-dependent part (greedy)
    while computation time limit not reached do
        $P_{e} \leftarrow \operatorname{EliteSolutions}\left(P, p_{e}\right)$
        $P_{m} \leftarrow \operatorname{Mutants}\left(P, p_{m}\right)$
        $P_{c} \leftarrow \operatorname{Crossover}\left(P, p_{e}\right.$, prob $\left._{\text {elite }}\right)$
        $\operatorname{Evaluate}\left(P_{m} \cup P_{c}\right) \quad \triangleright$ problem-dependent part (greedy)
        $P \leftarrow P_{e} \cup P_{m} \cup P_{c}$
    end while
    return Best solution in $P$
```

3. Function Crossover( $P, p_{e}$, prob $\left._{\text {elite }}\right)$ generates $p_{\text {size }}-\left|P_{e}\right|-\left|P_{m}\right|$ individuals by means of crossover and stores them in set $P_{c}$. The crossover, which involves combining two solutions, serves as the mechanism that enhances the search process, concentrating on transferring the superior traits of parents to their offspring.

The evaluation of an individual (see lines 2 and 7 of Algorithm 1) is the crucial problemdependent aspect of the BRKGA algorithm from 12 . This evaluation function-often termed the decoder-utilizes a straightforward greedy heuristic. The heuristic is based on the notion that nodes with a higher out-degree - that is, more neighbors-are likely to yield a higher influence.

For a node $v_{j} \in V$, the set of neighbors, $N\left(v_{j}\right)$, comprises nodes reachable via a directed arc from $v_{j}: N\left(v_{j}\right)=\left\{v_{i} \in V \mid\left(v_{j}, v_{i}\right) \in A\right\}$. The greedy value $\phi\left(v_{j}\right)$ for each $v_{j} \in V$ is calculated as:

$$
\begin{equation*}
\phi\left(v_{j}\right):=\left|N\left(v_{j}\right)\right| \cdot \pi(j) \tag{10}
\end{equation*}
$$

In other words, in this equation, the greedy value of a node $v_{j}$ is determined by multiplying its out-degree with the corresponding numerical value from the individual being translated into a solution. The final solution, $U_{\pi}$, is obtained by selecting the $k$ nodes with the highest greedy values.

The following will modify the greedy function $\phi$ to create our hybrid algorithm.

### 4.3.2 Hybrid algorithm

The proposed hybrid algorithm-referred to as BRKGA+LLM-begins with two offline steps. Given an evaluation graph $G=(V, A)$, a prompt is generated as outlined in the previous section and sent to an LLM. Based on the alpha and beta values obtained from the LLM's response, the probability $\mathbf{p}^{\mathrm{LLM}}\left(v_{j}\right)$ for each node $v_{j} \in V$ is determined using Eq. (9). Next, the original greedy function $\phi()$ from Eq. 10) is substituted with a modified version that integrates the node probabilities derived from Eq. (9):

$$
\begin{equation*}
\phi_{\operatorname{INFLUENCE}_{L L M}}\left(v_{j}\right):=\left|N\left(v_{j}\right)\right| \cdot \pi(j) \cdot \mathbf{p}^{\mathrm{LLM}}\left(v_{j}\right) \quad \forall v_{j} \in V \tag{11}
\end{equation*}
$$

Table 1: Summary of the assessed LLMs, which have been used via the OpenRouter API. This is except for Claude-3-Opus, the first LLM considered. At that point, we had yet to become familiarized with OpenRouter.

| Model | Chatbot | Version | License | Maximum | Test Environment (API) |
| :--- | :---: | :---: | :---: | :---: | :---: |
|  | Arena |  |  | Context |  |
|  | Ranking |  |  | Window |  |
| OpenAI/GPT-4o | $\# 1$ | may2024 | private | 128,000 | OpenRouter |
| Anthropic/Claude-3-Opus | $\# 2$ | march2024 | private | 200,000 | Anthropic |
| Cohere/Command-R+ | $\# 10$ | april2024 | CC-BY-NC-4.0 | 128,000 | OpenRouter |
| MistralAI/Mixtral-8x22b-Instruct-v0.1 | $\# 19$ | april2024 | Apache 2.0 | 32,768 | OpenRouter |

We hypothesize that with suitable predictions from the LLM, the algorithm can be guided/biased to explore more promising areas of the search space. These areas are believed to contain high-quality solutions that the BRKGA would have been unable to discover on their own without the guidance of these predictions. In other words, using an LLM to discover patterns in metric values (see Section4.1), rather than relying solely on the out-degree, might enhance the algorithm's performance.

## 5 Empirical Evaluation

This section presents empirical evidence demonstrating the benefits of integrating MHs and LLMs. The following algorithm variants are considered for the comparison:

- BRKGA: the pure BRKGA variant already published in 12 and described above in Section 4.3 .1 .
- BRKGA+FC: the BRKGA hybridized with a hand-designed GNN called FastCover (FC) that was used to derive the probability values (last term of Eq. 11) in 12 .
- BRKGA+LLM: the BRKGA enhanced with LLM output as described in the previous section.

Note that both BRKGA and BRKGA + FC underwent a general parameter tuning in 12 depending on the value of $k$. The well-known irace tool 30 was used for this purpose. In this work, we adopt the corresponding parameter settings of BRKGA for BRKGA+LLM. In this way, we can be sure that any difference in their performance is caused by the guidance of the probabilities computed from the LLM outputs. In any case, a specific tuning of BRKGA+LLM could only further improve its results.

Apart from comparing the three approaches mentioned above, we show results for different LLMs and provide evidence for the quality of LLM output. Additionally, we support our analysis with a visual examination, providing additional insight into why the hybrid BRKGA+LLM outperforms the other algorithm variants.

### 5.1 Experimental Setup

The BRKGA was implemented in C++, whereas the prompt construction process, which entails extracting metrics from graph instances, was conducted using Python 3.11. Regarding the choice of LLMs, we utilized two proprietary language models, GPT-4o and Claude-3-Opus, as well as two open-source models, Command-R+ and Mixtral-8x22b-Instruct-v0.1. We selected
these models based on the Chatbot Arena-a platform developed by LMSYS members and UC Berkeley SkyLab researchers-which provides an Arena Leaderboard ${ }^{11}$ a community-driven ranking system for LLMs 52 Table 1 presents a comprehensive overview of the models, including their ranking in the Chatbot Arena Leaderboard (as of May 2024), corresponding version numbers, licenses, maximum context windows, and crucially, the test environment employed for each model.

### 5.1.1 Execution Environment

We utilized the OpenRouter API 13 to execute prompts in their corresponding LLMs, except for Claude-3-Opus, which we used through the Anthropic API (see Table 1). Finally, all experiments involving the three BRKGA variants were conducted on a high-performance computing cluster comprising machines powered by Intel Xeon CPU 5670 processors with 12 cores running at $2.933 \mathrm{GHz}$ and a minimum of $32 \mathrm{~GB}$ of RAM.

### 5.1.2 Dataset

Our evaluation is based on two categories of $k$ - $d$ DSP instances (evaluation graphs). The first consists of rather small, synthetic social network graphs with 500 and 1000 nodes, generated using three configuration methods developed by Nettleton 36 . The corresponding graph generator requires four real-valued parameters, whose values are reflected by the instance names. ${ }^{14}$ The second instance set comprises four real-world social network graph instances obtained from the well-established SNAP (Stanford Network Analysis Project) repository 27. Moreover, note that the $k$ - $d \mathrm{DSP}$ can be solved in each graph for different values of $d$ and $k$. In this work we solved all evaluation graphs with $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$.

Restrictions. The size of the graphs poses a constraint on the prompts we have designed for the LLMs, which is limited by two factors:

1. The maximum context window of LLMs is still relatively small. ${ }^{15}$ For instance, the largest evaluation graph we use, soc-wiki-elec, results in an input prompt size of 181,719 tokens, which is close to the 200,000 tokens limit of Claude-3-Opus 4, the LLM which offers the currently largest context window.
2. The cost of processing larger instances is prohibitively high. For example, executing the prompt regarding the soc-wiki-elec evaluation graph on Claude-3-Opus exceeds $€ 2.5$.[^5]

Table 2: Number of input/output tokens and the associated cost of processing the input prompts concerning Claude-3-Opus. The costs correspond to March 2024.

| Instance | Input (tokens) | Output (tokens) | Cost (USD/EUR) |
| :--- | :---: | :---: | :---: |
| soc-wiki-elec | 181,719 | 463 | $2,78 / 2,58$ |
| soc-advogato | 160,812 | 410 | $2,46 / 2,28$ |
| sign-bitcoinotc | 66,406 | 303 | $1,02 / 0,95$ |
| soc-hamsterster | 17,097 | 438 | $0,29 / 0,27$ |

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-17.jpg?height=679&width=1474&top_left_y=714&top_left_x=311)

Figure 4: A comprehensive evaluation framework was used to assess the usefulness of integrating MHs with LLMs for solving combinatorial optimization problems (COPs) across the three dimensions shown in the graphic.

Table 2 provides a detailed breakdown of the constraints for the largest evaluation graphs considered in this work. Although these limitations currently restrict us to testing with smaller instances, we anticipate that this constraint will soon be alleviated as the maximum context window increases and processing costs decrease (see Section 6 for more information on this).

### 5.1.3 Repository

The complete results of our study presented in Sections 5.2 and 5.3 are available at GitHub.

### 5.2 Analysis of LLM Output

This section aims to validate the outputs of the LLMs and their usefulness for utilizing them as guidance within the BRKGA algorithm. The aim is to demonstrate that they are not arbitrary or devoid of significance. We have conducted three sets of experiments to achieve this, aiming at different aspects. Figure 4 shows the custom-designed, three-dimensional experimental framework developed specifically for this evaluation 16[^6]

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-18.jpg?height=2219&width=1168&top_left_y=364&top_left_x=455)

Before starting with the main experimental evaluation, we must choose the most suitable LLM for the considered task. For this purpose, we produced all prompts concerning the six synthetic graphs from the dataset (as described before) for all considered combinations of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$. These prompts were fed into the following LLMs: GPT-4o, Claude-3-Opus, Command-R+, and Mixtral-8x22b-Instruct-v0.1. The obtained probabilities were then directly used to produce solutions containing the $k$ nodes with the largest probability values. The same was done concerning metric out-degree. That is, solutions were produced that consist of the $k$ nodes with the highest out-degree values. The results shown in Table 3 allow us to make the following observations. First, although no LLM always outperforms the other LLMs, Claude-3-Opus shows advantages over the other LLMs, especially for increasing values of $k$. When comparing the results obtained with out-degree (the most popular greedy heuristic for the $k$-dDSP) to the results obtained with Claude-3-Opus, we can observe that out-degree seems to work slightly better for $k=32$, while the opposite is the case for $k=128$. Based on these results, we use Claude-3-Opus for the remainder of our experiments.

### 5.2.1 Dimension 1 of the Evaluation Framework: Result Quality

In the first set of experiments, we decided to compare the pure BRKGA approach with BRKGA+LLM in the context of the six synthetic graphs (and for all combinations of $d \in\{1,2,3\}$ and $k \in\{32,64,128\})$. Both algorithms were applied 10 times to each case, with a computation time limit of $900 \mathrm{CPU}$ seconds per run. The results, which are shown in Table 4, clearly show that BRKGA+LLM outperforms the pure BRKGA algorithm most of the time. Considerable improvements can be observed in the context of the last graph; see instance 0.2-0.0-0.3-0.5 with 1000 nodes and 8000 arcs. Only in three cases, the result obtained by BRKGA+LLM is slightly inferior to the one of BRKGA. While these results are promising, it is important to recognize that they are based on relatively small instances.

In the next set of experiments, we applied the BRKGA+FC 12], in addition to BRKGA and BRKGA+LLM, to the four larger real-world social networks. Remember that BRKGA+FC is a hybrid approach that uses a hand-crafted GNN approach for biasing the search process of BRKGA. The results are shown-again for each combination of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$-in Table 5. The computation time limit for the three approaches was 900 CPU seconds, as in the previously outlined experiments. Moreover, the numbers in the tables are averages over 10 algorithm runs. The results show that BRKGA+LLM outperforms both approaches, with higher margins than those observed in the context of smaller synthetic networks. This holds especially for a growing value of $k$. This is interesting as the prompts only contained an example solution for $k=32$. This indicates the LLM's ability to uncover meaningful patterns in the example graph, respectively, in the solution provided in the prompts.

Finally, we aimed to test how meaningful the LLM output really is. For this purpose, we produced two additional variants of BRKGA+LLM: the one called static is obtained by replacing the LLM output with probabilities obtained by random alpha and beta values. The second one, called dynamic, is a similar variant in which the LLM output is replaced with probabilities re-computed at each iteration based on newly determined random alpha and beta values. All three algorithm variants were applied 10 times to each of the four real-world social networks for each combination of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$. The results averaged over the 10 runs are shown in Table 6. They clearly indicate that guidance by the LLM output is much more useful than random guidance.

Table 4: Comparison of the pure BRKGA with BRKGA+LLM on the six synthetic social networks. For each network, the algorithms were applied for each combination of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$. Average results over 10 algorithm runs are shown.

| Instance | $\|N\|$ | $\|E\|$ | $d$ | $k=32$ |  | $k=64$ |  | $k=128$ |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  |  |  | BRKGA | BRKGA+LLM | BRKGA | BRKGA+LLM | BRKGA | BRKGA+LLM |
| $0.4-0.15-0.15-0.3$ | 500 | 3000 | 1 | 309.6 | 309.9 | 433.9 | 437.2 | 7499.0 | $\overline{500.0}$ |
|  |  |  | 2 | 496.0 | 499.9 | 497.4 | 500.0 | 500.0 | 500.0 |
|  |  |  | 3 | 496.0 | 500.0 | 498.0 | 500.0 | 500.0 | 500.0 |
| $0.3-0.0-0.3-0.4$ | 500 | 3000 | 1 | 353.7 | 353.1 | 432.9 | 434.1 | 489.0 | 498.8 |
|  |  |  | 2 | 413.0 | 413.0 | 453.0 | 454.0 | 489.0 | 500.0 |
|  |  |  | 3 | 417.0 | 416.9 | 455.0 | 456.0 | 489.0 | 500.0 |
| $0.2-0.0-0.3-0.5$ | 500 | 3000 | 1 | 203.8 | 204.4 | 287.6 | 291.4 | 373.0 | 380.0 |
|  |  |  | 2 | 247.0 | 252.6 | 316.0 | 323.8 | 386.0 | 394.0 |
|  |  |  | 3 | 247.0 | 254.9 | 316.0 | 323.8 | 386.0 | 394.0 |
| $0.4-0.15-0.15-0.3$ | 1000 | 8000 | 1 | 446.6 | 447.4 | 679.4 | 680.5 | 907.6 | 915.9 |
|  |  |  | 2 | 982.0 | 985.0 | 996.0 | $1,000.0$ | 996.0 | $1,000.0$ |
|  |  |  | 3 | 996.0 | 996.0 | 996.0 | $1,000.0$ | 996.0 | $1,000.0$ |
| $0.3-0.0-0.3-0.4$ | 1000 |  | 1 | 604.0 | 604.6 | 773.8 | 774.7 | 908.7 | 909.2 |
|  |  | 8000 | 2 | 808.8 | 808.0 | 880.0 | 879.6 | 948.8 | 949.8 |
|  |  |  | 3 | 824.3 | 824.8 | 888.6 | 891.0 | 955.0 | 955.9 |
| $0.2-0.0-0.3-0.5$ | 1000 | 8000 | 1 | 296.0 | 296.4 | 438.0 | 441.3 | 596.1 | 612.2 |
|  |  |  | 2 | 390.4 | 404.7 | 506.7 | 523.2 | 630.0 | 658.9 |
|  |  |  | 3 | 404.1 | 424.7 | 511.8 | 531.2 | 635.7 | 662.0 |

Table 5: Numerical comparison of three algorithms-BRKGA, BRKGA+FC (results extracted from $[12]$ ), and our hybrid approach BRKGA+LLM-on a total of four real-world social network instances. For each network, the algorithms were applied 10 times to each combination of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$.

| Instance | $\|V\|$ | $\|E\|$ | $d$ | $k=32$ |  |  | $k=64$ |  |  | $k=128$ |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  |  |  | BRKGA | BRKGA+FC | BRKGA+LLM | BRKGA | $\mathrm{BRKGA}+\mathrm{FC}$ | BRKGA+LLM | BRKGA | $\mathrm{BRKGA}+\mathrm{FC}$ | BRKGA+LLM |
| soc-hamsterster | 2426 | 16630 | 2 | $1,751.0$ | $1,682.1$ | $1,783.2$ | $1,779.6$ | $1,778.7$ | $1,892.0$ | $1,811.0$ | $1,857.0$ | $2,115.6$ |
| sign-bitcoinotc | 5881 | 35592 | 1 | $3,479.0$ | $3,479.0$ | $3,479.0$ | $4,040.3$ | $4,041.0$ | $4,054.7$ | $4,599.9$ | $4,618.0$ | $4,606.2$ |
|  |  |  | 2 | $5,632.0$ | $5,632.6$ | $5,650.2$ | $5,716.4$ | $5,715.2$ | $5,752.2$ | $5,769.0$ | $5,781.2$ | $5,835.1$ |
|  |  |  | 3 | $5,838.0$ | $5,838.0$ | $5,852.7$ | $5,839.0$ | $5,839.1$ | $5,863.4$ | $5,842.0$ | $5,844.0$ | $5,868.0$ |
| soc-advogato | 6551 | 51332 | 3 | $4,280.3$ | $4,275.5$ | $4,318.6$ | $4,284.4$ | $4,280.0$ | $4,359.9$ | $4,301.2$ | $4,284.0$ | $4,431.9$ |
| soc-wiki-elec | 7118 | 107071 | 1 | $2,167.0$ | $2,176.7$ | $2,188.0$ | $2,265.6$ | $2,268.6$ | $2,286.1$ | $2,367.7$ | $2,366.5$ | $2,408.8$ |
|  |  |  | 2 | $2,354.7$ | $2,355.1$ | $2,365.0$ | $2,390.0$ | $2,388.0$ | $2,409.7$ | $2,454.5$ | $2,427.5$ | $2,478.6$ |
|  |  |  | 3 | $2,357.1$ | $2,357.3$ | $2,366.2$ | $2,389.5$ | $2,389.7$ | $2,406.4$ | $2,452.2$ | $2,426.5$ | $2,474.2$ |

Table 6: Comparison of the LLM output with random values. static refers to a variant of BRKGA+LLM in which the LLM output is replaced by probabilities computed based on random alpha and beta values. dynamic refers to a very similar BRKGA+LLM variant in which the random values for the alpha's and beta's are dynamically changed at each iteration.

| Instance | $\|V\|$ | $\|E\|$ | $d$ | $k=32$ |  |  | $k=64$ |  |  | $k=128$ |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  |  |  | static | dynamic | BRKGA+LLM | static | dynamic | BRKGA+LLM | static | dynamic | BRKGA+LLM |
| soc-hamsterster |  |  | 1 | $1,226.5$ | $1,227.1$ | $1,238.9$ | $1,419.7$ | $1,418.5$ | $1,500.2$ | $1,605.6$ | $1,609.0$ | $1,791.5$ |
|  | 2426 | 16630 | 2 | $1,744.8$ | $1,746.3$ | $1,783.2$ | $1,777.5$ | $1,781.3$ | $1,972.5$ | $1,811.0$ | $1,811.0$ | $2,150.2$ |
|  |  |  | 3 | $1,788.0$ | $1,788.0$ | $1,876.0$ | $1,816.0$ | $1,811.8$ | $2,056.6$ | $1,825.2$ | $1,822.4$ | $2,211.0$ |
|  |  |  | 1 | $3,479.0$ | $3,479.0$ | $3,479.0$ | $4,037.6$ | $4,038.5$ | $4,061.0$ | $4,593.9$ | $4,594.1$ | $4,628.2$ |
| sign-bitcoinotc | 5881 | 35592 | 2 | $5,632.1$ | $5,632.1$ | $5,650.2$ | $5,715.3$ | $5,715.3$ | $5,767.7$ | $5,761.8$ | $5,734.4$ | $5,842.0$ |
|  |  |  | 3 | $5,838.0$ | $5,838.0$ | $5,852.7$ | $5,839.0$ | $5,839.0$ | $5,873.9$ | $5,842.0$ | $5,842.0$ | $5,874.0$ |
|  |  |  | 1 | $2,463.7$ | $2,464.1$ | $2,485.9$ | $2,949.1$ | $2,949.4$ | $2,958.5$ | $3,338.5$ | $3,339.2$ | $3,402.0$ |
| soc-advogato | 6551 | 51332 | 2 | $4,141.1$ | $4,138.7$ | $4,144.9$ | $4,207.2$ | $4,206.1$ | $4,234.8$ | $4,267.2$ | $4,266.4$ | $4,357.3$ |
|  |  |  | 3 | $4,279.0$ | $4,276.6$ |  | $4,281.3$ | $4,283.4$ | 7.8 | $4,301.1$ | $4,299.7$ | $4,451.5$ |
|  |  |  | 1 1 1 | $2,166.6$ | $2,169.1$ | $2,188.0$ | $2,265.0$ | $2,264.7$ | $2,295.0$ | $2,367.1$ | $2,366.5$ | $2,417.1$ |
| soc-wiki-elec | 7118 | 107071 | 2 | $2,354.8$ | $2,354.8$ | 2,3 | $2,389.0$ | $2,389.8$ | $2,418.6$ | $2,454.4$ | $2,454.8$ | $2,484.0$ |
|  |  |  | 3 | $2,357.3$ | $2,357.1$ | $2,366.2$ | $2,389.8$ | $2,390.1$ | $2,419.6$ | $2,451.9$ | $2,451.0$ | $2,485.0$ |

We can conclude that guidance by LLM output clearly leads to an improved algorithm and results. In other words, these experiments demonstrate that an LLM can provide valuable information to inform a metaheuristic. In fact, we would expect an even higher benefit through LLM guidance in the context of even larger networks. However, this is currently not possible due to the reasons outlined before.

### 5.2.2 Dimension 2 of the Evaluation Framework: Alternative Techniques for Guiding MHs

To assess the reliability of the LLM output in an alternative way, we decided to compare BRKGA+LLM to an algorithm variant in which the alpha and beta values are obtained by an explicit parameter tuning procedure using the irace tool 30 . This algorithm variant will henceforth be called BRKGA+irace. In particular, for each of the four large social networksmentioned in Section 5.1.2 and already used, for example, in Table 6-we applied a tuning procedure for obtaining well-working alpha and beta values in the following way. First, for every combination of $d \in\{1,2,3\}$ and $k \in\{32,64,128\}$ a training instance was generated. Second, irace was applied with a budget of 1000 algorithm runs, using (as before) a computation time limit of $900 \mathrm{CPU}$ seconds per run. After obtaining the final alpha and beta values from irace for each network, BRKGA+irace was applied under the same conditions as BRKGA+LLM to each of the four problem instances. The results are shown in Table 77. We observe that while BRKGA+irace outperforms BRKGA+LLM in the soc-hamsterster and soc-wiki-elec instances, the opposite is the case for the sign-bitcoinotc instance. In the soc-advogato instance, performance is similar except for $d=3$, where BRKGA+irace shows better results. For putting these results into perspective, consider that the alpha and beta values of BRKGA+irace were obtained by a specific tuning process that took 250 hours of computing time for each problem instance, while the LLM output (Claude-3-Opus) is obtained in less than a minute without any specific training for our purpose.

We used Pearson's correlation coefficient [8] to identify relationships between the alpha and beta parameters obtained from irace and those from the LLM output (see the rows labeled with $\rho_{\text {irace,LLM }}$ in Table 8). A value close to -1 indicates a negative correlation,

Table 7: A numerical comparison of BRKGA+LLM and BRKGA+irace. In the latter algorithm, the alpha and beta values are determined by tuning through irace.

| Instance | $\|V\|$ | $\|E\|$ | $d$ | $k=32$ |  | $k=64$ |  | $k=128$ |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  |  |  | BRKGA+irace | BRKGA+LLM | BRKGA+irace | BRKGA+LLM | BRKGA+irace | BRKGA+LLM |
| soc-hamsterster |  |  | 1 | $1,242.4$ | $1,238.9$ | $1,487.9$ | $1,478.0$ | $1,763.2$ | $1,731.3$ |
|  | 2426 | 16630 | 2 | $1,816.3$ | $1,783.2$ | $1,956.9$ | $1,892.0$ | $2,128.7$ | $2,115.6$ |
|  |  |  | 3 | $1,931.4$ | $1,876.0$ | $2,038.4$ | $1,947.3$ | $2,192.5$ | $2,180.2$ |
|  |  |  | 1 | $3,478.8$ | $3,479.0$ | $4,054.5$ | $4,054.7$ | $4,606.0$ | $4,606.2$ |
| sign-bitcoinotc | 5881 | 35592 | 2 | $5,642.3$ | $5,650.2$ | $5,749.1$ | $5,752.2$ | $5,823.5$ | $5,835.1$ |
|  |  |  | 3 | $5,851.6$ | $5,852.7$ | $5,860.4$ | $5,863.4$ | $5,867.1$ | $5,868.0$ |
|  |  |  | 1 | $2,487.3$ | $2,485.9$ | $2,951.9$ | $2,952.2$ | $3,380.9$ | $3,385.1$ |
| soc-advogato | 6551 | 51332 | 2 | $4,141.3$ | $4,144.9$ | $4,224.6$ | $4,223.1$ | $4,329.2$ | $4,330.1$ |
|  |  |  | 3 | $4,320.1$ | $4,318.6$ | $4,366.8$ | $4,359.9$ | $4,441.0$ | $4,431.9$ |
|  |  |  | 1 | $2,188.7$ | $2,188.0$ | $2,293.2$ | $2,286.1$ | $2,411.5$ | $2,408.8$ |
| soc-wiki-elec | 7118 | 107071 | 2 | $2,375.3$ | $2,365.0$ | $2,417.5$ | $2,409.7$ | $2,482.90$ | $2,478.6$ |
|  |  |  | 3 | $2,378.8$ | $2,366.2$ | $2,415.3$ | $2,406.4$ | $2,478.60$ | $2,474.2$ |

meaning that when one value increases, the other decreases. A value close to +1 indicates a positive correlation, where both values tend to move together. A value close to 0 means there is no clear relationship between the two series. Our observations are as follows:

1. In the instances where BRKGA+irace clearly dominates-soc-hamsterster and soc-wikielec-there is a moderate to strong negative correlation concerning the alpha values. However, concerning the beta values, there is no clear relationship in the context of soc-hamsterster, whereas there is a negative correlation in the context of soc-wiki-elec. Thus, negative correlations are predominant. This suggests that the values determined by irace and the LLM tend to move in opposite directions, and based on the results, the direction chosen by irace appears to be the better one.
2. In contrast, in the sign-bitcoinotc instance, where BRKGA+LLM outperforms BRKGA+irace, there is no correlation between the two methods concerning the alpha values. The LLM's prediction is unique and unrelated to irace's, demonstrating that the LLM could find good results that irace missed.
3. The results for the soc-advogato instance are inconclusive since, for each $k \in\{32,64,128\}$, there is no definitive winner between BRKGA+irace and BRKGA+LLM. A negative correlation concerning the alpha values but a positive correlation in the beta values can be observed. This suggests that either irace has identified the alpha values correctly but not the beta values, or the LLM has identified the beta values correctly but not the alpha values.

We believe that, although BRKGA+LLM's results are not favorable compared to those obtained with the help of irace in the context of two out of four problem instances, our approach benefits from a significantly reduced computational effort. This still holds when the computation time required to extract five metric values to build the prompts is taken into account. Additionally, with model improvements or prompt adjustments-for example, the LLM currently, by its own internal decision, produces values divisible by 0.05 , leading to a loss of precision compared to irace-greater precision could enable the LLM to improve in the future.

Table 8: The alpha and beta values as determined by irace and the LLM for each case. Pearson's correlation coefficient ( $\rho_{\text {irace,LLM }}$ ) is used to quantify the relationships between the two sets of values.

|  | soc-hamsterster |  | sign-bitcoinotc |  | soc-advogato |  | soc-wiki-elec |  |
| ---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | irace | LLM | irace | LLM | irace | LLM | irace | LLM |
| $\alpha_{1}$ | 0.40 | 0.10 | 0.28 | 0.15 | 0.21 | 0.15 | 0.08 | 0.15 |
| $\alpha_{2}$ | 0.08 | 0.30 | 0.14 | 0.25 | 0.21 | 0.25 | 0.05 | 0.25 |
| $\alpha_{3}$ | 0.03 | 0.20 | 0.30 | 0.20 | 0.12 | 0.35 | 0.21 | 0.20 |
| $\alpha_{4}$ | 0.40 | 0.10 | 0.18 | 0.30 | 0.34 | 0.15 | 0.25 | 0.30 |
| $\alpha_{5}$ | 0.09 | 0.30 | 0.10 | 0.10 | 0.12 | 0.10 | 0.41 | 0.10 |
| $\rho_{\text {irace,LLM }}$ | -0.85 |  | 0.02 |  | -0.27 | -0.38 |  |  |
| $\beta_{1}$ | 0.78 | 0.60 | 0.61 | 0.70 | 0.31 | 0.60 | 0.61 | 0.70 |
| $\beta_{2}$ | 0.83 | 0.60 | 0.21 | 0.60 | 0.65 | 0.70 | 0.92 | 0.60 |
| $\beta_{3}$ | 0.65 | 0.90 | 0.01 | 0.80 | 0.83 | 0.90 | 0.19 | 0.90 |
| $\beta_{4}$ | 0.01 | 0.60 | 0.51 | 0.05 | 0.75 | 0.60 | 0.80 | 0.60 |
| $\beta_{5}$ | 0.75 | 0.60 | 0.50 | 0.10 | 0.86 | 0.70 | 0.51 | 0.50 |
| $\rho_{\text {irace,LLM }}$ | 0.08 |  | -0.55 |  | 0.55 |  | -0.67 |  |

### 5.2.3 Dimension 3 of the Evaluation Framework: Prompt Quality

In the final dimension, we transition from a numerical analysis-as conducted in the previous two dimensions - to a more interpretative approach, where we discuss the complex process of designing a well-working prompt tailored to the considered optimization problem. To accomplish this, we first examine the five selected metrics already introduced in Section 4.1. This is crucial because every additional metric enlarges the prompt. And the larger the prompt, the smaller the maximum network size that-due to the limited size of the context window-can be passed to the LLM. Also, larger prompts are associated with increased financial costs. Hence, it is essential to determine whether similar or even superior results can be achieved using less information. To investigate this, we perform two experiments: the first assesses the correlation between each pair of metrics, and the second removes information from the prompt to analyze the impact on the LLM results.

Correlation between metrics. For this analysis, we utilize a matrix of plots provided in Figure 5 concerning the soc-hamsterster instance for which BRKGA+LLM significantly outperformed BRKGA; see Table 5. Hereby, the plots in the upper triangle of the matrix are scatter plots that display the values of all pairs of metrics. For example, the second plot in the first matrix row shows the scatter plot concerning the values of metrics out-degree (x-axis) and in-degree (y-axis). In contrast, the plots in the lower triangle are kernel density estimation (KDE) plots for each pair of metrics. KDE plots provide a smoothed representation of the underlying data distribution, aiding in the identification of patterns such as clusters, outliers, and non-linear relationships. Lastly, the diagonal showcases univariate KDE plots for each variable, analogous to a histogram, depicting the distribution of each variable independently. Note that a corresponding graphic concerning the other problem instances is provided in the GitHub repository, whose link can be found in Section 5.1.3. The following observations can be made based on Figure 5

- The upper triangle reveals that all pairs of metric comparisons exhibit a non-linear pattern, albeit to varying degrees. For instance, the relationship between in-degree and closeness indicates a complex interaction between the metrics, suggesting that each
metric contributes additional information about the problem. This finding indicates that none of the considered metrics is superfluous.
- The KDE plots in the lower triangle highlight non-linear relationships that may not be as apparent in the scatter plots. The relationship between pagerank and all other metrics (bottom row) indicates mainly a more linear relationship with other metrics, which was not as evident in the scatter plots. Still, the outliers shown in the scatter plots do not allow pagerank to be excluded from the prompt.
- Finally, the diagonal of univariate KDE plots reveals that certain metrics, such as betweenness, contain more frequently occurring values - observe the peak in the plot. In other words, some betweenness values repeat across many nodes in this instance. This insight suggests developing a prompt design strategy to further decrease the prompt size.

Upon examining each metric, we conclude that all are potentially relevant and contribute to the outcome. However, it is still possible that adjusting the set of metrics by removing certain metrics or adding alternative ones could lead to even better results. ${ }^{17}$

Removal of information. During our investigation, we discovered that modifying the prompt has the following effects:

- When removing the graph metrics from the prompt (by removing the [EXAMPLE GRAPH] tag), the LLM is still capable of generating useful response values. This implies that the LLM's extensive pre-training enables it to infer alpha and beta values, leveraging its prior knowledge of relevant metrics for social network node coverage problems. Despite this prior knowledge, providing an example graph (in terms of the five metric values per node) allows the LLM to refine the alpha and beta values to better suit the considered $k$ - $d \mathrm{DSP}$ problem, resulting in improved output.
- Expressing metric values for each node in scientific numerical notation does not compromise the quality of the LLM's response ([DATA] tag). This approach offers a dual benefit: it enables greater precision while reducing the character count and, therefore, the number of tokens in the prompt.
- The beta values play a crucial role in shaping the response quality. That is, omitting them significantly reduces the quality of the LLM's output. By assigning importance weights to each metric (alpha values) and requesting an expected value (beta), we apparently enable the LLM to uncover more subtle patterns in the evaluation graph's metrics ([EVALUATION GRAPH] tag), ultimately leading to enhanced results.

To summarize, while the LLM possesses prior knowledge, it appears insufficient to enable the model to independently identify patterns in tabular numerical data.

Differences in node selection. Finally, we wanted to study how the use of LLM output leads to the selection of different nodes for solutions produced by BRKGA+LLM in comparison to BRKGA. For this purpose, Figure 6 shows the node probabilities computed based on the alpha and beta values (black line) in relation to the (normalized) values of the five metrics,[^7]![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-25.jpg?height=1492&width=1518&top_left_y=397&top_left_x=271)

Figure 5: Correlations between all pairs of the five considered metrics concerning the sochamsterster network.

exemplary in the context of the synthetic graph 0.2-0.0-0.3-0.5. The $\mathrm{x}$-axis ranges over all 500 graph nodes, ordered by a non-increasing LLM-probability. Moreover, by means of horizontal lines the graphic marks the nodes chosen for the best BRKGA solution (dotted), the best BRKGA+LLM solution (solid), and their intersection (dashed). In the following, we point out three specific cases highlighted as (a), (b), and (c) in Figure 6 .

(a) One of the nodes selected by BRKGA+LLM (second solid green line) has a much higher closeness metric value than it has an out-degree metric value. Remember that out-degree is the standard metric used by BRKGA. This indicates that the LLM can identify more suitable nodes by blending information from several available metrics.
![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-26.jpg?height=610&width=1538&top_left_y=374&top_left_x=270)
(a)
(b)
(c)

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-26.jpg?height=220&width=163&top_left_y=758&top_left_x=1295)

Figure 6: Analysis of the probabilities computed based on the alpha and beta values (black line) in relation to the (normalized) values of the five metrics. The x-axis ranges of all 500 nodes of the synthetic graph 0.2-0.0-0.3-0.5 ordered by a non-increasing LLM-probability. Moreover, the graphic marks the nodes chosen for the best BRKGA solution, the best BRKGA+LLM solution, and their intersection.

(b) Similar to (a), it can be observed that for the first and last node selected by BRKGA+LLM, the closeness value is higher than the one of out-degree. In contrast, in the context of those nodes that are shared by both BRKGA and BRKGA+LLM (green dashed lines), closeness is high, but so is out-degree.

(c) Cases in which closeness is high and out-degree is relatively lower in the context of nodes selected by BRKGA+LLM can also be seen in this example. This indicates that, for the $0.2-$ 0.0-0.3-0.5 network, the best solution is achieved due to the LLM's ability to recognize the importance of closeness for certain nodes, an importance that pure BRKGA cannot detect due to a lack of information.

### 5.3 Visual Comparative Analysis

Numerical analysis can fall short of capturing the full complexity of a metaheuristics' search process due to its stochastic nature. Visual tools have emerged in recent years to address this limitation. They were developed to provide a more comprehensive understanding and additional insight. One such tool is STNWeb [13, which generates directed graphs from algorithm trajectories to visualize how these algorithms navigate the search space. This allows to compare and justify the performance of different algorithms. A visual analysis is presented in this section to understand better the advantages of our BRKGA+LLM approach over BRKGA and BRKGA+FC.

Figure 7/shows a STNWeb plot displaying 10 runs of each BRKGA+LLM, BRKGA, and BRKGA+FC when applied to the soc-hamsterster instance. The following analysis highlights the insights that can be obtained from this visualization. However, first of all, let us explain the technical elements of the plot:

1. Each of the 30 algorithm runs is shown as a trajectory - that is, a directed path-in

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-27.jpg?height=868&width=1514&top_left_y=383&top_left_x=291)

Figure 7: STNWeb-generated plot comparing the trajectories of BRKGA (cyan), BRKGA+FC (magenta) and BRKGA+LLM (green) over 10 runs on the soc-hamsterster instance (with $d=1$ and $k=32$ ). This plot was generated using the so-called agglomerative clustering partitioning method available in STNWeb, with the number of clusters set to approximately $20 \%$ of the total, allowing for a visualization focusing on the essential characteristics.

the search space. Hereby, the trajectories of the three algorithms are distinguished by color: BRKGA (cyan $\bullet$ ), BRKGA+FC (magenta $\bullet$ ), and BRKGA+LLM (green $\bullet$ ).

2. Trajectory starting points are marked by a yellow square ( - . Moreover, trajectory end points are generally marked by a black triangle ( $)$.
3. A trajectory consists of multiple solutions (nodes, $\bullet, \bullet$, and $\bullet$ ) connected by directed edges, each with an associated fitness value. Since this is a maximization problem $(k-d \mathrm{DSP})$, the fitness increases as it approaches the end of the trajectory $>$.
4. The size of each node indicates the number of trajectories that have passed through it.
5. A red node $\bullet$ includes a best solution found by all 30 algorithm trajectories. Note that different best solutions might have been found.

Several interesting observations can be made based on Figure 7. First of all, only BRKGA+LLM can find best solutions (see the two red dots). Moreover, the two best solutions found by BRKGA+LLM are rather different from each other, as they are found in different areas of the search space. The three algorithms seem to be attracted by different areas of the search space. Moreover, while BRKGA and BRKGA+FC clearly converge to solutions that are close to each other, this is not so much the case for BRKGA+LLM, which does not show a clear convergence behavior towards a single area of the search space. Finally, note that the search
trajectories of BRKGA are much shorter than those of the two hybrid approaches. Additional STN plots concerning other problem instances can be found in the repository whose link was provided in Section 5.1.3.

Following the empirical study of our prompt's design and quality (Section 5.2) and following a visual analysis, we can conclude that our proposed hybridization achieves its intended objective: showing that LLMs can generate heuristic information that can be used to improve the search process of a metaheuristic. Interestingly, our approach has also outperformed an alternative hybridization scheme that used heuristic information produced by a hand-crafted,

![](https://cdn.mathpix.com/cropped/2024_06_04_4b5b0da92d35b97d1bbbg-28.jpg?height=51&width=1548&top_left_y=800&top_left_x=274)
into MHs involves addressing several critical issues and open questions, detailed in the next section.

## 6 Discussion and open questions

The LLM frenzy continues to gain momentum, with new papers appearing daily praising their virtues. LLMs are being applied far and wide, from tackling complex problems to simplifying mundane tasks. While it is uncertain whether their utility is universally applicable, our approach reveals the potential of LLMs to serve as pattern recognizers, uncovering hidden patterns and providing researchers with insights to boost their optimization algorithms. Our study gives rise to several open questions, including the following ones:

- Are LLMs merely stochastic parrots or black boxes capable of reasoning? In the influential paper by Bender et al. [7], the authors raise concerns about the risks of using LLMs and question their necessity. They argue that LLMs are trained on vast amounts of data based on probability distributions but lack any reference to meaning, earning them the label of stochastic parrots. However, significant progress has been made since the paper's publication in 2021. LLMs have improved their capabilities, and it is questionable if they can still be called "stochastic parrots." Instead, they might be seen as black boxes that can reason within a certain context. Our research demonstrates the utility of LLMs in one such context of reasoning. Moreover, several other studies have confirmed the abil of LLMs to reason in other specific contexts 1,34 . On the other hand, other - more sensitive - contexts such as legal or moral reasoning [3] need more thoughtful human oversight, since a careless integration of LLMs could potentially have an unpredictably disruptive effect. Thus, we suggest approaching LLMs with caution and letting the experiments speak for themselves. After all, technology can improve rapidly, and it is essential to avoid hasty dismissal or overhyping LLMs as a silver bullet.
- Are private LLMs the sole providers of superior outcomes? In the past, it would have been accurate to affirm this, as models such as GPT-4 and Claude-3-Opus were recognized for their top-tier response quality. In fact, our research demonstrates that Claude-3-Opus outperforms its competitors. However, the scene is evolving rapidly. Recent models, such as Cohere's Command-R +, Mistral's Mistral models, and Meta's Llama 3 (which we did not incorporate in our study, because its context limit is very low: 8192), are delivering results comparable to some of the before-mentioned models (e.g., $17,29,15$ ). These models also come with open licenses, although with varying
levels of permissiveness. Nonetheless, it is important to note that these models are all products of private entities with substantial financial resources. The prospect of a public entity or small business independently creating an LLM from scratch appears remote, largely due to the computational demands and associated costs. This could potentially pose a risk to the transparency of their design processes 23 .
- What are the primary obstacles to adopting the strategy proposed in our research? We identify two significant hurdles: cost constraints and technical limitations. While leveraging LLMs as software-as-service can alleviate the need for in-house cluster training, a substantial financial burden is incurred by processing large volumes of tokens. Our investigation revealed that even with moderate-sized graph instances of around 7000 nodes, we quickly reach the token limit of what the most permissive LLM can handle within its context window (see subsection 5.1.2). Having said that, recent studies (see, for example, 35 ) have proposed the possibility of "infinite" context windows. Additionally, Google's Gemini Pro 1.5 model boasts an impressive 2,800,000token context window limit 43. However, to successfully apply a strategy similar to ours in the context of massive graphs - or, more generally, in the context of large-scale problem instances-these two limitations must be significantly mitigated. Alternatively, a novel prompt strategy could be developed to detect patterns in metrics while reducing token counts, potentially through prompt compression 25 or relevant node metric filtering. Neither of these alternatives has been investigated in our research.
- As researchers, what other aspects of LLMs should we be cautious about? Earlier, we touched on the issue of LLMs' capability for reasoning in certain contexts. However, many argue that they are incapable of reasoning altogether. This discrepancy stems from the ambiguity surrounding the term "reasoning". In our context, reasoning refers to the ability to infer and identify useful patterns in metrics associated with each node of a graph. In particular, we demonstrated that LLMs do not produce random or uninformative values but rather follow the given instructions. However, if we had left the concept of "reasoning" or "pattern discovery" too vague, our research would be susceptible to misinterpretation. Therefore, we recommend that researchers be aware of the underlying philosophical discussions surrounding this technology when working with LLMs. After all, technological advancements can shape the way we express ourselves. A good starting point may be to engage with the works of Floridi (e.g., 19, 20 ). Particularly since the boundaries of LLMs' capabilities remain undefined and are a subject of ongoing debate.
- Are there ways to improve the integration between MHs and LLMs? As discussed in Section 2.2, there are already a few hybridization approaches. These include creating new MHs by leveraging LLMs to generate code and employing LLMs as solvers for optimization problems described in natural language. In contrast, our approach utilizes LLMs as pattern detectors for complex instances. These patterns are then used to bias the search process of the metaheuristic. However, an intriguing integration could involve combining all these hybridization techniques within a single software framework. We believe that these approaches are not mutually exclusive but rather complementary. By unifying them, we may unlock even greater contributions to the field of MHs. One potential approach to achieving this integration could be through the use of agents 49], which would be responsible for orchestrating the three hybridization methods. Note
that agents are currently a topic of significant interest in the LLM community [22.


## 7 Conclusion

This paper showcased the potential of leveraging Large Language Models (LLMs) as pattern search engines to enhance metaheuristics (MH) by integrating the information they provide. We demonstrate the effectiveness of this approach on a combinatorial optimization problem in the realm of social networks. An important aspect of our work is prompt engineering. In fact, useful LLM answers are only obtained with well-designed prompts. In the context of the considered social networks problem, the LLM output is used to compute a probability for each node of the input graph to belong to an optimal solution. These node probabilities are then used to bias the search process of a biased random key genetic algorithm (BRKGA). We could show that our hybrid approach outperforms both the pure BRKGA and the stateof-the-art BRKGA variant, whose search process is biased by the output of a hand-designed (and trained) graph neural network model.

This pioneering approach paves the way for further exploration, including extending LLMassisted pattern recognition to problem instances in a broader range of optimization problems.

## Acknowledgements

C. Chacón, C. Blum and F. Bistaffa were supported by grants TED2021-129319B-I00 and PID2022-136787NB-I00 funded by MCIN/AEI/10.13039/501100011033.

## References

[1] Janice Ahn, Rishu Verma, Renze Lou, Di Liu, Rui Zhang, and Wenpeng Yin. Large Language Models for Mathematical Reasoning: Progresses and Challenges. 2024. arXiv: 2402.00157 [cs.CL]

[2] Mirko Alicastro, Daniele Ferone, Paola Festa, Serena Fugaro, and Tommaso Pastore. "A reinforcement learning iterated local search for makespan minimization in additive manufacturing machine scheduling problems". In: Computers \& Operations Research 131 (2021), p. 105272.

[3] Guilherme F.C.F. Almeida, José Luiz Nunes, Neele Engelmann, Alex Wiegmann, and Marcelo de Araújo. "Exploring the psychology of LLMs' moral and legal reasoning". In: Artificial Intelligence 333 (2024), p. 104145. ISSN: 0004-3702. DOI: https://doi.org/ $10.1016 / j . a r t i n t .2024 .104145$

[4] Anthropic. The Claude 3 Model Family: Opus, Sonnet, Haiku. 2024. eprint: https : //paperswithcode.com/paper/the-claude-3-model-family-opus-sonnet-haiku.

[5] Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fairness and machine learning: Limitations and opportunities. MIT Press, 2023.

[6] Partha Basuchowdhuri and Subhashis Majumder. "Finding Influential Nodes in Social Networks Using Minimum k-Hop Dominating Set". In: Applied Algorithms. Ed. by Prosenjit Gupta and Christos Zaroliagis. Cham: Springer International Publishing, 2014, pp. 137-151. ISBN: 978-3-319-04126-1. URL: https://link.springer.com/chapter/ 10.1007/978-3-319-04126-1_12.

[7] Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" In: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT '21. Virtual Event, Canada: Association for Computing Machinery, 2021, pp. 610-623. ISBN: 9781450383097. DOI: $10.1145 / 3442188.3445922$. URL: https://doi.org/10. $1145 / 3442188.3445922$.

[8] Jacob Benesty, Jingdong Chen, Yiteng Huang, and Israel Cohen. "Pearson Correlation Coefficient". In: Noise Reduction in Speech Processing. Berlin, Heidelberg: Springer Berlin Heidelberg, 2009, pp. 1-4. ISBN: 978-3-642-00296-0. DOI: 10.1007/978-3-64200296-0_5. URL: https://doi.org/10.1007/978-3-642-00296-0_5.

[9] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. "Machine learning for combinatorial optimization: a methodological tour d'horizon". In: European Journal of Operational Research 290.2 (2021), pp. 405-421.

[10] Christian Blum, Jakob Puchinger, Günther R. Raidl, and Andrea Roli. "Hybrid metaheuristics in combinatorial optimization: A survey". In: Applied Soft Computing 11.6 (2011), pp. 4135-4151. ISSN: 1568-4946. DOI: https://doi .org/10 . 1016/j . asoc. 2011.02.032. URL: https://www. sciencedirect.com/science/article/pii / S1568494611000962.

[11] Tom B. Brown et al. Language Models are Few-Shot Learners. 2020. arXiv: 2005.14165 [cs.CL].

[12] Camilo Chacón Sartori and Christian Blum. "Boosting a Genetic Algorithm with Graph Neural Networks for Multi-Hop Influence Maximization in Social Networks". In: 2022 17th Conference on Computer Science and Intelligence Systems (FedCSIS). 2022, pp. 363371. DOI: $10.15439 / 2022 \mathrm{~F} 78$.

[13] Camilo Chacón Sartori, Christian Blum, and Gabriela Ochoa. "STNWeb: A new visualization tool for analyzing optimization algorithms". In: Software Impacts 17 (2023), p. 100558. ISSN: 2665-9638. DOI: https://doi.org/10.1016/j.simpa.2023.100558 URL: https://www.sciencedirect.com/science/article/pii/S2665963823000957.

[14] Antônio Augusto Chaves and Luiz Henrique Nogueira Lorena. "An adaptive and near parameter-free BRKGA using Q-learning method". In: 2021 IEEE Congress on Evolutionary Computation (CEC). IEEE. 2021, pp. 2331-2338.

[15] Hailin Chen et al. ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up? 2024. arXiv: 2311.16989 [cs.CL].

[16] Wenhu Chen. Large Language Models are few(1)-shot Table Reasoners. 2023. arXiv: 2210.06710 [cs.CL].

[17] Christopher Davis et al. Prompting open-source and commercial language models for grammatical error correction of English learner text. 2024. arXiv: 2401.07702 [cs.CL].

[18] Adrià Fenoy, Filippo Bistaffa, and Alessandro Farinelli. "An attention model for the formation of collectives in real-world domains". In: Artificial Intelligence 328 (2024), p. 104064. ISSN: 0004-3702. DOI: https://doi.org/10.1016/j.artint.2023.104064. URL: https://www.sciencedirect.com/science/article/pii/S0004370223002102.

[19] Luciano Floridi. "Ai as Agency Without Intelligence: On Chatgpt, Large Language Models, and Other Generative Models". In: Philosophy and Technology 36.1 (2023), pp. 1-7. DOI: $10.1007 /$ s13347-023-00621-y.

[20] Luciano Floridi and Anna C Nobre. "Anthropomorphising machines and computerising minds: the crosswiring of languages between Artificial Intelligence and Brain \& Cognitive Sciences". In: SSRN Electron. J. (2024).

[21] Michel Gendreau and Jean-Yves Potvin, eds. Handbook of Metaheuristics. 3rd. Springer Publishing Company, Incorporated, 2019.

[22] Taicheng Guo et al. Large Language Model based Multi-Agents: A Survey of Progress and Challenges. 2024. arXiv: 2402.01680 [cs.CL].

[23] Bahareh Harandizadeh, Abel Salinas, and Fred Morstatter. Risk and Response in Large Language Models: Evaluating Key Threat Categories. 2024. arXiv: 2403.14988 [cs.CL].

[24] Marc Huber and Günther R Raidl. "Learning beam search: Utilizing machine learning to guide beam search for solving combinatorial optimization problems". In: International Conference on Machine Learning, Optimization, and Data Science. Springer. 2021, pp. 283-298.

[25] Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models. 2023. arXiv: 2310.05736 [Cs.CL]

[26] Maryam Karimi-Mamaghan, Mehrdad Mohammadi, Patrick Meyer, Amir Mohammad Karimi-Mamaghan, and El-Ghazali Talbi. "Machine learning at the service of metaheuristics for solving combinatorial optimization problems: A state-of-the-art". In: European Journal of Operational Research 296.2 (2022), pp. 393-422. ISSN: 0377-2217. DOI: https : / / doi . org / 10 . 1016 / j . ejor . 2021 . 04 . 032, URL: https : / / www . sciencedirect.com/science/article/pii/S0377221721003623.

[27] Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford Large Network Dataset Collection. http://snap.stanford.edu/data. June 2014.

[28] Defeng Liu, Vincent Perreault, Alain Hertz, and Andrea Lodi. "A machine learning framework for neighbor generation in metaheuristic search". In: Frontiers in Applied Mathematics and Statistics 9 (2023), p. 1128181.

[29] Zhengzhong Liu et al. LLM360: Towards Fully Transparent Open-Source LLMs. 2023. arXiv: 2312.06550 [cs.CL]

[30] Manuel López-Ibáñez, Jérémie Dubois-Lacoste, Leslie Pérez Cáceres, Mauro Birattari, and Thomas Stützle. "The irace package: Iterated racing for automatic algorithm configuration". In: Operations Research Perspectives 3 (2016), pp. 43-58.

[31] Flavien Lucas, Romain Billot, Marc Sevaux, and Kenneth Sörensen. "Reducing Space Search in Combinatorial Optimization Using Machine Learning Tools". In: Learning and Intelligent Optimization. Ed. by Ilias S. Kotsireas and Panos M. Pardalos. Cham: Springer International Publishing, 2020, pp. 143-150. ISBN: 978-3-030-53552-0.

[32] Christopher M. and Hugh. Deep learning: Foundations and concepts. en. 1st ed. Cham, Switzerland: Springer International Publishing, Nov. 2023.

[33] Zeyuan Ma et al. LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation. 2024. arXiv: 2403.01131 [math.0C]

[34] Suvir Mirchandani et al. Large Language Models as General Pattern Machines. 2023. arXiv: 2307.04721 [cs.AI].

[35] Tsendsuren Munkhdalai, Manaal Faruqui, and Siddharth Gopal. Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention. 2024. arXiv: 2404. 07143 [cs.CL].

[36] David Nettleton. "A Synthetic Data Generator for Online Social Network Graphs". In: Social Network Analysis and Mining December 2016, (July 2016). DOI: 10 . 1007/ s13278-016-0352-y

[37] Runbo Ni, Xueyan Li, Fangqi Li, Xiaofeng Gao, and Guihai Chen. FastCover: An Unsupervised Learning Framework for Multi-Hop Influence Maximization in Social Networks. 2021. DOI: 10.48550/ARXIV.2111.00463. URL: https://arxiv.org/abs/2111.00463

[38] Erdős Paul. "On random graphs I". In: Publicationes Mathematicae 6 (1959), p. 290.

[39] Michal Pluhacek, Anezka Kazikova, Tomas Kadavy, Adam Viktorin, and Roman Senkerik. "Leveraging Large Language Models for the Generation of Novel Metaheuristic Optimization Algorithms". In: Proceedings of the Companion Conference on Genetic and Evolutionary Computation. GECCO '23 Companion. Lisbon, Portugal: Association for Computing Machinery, 2023, pp. 1812-1820. ISBN: 9798400701207. DOI: $10.1145 /$ 3583133.3596401. URL: https://doi.org/10.1145/3583133.3596401.

[40] Shuofei Qiao et al. Reasoning with Language Model Prompting: A Survey. 2023. arXiv: 2212.09597 [cs.CL]

[41] Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng Gao. Rethinking Interpretability in the Era of Large Language Models. 2024. arXiv: 2402. 01761 [cs.CL].

[42] Yuan Sun, Sheng Wang, Yunzhuang Shen, Xiaodong Li, Andreas T. Ernst, and Michael Kirley. "Boosting ant colony optimization via solution prediction and machine learning". In: Computers 8 Operations Research 143 (2022), p. 105769. ISSN: 0305-0548. DOI: https : / / doi . org / 10 . 1016 / j . cor . 2022 . 105769. URL: https : / / www . sciencedirect.com/science/article/pii/S0305054822000636.

[43] Gemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. 2024. arXiv: 2403.05530 [cs.CL].

[44] OpenAI team. GPT-4 Technical Report. 2023. arXiv: 2303.08774 [cs. CL]

[45] Hugo Touvron et al. LLaMA: Open and Efficient Foundation Language Models. 2023. arXiv: 2302.13971 [cs.CL].

[46] Ashish Vaswani et al. Attention Is All You Need. 2023. arXiv: 1706.03762 [cs.CL].

[47] Zhongwei Wan et al. Efficient Large Language Models: A Survey. 2024. arXiv: 2312 . 03863 [cs.CL].

[48] Jason Wei et al. Emergent Abilities of Large Language Models. 2022. arXiv: 2206.07682 [cs.CL].

[49] Zhiheng Xi et al. The Rise and Potential of Large Language Model Based Agents: A Survey. 2023. arXiv: 2309.07864 [cs.AI]

[50] Yingjie Xing, Zhentong Chen, Jing Sun, and Long Hu. "An Improved Adaptive Genetic Algorithm for Job-Shop Scheduling Problem". In: Third International Conference on Natural Computation (ICNC 2007). Vol. 4. 2007, pp. 287-291. DOI: 10.1109/ICNC. 2007.202 .

[51] Chengrun Yang et al. Large Language Models as Optimizers. 2023. arXiv: 2309.03409 [cs.LG].

[52] Lianmin Zheng et al. Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. 2023. arXiv: 2306.05685 [cs.CL].


[^0]:    ${ }^{1}$ The reverse integration, which involves enhancing ML architectures with $\mathrm{MH}$ techniques, is beyond the scope of this study.

[^1]:    ${ }^{2}$ https://openai.com/index/hello-gpt-4o.

    3 https://www.anthropic.com/news/claude-3-family,

    ${ }^{4}$ https://deepmind.google/technologies/gemini

    5 https://mistral.ai/news/mixtral-8x22b

    ${ }^{6}$ https://docs.cohere.com/docs/command-r-plus

[^2]:    ${ }^{7}$ The term "hallucination" in the context of LLMs was derived from the concept of "AI hallucination," which refers to incorrect responses generated by AI systems. In fact, this term was adopted due to the tendency of humans to anthropomorphize technology, attributing human qualities to it. As Floridi and Nobre have recently shown 20 , such a tendency is common with disruptive technologies. It has also been shown that, as we become more familiar with these technologies, the tendency to anthropomorphize should decrease over time.

[^3]:    ${ }^{8}$ When generating text or paraphrasing, it is advisable to increase the temperature. This is because creativity is a welcome characteristic in these scenarios.

[^4]:    ${ }^{9}$ The sigmoid function has been used for many purposes in neural networks. But also in metaheuristics, for example, for significantly accelerating the convergence of a genetic algorithm 50 .

    ${ }^{10}$ BRKGA's are well-known GA variants, mostly for solving combinatorial optimization problems.

[^5]:    11 https://chat.Imsys.org

    ${ }^{12}$ Please be aware that our experiments took place between February and May 2024, and the LLMs ranking classification in Chatbot Arena may have changed by the time of reading.

    ${ }^{13}$ https://openrouter.ai.

    ${ }^{14}$ The instance names are obtained by a concatenation of the utilized parameter values: examples are 0.4$0.15-0.15-0.3,0.3-0.0-0.3-0.4$, and $0.2-0.0-0.3-0.5$. The parameters labeled $a, b, c$, and $d$, respectively, define communities weights $(a$ and $d$ ) and link weights between communities ( $b$ and $c), a+b+c+d \approx 1$. These parameters influence the topology of the network, specifically the total number of connections and the density.

    ${ }^{15}$ The maximum context window of an LLM sets the maximum amount of text it can process simultaneously when generating a response. This constraint determines the scope of contextual information the LLM can draw upon when answering a question or completing a task. The response quality will likely degrade if the input prompt exceeds this limit. Given that our prompt design requires each metric for each node to be equally important, the LLM needs to consider as much context as possible to deliver reasonable and trustworthy results.

[^6]:    ${ }^{16}$ Future research could expand the framework's dimensions to better justify LLMs' response quality and integration with MHs and to address unexplored aspects.

[^7]:    ${ }^{17}$ Financial limitations prevent from conducting extensive experiments and from studying every aspect of the prompt, especially for large-size, challenging scenarios; hence, careful consideration is essential.

