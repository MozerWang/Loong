# Semantics-Preserved Distortion for Personal Privacy Protection in Information Management 

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-01.jpg?height=311&width=1223&top_left_y=387&top_left_x=425)

December 6, 2022


#### Abstract

Although machine learning and especially deep learning methods have played an important role in the field of information management, privacy protection is an important and concerning topic in current machine learning models. In information management field, a large number of texts containing personal information are produced by users every day. As the model training on information from users is likely to invade personal privacy, many methods have been proposed to block the learning and memorizing of the sensitive data in raw texts. In this paper, we try to do this more linguistically via distorting the text while preserving the semantics. In practice, we leverage a recently our proposed metric, Neighboring Distribution Divergence, to evaluate the semantic preservation during the distortion. Based on the metric, we propose two frameworks for semantics-preserved distortion, a generative one and a substitutive one. We conduct experiments on named entity recognition, constituency parsing, and machine reading comprehension tasks. Results from our experiments show the plausibility and efficiency of our distortion as a method for personal privacy protection. Moreover, we also evaluate the attribute attack on three privacy-related tasks in the current natural language processing field, and the results show the simplicity and effectiveness of our data-based improvement approach compared to the structural improvement approach. Further, we also investigate the effects of privacy protection in specific medical information management in this work, and show that the medical information pre-training model using our approach can effectively reduce the memory of patients and symptoms, which fully demonstrates the practicality of our approach.


Keywords: Semantic-Preserved Distortion; Personal Privacy Protection; Neighboring Distribution Divergence; Medical Information Management.

## 1 Introduction

With the development of mobile applications and the application of artificial intelligence, intelligent services are gradually penetrating the lives of people, such as personalized recommendation services based on social media, e-commerce, information search engine, business management, and location-based services (Zhou, Li, \& Teng, 2022). Online service providers access and collect users' personal information through privacy statements and privacy seals for automated decision making. They provide individually tailored recommendations to users, enabling them to enjoy a variety of features and personalized services (Tang, Akram, \& Shi. 2021), so as to target and attract current and potential users. This is an important business model for online service providers to achieve user growth to remain competitive.

While Internet users and online service providers enjoy the benefits of this business model, individuals are under constant surveillance by online service providers, along with the acquisition and use of a large amount of personal information (Harborth \& Pape, 2020). The over-collection and over-use of personal information make users face potential threats related to online information privacy invasion and data breach, which has aroused more and more Internet users' concerns about personal privacy. The potential disclosure and abuse of personal information has become an important concern of users. This may affect user satisfaction, technology adoption and continuous usage (Gong, Zhang, Chen, Cheung, \& Lee, 2020; L. Wang, Sun, Dai, Zhang, \& Hu, 2019). Therefore, alleviating users' privacy concerns and protecting users privacy, retaining users and facilitating their usage behavior have become the key challenges for online service providers to gain competitive advantages (Gerlach, Eling, Wessels, \& Buxmann, 2019; Hudson \& Liu, 2022).

Many scholars have conducted studies on users' privacy protection algorithm for privacy issues (Dreiseitl, Vinterbo, \& Ohno-Machado, 2001). Currently proposed protecting methods for personal privacy mostly cast their attention to the model training procedure, for instance, differential privacy. In their procedure, local data are trained on local devices and the gradients are passed through the network to update the parameters in the center model. However, traditional deep learning algorithms needs to integrate massive personal data of users to train various intelligent service models locally, so as to provide services for users. This integration presents challenges in protecting user privacy since current deep learning models have good memory for training data (Riazi \& Koushanfar, 2018; Song, Ma, Wu, \& Zhang, 2019).

Therefore, this paper proposes a privacy protection algorithm, which differs from previous works by leveraging the very fundamental property of text data, semantics. Rather than proposing new model structure, we concentrate on the data distortion that prevents the model from access to the sensitive data while still guaranteeing the data quality to support the training. To implement such a distortion in practice, an editor that rewrites the original text and preserves the semantics is necessary. Thus, Bidirectional Pre-trained Language Models (PLMs) (Devlin, Chang, Lee, \& Toutanova, 2019) that trained on Masked Language Model (MLM) tasks are desirable choices. We can simply mask the information that should be private to the center model and use the PLMs to reconstruct the masked parts. However, we observe that the direct generation from PLMs is not enough for text data reconstruction as many reconstructed results are semantically irrelevant to the initial content.

Facing the semantics preserving problem, we go for a recently our proposed semantic metric to evaluate the semantic preservation during editions. Neighboring Distribution Divergence (NDD) is a metric that evaluates the contextualized semantic distance between spans based on MLM predictions on masked neighboring words. NDD shows awareness of syntax and semantics and is capable of detecting precise semantic differences like synonyms and antonyms. Based on NDD, we implement two frameworks for semanticspreserved distortion: Generative Distortion and Substitutive Distortion. These distorting
frameworks have experimented on three natural language processing tasks: named entity recognition (NER), constituency parsing and machine reading comprehension (MRC), to explore the performance-preserving ability of our approach for natural language processing models trained with desensitized data.

Apart from these natural language processing tasks, we also employ the proposed semantics-preserved distortion method to defend against the Attribute Inference Attack (AIA) He, Chen, Lyu, and Xu (2022a) for the purpose of exploring the defensive capabilities of our approach to information leakage attacks. Finally, we performed a detailed evaluation analysis in a real medical information management system and the results showed that our approach can be effective in protecting user names and conditions.

Results from our experiments verify the efficiency of our methods as editions with NDD result in texts in much higher quality, which is reflected by the training results and edited results. Our main contributions are reported as follows:

- We propose a novel method for personal privacy protection approach for natural language processing tasks, semantics-preserved distortion.
- We implement a generative and a substitutive framework for semantics-preserved distortion, which is a useful defense against information inference attacks.
- The efficiency of our methods is verified by training results on real medical information management systems.


## 2 Related Work

To effectively deal with personal information security and privacy threats in online services, the researchers have paid attention to the technical solutions to protect privacy. Prior works on privacy protection technology either provide a general architecture, or offer specific algorithms (Friedman, Knijnenburg, Vanhecke, Martens, \& Berkovsky, 2015). Although these two solutions are independent, most researches and applications apply the combination of the two solutions to protect the privacy (Bonomi, Jiang, \& Ohno-Machado. 2020; Kho et al., 2015).

### 2.1 Architectures Solutions

According to the reported work, the architectural approaches can be categorized into two aspects: centralized and distributed. In the centralized privacy protection scheme, the service provider collects the user information provided by the client, processed data centrally and generates appropriate resources for the client without having to know their actual identity (C. Xu, Ding, \& Liao, 2020). Many researches have been devoted in various areas including healthcare, location based services and retrieval services (Adem et al. 2021; Croft, Shi, Sack, \& Corriveau, 2016, Wu et al., 2020). Compared to the centralized scheme, a distributed scheme generates recommendations on the client side, resulting in less sensitive information being disclosed by third party servers (Friedman et al., 2015: Pramod,

2022). It eliminates the single point of failure typical to centralized user modeling data. Therefore, most studies on privacy protection used distributed or decentralized solutions to facilitate online services, especially personalized recommendation services, when designing the security model (Beg, ur Rehman Khan, \& Anjum, 2022).

To address the privacy and security concerns arising from patient data aggregation, Kho et al. (2015) designd and implementd a software application (Distributed Common Identity for the Integration of Regional Health Data-DCIFIRHD), which performs secure, cross-site aggregation, and linkage of EHR data using a distributed encryption algorithm. Relying on a distributed client-server architecture and a two-stage Randomized Response algorithm, Jiang, Li, and Lin (2019) proposed a Secure Distributed Collaborative Filtering (SDCF) recommendation framework to protect privacy, in which user information, item ratings, existence of the ratings, as well as the learned recommendation models are kept secret private. SDCF does not sacrifice too much accuracy for privacy. C. Gao, Huang, Lin, Jin, and Li(2020) proposed a general framework named differential private local collaborative filtering (DPLCF) for recommendation. DPLCF adopts differential private protection mechanism to obfuscate behavior logs and generate recommendation results on user devices. The server only needs to generate and send item-similarity matrix that is irrelevant to user privacy, so it will not introduce any privacy risk. This method is effective under various privacy budgets and different data sparsity levels. In order to ensure the privacy of local data with a low cost of communication bandwidth, an efficient framework named Secure Decentralized Training Framework (SDTF) for Privacy Preserving Deep Learning models was developed Tran, Luong, Karnjana, and Huynh (2021). It can achieve both the privacy and efficiency, while it also retains higher model's utility. In addition, to accommodate the two architectural styles of the application recommendation system domain, C. Xu et al. (2020) proposed two privacy-preservation schemes for two different settings based on trust assessment, i.e. centralized and distributed settings. The results show that the both schemes have good security, efficiency, accuracy and robustness.

Although distributed architecture has been widely applied to privacy protection in online services, especially in the field of recommendation, it still faces the challenge of more computing and communication cost. Many online service algorithms based on user information are computationally intensive and their heavy computations are not applicable to mobile devices. Furthermore, in architectural studies, the authors usually assumed a secure communication channel where such an assumption sometimes may not be true (Friedman et al. 2015).

### 2.2 Algorithmic Solutions

The algorithmic methods for privacy protection focus on Statistical Disclosure Control (SDC) such as anonymization, encryption, differential privacy, data modification, even if the users' personal data accessed by an untrusted party, only modified or encrypted user data is disclosed, not the original data (Friedman et al., 2015).

Anonymization is a kind of widely used methods in privacy protection, which break
the relationship between an individual user and their rating profile (Wu et al. 2018). It ensures that data cannot be traced back to an individual (Nergiz \& Clifton, 2007). In the case of anonymization, the quality of user data and the accuracy of the system cannot be ensured while protecting privacy. To balance data privacy and data validity, a new top-down thinning k-anonymous heuristic algorithm HCE-TDR was proposed under social network environment (Y. Li \& Hu, 2022). Firdaus, Anuar, Karim, and Razak (2018) improved an anonymous location privacy protection model to alleviate the contradiction between personalized mobile service and privacy protection.

A technique of encrypting user service requests is widely used in distributed application recommendation systems to achieve the goal of privacy protection (Yargic \& Bilge, 2019). Beg et al. (2020) designed a fast data encryption scheme based on S-Box to protect data transfers between mobile devices and service providers. The effectiveness and security of the proposed scheme is verified by histogram analysis and MLC results. To solve the problem of forward secrecy, Shuai, Yu, Wang, Xiong, and Li (2021) proposed three-factor anonymous authentication scheme, employing one-way hash chain technique. It applies to only use lightweight cryptographic primitives, personalized health care applications.

However, encryption algorithms may not meet both data security and system availability requirements. Once encryption algorithms are used to encrypt data, many inherent characteristics of private data, such as order and comparability, will be lost (Shuai et al. 2021). To overcome these drawbacks, homomorphic encryption (HE) algorithms that allow operations on encrypted data were proposed. SSengan et al. (2021) incorporated a privacy-protected HE model in the context of physical activity recommendation. Lyu, Ishimaki, and Yamana (2019) designed a privacy recommendation mechanism which adopts collaborative filtering techniques with an encrypted database based on fully homomorphic encryption. The privacy service provider creates and holds the private key, ensuring decryption while maintaining the privacy of individual users. Recently, blockchain-based privacy-enhancing technologies are becoming popular (Lin, Tian, \& Liu, 2021; Pramod, 2022).

Differential privacy highlights the summary information about user habits and behaviors while hiding personal information, which is suitable for recommendation systems and usually adopts distributed architecture (Bonomi et al. 2020). Based on this idea, the local differential privacy (LDP) was added to short-term dynamic recommendation model for small data sets to make private data available and protect private information $(\mathrm{G}$. Li, Yin, Yang, \& Chen, 2021). Bonomi, Wu, and Fan (2022) presented a privacy protection method in sharing personal ECG time-series data, which utilizes dimensionality reduction techniques and random sampling to achieve privacy protection and clinical utility of original data. Focusing on the field of context-aware recommendation systems for information retrieval, S. Zhang et al. (2021) proposed a novel graph convolutional networks integrating the local differential privacy, which can defend against privacy attacks that infer user attributes based on behavioral footprints and recommendation results.

For data modification approaches, obfuscation, data perturbation, data hiding and ran-
domization are frequently used. For instance, in order to protect the privacy of digital library users, Wu et al. (2020) constructed a set of reasonable fake queries for each user query, and confused the sensitive topic behind the user query by the feature similarity. Scheider, Wang, Mol, Schmitz, and Karssenberg (2020) introduced simulated crowding as an obfuscation technique to defend against inference attacks in the study of spatial behaviour patterns. It hides spatial point tracks in extensions which emulate credible behaviour. Beg et al. (2021) proposed a chaotic based RDT approach for privacy-preserving data mining (PPDM) in recommendation system.

Most of the above solutions only address data privacy issues from a statistical perspective based on data distribution. Their abstract parameters are often difficult for users to understand and can hardly capture the qualitative and inherent semantic requirements of the current legal framework. As a result, they face limitations both in practical feasibility and the utility of preserving the semantics of the protected data (Batet \& Sánchez, 2018). To overcome the limitations of statistical approaches to privacy protection, researchers have made some explorations on semantic privacy-preserving model. For instance, Batet and Sánchez (2018) defined an inherently semantic privacy protection paradigm, named Semantic Disclosure Control (SeDC) was proposed, which relies on state of the art semantic technologies, and rethinks privacy protection in terms of the meaning of the data. Protecting privacy from a semantic perspective can provide more general, intuitive, powerful and practical protection for data. However, so far, the research on privacy protection considering data semantics up to some degree have been scarce.

Hence, we concentrate on the property of text data and propose a more linguistic framework for data distortion with the main semantics preserved. Many metrics have been proposed to evaluate the semantics of sequences in NLP. The cosine similarity (T. Gao, Yao, \& Chen, 2021; Reimers \& Gurevych, 2019) is a commonly used metric for word and text similarity evaluation. BERTScore (T. Zhang, Kishore, Wu, Weinberger, \& Artzi, 2020) is a recently proposed PLM-based semantic metric that shows significant potential for generated results evaluation, compared with the conventional word matching metrics.

## 3 Neighboring Distribution Divergence

### 3.1 Background

In this paper, we use two most commonly used semantic textual similarity metric: perplexity and cosine similarity. Before the main discussion, we first recall the definition of perplexity and cosine similarity as the basis for further discussion.

Perplexity Perplexity is widely used as a evaluation metric for language models. Given a model and an input text sequence, perplexity measures the possibility of the model to generate the input sequence.

For a sentence with $n$ words (more specifically, subwords) $W=\left[w_{1}, w_{2}, \cdots, w_{n}\right]$, perplexity refers to the average of $\log$ possibility for each word to exist in $W$. If the perplexity
is evaluated by an MLM-based PLM, then the existing possibility is represented by the predicting distribution on the masked position.

$$
\begin{aligned}
W_{m} & =\left[w_{1}, \cdots, w_{i-1},[\mathrm{MASK}], w_{i+1}, \cdots, w_{n}\right] \\
Q & =\mathrm{PLM}^{M L M}\left(W_{m}\right), \quad q_{i}=\operatorname{softmax}\left(Q_{i}\right) \in \mathbb{R}^{c} \\
p_{i} & =q_{i, \operatorname{Idx}\left(w_{i}\right)}, \quad \mathrm{PPL}=\frac{1}{n} \sum_{i=0}^{n}-\log \left(p_{i}\right)
\end{aligned}
$$

The PLM predicts the distribution $Q$ for the masked word on $i$-th position. Then, the softmax function is used to get the probability distribution $Q$ where $q_{j}$ refers to the appearance possibility of $j$-th word in the $c$-word dictionary on $i$-th position. Here $\operatorname{Idx}(\cdot)$ returns the index of word in the dictionary. The distribution predicting process is summarized as a function $\operatorname{MLM}(\cdot)$ where $\operatorname{MLM}(W, i)=q_{i}$. As implausible words or structures will result in high perplexity, this metric can reflect some semantic information. Perplexity is commonly used to evaluate the plausibility of text and detect semantic errors in sentences.

Cosine Similarity Cosine similarity has been widely used for calculating the semantic similarity of words, sentences and documents. It focuses on measuring the the angle between two vectors projected in the multi-dimensional space instead of their lengths.

For the a sentence pair $W_{x}, W_{y}$, a pre-trained encoder (like PLM or word embedding) encodes their contextual representations as $R_{x}, R_{y}$. We use PLM-based $\mathrm{S}_{C}$ for experiments and follow the best representing scenario in (T. Gao et al., 2021) to use the CLS token as the sentence representation. The cosine similarity between the $W_{x}$ and $W_{y}$ can be calculated by:

$$
\begin{aligned}
& R_{x}=\operatorname{PLM}\left(W_{x}\right), \quad R_{y}=\operatorname{PLM}\left(W_{y}\right) \\
& \mathrm{S}_{C}\left(W_{x}, W_{y}\right)=\frac{R_{x}^{C L S} \cdot R_{y}^{C L S}}{\left\|R_{x}^{C L S}\right\| \times\left\|R_{y}^{C L S}\right\|}
\end{aligned}
$$

### 3.2 NDD Calculation

In this section, we follow Peng, Li, and Zhao (2021) to describe the procedure for calculating NDD. In the definition of Neighboring Distribution Divergence, distribution refers to the predicted probability distributions in MLM, and divergence refers to the KL divergence of the predicted distributions between two different sentences. Then neighboring means that more weight will be on words near the edited spans. NDD directly reflects the semantic perturbance on other unedited words caused by the edit. The overview of NDD calculating procedure can be found in Figure 1

Given a sentence $W$ with $n$ words $W=\left[w_{1}, w_{2}, \cdots, w_{n}\right]$, an editing operation $E$ is used to convert the sentence. For formula simplification, $E$ is supposed to be a single replacing operation. $E$ replaces a span $\left[w_{i}, w_{i+1}, \cdots, w_{j}\right]$ in $W$ with a span $V=\left[v_{1}, v_{2}, \cdots, v_{k}\right]$, and results in the new sentence $W^{\prime}=\left[w_{1}, \cdots, w_{i-1}, v_{1}, \cdots, v_{k}, w_{j+1}, \cdots, w_{n}\right]$. We calculate

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-08.jpg?height=728&width=1324&top_left_y=224&top_left_x=366)

Figure 1: Calculating procedure for Neighboring Distribution Divergence.

the predicted distribution divergence on neighboring words $\left[w_{1}, \cdots, w_{i-1}, w_{j+1}, \cdots, w_{n}\right]$ of the edit. We use MLM-based prediction as depicted in Figure 1 .

For a sentence $W$, we predict the MLM-based distribution on $i$-th position as follows.

$$
\begin{aligned}
W_{m} & =\left[w_{1}, \cdots, w_{i-1},[\operatorname{MASK}], w_{i+1}, \cdots, w_{n}\right] \\
R & =\operatorname{PLM}\left(W_{m}\right) ; d=\operatorname{softmax}\left(R_{i}\right) \in \mathbb{R}^{c}
\end{aligned}
$$

We mask the word on $i$-th position and then apply PLM for prediction on that position. Finally, a softmax function is used to get the probability distribution $D$ where $d_{j}$ refers to the appearance possibility of $j$-th word in the $c$-word dictionary on $i$-th position. We summarize this distribution predicting process with a function $\operatorname{MLM}(\cdot)$ where $\operatorname{MLM}(W, i)=d$.

Then we go back to edit. For the edit $E$, we use $\operatorname{MLM}(\cdot)$ to predict the distribution $D=$ $\left[d_{1}, \cdots, d_{i-1}, d_{j+1}, \cdots, d_{n}\right]$ of neighboring words in the unedited sentence $W$. We calculate another distribution $D^{\prime}$ for those unedited neighboring words in the edited sentence $W^{\prime}$. After we get the distributions $D$ and $D^{\prime}$, we use KL divergence to calculate the difference between the two distributions.

$$
\operatorname{div}=D_{K L}\left(d^{\prime}|| d\right)=\sum_{i=1}^{c} d_{i}^{\prime} \log \left(\frac{d_{i}^{\prime}}{d_{i}}\right)
$$

Here we use $D$ from the unedited sentence as the observed distribution and $D^{\prime}$ from the edited sentence for approximation. After we get the divergence div between each pair in $D$ and $D^{\prime}$, we use a weighted sum for the final NDD score.

$$
\operatorname{NDD}\left(W, W^{\prime}\right)=\sum_{k \in[1, \cdots, i-1, j+1, \cdots, n]} a_{k} d i v_{k}
$$

where $a_{k}$ is the distance weight which can be designed as $\mu^{\min (|k-i|,|k-j|)}(\mu \leq 1.0)$. Dis-
tance weight is added for scaling for that more divergence will be detected on words closer to edited spans. In later experiments, this weight will be re-designed for specific tasks. Generally speaking, words closer to edited spans will be weighted higher.

## 4 Generative and Substitutive Distortion

We then introduce our distorting procedure in this section. For the sentence $W$ and a span $W_{i: j}=\left[W_{i}, W_{i+1}, \cdots, W_{j}\right]$ that contains private information that should be rewritten. We first use the mask token of the PLM to substitute the span.

$$
W_{\text {masked }}=\left[w_{1}, \cdots, w_{i-1},[\mathrm{MASK}], \cdots,[\mathrm{MASK}], w_{j+1}, \cdots, w_{n}\right]
$$

We then search for the span $S$ to fill in the masked positions that cause as small semantic perturbance as possible. In the generative scenario, we leverage the PLM to predict the distributions of masked positions from left to the right. We sample a token from each predicted distribution. In the substitutive scenario, the center model stores a group of phrases that are collected in advance and uses them to fill in the masked positions.

$$
W^{\prime}=\left[w_{1}, \cdots, w_{i-1}, s_{1}, \cdots, s_{k}, w_{j+1}, \cdots, w_{n}\right]
$$

In both scenarios, we sample the rewritten spans for multiple $k$ times, and the semantic changes caused by the rewriting are evaluated by the NDD metrics as described above.

$$
S=\underset{S}{\operatorname{argmin}}\left(\operatorname{NDD}\left(W, W^{\prime}\right)\right)
$$

## 5 Experiments

To have a thorough comparison between NDD and other semantic similarity metrics, we conduct experiments on the test dataset of Semantic Textual Similarity Benchmark Dinarelli and Grobol (2019) ${ }^{1}$ (STS-B). We designed five sentence pair similarity evaluation tasks to compare the metric performance and investigate the metric property, including Synonym-Antonym test, Part-of-speech (POS) test, Term test, Lemma test, and Initial test.

Semantic Distance Evaluation Semantic Textual Similarity Benchmark (STS-B) includes English datasets used in the STS tasks organized in the context of SemEval between 2012 and 2017. The data include 8,628 sentence pairs from image captions, news headlines and user forums. Each pair has a human-labeled degree of similarity scores, ranging from 0 for no meaning overlap to 5 for meaning equivalence. The detailed statistics of the dataset can be seen in Table 1[^0]

|  | News | Caption | Forum | Total |
| :--- | :--- | :--- | :--- | :--- |
| Train | 3299 | 2000 | 450 | 5749 |
| Dev | 500 | 625 | 375 | 1500 |
| Test | 500 | 625 | 254 | 1379 |

Table 1: Detailed statistics of STS-B

As the source of privacy-related text data is limited, we secondly conduct our experiments on three phrase-related NLP tasks, named entity recognition, constituency parsing, and machine reading comprehension, whose examples are presented in Figure 2. We experiment on the CoNLL03 dataset Sang and Meulder (2003) for named entity recognition and Penn Treebank Marcus, Santorini, and Marcinkiewicz (1993) for constituency parsing. The machine reading comprehension experiments are conducted on SQuAD 1.0 dataset Rajpurkar, Zhang, Lopyrev, and Liang (2016), SQuAD 2.0 dataset Rondeau and Hazen (2018), and COQA Reddy, Chen, and Manning (2019) dataset. And we evaluate the Attribute Inference Attack on three tasks: Trustpilot (TP) Hovy, Johannsen, and Søgaard (2015), AG news Corso, Gulli, and Romani (2005), and Blog posts (Blog) Schler, Koppel, Argamon, and Pennebaker (2006).

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-10.jpg?height=1065&width=1445&top_left_y=1238&top_left_x=311)

Figure 2: Examples for NER, constituency parsing and MRC

Named Entity Recognition NER, a common sub-task of Information Extraction, aims at identifying and classify named entities in unstructured text into different categories including locations, person names and organizations. NER systems often serves as the first stage for many downstream crucial information management tasks, such as question answering, coreference resolution and topic modeling.

For named entity recognition, we experiment on the CoNLL03 dataset which is a collection of news wire articles from the Reuters Corpus. CoNLL03 contains four types of entities: person, location, organization, and miscellaneous. The detailed statistics of the dataset can be seen in Table 2

|  | Person | Location | Organization | Miscellaneous |
| :--- | :---: | :---: | :---: | :---: |
| Train | 6600 | 7140 | 6321 | 3438 |
| Dev | 1842 | 1837 | 1341 | 922 |
| Test | 1617 | 1668 | 1661 | 702 |

Table 2: Detailed statistics of CoNLL03 dataset (number of named entities)

Constituency Parsing Given an unstructured sentence, constituency parsing seeks to generate a constituency-based parse tree which represents the sentence's syntactic structure. Constituency parsing are often used as the basis of many NLP downstream tasks such as information extraction and question answering.

For the constituency parsing, we conduct experiments on the Penn Treebank which consists of about 40,000 sentences from Wall Street Journal (WSJ) articles. We use the most common split of this corpus where sections 2-21 are used for training, section 22 for development data, and section 23 for final testing. The Penn Treebank contains 46 part-of-speech tags and 27 non-terminal labels. The detailed statistics of Penn Treebank can be seen in Table 3

|  | \#Train | \#Dev | \#Test | \#POS | \#Labels |
| :---: | :---: | :---: | :---: | :---: | :---: |
| PTB | 39,832 | 1,700 | 2,416 | 46 | 27 |

Table 3: Detailed statistics of CoNLL03 dataset (\# denotes numbers)

Machine Reading Comprehension Machine Reading Comprehension is one of the most significant and challenging tasks in Natural Language Preprocessing. Given a text passage, MRC aims at extracting meaning and generating the answers to the questions based on the passage.

The Stanford Question Answering Dataset v1.0 (SQuAD v1.0) consists of 107,785 questions/answer pairs, where the answer to each question is a span from the corresponding Wikipedia articles. SQuAD v2.0 extends the SQuAD v1.0 with over 50,000 crowd-sourced unanswerable questions which is similar to answerable ones. CoQA dataset contains more than 127,000 questions with answers collected from more than 8000 crowd-sourced conver-
sations about given passages collected from seven diverse domains in the form of questions and answers. The detailed dataset statistics can be seen in Table4

|  | SQuAD 1.1 |  | SQuAD 2.0 |  | COQA |  |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
|  | \#QA pair | \#article | \#QA pair | \#article | \#QA pair | \#passages |
| Train | 87,599 | 442 | 130,319 | 442 | 108,647 | 7199 |
| Dev | 10,570 | 48 | 11,873 | 35 | 7,983 | 500 |
| Test | 9,533 | 46 | 8,862 | 28 | - | 200 |

Table 4: Detailed statistics of SQuAD 1.0 SQUAD 2.0 and COQA dataset (\# dennotes numbers)

To further prove the efficiency of our proposed NDD, we employ NDD to defend against Attribute Inference Attack (AIA) He et al. (2022a) on three AIA evaluation datasets.

AIA Defense Evaluation We adopt the same preprocess method in He et al. (2022a). For TP dataset, we merely includes the examples containing information of both gender and age, and treat them as the private variables. For AG news dataset, we take person entities as private information. For Blog dataset, the age and gender of the author are treated as private information. The detailed statistics of all three datasets can be found in Table 5

|  | TP | AG | Blog |
| :--- | :--- | :--- | :--- |
| Train | 22,142 | 11,657 | 7,098 |
| Dev | 2,767 | 1,457 | 887 |
| Test | 2,767 | 1,457 | 887 |

Table 5: Detailed statistics of TP, AG, and Blog dataset

### 5.1 Model Setup

### 5.1.1 Semantic Distance Evaluation

Multiple sentence pair similarity evaluation tasks are designed to compare the metric performance and investigate the metric property.
- Synonym-Antonym test creates sentence pairs by replacing words with their synonyms and antonyms. Replacing by the synonym (antonym) results in a positive (negative) pair.
- Part-of-speech (POS) test replaces words with ones that have the same (positive) or different (negative) parts-of-speech ${ }^{2}$
- Term test replaces verbs with ones in the same (positive) and different (negative) terms.
- Lemma test replaces words with ones that have the same (positive) or different (negative) lemma root.[^1]- Initial test uses initial STS-B sentence pairs.

We replace $20 \%$ words for synonym-antonym, POS, and lemma tests. $100 \%$ verbs are replaced for term test. The words for the replacement are sampled from the STS test dataset following their frequency. For initial test, we sample sentence pairs with an LCS (longest common sequence) that consists of at least $80 \%$ words in the shorter sentence. We use Roberta $_{\text {base }}$ as the PLM and apply Hellinger distance as the divergence function to guarantee the boundary of our metric. Mean pooling is used as the attention assigning strategy.

$$
\mathrm{H}\left(q, q^{\prime}\right)=\frac{1}{\sqrt{2}} \sqrt{\sum_{k=1}^{c}\left(\sqrt{q_{k}}-\sqrt{q_{k}^{\prime}}\right)^{2}} \sim[0,1]
$$

### 5.1.2 Natural Language Processing Tasks

We build the model following the parser in (Yu, Bohnet, \& Poesio, 2020) and (Y. Zhang, Zhou, \& Li. 2020). Instead of the conventional biaffine (Dozat \& Manning, 2017) parser, we use a recently proposed Accumulative Operation-based Induction (AOI) as our parser in the experiment. Concretely, we use GloVe embedding with 100 (Pennington, Socher, \& Manning, 2014) dimensions as the word embedding. Other features, including character sequence, part-of-speech tag, and lemma, are represented by 50 -dimension tensors and concatenated to the input embedding. Roberta-large is used as the pre-trained language model to produce contextual representations of 100 dimensions that are also concatenated to the input representation. The BiLSTM (Hochreiter \& Schmidhuber, 1997) with 3 layers and 400 hidden size is used to contextualize the input representations. Then, the edge and label scores are scored by two AOI scorers with 4 attention heads.

Specifically, AOI scorer has two sub-scorers, SelfAttn scorer and Multi-head Gathering Attention scorer (MHG). The first sub-scorer sketch the general relation of head-dependent pairs and the second sub-scorer compute the relations from a more global aspect. SelfAttn scorer obtains dot product scores for head and dependent representations. Multi-head Gathering Attention scorer first calculate global representations using multiple attention heads. Then, the MHG concatenates the global representations with each attention head to compute the attention distribution of each head. MHG chooses the max head attention scores as the attention scores for head and depend. The final MHG attention scores are calculated by mutual product between head and depend scores multiplied by the sentence length. The final AOI scores are the direct product of SelfAttn scores and MHG scores.

We train the parser to minimize the Cross Entropy Loss and use the Adam optimizer (Kingma \& Ba. 2015) initialized with the learning rate $10^{-3}$ to update the parameters in the model. We sample 8 candidates for both generative and substitutive distorting scenarios.

In our first experiment, we train the parsers on the client data distorted by different methods. We first train the model on the undistorted dataset to get the upper bound of the model performance. Then we build a simple baseline by training the model on the data whose entity spans are substituted by mask tokens in the same length. Finally, we
experiment on the distortion caused by generations and substitutions that are or are not controlled by NDD.

We also conduct experiments for our proposed NDD metric on machine reading comprehension task. We test the performance of single model on all three original MRC datasets along with their distorted version (substituted with or without NDD metric). To have a fair comparison, we follow the setup in Devlin et al. (2019) and use the $B E R T_{\text {large }}$ as our encoder. MRC models are fine-tuned for 3 epochs with a learning rate of $5 e^{-5}$ and a batch size of 32 .

### 5.1.3 AIA Defense Evaluation

We also conduct defense experiment using NDD against Attribute Inference Attack (AIA), in which we substituting the original dataset with the NDD metric. AIA aims to reconstruct the sensitive components, based on the hidden representation of generated by the extracted mode. Following He et al. (2022a), we adopt five representative defense methods as baselines: (1) Softening prediction Q. Xu, He, Lyu, Qu, and Haffari (2022) which uses temperature parameter $\tau$ on softmax to scale probability vector, (2) Prediction perturbation Q. Xu et al. (2022) which perturbs the original probability vector by adding Gaussian noise with variance of $\sigma$ (3) Reverse sigmoid Lee, Edwards, Molloy, and Su (2019a) which adds random noises on the non-argmax probabilities, (4) Nasty teacher Ma et al. (2021a) which uses Self-Undermining Knowledge Distillation to maintaining correct predictions while maximally disturbing its in-correct predictions. and Most Least He et al. (2022a) which sets the predicted probabilities of the most and least likely categories to $0.5+\epsilon$ and $0.5-\epsilon$, and 0 for others. To have a fair comparison, we employ the same training setting as He et al. (2022a) in which we use BERT-base Devlin et al. (2019) as victim and extracted models. The models are trained for 5 epochs. We adopt Adam optimizer Kingma and $\mathrm{Ba}$ (2015) with a learning rate of $2 e^{-5}$.

### 5.2 Main Results

### 5.2.1 Semantic Distance Evaluation

The STS experiment results are presented in Table 6. NDD outperforms other metrics in all tasks, showing the strong capability of NDD to analyze semantic similarity. Also, NDD is more sensitive to POS, lemma, which is an admirable property to preserve the semantic structure for text editing.

Figure 3 shows how the ratio of LCS affects the metric performance. While $S_{C}$ performs better when fewer overlapped words hinder its evaluation, its performance severely suffers from a drop to even negative when the overlapped word ratio becomes $>80 \%$. In contrast, rising of the ratio helps NDD perform even better as more neighboring words participate in the evaluation to provide a preciser evaluation. The ensemble (ratio $=1: 0.0025$ ) of $\mathrm{NDD}$ and $\mathrm{S}_{C}$ generally boost the evaluating performance when the overlapped ratio $\leq 80 \%$, indicating that NDD and $\mathrm{S}_{C}$ evaluate different aspects of the semantic similarity.

| Metric | Syn-Ant | POS | Term | Lemma | Init. |
| :--- | :---: | :---: | :---: | :---: | :---: |
| $\Delta$ PPL | 5.3 | 2.8 | 8.7 | 7.9 | 11.2 |
| $\mathrm{~S}_{C}$ | 7.8 | 8.1 | 9.1 | 0.0 | 20.8 |
| NDD | $\mathbf{1 9 . 1}$ | $\mathbf{2 2 . 7}$ | $\mathbf{1 1 . 2}$ | $\mathbf{1 7 . 8}$ | 24.0 |
| NDD $+\mathrm{S}_{C}$ | 12.5 | 14.5 | 10.8 | 6.8 | $\mathbf{2 8 . 2}$ |

Table 6: Text similarity evaluation on STS-B subset. We use the Pearson Correlation as the evaluating metric. Syn-Ant: synonym-antonym test. POS: part-of-speech test. Term: verb term test. Lemma: lemma test. Init.: initial STS test.

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-15.jpg?height=563&width=788&top_left_y=672&top_left_x=634)

Figure 3: Relationship between metric performance on the initial test and the ratio of overlapped words.

### 5.2.2 Natural Language Processing Task

| Method | UP | UR | UF | LP | LR | LF |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Unprotected (Upper Bound) | 93.73 | 93.62 | 93.67 | 89.08 | 88.96 | 89.02 |
| Masked | 76.54 | 11.66 | 20.23 | 74.64 | 11.37 | 19.73 |
| Generated w/o NDD | 87.29 | 72.23 | 79.05 | 76.44 | 63.25 | 69.22 |
| Generated w / NDD | $\mathbf{9 0 . 4 4}$ | $\mathbf{8 2 . 6 0}$ | $\mathbf{8 6 . 3 4}$ | $\mathbf{8 1 . 8 9}$ | $\mathbf{7 4 . 7 9}$ | $\mathbf{7 8 . 1 8}$ |
| Substituted w/o NDD | $\mathbf{9 4 . 2 7}$ | 92.05 | $\mathbf{9 3 . 1 5}$ | 88.81 | 86.71 | 87.75 |
| Substituted w/ NDD | 93.82 | $\mathbf{9 2 . 2 1}$ | $\mathbf{9 3 . 0 1}$ | $\mathbf{8 8 . 4 9}$ | $\mathbf{8 7 . 9 5}$ | $\mathbf{8 8 . 7 1}$ |

Table 7: Performances of named entity recognition models trained on client data distorted by different methods to predict the test data.

The results from our main experiments on named entity recognition are shown in Table 7. Our parsers perform well on the task as it achieves 93.67 unlabeled F1 score and 89.02 labeled F1 score. The masking distortion is not a reliable rewriting method for preserving semantics as the model performance dropped sharply when training on data whose entities are masked. NDD is verified to be beneficial for improving the rewritten data quality in both the generative and substitutive scenarios by lifting the labeled F1 scores by 8.96 and 0.96 respectively. The substitutive scenario controlled by the NDD achieves labeled an F1 score very close to the unprotected upper bound (88.71 v.s. 89.02), reflecting the high performance of NDD in semantics preservation. Compared to the substitutive scenario,
the generative scenario is more likely to be benefited from NDD controlling as the generated results from the bidirectional PLMs are more arbitrary and have no guarantee to still be an entity in the same label.

| Method | Config. | UP | UR | UF | LP | LR | LF |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Unprotected (Upper Bound) | - | 92.20 | 91.79 | 91.99 | 90.67 | 90.27 | 90.47 |
| Substituted w / NDD | $100 \% \mathrm{P}$ | 89.38 | 89.46 | 89.42 | 87.55 | 87.63 | 87.59 |
| Substituted w / NDD | $100 \% \mathrm{NP}$ | $\mathbf{9 0 . 6 1}$ | 90.44 | 90.52 | 88.94 | 88.78 | 88.86 |
| Substituted w / NDD | $33 \% \mathrm{NP}$ | $\mathbf{9 2 . 1 1}$ | $\mathbf{9 1 . 6 3}$ | $\mathbf{9 1 . 8 7}$ | $\mathbf{9 0 . 6 8}$ | $\mathbf{9 0 . 2 1}$ | $\mathbf{9 0 . 4 4}$ |

Table 8: Performances of constituency parsers trained on client data distorted by the substitutive scenario in different extents to predict the test data.

Then, we experiment with the substitutive scenario on the constituency parsing task. We substitute different phrases in the text and use the distorted data to train constituency parsers. In major, we substitute the noun phrases as we believe that most private information is stored in them. As shown in Table 8, thanks to the controlling of NDD, even substitution to the whole phrases will not disturb the trained parser performance. When only $33 \%$ noun phrases are substituted, the performance of the constituency parser only drops by 0.03 labeled F1 score, which is a surprising result.

Experiments on NER as well as constituency parsing illustrate that our approach can maintain the accuracy of whole systems while effectively masking sensitive data for the training set. Since named entity recognition and constituency parsing are not the final application in general, we have chosen a typical application of natural language processing, machine reading comprehension, for our experiments. We use the spacy NER tool to locate entities in the training set to perform subsequent masking/replacement operations to preserve private information. The machine reading comprehension results are shown in Table 9 . First, the model trained after desensitization using the NER tool has degraded performance on all three datasets compared to the model trained without desensitization. However, the degradation is significantly smaller after using our Substitute w/ NDD method, which indicates that our method can maintain the generalization ability of the model while effectively protecting privacy.

### 5.2.3 AIA Defense Evaluation

In the previous experiments, we focused on the privacy information protection of specific applications/systems. And next we explore the real user information leakage problem using three user information leakage evaluation datasets, AG News, BLOG and TP-US, and we compare our proposed method with other currently available methods, and the results are shown in Table 10. It is worth noting that since our proposed method is a method that adds confusions to the training data, it is orthogonal to the other methods compared that modify in the model structure, i.e., it can be further integrated to enhance the final effect.

| Single Model | SQuAD 1.0 |  | SQUAD 2.0 |  | $\frac{\mathrm{COQA}}{\mathrm{F}_{1}}$ |
| :---: | :---: | :---: | :---: | :---: | :---: |
|  | $\overline{E M}$ | $\mathrm{~F}_{1}$ | $\overline{E M}$ | $\mathrm{~F}_{1}$ |  |
| Test Set |  |  |  |  |  |
| SAN (Liu et al., 2018) | 76.8 | 84.2 | 68.6 | 71.4 |  |
| BiDAF++ (Shen et al., 2018) | 77.6 | 84.9 | 65.6 | 68.7 | 69.5 |
| QANet (Yu et al., 2018) | 80.9 | 87.8 | 65.4 | 67.2 | - |
| $B^{B E R T}$ large (Devlin et al., 2018) | 85.1 | 91.8 | 79.9 | 83.1 | 74.4 |
| SDNet (Zhu et al., 2018) | - | - | 76.7 | 79.8 | 76.6 |
| SGNet (Zhang et al., 2020a) | - | - | 85.1 | 87.9 | 放 |
| SemBERT large (Zhang et al., 2019b) | - | - | 86.1 | 88.8 | - |
| RoBERTa large (Liu et al., 2019d) | - | - | 86.8 | 89.8 | 84.9 |
| ALBERT $_{\text {large }}$ (Lan et al., 2019) | 89.1 | 94.6 | 86.8 | 89.6 | 85.4 |
| XLNet large (Yang et al., 2019b) | 89.9 | 95.0 | 87.9 | 90.7 | 84.6 |
| Retr-Reader on ELECTRA (Zhang et al., 2020b) | - | - | 89.5 | 92.0 | ![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-17.jpg?height=55&width=146&top_left_y=877&top_left_x=1598) |
| TR-MT (WeChatAI, 2019) | - | - | - | - | 89.3 |
| Dev Set |  |  |  |  |  |
| ![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-17.jpg?height=56&width=802&top_left_y=1040&top_left_x=323) | 90.0 | 95.2 | 88.6 | 90.9 | 88.3 |
| Substituted w/o NDD | 87.9 | 93.1 | 85.1 | 87.4 | 86.5 |
| Substituted w / NDD | 89.6 | 95.0 | 87.8  | 90.5 | 87.7 |

Table 9: The performances of single models on different machine reading comprehension datasets.

Comparing Utility scores, the model structure-based improvement approach is partially helpful for system performance improvement, but not consistently. Our method based on adding confusion to the data has a slight negative impact on the system performance. When comparing the AIA attack metrics, our approach leads to an improvement in defense performance compared to the "No Defense" approach, while the other structure improvement-based approaches are not always beneficial. However, our method is simple, has no dumping on the model, and can be integrated with these model structure improvement-based methods to further improve the results. This suggests that our approach is a very competitive data-based defense method.

## 6 Further Analysis and Discussion

We further analyze our framework by comparing different settings and doing case studies. First, we analyze how much initial information has been preserved during the distortion. We train our named entity recognition model on the distorted data and use the initial data as the test dataset. Table 11 presents our results from this experiment. Masked text can hardly preserve the information of entities. Compared with the conventional generation not controlled by NDD, our methods result in a sharp improvement in entity information preservation.

To certify the benefit of using distorted data in FL, we merge the data distorted by generative distortion with NDD from the client device to the training dataset. Table 12 verifies

|  | AG News |  | BLOG |  | TP-US |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | Utility $\uparrow$ | $\mathrm{AIA} \uparrow$ | Utility $\uparrow$ | $\mathrm{AIA} \uparrow$ | Utility $\uparrow$ | $\mathrm{AIA} \uparrow$ |
| No Defense | 79.99 | 15.76 | $97.07 \quad$ | 34.34 | 85.53 | 36.92 |
| Softening Predictions Q. Xu et al. 2022, | 79.99 | 20.78 | 97.07 | 34.91 | 85.53 | 37.69 |
| Prediction Perturbation (Q. Xu et al., 2022. | 80.03 | 14.46 | 96.17 | $34.75 \quad$ | 85.83 | 37.43 |
| Reverse Sigmoid (Lee, Edwards, Molloy, \& Su, 2019b) | 79.99 | 12.17 | 97.07 | 33.09 | 85.53 | 32.81 |
| NASTY (Ma et al., 2021b) | 79.90 | 17.00 | 96.05 | $34.24 \quad$ | 85.15 | 36.77 |
| MostLeast (He, Chen, Lyu, \& Xu, 2022b) | 79.99 | 17.86 | 97.07 | 34.44 | 85.53 | 37.60 |
| Substituted w/ NDD | 79.70 | 15.95 | 96.84 | $34.47 \quad$ | 84.92 | 37.41 |

Table 10: Attack performance under different defenses on AG News, BLOG and TP-US. Utility means the accuracy of the victim model after adopting defense. For AIA, higher scores indicate better defenses. All experiments are conducted on datasets with $1 \mathrm{x}$ queries.

| Data | UP | UR | UF | LP | LR | LF |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Masked | 67.58 | 15.60 | 25.35 | 62.34 | 14.39 | 23.38 |
| Generated w /o NDD | 93.06 | 86.01 | 89.40 | 92.29 | 85.30 | 88.66 |
| Generated w / NDD | $\mathbf{9 5 . 6 7}$ | $\mathbf{9 4 . 7 8}$ | $\mathbf{9 5 . 2 2}$ | $\mathbf{9 5 . 3 6}$ | $\mathbf{9 4 . 4 7}$ | $\mathbf{9 4 . 9 1}$ |

Table 11: Comparison on entity information preservation among generative distorting methods.

| Data | UP | UR | UF | LP | LR | LF |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Center | 96.42 | 96.49 | 96.46 | 94.69 | 94.75 | 94.72 |
| Center + Distorted Client | $\mathbf{9 7 . 0 1}$ | $\mathbf{9 7 . 1 4}$ | $\mathbf{9 7 . 0 7}$ | $\mathbf{9 5 . 4 4}$ | $\mathbf{9 5 . 5 7}$ | $\mathbf{9 5 . 5 1}$ |

Table 12: Benefit for named entity recognition model training from the augmentation of distorted data.

| PLM | N-Candidate $(k)$ | UP | UR | UF | LP | LR | LF |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| BERT-base-cased | 2 | 94.14 | 92.30 | 93.21 | 88.97 | 87.21 | 88.08 |
| BERT-base-cased | 4 | 94.03 | 92.35 | 93.18 | 89.19 | 87.67 | 88.42 |
| BERT-base-cased | 8 | 93.82 | 92.21 | 93.01 | 89.49 | 87.95 | 88.71 |
| BERT-base-uncased | 8 | 93.65 | 92.32 | 92.98 | 88.79 | 87.67 | 88.23 |
| BERT-large-cased | 8 | $\mathbf{9 4 . 5 6}$ | $\mathbf{9 2 . 3 8}$ | $\mathbf{9 3 . 4 5}$ | $\mathbf{8 9 . 7 0}$ | $\mathbf{8 8 . 1 7}$ | $\mathbf{8 8 . 9 3}$ |

Table 13: Comparison the distorted results of variant configurations.

| Label | Sentence | NDD |
| :---: | :---: | :---: |
| [PER] | Masao Yoshikawa was defeated in the match in Hokkaido. | 0.00 (original) |
|  | Cobb Hero was defeated in the match in Hokkaido . | 0.23 (selected) |
|  | Eventually Blackpool was defeated in the match in Hokkaido . | 5.20 |
| [\mathrm{LOC}]{} | Masao Yoshikawa was defeated in the match in Hokkaido . | $\mathbf{0 . 0 0}$ (original) |
|  | Masao Yoshikawa was defeated in the match in Moscow. | 0.04 (selected) |
|  | Masao Yoshikawa was defeated in the match in 1926. | 5.23 |
| [ORG] | The World Trade Organization deals with the global rules of trade between nations. | 0.00 (original) |
|  | The Swedish Technical Centre deals with the global rules of trade between nations. | 0.05 (selected) |
|  | The underlying principles agree deals with the global rules of trade between nations. | 8.06 |
| [\mathrm{MISC}]{} | The organization admitted Russian as an official language in 2006 . | 0.00 (original) |
|  | The organization admitted Indonesian as an official language in 2006 . | 0.01 (selected) |
|  | The organization admitted efforts as an official language in 2006 . | 4.65 |

Figure 4: Case study for named entity recognition.

| Label | Sentence | NDD |
| :--- | :--- | :--- |
| NP | Big Bear doesn't care for disposable diapers, which aren't biodegradable. | $\mathbf{0 . 0 0}$ (original) |
|  | Big Bear doesn't care for Democrats, which aren't biodegradable. | $\mathbf{0 . 1 1}$ (selected) |
|  | Prices in Bear doesn't care for an election, which aren't biodegradable. | $\mathbf{5 . 7 4}$ |
|  | Prices in Brussels, where a computer breakdown disrupted trading, also surged. | $\mathbf{0 . 0 0}$ (original) |
|  | Prices in Brussels, where a computer breakdown disrupted trading, also go. | $\mathbf{0 . 1 7}$ (selected) |
| ADJP | "Everybody was still confident, including most institutional investors. | $\mathbf{0 . 0 0}$ (original) |
|  | "Everybody was still pleased, including most institutional investors. | $\mathbf{0 . 2 8}$ (selected) |
| ADVP | They went a collective 5-for-24 here, with zero homers and ribbies. | 4.51 |
|  | They went a collective 5-for-24 right now, with zero homers and ribbies. | $\mathbf{0 . 0 0}$ (original) |
|  | They went a collective 5-for-24 back, with zero homers and ribbies. | $\mathbf{0 . 1 6}$ (selected) |

Figure 5: Case study for constituency parsing.

the efficiency of additional distorted data in training, which leads to a 0.79 improvement on the labeled F1 score.

Table 13 shows the performances of the variant configurations of our distorting scheme. Generally, more candidates for selection will result in better semantics preservation during the distortion. Thus, there exists a trade-off between the distorting efficiency and the preservation extend. For the choice of PLM for calculating NDD, larger BERT outperforms smaller BERT, and cased BERT performs better than uncased BERT.

Figure 4 and Figure 5 respectively show the specific rewritten cases from our distorting framework. Compared with the arbitrary generated results from the PLMs, NDDcontrolled generated results preserve most of the original semantics while changing the real content to protect privacy. The better performance of models trained on our distorted scheme can thus be attributed to the higher quality of data rewritten by our framework.

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-20.jpg?height=361&width=1480&top_left_y=208&top_left_x=288)

Figure 6: Privacy theft attacks for medical information management models.

## 7 Application in Medical Information Management

In the previous experimental section, we evaluated the effectiveness of the proposed approach in maintaining performance while keeping sensitive data removed. To further evaluate the usefulness of our approach for privacy preservation, we explore the application in medical information management. With the development of pre-trained Transformer language models such as BERT, GPT, natural language processing tasks based on pre-trained language models in medical information management have also gained remarkable performance improvements. To maintain domain consistency, these pre-trained language models for medical information management applications are typically trained on medical texts such as clinical notes. And because of the high training cost of such pre-trained models, it has motivated the sharing of model parameters, such as the open pre-trained model ClinicalBERT (Alsentzer et al. 2019). Unintended memorization by pretrained models has significant privacy implications, especially where models are trained over non-deidentified data. This makes the use of medical information management systems risky in terms of privacy disclosure.

According to the research of Lehman, Jain, Pichotta, Goldberg, and Wallace (2021), three methods are commonly used to mine sensitive data involved in pre-trained models, as shown in Figure 6, namely Prompt, Probe and Generate. In Lehman et al. (2021)'s experiments, Prompt and Probe are less capable of mining sensitive data, so only the Generate method is explored in this work. According to the experimental setup of Lehman et al. (2021), we trained two BERT structures, Deidentified BERT base and SPL-Deidentified $\mathrm{BERT}_{\text {base }}$. Deidentified BERT base was trained on Medical Information Mart for Intensive

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-20.jpg?height=59&width=1510&top_left_y=2015&top_left_x=273)
sentences generated by inserting patient names to every sentence within corresponding notes (ignoring grammar) in EHR (Electronic Health Records) dataset, which is more likely that an adversary could recover sensitive information.

In this case, we evaluated two main aspects, one was the results of the pre-trained model on the BioNER task to demonstrate its ability to understand medical texts, and the other was to evaluate the potentials of the pre-trained model in memorizing sensitive data according to Lehman et al. (2021)'s practice. In the BioNER task, we chose NCBIDisease X. Wang et al. 2018) as the specific dataset, which was initially introduced for disease name recognition and normalization and has been widely used for a lot of ap-

| Model | BioNER | w/ Name | FirstName | LastName | A@100 | EM |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| BERT $_{\text {base }}$ | 88.32 | $84.7 \%$ | $2.16 \%$ | $7.72 \%$ | $34 \%$ | $12.17 \%$ |
| Deidentified BERT |  |  |  |  |  |  |
| Suse | 90.60 | $47.9 \%$ | $0.94 \%$ | $3.14 \%$ | $16 \%$ | $23.53 \%$ |
| Substituted w/ NDD | $\mathbf{9 0 . 9 5}$ | $52.3 \%$ | $1.37 \%$ | $5.21 \%$ | $5 \%$ | $4.32 \%$ |
| SPL-Deidentified BERT $_{\text {base }}$ | 89.24 | $59.6 \%$ | $2.65 \%$ | $4.56 \%$ | $84 \%$ | $4.17 \%$ |
| Substituted w/ NDD | 90.13 | $64.3 \%$ | $3.42 \%$ | $6.64 \%$ | $23 \%$ | $0.95 \%$ |

Table 14: Results over texts generated by the Deidentified and SPL-Deidentified models. The 'w/ Name' column is percentage of extracted sentences that contain a name token. The First and Last name columns show what percent of unique names produced are in the MIMIC dataset. After re-ranking all unique names, we report the percentage of top 100 names that belong to a reidentified patient. Finally, The EM (exact match) displays what percent of sentences with a patient's name also contain one of their true (MedCAT) conditions.

plications. While in sensitive data extraction, we focus on patient names and normalized condition mentions and map them to their UMLS (Bodenreider, 2004) CUI and description, i.e., MedCAT.

Table 14 shows the comparison of BioNER and sensitive information extraction for standard $\mathrm{BERT}_{\text {base }}$ (general domain), Deidentified $\mathrm{BERT}_{\text {base }}$ and SPL-Deidentified $\mathrm{BERT}_{\text {base }}$ (medical domain). Firstly, comparing the BioNER results shows that the medical domain BERT outperforms the general domain BERT, which indicates that domain pre-training is more helpful for the understanding of medical text. Secondly, Deidentified BERT base is bet-

![](https://cdn.mathpix.com/cropped/2024_06_04_19bde0e7c5f25d4318b3g-21.jpg?height=57&width=1514&top_left_y=1442&top_left_x=274)
in the pre-training of SPL-Deidentified $\mathrm{BERT}_{\text {base }}$, which impairs the linguistic diversity and does not match the input form of the downstream task.

In the metrics of "w / Name" and "Last Name", the general domain BERT is higher in extraction ratio compared to the medical domain BERT, which is caused by the desensitization in medical text before pre-training. The "First Name", in addition to SPL-Deidentified $B^{2} T_{\text {base, }}$, is lowered accordingly. The elevation of SPL-Deidentified $\mathrm{BERT}_{\text {base }}$ is due to the addition of the name insertion.

The variation of the above three metrics only represents the amount of information extracted, and does not reflect the accuracy of the extraction. The accuracy of name implication is reflected by the A100 metric, while the name to condition correspondence is reflected by the EM metric. On the A100 metric, medical $\mathrm{BERT}_{\text {base }}$ is lower compared to general $\mathrm{BERT}_{\text {base, }}$, indicating the effect of de-sensitized data. Whereas, the higher $\mathrm{A} @ 100$ of SPL-Deidentified BERT exacerbates the leakage of information. This is also a side reaction to the fact that pretrained models such as BERT have a memory effect on the training data. And after using our proposed Substituted w/ NDD approach, the exact name extraction effect is significantly lower, both in Deidentified BERT serving the EM metrics, Deidentified $\mathrm{BERT}_{\text {base }}$ even has an improvement compared to general BERT, which is due to the fact that general BERT is not pre-trained on full medi-
cal data and thus less likely to leak the conditions. The higher EM metric of Deidentified $\mathrm{BERT}_{\text {base }}$ also confirms our concern about privacy leakage by pre-training on full medical corpus data, despite the use of some desensitization measures. In contrast, the EM metrics significantly decreased after using our Substituted w/ NDD method as well. In addition, we also observed an interesting phenomenon on SPL-Deidentified $\mathrm{BERT}_{\text {base }}$, where the EM metric also decreased after using name insertion strategy, which may be due to the fact that adding irrelevant names to the sentences diminishes the correspondence between names and conditions and confuse the model's memory. And further using Substituted w/ NDD, a similar decrease in EM metrics was continued to be observed.

## 8 Research Implications

In this paper, we propose a semantics-preserved distortion framework based on NDD for information management models, which is proven to protect personal privacy of user data in training deep models from disclosure. This has important research implication and social value for the protection of user personal privacy in online services.

Compared with statistics-based privacy methods, semantic techniques bring more benefits for improving the accuracy of data protection and preserving the utility of data. Works on privacy protection in context of social media that, so far, have considered integrating semantic technologies up to some degree are scarce. In this paper, we propose a novel method for personal privacy protection in information management for natural language processing tasks, semantics-preserved distortion. A generative and a substitutive framework for semantics-preserved distortion is also implemented to analyze and use the semantics of user data more accurately, as well to achieve more effective distortion of user privacy data. Experiments on privacy-related social media text datasets verified that our approach achieves a good balance between preserving the original semantics of data and preserving personal privacy. To some extent, our method contributes to this topic and provides reference for future semantic research. In addition, our new proposed method can be further applied to the data-distributed deep learning framework, Federated Learning, to maximize the protection of user privacy. It is able to train models in multiple clients without transferring or pooling data in a single location, which eliminates the privacy risks caused by directly sharing data (Sarma et al., 2021). Our experiments demonstrate the superior performance and generalizability of the proposed method for model training in the field of information management.

From a social perspective, our research has important implications for the healthy development of online services represented such as social media, medical. Although personalized service systems for online services are very useful in improving the service level, these systems introduce additional privacy risks in the process of model training. Due to the uncontrolled collection and use of personal data by online service providers to provide personalized services. More and more users are aware of the threat to their privacy and restrict their use of online services. Faced with the privacy threats along with personal-
ized services, our approach proposed new semantic distortion technology to effectively balance the contradiction between improving personalized service level and personal privacy disclosure. The instantiation of our privacy protection model will help online service providers to design personalized service systems that protect users' privacy, so as to improve users' acceptance and utilization of online services, which has important social significance for the healthy development of online services. In addition, the semantic privacy protection framework we proposed reconsiders privacy and data protection from the perspective of data meaning, with more emphasis on data content. By studying the semantics underlying to the data, the disclosure risk of each individual can be automatically assessed, thus coping with heterogeneous sensitivities and the protection needs of per individual (Batet \& Sánchez, 2018).

## 9 Conclusion

In this paper, we propose a novel method, Semantics-Preserved Distortion, to protect the personal privacy of natural language text. We base our framework on the metric, Neighboring Distribution Divergence, which precisely evaluates the semantic changes caused by editions. We use generation and substitution to edit the sentences and complete the edition by choosing the candidates with the smallest Neighboring Distribution Divergence. Experiment results on named entity recognition, constituency parsing, and machine reading comprehension tasks verify the our performance advantage in the case of using desensitized data. Our proposed method can also have a positive effect in the evaluation of attack inference attacks. Moreover, our data-based approach can be integrated with existing model structure-based defense methods to further improve the defense effectiveness. In a practical medical information management scenario, we evaluate that our proposed approach can reduce the model's accurate memory of patient names and conditions.

## References

Adem, B. A., Alrashdan, M., Abdulnabi, M., Jaradat, A., Tubishat, M., Ghanem, W. A., \& Yusof, Y. (2021). A general review on location based services (lbs) privacy protection using centralized and decentralized approaches with potential of having a hybrid approach. International Journal of Future Generation Communication and Networking, 14(1), 3057-3079.

Alsentzer, E., Murphy, J., Boag, W., Weng, W.-H., Jindi, D., Naumann, T., \& McDermott, M. (2019, June). Publicly available clinical BERT embeddings. In Proceedings of the 2nd clinical natural language processing workshop (pp. 72-78). Minneapolis, Minnesota, USA: Association for Computational Linguistics. Retrieved from https://aclanthology.org/W19-1909 doi: 10.18653/v1/W19-1909

Batet, M., \& Sánchez, D. (2018). Semantic disclosure control: semantics meets data privacy. Online Inf. Rev., 42(3), 290-303. Retrieved from https://doi.org/10.1108/OIR $-03-2017-0090$ doi: 10.1108/OIR-03-2017-0090

Batet, M., \& Sánchez, D. (2018). Semantic disclosure control: semantics meets data privacy. Online Information Review.

Beg, S., Ahmad, N., Anjum, A., Ahmad, M., Khan, A., Baig, F., \& Khan, A. (2020). S-box design based on optimize LFT parameter selection: a practical approach in recommendation system domain. Multim. Tools Appl., 79(17-18), 11667-11684. Retrieved fromhttps://doi.org/10.1007/s11042-019-08464-6 doi: 10.1007/s11042 $-019-08464-6$

Beg, S., Anjum, A., Ahmed, M., Malik, S. U. R., Malik, H., Sharma, N., \& Waqar, O. (2021). Dynamic parameters-based reversible data transform (RDT) algorithm in recommendation system. IEEE Access, 9, 110011-110025. Retrieved from https://doi.org / $10.1109 / A C C E S S .2021 .3101150$ doi: 10.1109/ACCESS.2021.3101150

Beg, S., ur Rehman Khan, S., \& Anjum, A. (2022). Data usage-based privacy and security issues in mobile app recommendation (MAR): a systematic literature review. Libr. Hi Tech,40(3), 725-749. Retrieved from https://doi.org/10.1108/LHT-04-2021 -0147 doi: $10.1108 /$ LHT-04-2021-0147

Bodenreider, O. (2004). The unified medical language system (umls): integrating biomedical terminology. Nucleic acids research, 32(suppl_1), D267-D270.

Bonomi, L., Jiang, X., \& Ohno-Machado, L. (2020). Protecting patient privacy in survival analyses. J. Am. Medical Informatics Assoc., 27(3),366-375. Retrieved from https: / doi.org/10.1093/jamia/ocz195 doi: 10.1093/jamia/ocz195

Bonomi, L., Wu, Z., \& Fan, L. (2022). Sharing personal ecg time-series data privately. Journal of the American Medical Informatics Association.

Corso, G. M. D., Gulli, A., \& Romani, F. (2005). Ranking a stream of news. In A. Ellis \& T. Hagino (Eds.), Proceedings of the 14th international conference on world wide web, WWW 2005, chiba, japan, may 10-14, 2005 (pp. 97-106). ACM. Retrieved from https://doi.org/10.1145/1060745.1060764 doi: 10.1145/1060745 .1060764

Croft, W. L., Shi, W., Sack, J., \& Corriveau, J. (2016). Location-based anonymization: comparison and evaluation of the voronoi-based aggregation system. Int. J. Geogr. Inf. Sci., 30(11), 2253-2275. Retrieved from https://doi.org/10.1080/13658816 .2016 .1172314 doi: $10.1080 / 13658816.2016 .1172314$

Devlin, J., Chang, M., Lee, K., \& Toutanova, K. (2019). BERT: pre-training of deep bidirectional transformers for language understanding. In J. Burstein, C. Doran, \& T. Solorio (Eds.), Proceedings of the 2019 conference of the north american chapter of the association for computational linguistics: Human language technologies, NAACL-HLT 2019, minneapolis, mn, usa, june 2-7, 2019, volume 1 (long and short papers) (pp. 4171-4186). Association for Computational Linguistics. Retrieved from https://doi.org/10.18653/v1/ n19-1423 doi: $10.18653 / v 1 / n 19-1423$

Dinarelli, M., \& Grobol, L. (2019). Seq2biseq: Bidirectional output-wise recurrent neural networks for sequence modelling. CoRR, abs/1904.04733. Retrieved from http:// arxiv.org/abs/1904.04733

Dozat, T., \& Manning, C. D. (2017). Deep biaffine attention for neural dependency parsing. In 5th international conference on learning representations, ICLR 2017, toulon, france, april 24-26, 2017, conference track proceedings. OpenReview.net. Retrieved from https:// openreview.net/forum?id=Hk95PK9le

Dreiseitl, S., Vinterbo, S. A., \& Ohno-Machado, L. (2001). Disambiguation data: extracting information from anonymized sources. In AMIA 2001, american medical informatics association annual symposium, washington, dc, usa, november 3-7, 2001. AMIA. Retrieved from https://knowledge.amia.org/amia-55142-a2001a-1.597057/ t-001-1.599654/f-001-1.599655/a-029-1.600050/a-030-1.600047

Firdaus, A., Anuar, N. B., Karim, A., \& Razak, M. F. A. (2018). Discovering optimal features using static analysis and a genetic search based method for android malware detection. Frontiers Inf. Technol. Electron. Eng., 19(6), 712-736. Retrieved from https://doi.org/10.1631/FITEE. 1601491 doi: 10.1631/FITEE. 1601491

Friedman, A., Knijnenburg, B. P., Vanhecke, K., Martens, L., \& Berkovsky, S. (2015). Privacy aspects of recommender systems. In F. Ricci, L. Rokach, \& B. Shapira (Eds.), Recommender systems handbook (pp. 649-688). Springer. Retrieved from https://doi .org/10.1007/978-1-4899-7637-6_19 doi: 10.1007/978-1-4899-7637-6\_19

Gao, C., Huang, C., Lin, D., Jin, D., \& Li, Y. (2020). DPLCF: differentially private local collaborative filtering. In J. X. Huang et al. (Eds.), Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval, SIGIR 2020, virtual event, china, july 25-30, 2020 (pp. 961-970). ACM. Retrieved from https:// doi.org/10.1145/3397271.3401053 doi: 10.1145/3397271.3401053

Gao, T., Yao, X., \& Chen, D. (2021). Simcse: Simple contrastive learning of sentence embeddings. In M. Moens, X. Huang, L. Specia, \& S. W. Yih (Eds.), Proceedings of the 2021 conference on empirical methods in natural language processing, EMNLP 2021, virtual event / punta cana, dominican republic, 7-11 november, 2021 (pp. 6894-6910). Association for Computational Linguistics. Retrieved from https://aclanthology.org/ 2021.emnlp-main. 552

Gerlach, J. P., Eling, N., Wessels, N., \& Buxmann, P. (2019). Flamingos on a slackline: Companies' challenges of balancing the competing demands of handling customer information and privacy. Inf. Syst. J., 29(2), 548-575. Retrieved from https://doi .org/10.1111/isj. 12222 doi: 10.1111/isj. 12222

Gong, X., Zhang, K. Z. K., Chen, C., Cheung, C. M. K., \& Lee, M. K. O. (2020). What drives self-disclosure in mobile payment applications? the effect of privacy assurance approaches, network externality, and technology complementarity. Inf. Technol. People, 33(4), 1174-1213. Retrieved from https://doi.org/10.1108/ ITP-03-2018-0132 doi: 10.1108/ITP-03-2018-0132

Harborth, D., \& Pape, S. (2020). How privacy concerns, trust and risk beliefs, and pri-
vacy literacy influence users' intentions to use privacy-enhancing technologies: The case of tor. Data Base, 51(1), 51-69. Retrieved from https://doi.org/10.1145/ 3380799.3380805 doi: 10.1145/3380799.3380805

He, X., Chen, C., Lyu, L., \& Xu, Q. (2022a). Extracted BERT model leaks more information than you think! CoRR, abs/2210.11735. Retrieved from https://doi.org/ 10.48550 /arXiv. 2210.11735 doi: 10.48550/arXiv.2210.11735

He, X., Chen, C., Lyu, L., \& Xu, Q. (2022b). Extracted bert model leaks more information than you think! arXiv preprint arXiv:2210.11735.

Hochreiter, S., \& Schmidhuber, J. (1997). Long short-term memory. Neural Comput., 9(8), 1735-1780. Retrieved from/https://doi.org/10.1162/neco.1997.9.8.1735 doi: 10.1162/neco.1997.9.8.1735

Hovy, D., Johannsen, A., \& Søgaard, A. (2015). User review sites as a resource for largescale sociolinguistic studies. In A. Gangemi, S. Leonardi, \& A. Panconesi (Eds.), Proceedings of the 24th international conference on world wide web, WWW 2015, florence, italy, may 18-22, 2015 (pp. 452-461). ACM. Retrieved from https://doi.org/ $10.1145 / 2736277.2741141$ doi: $10.1145 / 2736277.2741141$

Hudson, S., \& Liu, Y. (2022). Mobile app users' privacy concerns: different heuristics for privacy assurance statements in the eu and china. Information Technology $\mathcal{E}$ People.

Jiang, J., Li, C., \& Lin, S. (2019). Towards a more reliable privacy-preserving recommender system. Inf. Sci., 482, 248-265. Retrieved from https://doi.org/10.1016/j .ins.2018.12.085 doi: 10.1016/j.ins.2018.12.085

Kho, A. N., Cashy, J. P., Jackson, K. L., Pah, A. R., Goel, S., Boehnke, J., . . . Galanter, W. L. (2015). Design and implementation of a privacy preserving electronic health record linkage tool in chicago. J. Am. Medical Informatics Assoc., 22(5), 1072-1080. Retrieved from https://doi.org/10.1093/jamia/ocv038 doi: 10.1093/jamia/ocv038

Kingma, D. P., \& Ba, J. (2015). Adam: A method for stochastic optimization. In Y. Bengio \& Y. LeCun (Eds.), 3rd international conference on learning representations, ICLR 2015, san diego, ca, usa, may 7-9, 2015, conference track proceedings. Retrieved from http:// arxiv.org/abs/1412.6980

Lee, T., Edwards, B., Molloy, I., \& Su, D. (2019b). Defending against neural network model stealing attacks using deceptive perturbations. In 2019 ieee security and privacy workshops (spw) (pp. 43-49).

Lee, T., Edwards, B., Molloy, I. M., \& Su, D. (2019a). Defending against neural network model stealing attacks using deceptive perturbations. In 2019 IEEE security and privacy workshops, SP workshops 2019, san francisco, ca, usa, may 19-23, 2019 (pp. 43-49). IEEE. Retrieved from https://doi.org/10.1109/SPW.2019.00020 doi: 10.1109/SPW.2019.00020

Lehman, E., Jain, S., Pichotta, K., Goldberg, Y., \& Wallace, B. (2021, June). Does BERT pretrained on clinical notes reveal sensitive data? In Proceedings of the 2021 conference of the north american chapter of the association for computational linguistics: Human language technologies (pp. 946-959). Online: Association for Computational Linguis-
tics. Retrieved from https://aclanthology.org/2021.naacl-main. 73 doi: 10.18653/v1/2021.naacl-main. 73

Li, G., Yin, G., Yang, J., \& Chen, F. (2021). SDRM-LDP: A recommendation model based on local differential privacy. Wirel. Commun. Mob. Comput., 2021, 6640667:16640667:15. Retrieved from https://doi.org/10.1155/2021/6640667 doi: $10.1155 / 2021 / 6640667$

Li, Y., \& Hu, X. (2022). Social network analysis of law information privacy protection of cybersecurity based on rough set theory. Libr. Hi Tech, 40(1), 133-151. Retrieved from https://doi.org/10.1108/LHT-11-2018-0166 doi: 10.1108/LHT-11 $-2018-0166$

Lin, L., Tian, Y., \& Liu, Y. (2021). A blockchain-based privacy-preserving recommendation mechanism. In 5th IEEE international conference on cryptography, security and privacy, CSP 2021, zhuhai, china, january 8-10, 2021 (pp. 74-78). IEEE. Retrieved from https://doi.org/10.1109/CSP51677.2021.9357604 doi: 10.1109/ CSP51677.2021.9357604

Liu, X., Li, W., Fang, Y., Kim, A., Duh, K., \& Gao, J. (2018). Stochastic answer networks for squad 2.0. arXiv preprint arXiv:1809.09194.

Lyu, Q., Ishimaki, Y., \& Yamana, H. (2019). Privacy-preserving recommendation for location-based services. In 2019 ieee 4th international conference on big data analytics (icbda) (pp. 98-105).

Ma, H., Chen, T., Hu, T., You, C., Xie, X., \& Wang, Z. (2021a). Undistillable: Making A nasty teacher that CANNOT teach students. In 9th international conference on learning representations, ICLR 2021, virtual event, austria, may 3-7, 2021. OpenReview.net. Retrieved from https://openreview.net/forum?id=0zvfm-nZqQs

Ma, H., Chen, T., Hu, T.-K., You, C., Xie, X., \& Wang, Z. (2021b). Undistillable: Making a nasty teacher that $\{$ cannot\} teach students. In International conference on learning representations. Retrieved from https://openreview.net/forum?id=0zvfm $-\mathrm{nZqQs}$

Marcus, M. P., Santorini, B., \& Marcinkiewicz, M. A. (1993). Building a large annotated corpus of english: The penn treebank. Comput. Linguistics, 19(2),313-330.

Nergiz, M. E., \& Clifton, C. (2007). Thoughts on k-anonymization. Data Knowl. Eng., 63(3), 622-645. Retrieved from https://doi.org/10.1016/j.datak.2007.03.009 doi: 10.1016/j.datak.2007.03.009

Peng, L., Li, Z., \& Zhao, H. (2021). A novel metric for evaluating semantics preservation. CoRR, abs/2110.01176. Retrieved from https://arxiv.org/abs/2110.01176

Pennington, J., Socher, R., \& Manning, C. (2014, October). GloVe: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP) (pp. 1532-1543). Doha, Qatar: Association for Computational Linguistics. Retrieved from https://www.aclweb.org/anthology/ D14-1162 doi: $10.3115 / v 1 / D 14-1162$

Pramod, D. (2022). Privacy-preserving techniques in recommender systems: state-of-the-
art review and future research agenda. Data Technologies and Applications(ahead-ofprint).

Rajpurkar, P., Zhang, J., Lopyrev, K., \& Liang, P. (2016). Squad: 100, 000+ questions for machine comprehension of text. In J. Su, X. Carreras, \& K. Duh (Eds.), Proceedings of the 2016 conference on empirical methods in natural language processing, EMNLP 2016, austin, texas, usa, november 1-4, 2016 (pp. 2383-2392). The Association for Computational Linguistics. Retrieved from https://doi.org/10.18653/v1/d16-1264 doi: $10.18653 / \mathrm{v} 1 / \mathrm{d} 16-1264$

Reddy, S., Chen, D., \& Manning, C. D. (2019). Coqa: A conversational question answering challenge. Trans. Assoc. Comput. Linguistics, 7, 249-266. Retrieved from https:// doi.org/10.1162/tacl_a_00266 doi: 10.1162/tacl \a a _00266

Reimers, N., \& Gurevych, I. (2019). Sentence-bert: Sentence embeddings using siamese bert-networks. In K. Inui, J. Jiang, V. Ng, \& X. Wan (Eds.), Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing, EMNLP-IJCNLP 2019, hong kong, china, november 3-7, 2019 (pp. 3980-3990). Association for Computational Linguistics. Retrieved from https://doi.org/10.18653/v1/D19-1410 doi: 10.18653/v1/ D19-1410

Riazi, M. S., \& Koushanfar, F. (2018). Privacy-preserving deep learning and inference. In I. Bahar (Ed.), Proceedings of the international conference on computer-aided design, ICCAD 2018, san diego, ca, usa, november 05-08, 2018 (p. 18). ACM. Retrieved from https://doi.org/10.1145/3240765.3274560 doi: 10.1145/ 3240765.3274560

Rondeau, M., \& Hazen, T. J. (2018). Systematic error analysis of the stanford question answering dataset. In E. Choi, M. Seo, D. Chen, R. Jia, \& J. Berant (Eds.), Proceedings of the workshop on machine reading for question answering@acl 2018, melbourne, australia, july 19, 2018 (pp. 12-20). Association for Computational Linguistics. Retrieved from https://aclanthology.org/W18-2602/ doi: 10.18653/v1/W18-2602

Sang, E. F. T. K., \& Meulder, F. D. (2003). Introduction to the conll-2003 shared task: Language-independent named entity recognition. In W. Daelemans \& M. Osborne (Eds.), Proceedings of the seventh conference on natural language learning, conll 2003, held in cooperation with HLT-NAACL 2003, edmonton, canada, may 31 - june 1, 2003 (pp. 142147). ACL. Retrieved from https://aclanthology.org/w03-0419/

Sarma, K. V., Harmon, S., Sanford, T., Roth, H. R., Xu, Z., Tetreault, J., ... others (2021). Federated learning improves site performance in multicenter deep learning without data sharing. Journal of the American Medical Informatics Association, 28(6), 1259-1264.

Scheider, S., Wang, J., Mol, M., Schmitz, O., \& Karssenberg, D. (2020). Obfuscating spatial point tracks with simulated crowding. Int. J. Geogr. Inf. Sci., 34(7), 1398-1427. Retrieved from https://doi.org/10.1080/13658816.2020.1712402 doi: 10.1080/13658816.2020.1712402

Schler, J., Koppel, M., Argamon, S., \& Pennebaker, J. W. (2006). Effects of age and gender
on blogging. In Computational approaches to analyzing weblogs, papers from the 2006 AAAI spring symposium, technical report ss-06-03, stanford, california, usa, march 27-29, 2006 (pp. 199-205). AAAI. Retrieved from http://www.aaai.org/Library/ Symposia/Spring/2006/ss06-03-039.php

Sengan, S., Jhaveri, R. H., Varadarajan, V., Setiawan, R., Ravi, L., et al. (2021). A secure recommendation system for providing context-aware physical activity classification for users. Security and Communication Networks, 2021.

Shuai, M., Yu, N., Wang, H., Xiong, L., \& Li, Y. (2021). A lightweight three-factor anonymous authentication scheme with privacy protection for personalized healthcare applications. J. Organ. End User Comput., 33(3), 1-18. Retrieved from https:// doi.org/10.4018/joeuc.20210501.oa1 doi: 10.4018/joeuc.20210501.oa1

Song, L., Ma, C., Wu, P., \& Zhang, Y. (2019). PPD-DL: privacy-preserving decentralized deep learning. In X. Sun, Z. Pan, \& E. Bertino (Eds.), Artificial intelligence and security 5th international conference, ICAIS 2019, new york, ny, usa, july 26-28, 2019, proceedings, part I (Vol. 11632, pp. 273-282). Springer. Retrieved from https://doi.org/10 $.1007 / 978-3-030-24274-9 \_24$ doi: 10.1007/978-3-030-24274-9\24

Tang, J., Akram, U., \& Shi, W. (2021). Why people need privacy? the role of privacy fatigue in app users' intention to disclose privacy: based on personality traits. J. Enterp. Inf. Manag., 34(4), 1097-1120. Retrieved from https://doi.org/10.1108/JEIM-03 -2020-0088 doi: 10.1108/JEIM-03-2020-0088

Tran, A., Luong, T., Karnjana, J., \& Huynh, V. (2021). An efficient approach for privacy preserving decentralized deep learning models based on secure multi-party computation. Neurocomputing, 422, 245-262. Retrieved from https://doi.org/10.1016/ j.neucom.2020.10.014 doi: 10.1016/j.neucom.2020.10.014

Wang, L., Sun, Z., Dai, X., Zhang, Y., \& Hu, H. (2019). Retaining users after privacy invasions. Inf. Technol. People, 32(6), 1679-1703. Retrieved from https://doi.org/ 10.1108/ITP-01-2018-0020 doi: 10.1108/ITP-01-2018-0020

Wang, X., Zhang, Y., Ren, X., Zhang, Y., Zitnik, M., Shang, J., ... Han, J. (2018, 10). Cross-type biomedical named entity recognition with deep multi-task learning. Bioinformatics, 35(10), 1745-1752. Retrieved from https://doi.org/10.1093/ bioinformatics/bty869 doi: 10.1093/bioinformatics/bty869

Wu, Z., Li, R., Zhou, Z., Guo, J., Jiang, J., \& Su, X. (2020). A user sensitive subject protection approach for book search service. J. Assoc. Inf. Sci. Technol., 71(2), 183-195. Retrieved from https://doi.org/10.1002/asi. 24227 doi: 10.1002/asi.24227

Wu, Z., Zheng, C., Xiejian, J., Zhou, Z., Xu, G., \& Chen, E. (2018). An approach for the protection of users' book browsing preference privacy in a digital library. Electron. Libr., 36(6), 1154-1166. Retrieved from https://doi.org/10.1108/ EL-07-2017-0162 doi: 10.1108/EL-07-2017-0162

$\mathrm{Xu}$, C., Ding, A. S., \& Liao, S. S. (2020). A privacy-preserving recommendation method based on multi-objective optimisation for mobile users. Int. J. Bio Inspired Comput., 16(1), 23-32. Retrieved from/https://doi.org/10.1504/IJBIC.2020.108995
doi: 10.1504/IJBIC.2020.108995

Xu, Q., He, X., Lyu, L., Qu, L., \& Haffari, G. (2022, October). Student surpasses teacher: Imitation attack for black-box NLP APIs. In Proceedings of the 29th international conference on computational linguistics (pp. 2849-2860). Gyeongju, Republic of Korea: International Committee on Computational Linguistics. Retrieved from https://aclanthology.org/2022.coling-1.251

Yargic, A., \& Bilge, A. (2019). Privacy-preserving multi-criteria collaborative filtering. Inf. Process. Manag., 56(3), 994-1009. Retrieved from https: //doi . org/10.1016/ j.ipm.2019.02.009 doi: 10.1016/j.ipm.2019.02.009

Yu, J., Bohnet, B., \& Poesio, M. (2020). Named entity recognition as dependency parsing. In D. Jurafsky, J. Chai, N. Schluter, \& J. R. Tetreault (Eds.), Proceedings of the 58th annual meeting of the association for computational linguistics, ACL 2020, online, july 5-10, 2020 (pp. 6470-6476). Association for Computational Linguistics. Retrieved from https://doi.org/10.18653/v1/2020.acl-main.577 doi: 10.18653/v1/2020.acl-main. 577

Zhang, S., Yin, H., Chen, T., Huang, Z., Cui, L., \& Zhang, X. (2021). Graph embedding for recommendation against attribute inference attacks. In J. Leskovec, M. Grobelnik, M. Najork, J. Tang, \& L. Zia (Eds.), WWW '21: The web conference 2021, virtual event / ljubljana, slovenia, april 19-23, 2021 (pp. 3002-3014). ACM / IW3C2. Retrieved from https://doi.org/10.1145/3442381.3449813 doi: $10.1145 / 3442381.3449813$

Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., \& Artzi, Y. (2020). Bertscore: Evaluating text generation with BERT. In 8th international conference on learning representations, ICLR 2020, addis ababa, ethiopia, april 26-30, 2020. OpenReview.net. Retrieved from https://openreview.net/forum?id=SkeHuCVFDr

Zhang, Y., Zhou, H., \& Li, Z. (2020). Fast and accurate neural CRF constituency parsing. In C. Bessiere (Ed.), Proceedings of the twenty-ninth international joint conference on artificial intelligence, IJCAI 2020 (pp. 4046-4053). ijcai.org. Retrieved from https://doi.org/10.24963/ijcai.2020/560 doi: 10.24963/ijcai.2020/560

Zhou, C., Li, K., \& Teng, C. (2022). Understanding the influence of privacy protection functions on continuance usage of push notification service. Aslib J. Inf. Manag., 74(2), 202-224. Retrieved from https://doi.org/10.1108/AJIM-04-2021-0121 doi: 10.1108/AJIM-04-2021-0121


[^0]:    ${ }^{1}$ http:/ /ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark

[^1]:    ${ }^{2}$ Linguistic features in this paper are gotten by models from SpaCy. https:// spacy.io/

