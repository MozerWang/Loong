# Divide \& Scale: <br> Formalization and Roadmap to Robust Sharding 

Zeta Avarikioti ${ }^{1}$, Antoine Desjardins ${ }^{2}$, Lefteris Kokoris-Kogias ${ }^{2}, 4$, and Roger<br>Wattenhofer ${ }^{3}$<br>1 TU Wien, Austria<br>${ }^{2}$ ISTA, Austria<br>${ }^{3}$ ETH ZÃ¼rich, Switzerland<br>${ }^{4}$ Mysten Labs


#### Abstract

Sharding distributed ledgers is a promising on-chain solution for scaling blockchains but lacks formal grounds, nurturing skepticism on whether such complex systems can scale blockchains securely. We fill this gap by introducing the first formal framework as well as a roadmap to robust sharding. In particular, we first define the properties sharded distributed ledgers should fulfill. We build upon and extend the Bitcoin backbone protocol by defining consistency and scalability. Consistency encompasses the need for atomic execution of cross-shard transactions to preserve safety, whereas scalability encapsulates the speedup a sharded system can gain in comparison to a non-sharded system.

Using our model, we explore the limitations of sharding. We show that a sharded ledger with $n$ participants cannot scale under a fully adaptive adversary, but it can scale up to $m$ shards where $n=c^{\prime} m \log m$, under an epoch-adaptive adversary; the constant $c^{\prime}$ encompasses the trade-off between security and scalability. This is possible only if the sharded ledgers create succinct proofs of the valid state updates at every epoch. We leverage our results to identify the sufficient components for robust sharding, which we incorporate in a protocol abstraction termed Divide \& Scale. To demonstrate the power of our framework, we analyze the most prominent sharded blockchains (Elastico, Monoxide, OmniLedger, RapidChain) and pinpoint where they fail to meet the desired properties.


Keywords: Blockchains $\cdot$ Sharding $\cdot$ Scalability $\cdot$ Formalization.

## 1 Introduction

A promising solution to scaling blockchain protocols is sharding, e. g. 55|36|53|33. Its high-level idea is to employ multiple blockchains in parallel, the shards, that operate using the same consensus protocol. Different sets of participants run consensus and validate transactions, so that the system "scales out".

However, there is no formal definition of a robust sharded ledger (similar to the definition of what a robust transaction ledger is [24]), which leads to multiple problems. First, each protocol defines its own set of goals, which tend to favor the protocol design presented. These goals are then confirmed achievable
by experimental evaluations that demonstrate their improvements. Additionally, due to the lack of robust comparisons (which cannot cover all possible Byzantine behaviors), sharding is often criticized as some believe that the overhead of transactions between shards cancels out the potential benefits. In order to fundamentally understand sharding, one must formally define what sharding really is, and then see whether different sharding techniques live up to their promise.

Related work. Recently, a few systemizations of knowledge on sharding [52], consensus [8, and cross-shard communication [56] which have also discussed part of sharding, have emerged. These works, however, do not define sharding in a formal fashion to enable an "apples-to-apples" comparison of existing works nor do they explore its limitations.

There are very few works that lay formal foundations for blockchain protocols. In particular, the Bitcoin backbone protocol [24] was the first to formally define and prove a blockchain protocol, specifically Bitcoin, in a PoW setting. Later, Pass et al. 41 showed that there is no PoW protocol that can be robust under asynchrony. With Ouroboros 30 Kiayias et al. extended the ideas of backbone to the Proof-of-Stake (PoS) setting, where they showed that it is possible to have a robust transaction ledger in a semi-synchronous environment as well [21. However, all of these works consider only non-sharded ledgers but can be used as stepping stones to the formalization of sharded ledgers.

Our contribution. In this work, we take up the challenge of providing formal "common grounds" under which we can capture the sharding limitations, determine the necessary components of a sharding system, and fairly compare different sharding solutions. We achieve this by defining a formal sharding framework as well as formal bounds of what a sharded transaction ledger can achieve.

To maintain compatibility with the existing models of a robust transaction ledger, we build upon the work of Garay et al. 24. We generalize the transaction ledger properties, originally introduced in 24, namely Persistence and Liveness, to also apply to sharded ledgers. Persistence expresses the agreement between honest parties on the transaction order, while liveness encompasses that a transaction will eventually be processed and included in the transaction ledger. Further, we extend the model to capture what sharding offers to blockchain systems by defining Consistency and Scalability. Consistency is a security property that conveys the atomic property of cross-shard transactions (transactions that span multiple shards and should either abort or commit in all shards). Scalability, on the other hand, is a performance property that encapsulates the resource gains per party (in bandwidth, storage, and computation) in a sharded system compared to a non-sharded system.

Once we define the properties, we explore the limitations of sharding protocols that satisfy them. We identify a trade-off between the bandwidth requirements and how adaptive the adversary is, i.e., how "quickly" the adversary can change the corrupted parties. Specifically, with a fully adaptive adversary, scalable and secure sharding is impossible in our model. With a slowly-adaptive adversary, however, sharding can scale securely with up to $m$ shards, where $n=c^{\prime} m \log m$. The constant $c^{\prime}$ encompasses the trade-off between scalability and security: if the
overall and per-shard adversarial thresholds are close to each other, then $c^{\prime}$ must be large to ensure security within each hard. Furthermore, scaling against a somewhat adaptive adversary is only possible under two conditions: first, the parties of a shard cannot be light clients to other shards to scale storage. Second, shards must periodically compact the state updates in a verifiable and succinct manner (e.g., via checkpoints 33, cryptographic accumulators 10, zero-knowledge proofs 9|39 or other techniques 28|15|27|26); else eventually the bandwidth resources per party will exceed those of a non-sharded blockchain.

Once we provide solid bounds on the design of sharding protocols, we identify seven components that are critical to designing a robust permissionless sharded ledger: (a) a core consensus protocol for each shard, (b) a protocol to partition transactions in shards, (c) an atomic cross-shard communication protocol that enables transferring of value across shards, (d) a Sybil-resistance mechanism that forces the adversary to commit resources in order to participate, (e) a process that guarantees honest and adversarial nodes are appropriately dispersed to the shards to defend security against adversarial adaptivity, (f) a distributed randomness generation protocol, $(\mathrm{g})$ a process to occasionally compact the state in a verifiable manner. We then employ these components to introduce a protocol abstraction, termed Divide $\&$ Scale, that achieves robust sharding in our model. We explain the design rationale, provide security proofs, and identify which components affect the scalability and throughput of our protocol abstraction.

To demonstrate the power of our framework, we further describe, abstract, and analyze the most well-established permisionless sharding protocols: Elastico [36] (inspiration of Zilliqa), OmniLedger [33] (inspiration of Harmony), Monoxide [53], and RapidChain 555. We demonstrate that all sharding systems fail to meet the desired properties in our model. Elastico and Monoxide do not actually (asymptotically) improve on storage over non-sharded blockchains according to our model. OmniLedger is susceptible to a liveness attack where the adaptive adversary can simply delete a shard's state effectively preventing the system's progress. Albeit, with a simple fix, OmniLedger satisfies all the desired properties in our model. Last, we prove RapidChain meets the desired properties but only in a weaker adversarial model. For all protocols, we provide elaborate proofs while for OmniLedger and RapidChain we further estimate how much they improve over their blockchain substrate. To that end, we define and use a theoretical performance metric, termed throughput factor, which expresses the average number of transactions that can be processed per round under the worst possible Byzantine behavior. We show that both OmniLedger and RapidChain scale optimally with $m$ shards where $n=O(m \log m)$.

In summary, the contribution of this work is the following:

- We introduce a framework where sharded transaction ledgers are formalized and the necessary properties of sharding protocols are defined. Further, we define a throughput factor to estimate the transaction throughput improvement of sharding blockchains over non-sharded blockchains (Section 2).
- We explore the limitations of secure and efficient sharding protocols under our model (Section 3. Appendix A).
- We identify the critical and sufficient ingredients for designing a robust sharded ledger, which we incorporate into a protocol abstraction for robust sharding, termed Divide \& Scale (Section 4. Appendix B).
- We evaluate Elastico, Monoxide, OmniLedger, and RapidChain. We pinpoint where the former three fail to satisfy our properties, whereas the latter satisfies them all only under a weaker adversarial model (Section5, Appendix C).


## 2 The sharding framework

In this section, we define the desired security and performance properties of a secure and efficient distributed sharded ledger, extending the work of Garay et al. 24]. We further define a theoretical performance metric, the transaction throughput. To assist the reader, we provide a glossary of the most frequently used parameters in Table 2 (Section Figures 5 ).

### 2.1 The Model

Network model. We analyze blockchain protocols assuming a synchronous communication network. In particular, a protocol proceeds in rounds, and at the end of each round the participants of the protocol are able to synchronize, and all messages are delivered. A set of $R$ consecutive rounds $E=\left\{r_{1}, r_{2}, \ldots, r_{R}\right\}$ defines an epoch. We consider a fixed number of participants in the system denoted by $n$. However, this number might not be known to the parties.

Threat model. The adversary is slowly-adaptive, meaning that the adversary can corrupt parties on the fly at the beginning of each epoch but cannot change the corrupted set during the epoch, i.e., the adversary is static during each epoch. In addition, in any round, the adversary decides its strategy after receiving all honest parties' messages. The adversary can change the order of the honest parties' messages but cannot modify or drop them. Furthermore, the adversary is computationally bounded and can corrupt at most $f$ parties during each epoch. This bound $f$ holds strictly at every round of the protocol execution. Note that depending on the specifications of each protocol, i.e., which Sybil-attackresistant mechanism is employed, the value $f$ represents a different manifestation of the adversary's power (e. g., computational power, stake in the system).

Transaction model. We assume transactions consist of inputs and outputs that can only be spent as a whole. Each transaction input is an unspent transaction output (UTXO). Thus, a transaction takes UTXOs as inputs, destroys them and creates new UTXOs, the outputs. A transaction ledger that handles such transactions is UTXO-based, similarly to Bitcoin 40. Most protocols considered in this work are UTXO-based. Transactions can have multiple inputs and outputs. We define the average size of a transaction, i.e., the average number of inputs and outputs of a transaction in a transaction set, as a parameter $v$. This way $v$ correlates to the number of shards a transaction is expected to affect; the actual size in bytes is proportional to $v$ but unimportant for measuring scalability.

Further, we assume a transaction set $T$ follows a distribution $D_{T}$ (e.g. $D_{T}$ is the uniform distribution if the sender(s) and receiver(s) of each transaction are chosen uniformly at random from all possible users).

### 2.2 Sharded Transaction Ledgers

In this section, we introduce the necessary properties a sharding blockchain protocol must satisfy in order to maintain a robust sharded transaction ledger. We build upon the definition of a robust transaction ledger introduced in 24].

A sharded transaction ledger is defined with respect to a set of valid 5 transactions $T$ and a collection of transaction ledgers for each shard $S=\left\{S_{1}, S_{2}, \ldots, S_{m}\right\}$. In each shard $i \in[m]=\{1,2, \ldots, m\}$, a transaction ledger is defined with respect to a set of valid ledgers ${ }^{6} S_{i}$ and a set of valid transactions. Each set possesses an efficient membership test. A ledger $L \in S_{i}$ is a vector of sequences of transactions $L=\left\langle x_{1}, x_{2}, \ldots, x_{l}\right\rangle$, where $t x \in x_{j} \Rightarrow t x \in T, \forall j \in[l]$.

In a sharding blockchain protocol, a sequence of transactions $x_{i}=t x_{1} \ldots t x_{e}$ is inserted in a block which is appended to a party's local chain $C$ in a shard. A chain $C$ of length $l$ contains the ledger $L_{C}=\left\langle x_{1}, x_{2}, \ldots, x_{l}\right\rangle$ if the input of the $j$-th block in $C$ is $x_{j}$. The position of transaction $t x_{j}$ in the ledger of a shard $L_{C}$ is the pair $(i, j)$ where $x_{i}=t x_{1} \ldots t x_{j} \ldots t x_{e}$ (i.e., the block that contains the transaction). Essentially, a party reports a transaction $t x_{j}$ in position $i$ only if one of their shards' local ledger includes transaction $t x_{j}$ in the $i$-th block. We assume that a block has constant size, i. e., there is a maximum constant number of transactions included in each block $\sqrt[7]{7}$

Furthermore, we define a symmetric relation on $T$, denoted by $M(\cdot, \cdot)$, that indicates if two transactions are conflicting, i.e., $M\left(t x, t x^{\prime}\right)=1 \Leftrightarrow t x, t x^{\prime}$ are conflicting. Note that valid ledgers can never contain conflicting transactions. Similarly, a valid sharded ledger cannot contain two conflicting transactions even across shards. In our model, we assume there exists a verification oracle denoted by $V(T, S)$, which instantly verifies the validity of a transaction with respect to a ledger. In essence, the oracle $V$ takes as input a transaction $t x \in T$ and a valid ledger $L=\left\langle x_{1}, x_{2}, \ldots, x_{l}\right\rangle \in S$ and checks whether the transaction is valid and not conflicting in this ledger; formally, $V(t x, L)=1 \Leftrightarrow \exists t x^{\prime} \in L$ s.t. $M\left(t x, t x^{\prime}\right)=1$ or $L^{\prime}=\left\langle x_{1}, x_{2}, \ldots, x_{l}, t x\right\rangle$ is an invalid ledger.

Next, we introduce the security and performance properties a blockchain protocol must uphold to maintain a robust and efficient sharded transaction ledger: persistence, consistency, liveness, and scalability. Intuitively, persistence expresses the agreement between honest parties on the transaction order, whereas consistency conveys that cross-shard transactions are either committed or aborted atomically (in all shards). Liveness indicates that transactions will eventually be included in a shard, i.e., the system makes progress. Last, scalability encapsulates the speedup of a sharded system in comparison to a non-sharded system:[^0]

The blockchain's throughput limitation stems from the need for data propagation, maintenance, and verification by every party. Thus, to scale via sharding, each party must broadcast, maintain and verify mainly local information.

Definition 1 (Persistence) Parameterized by $k \in \mathbb{N}$ ("depth" parameter), if in a certain round an honest party reports a shard that contains a transaction tx in a block at least $k$ blocks away from the end of the shard's ledger (such transaction will be called "stable"), then whenever tx is reported by any honest party it will be in the same position in the shard's ledger.

Definition 2 (Consistency) Parametrized by $k \in \mathbb{N}$ ("depth" parameter), there is no round $r$ in which there are two honest parties $P_{1}, P_{2}$ reporting transactions $t x_{1}, t x_{2}$ respectively as stable (at least in depth $k$ in the respective shards), such that $M\left(t x_{1}, t x_{2}\right)=1$.

Both persistence and consistency are necessary properties because one may fail while the other holds. For instance, if a party double-spends across two shards without reverting a stable transaction (e.g., due to a badly designed mechanism to process cross-shard transactions), consistency fails while persistence holds.

We further note consistency depends on the average size of transactions $v \in \mathbb{N}$ as well as the distribution of the input set of transactions $D_{T}$. For example, if all transactions are intra-shard, consistency is trivially satisfied due to persistence.

To evaluate the system's progress, we assume that the block size is sufficiently large, thus a transaction will never be excluded due to space limitations.

Definition 3 (Liveness) Parameterized by u ("wait time") and $k$ ("depth" parameter), provided that a valid transaction is given as input to all honest parties of a shard continuously for the creation of $u$ consecutive rounds, then all honest parties will report this transaction at least $k$ blocks from the end of the shard, i. e., all report it as stable.

Scaling distributed ledgers depends on three vectors: communication, space, and computation. In particular, to allow high transaction throughput, the bandwidth and computation required per party should ideally be constant and independent of the number of parties while the storage requirements per party should decrease with the number of parties. Such a system can scale optimally because an increased transaction load, e.g. double, can be processed with the same storage resources if the parties increase proportionally, e.g. double, as well as the same communication and computation resources per node. To measure scalability, i.e., the resource requirements per node, we define three scaling factors, namely the communication, space, and computation factor.

We define the communication factor $\omega_{m}$ as the communication complexity of the system (per transaction) scaled over the number of participants. In essence, $\omega_{m}$ represents the average amount of sent or received data (bandwidth) required per party to include a transaction in the ledger. $\omega_{m}$ expresses the worst communication complexity of all the subroutines of the system, incorporating the bandwidth requirements of the protocols both within an epoch (i.e., within
and across shards communication), as well as during epoch transitions (amortized over the epoch's length). The latter becomes the bottleneck for scalability in the long run as rotating parties must bootstrap to new shards and download the ever-growing shard ledgers.

We next introduce the space factor $\omega_{s}$ that estimates how much data each party stores in the system. To do so, we count the amount of data stored in total by all the parties scaled over the number of parties and the transaction load. When $\omega_{s}$ is constant, $\Theta(1)$, each node stores all transactions equivalently to a central database, e.g., Bitcoin. On the contrary, a perfectly scalable system allows parties to share the transaction load equally, $\omega_{s}=c / n, c$ constant; as a result, if parties increase proportionally to the transaction load the space resources per party remain the same.

To define the space factor we introduce the notion of average-case analysis. Typically, sharding protocols scale well when the analysis is optimistic, that is, for transaction inputs that contain neither cross-shard nor multi-input (multioutput) transactions. However, in practice transactions are both cross-shard and multi-input/output. For this reason, we define the space factor as a random variable dependent on an input set of transactions $T$ drawn uniformly at random from a distribution $D_{T}$.

We assume $T$ is given well in advance as input to all parties. To be specific, we assume every transaction $t x \in T$ is given at least for $u$ consecutive rounds to all parties of the system. Hence, from the liveness property, all transaction ledgers held by honest parties will report all transactions in $T$ as stable. Further, we denote by $L^{\lceil k}$ the vector $L$ where the last $k$ positions are "pruned", while $\left|L^{\lceil k}\right|$ denotes the number of transactions contained in this "pruned" ledger. We note that a similar notation holds for a chain $C$ where the last $k$ positions map to the last $k$ blocks. Each party $P_{j}$ maintains a collection of ledgers $S L_{j}=$ $\left\{L_{1}, L_{2}, \ldots, L_{s}\right\}, 1 \leq s \leq m$. We may now define the space factor for a sharding protocol with input $T$ as the number of stable transactions included in every party's collection of transaction ledgers over the number of parties $n$ and the number of input transactions $T^{8}, \omega_{s}(T)=\sum_{\forall j \in[n]} \sum_{\forall L \in S L_{j}}\left|L^{\lceil k}\right| /(n|T|)$.

Lastly, we consider the verification process which can be computationally expensive. In our model, we focus on the average verification cost per transaction. We assume a constant computational cost per verification, i.e., a party's running time of verifying if a transaction is invalid or conflicting with a ledger is considered constant because this process can always speed up using efficient data structures (e.g. trees allow for logarithmic lookup time). Thus, the computational cost of a party is defined by the number of times the party executes the verification process. For this purpose, we employ a verification oracle $V$. Each party calls the oracle to verify transactions, pending or included in a block. We denote by $q_{i}$ the number of times party $P_{i}$ calls oracle $V$ in a protocol execution. The computational factor $\omega_{c}$ reflects the total number of times all parties[^1]call the verification oracle in a protocol execution scaled over the number of transactions $T, \omega_{c}(T)=\sum_{\forall i \in[n]} q_{i} /|T|$.

An ideal sharding system only involves a constant number of parties to verify each transaction, $\omega_{c}=\Theta(1)$, while both a typical BFT-based protocol and Bitcoin demand all nodes to verify all transactions, $\omega_{c}=\Theta(n)$. Furthermore, the computational factor is a random variable, hence the objective is to calculate the expected value of $\omega_{c}$, i.e., the probability-weighted average of all possible values, where the probability is taken over the input transactions $T$.

Intuitively, scaling means processing more transactions with similar (i. e., not proportionally increasing) resources per party. If parties share the transaction load, e.g., space scales $\omega_{s}=c / n$, increased transactions can be processed by increasing the number of parties. Subsequently, the communication and computational costs must not increase proportionally to the number of parties, i.e., $\omega_{c}=o(n)$ and $\omega_{m}=o(n)$, else the system cannot truly scale the transaction load. We observe, however, that in practice protocols may scale well in one dimension but fail in another. A notable example is the Bitcoin protocol which has minimal communication overhead but does not scale in space and computation. To ensure overall scaling capabilities, we define the scalability property of sharded ledgers below; we say that a sharded ledger satisfies scalability if and only if the system scales in all the aforementioned dimensions.

Definition 4 (Scalability) Parameterized by $n$ (number of participants), $v \in$ $\mathbb{N}$ (average size of transactions), $D_{T}$ (distribution of the input set of transactions), the communication, space and computational factors of a sharding blockchain protocol are $\omega_{m}=o(n), \omega_{s}=o(1)$, and $\omega_{c}=o(n)$, respectively.

In order to adhere to standard security proofs from now on we say that the protocol $\Pi$ satisfies property $Q$ in our model if $Q$ holds with overwhelming probability (in a security parameter). Note that a probability $p$ is overwhelming if $1-p$ is negligible. A function negl $(k)$ is negligible if for every $c>0$, there exists an $N>0$ such that $n e g l(k)<1 / k^{c}$ for all $k>\geq N$. Furthermore, we denote by $\mathbb{E}(\cdot)$ the expected value of a random variable.

Definition 5 (Robust Sharded Transaction Ledger) A protocol that satisfies the properties of persistence, consistency, liveness, and scalability maintains a robust sharded transaction ledger.

## 2.3 (Sharding) Blockchain Protocols

In this section, we adopt the definitions and properties of 24 for blockchain protocols, while we slightly change the notation to fit our model. In particular, we assume the parties of a shard of any sharding protocol maintain a chain (ledger) to achieve consensus. This means that every shard internally executes a blockchain (consensus) protocol that has three properties as defined by [24]: chain growth, chain quality, and common prefix. Each consensus protocol satisfies these properties with different parameters.

In this work, we will use the properties of the shards' consensus protocol to prove that a sharding protocol maintains a robust sharded transaction ledger. In addition, we will specifically use the shard growth and shard quality parameters to estimate the transaction throughput of a sharding protocol. The following definitions follow closely Definitions 3,4 and 5 of [24].

Definition 6 (Shard Growth Property) Parametrized by $\tau \in \mathbb{R}$ and $s \in \mathbb{N}$, for any honest party $P$ with chain $C$, it holds that for any s rounds there are at least $\tau \cdot s$ blocks added to chain $C$ of $P$.

Definition 7 (Shard Quality Property) Parametrized by $\mu \in \mathbb{R}$ and $l \in \mathbb{N}$, for any honest party $P$ with chain $C$, it holds that for any $l$ consecutive blocks of $C$ the ratio of honest blocks in $C$ is at least $\mu$.

Definition 8 (Common Prefix Property) Parametrized by $k \in \mathbb{N}$, for any pair of honest parties $P_{1}, P_{2}$ adopting chains $C_{1}, C_{2}$ (in the same shard) at rounds $r_{1} \leq r_{2}$ respectively, it holds that $C_{1}^{\lceil k} \preceq C_{2}$, where $\preceq$ denotes the prefix relation.

Next, we define the degree of parallelism (DoP) of a sharding protocol, denoted $m^{\prime}$. To evaluate the DoP of a protocol with input $T$, we need to determine how many shards are affected by each transaction on average; essentially, estimate how many times we run consensus for each valid transaction until it is stable. This is determined by the mechanism that handles the cross-shard transactions. To that end, we define $m_{i, j}=1$ if the $j$-th transaction of set $T$ has either an input or an output that is assigned to the $i$-th shard; otherwise $m_{i, j}=0$. Then, the DoP of a protocol execution over a set of transactions $T$ is defined as follows: $m^{\prime}=\frac{T \cdot m}{\sum_{j=1}^{T} \sum_{i=1}^{m} m_{i, j}}$. The DoP of a protocol execution depends on the distribution of transactions $D_{T}$, the average size of transactions $v$, and the number of shards $m$. For instance, assuming a uniform distribution $D_{T}$, the expected DoP is $\mathbb{E}\left(m^{\prime}\right)=m / v$.

We can now define an efficiency metric, the transaction throughput of a sharding protocol. Considering constant block size, we have:

Definition 9 (Throughput) The expected transaction throughput in s rounds of a sharding protocol with $m$ shards is $\mu \cdot \tau \cdot s \cdot m^{\prime}$. We define the throughput factor of a sharding protocol $\sigma=\mu \cdot \tau \cdot m^{\prime}$.

Intuitively, the throughput factor expresses the average number of blocks that can be processed per round by a sharding protocol. Thus, the transaction throughput (per round) can be determined by the block size multiplied by the throughput factor. The block size is considered constant; however, it cannot be arbitrarily large. The limit on the block size is determined by the bandwidth of the "slowest" party within each shard. At the same time, the constant block size guarantees low latency. If the block size is very large or depends on the number of shards or the number of participants, bandwidth or latency becomes the performance bottleneck. As our goal is to estimate the efficiency of the transactions' parallelism in a protocol, other factors like cross-shard communication latency are omitted.

## 3 Limitations of sharding protocols

In this section, we present a summary of our analysis on the limitations of sharding protocols in our framework (cf. Appendix A).

First, we focus on the limitations that stem from the nature of the transaction workload. In particular, sharding protocols are affected by two characteristics of the input transaction set: the transaction size $v$ (number of inputs and outputs of each transaction), and more importantly the number of cross-shard transactions.

The average size of transactions is fairly small in practice, e.g., an average Bitcoin transaction has 2 inputs and 3 outputs with a small deviation 11. We thus assume a fixed number of UTXOs participating in each transaction, meaning the transaction size $v$ is a small constant. Furthermore, as $v$ increases, more shards are affected by each transaction on expectation, hence the number of cross-shard transactions increases. To meaningfully lower bound the ratio of cross-shard transactions, we thus consider the minimum transaction size $v=2$. If a transaction has more UTXOs, its chance of being cross-shard only increases.

The number of cross-shard transactions depends on the distribution of the input transactions $D_{T}$, as well as the process that partitions transactions into shards. First, we assume each ledger interacts (i.e., shares a cross-shard transaction) with $\gamma$ other ledgers on average, $\gamma$ being a function dependent on the number of shards $m$. We examine protocols where parties maintain information on shards other than their own and derive an upper bound for the expected value of $\gamma$ such that scalability holds. Leveraging that, we prove the following:

Theorem 10. There is no protocol maintaining a robust sharded transaction ledger against an adaptive adversary in our model controlling $f \geq n / m$, where $m$ is the number of shards, and $n$ is the number of parties.

Next, we extend our results assuming, similarly to most sharding systems, that the UTXO space is partitioned uniformly at random into shards. In particular, we first show that a constant fraction of transactions is expected to be cross-shard. Using that we demonstrate there is no sharded ledger that satisfies scalability if parties store any information on ledgers (other than their own) involved in cross-shard transactions, i. e., are light clients on other shards 18 . We stress that our results hold for any distribution where the expected number of cross-shard transactions is proportional to the number of shards.

Theorem 11. There is no protocol that maintains a robust sharded transaction ledger in our model under uniform space partition when parties are light nodes on the shards involved in cross-shard transactions.

We further identify a concrete trade-off between security and scalability, that stems from the way parties are partitioned into shards. In particular, when parties are randomly permuted among shards, which is a common practice in sharding, e. g., 33|36, sharding scales almost linearly. The trade-off is now captured by the constant $c^{\prime}$ : if the overall and per-shard adversarial thresholds are close to each other, then $c^{\prime}$ must be large to ensure security within each shard.

Theorem 12. Any protocol that maintains a robust sharded transaction ledger in our model under uniformly random partition of the state and parties, can scale at most by a factor of $m$, where $n=c^{\prime} m \log m$ and the constant $c^{\prime}$ encompasses the trade-off between security and scalability.

Finally, we demonstrate the importance of periodical compaction of the valid state-updates in sharding protocols: we prove that any sharding protocol that satisfies scalability in our model, when the state is uniformly partitioned and the parties are periodically shuffled among shards, requires a state-compaction process such as checkpoints [33], cryptographic accumulators 10], zero-knowledge proofs [9, non-interactive proofs of proofs-of-work [28|15], proof of necessary work [27], erasure codes [26], etc. Intuitively, parties must be periodically shuffled among shards to maintain security against adaptivity. Subsequently, the parties must occasionally bootstrap to the new ever-increasing blockchains, leading to bandwidth or storage overheads that exceed those of a non-sharded blockchain in the long run. We stress that this result holds even if the parties are not randomly shuffled among the shards, as long as a significant fraction of parties changes shards from epoch to epoch.

Theorem 13. Any protocol that maintains a robust sharded transaction ledger in our model, under uniformly random partition of the state and parties, employs verifiable compaction of the state.

## 4 Divide \& Scale

In this section, we discuss our design rationale for robust sharding; using the bounds of Section 3, we deduce some sufficient components for robust sharding in our model. We leverage these components to introduce a protocol abstraction for robust sharding, termed Divide 8 Scale, in Algorithm1. We prove Divide \& Scale is secure in our model (assuming the components are secure) and evaluate its efficiency depending on the choices of the individual components in Appendix B.

Sharding Components. We explain our design rationale and introduce the ingredients of a protocol that maintains a robust sharded ledger.

(a) Consensus protocol of shards or Consensus: A sharding protocol either runs consensus in every shard separately (multi-consensus) or provides a single total ordering for all the blocks generated in each shard (uni-consensus [243]). Since uni-consensus takes polynomial cost per block, such a protocol can only scale if the block size is also polynomial (e.g., includes $\Omega(n)$ transactions 43]). However, in such a case, the resources of each node generating an $\Omega(n)$-sized block must also grow with $n$, and therefore scalability cannot be satisfied 9 . For this reason, in our protocol abstraction, we chose the multi-consensus approach.

The consensus protocol run per shard must satisfy the properties of Garay et al. 24]: common prefix, chain quality, and chain growth. These properties are necessary (but not sufficient) to ensure persistence, liveness, and consistency.[^2](b) Cross-shard mechanism or CrossShard: The cross-shard mechanism is the protocol that handles the transactions that span across multiple shards. It is critical for the security of the sharding system, as it guarantees consistency, as well as scalability; a naively designed cross-shard mechanism may induce high storage or communication overhead on the nodes when handling several crossshard transactions. To that end, the limitations of Section 3 apply.

The cross-shard mechanism should provide the ACID properties (as in database transactions). Durability and Isolation are provided directly by the blockchains of the shards, hence, the cross-shard mechanism should provide Consistency, i.e., every transaction that commits produces a semantically valid state, and Atomicity, i.e., transactions are committed and aborted atomically (all or nothing). Typically the cross-shard mechanism runs hand in hand with the consensus protocol to guarantee consistency across shards.

(c) Sybil-resistance mechanism or Sybil: The Sybil-resistance mechanism enables the participants of a permissionless setting to reach a global consensus on a set of fairly-selected valid identities. Its fair selection, i.e., assigning valid identities to each party proportionally to its spent resources, guarantees the security bounds of the consensus protocol (e.g., $f<1 / 3$ for BFT). To ensure fairness against slowly-adaptive adversaries, the Sybil-resistance mechanism must have access to unknown unbiasable randomness (see below DRG). The exact protocol (e. g. PoW, PoS) is irrelevant to our analysis as long as it guarantees (i) correctness: all parties can verify a valid identity, (ii) fairness: each party is selected with probability proportional to its resources, and (iii) unpredictability: no party can predict beforehand the valid set of identities (for the new epoch).

(d) StatePartition: This protocol determines how the state (e.g. transactions) is partitioned into shards. A naive design may violate consistency but there are several secure solutions to employ, e. g. 33155. We perform our analysis assuming all transactions are cross-shard, because any secure protocol that performs well in the pessimistic case, also performs well when transactions are intra-shard. Moreover, in the latter case, scaling is not challenging as the transaction throughput can be processed securely in blockchains that work in parallel.

(e) Division of nodes to shards or Divide2Shards: This is the protocol that determines how parties are assigned to shards. It is crucial for security against slowly adaptive adversaries as a fully corrupted shard may result in the loss of all three security properties. It is also the reason that sharding cannot tolerate fully-adaptive adversaries in our model (Theorem 10). Note that static adversaries are an easier subcase of the slowly adaptive one.

In particular, to ensure transaction finality (i.e., liveness and persistence), either the consensus security bounds must hold for each shard, or the protocol must guarantee that if the adversary compromises a shard then the security violation will be restored within a specific (small) number of rounds. Specifically, if an adversary completely or partially compromises a shard, effectively violating the consensus bounds, then the adversary can double spend within the shard (violates persistence), as well as across shards (because nodes cannot verify crossshard transactions from Lemma 15). Therefore, the transactions included in
these blocks can only be executed when honest parties have verified them. Partial solutions towards this direction have been proposed such as proofs of fraud that allow an honest party to later prove misbehavior. Another challenge of this approach is to guarantee data availability.

Due to the complexity of such solutions and their implications on the transactions' finality, we design Divide \& Scale assuming the security bounds of consensus are maintained when parties are divided into shards. Specifically, the parties are shuffled at the beginning of each epoch so that the threat model holds. A secure shuffling process requires an ubiasable source of randomness (see below DRG). When assigned to a shard, the nodes update their local state with the state of the new shard they are asked to secure, which in turn affects scalability. The frequency of shuffling is thereby incorporating the trade-off between scalability and adaptive security.

(f) Randomness generation protocol or DRG: The DRG protocol provides unpredictable unbiasable randomness [22|16|45|51|34|11|14|20] such that both Sybil and Divide2Shards result in shards that maintain the security bounds for the consensus protocol. Given a slowly-adaptive adversary, the DRG protocol must be executed (at least) once per epoch; its high communication complexity can be amortized over the rounds of an epoch such that the system scales.

(g) Verifiable compaction of state or CompactState: CompactState guarantees that periodically state updates can be verifiably compacted. This protocol is necessary for scaling sharding systems in the long run, as it ensures that new parties can bootstrap with minimal effort (Theorem 13). The compacted state must be broadcasted to all parties, e. g. via reliable broadcast 13], to ensure data integrity and data availability; else a slowly-adaptive adversary can corrupt an entire shard after an epoch transition, violating liveness. Any protocol that ensures data binding and data availability can be used. In summary, this protocol must guarantee (i) verifiable asymptotic compression (more than constant), and (ii) data integrity and availability, i.e., the ledgers' history is available and can be retrieved. To satisfy scalability, the protocol must also ensure (iii) efficient communication complexity with respect to the epoch size (in rounds).

## 5 Evaluation of sharding protocols

To showcase the wide applicability and value of our framework, we evaluate in our model the well-established sharding protocols Elastico, Monoxide, OmniLedger, and RapidChain, and discuss Chainspace. We refer the reader to Appendix C for the complete analysis where we identify each protocol's sharding components as defined in Section 4 which we use to prove or disprove the desired properties of Section 2, often leveraging the bounds of Section 3. Due to space limitations, we only discuss here the final results of our analysis, also illustrated in Table 1, with key insights on how each protocol fails to meet some of the properties. We include in the evaluation the "permissionless" and "slowly-adaptive" properties to fairly compare the protocols. In our analysis, we evaluate the cross-shard communication protocols considering the fixes of 48] against replay attacks.

```
Protocol Abstraction 1: Divide \& Scale
    Data: $N_{0}$ nodes are participating in the system at round 0 (genesis block).
        $m\left(N_{E}\right)$ denotes the function that determines the number of shards in
        epoch $E$. The transactions of epoch $E$ are $T_{E} . i$ denotes the block
        round (its relation to the communication rounds depends on the
        employed components).
    Result: Shard state $T=\left\{T_{0}, T_{1}, \ldots\right\}$.
    /* Initialization */
$1 i \leftarrow 1$
$2 E \leftarrow 0$
    /* Beginning of epoch: retrieve identities from Sybil resistant
        protocol, execute the DRG protocol to create the new epoch
        randomness, and assign nodes to shards */
    3 if $i \bmod R=1$ :
        $E \leftarrow E+1$
        if $i \neq 1$ :
            $N_{E} \leftarrow \operatorname{Sybil}\left(r_{E-1}\right)$
        $r_{E} \leftarrow \operatorname{DRG}\left(N_{E}\right)$
        Call Divide2Shards ( $N_{E}, m\left(N_{E}\right), r_{E}$ )
    /* End of epoch: compact the state of the shard */
    elif $i \bmod R=0$ :
        Call CompactState(i)
    /* During epoch: run the consensus protocol for intra-shard and
        cross-shard transactions */
    else:
        if If transaction $t \in T_{E}$ is cross-shard :
            Call CrossShard(t) ; // Invokes Consensus in multiple shards
        else:
            Call Consensus ( $t$ )
    $i \leftarrow i+1$
    Go to step 3
```

We first show that Elastico does not satisfy consistency in our model because the adversary may double-spend across shards when multi-input transactions are allowed (Theorem 25). Additionally, Elastico does not satisfy scalability by design regardless of the transaction distribution - even with a few cross-shard transactions (Theorem 27). Specifically, all epoch-transition protocols are executed for every block while parties maintain a global hash chain. Thus, transactions are only compressed by a constant factor, the block size, resulting in space and communication growing proportionally to the number of parties.

We then show that Monoxide does not satisfy scalability because miners must mine in parallel in all shards, verifying and storing all transactions to ensure security (Theorem 30). Due to its design rationale, Monoxide cannot scale even with optimistic transaction distributions with no cross-shard transactions.

Third, we prove that OmniLedger satisfies all properties but liveness (Theorems $35 \mid 3736$. 41. Specifically, OmniLedger checkpoints the UTXO pool at

Table 1: Summarizing sharding protocol properties under our model

| Protocol | Persistence | Consistency | Liveness | Scalability | Permissionless | S.-adaptive |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| Elastico | $\checkmark$ | $\boldsymbol{n}$ | $\checkmark$ | $\boldsymbol{x}$ | $\checkmark$ | $\checkmark$ |
| Monoxide | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\boldsymbol{X}$ | $\checkmark$ | $\checkmark$ |
| OmniLedger | $\checkmark$ | $\checkmark$ | $\boldsymbol{l n}$ | $\checkmark$ | $\checkmark$ | $\checkmark$ |
| RapidChain | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\sim$ |
| Chainspace | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\boldsymbol{X}$ | $\boldsymbol{X}$ |

each epoch transition, but the state is not broadcasted to the network. Hence, a slowly adaptive adversary can corrupt a shard from the previous epoch before the new nodes of the shard bootstrap to the state in epoch transition. This attack violates liveness but simply adding a reliable broadcast step after checkpointing restores the liveness since all other components satisfy it already. The overhead of reliable broadcast can be amortized over the rounds of the epoch hence the overall scalability is not affected.

Fourth, we prove RapidChain maintains a robust sharded ledger but only under a weaker model than the one defined in Section 2 (Theorems 47|4948|53). Specifically, the protocol only allows a constant number of parties to join or leave and the adversary can at most corrupt a constant number of additional parties with each epoch transition. Another shortcoming of RapidChain is the synchronous consensus mechanism it employs. In case of temporary loss of synchrony in the network, the consensus of cross-shard transactions is vulnerable, hence consistency might break 55. However, most of these drawbacks can be addressed with simple solutions, such as changing the consensus protocol (tradeoff performance with security), replacing the epoch transition process with one similar to (fixed) OmniLedger, etc. Although OmniLedger (with the proposed fix) maintains a robust sharded ledger in a stronger model (as defined in Section 2, RapidChain introduces practical speedups on specific components of the system. These improvements are not asymptotically important - and thus not captured by our framework - but might be significant for the performance of deployed sharding protocols.

Finally, we include in the comparison Chainspace, which maintains a robust sharded transaction ledger but only in the permissioned setting against a static adversary. Chainspace could be secure in our model in the permissioned setting if it adopts OmniLedger's epoch transition protocols and the proposed fix for data availability in the verifiable compaction of state. We omit the security proofs for Chainspace since they are either included in 3 or are similar to OmniLedger.

Discussion. Although we restrict our evaluation to the most impactful (so far) sharding proposals, we stress that the power of our framework and the bounds we provide are not limited to these works. For instance, we observe that Chainweb [37], a recently deployed sharding proposal, does not scale because it violates Theorem 11. We believe our framework is general enough to cover most sharding approaches, and we aspire it will be established as a tool for proving the security of future sharding protocols.

## Figures

Table 2: (Glossary) The parameters in our analysis.

```
$n$ number of parties
    $f$ number of Byzantine parties
    $m$ number of shards
    $v$ average transaction size (number of inputs and outputs)
    $E$ epoch, i. e., a set of consecutive rounds
    $T$ set of transactions (input)
    $k$ "depth" security parameter (persistence)
    $u$ "wait" time (liveness)
    $\omega_{m}$ communication factor
    $\omega_{s}$ space factor
    $\omega_{c}$ computational factor
    $\sigma$ throughput factor
    $\mu$ chain quality parameter
    $\tau$ chain growth parameter
    $v$ average transaction size
    $m^{\prime}$ degree of parallelism
    $\gamma$ average number of a shard's interacting shards (cross-shard)
```


## Acknowledgments

The work was partially supported by the Austrian Science Fund (FWF) through the project CoRaF (grant agreement 2020388).

## References

1. Bitcoin statistics on transaction utxos. https://bitcoinvisuals.com/ accessed: 2020$11-20$
2. Al-Bassam, M.: Lazyledger: A distributed data availability ledger with client-side smart contracts. arXiv preprint: 1905.09274 (2019)
3. Al-Bassam, M., Sonnino, A., Bano, S., Hrycyszyn, D., Danezis, G.: Chainspace: A sharded smart contracts platform. 25th Annual Network and Distributed System Security Symposium (2018)
4. Al-Bassam, M., Sonnino, A., Buterin, V.: Fraud and data availability proofs: Maximising light client security and scaling blockchains with dishonest majorities. arXiv preprint: 1809.09044 (2018)
5. Androulaki, E., Barger, A., Bortnikov, V., Cachin, C., Christidis, K., Caro, A.D., Enyeart, D., Ferris, C., Laventman, G., Manevich, Y., et al.: Hyperledger fabric: a distributed operating system for permissioned blockchains. In: Proceedings of the 13th EuroSys Conference. pp. 30:1-30:15 (2018)
6. Androulaki, E., Cachin, C., De Caro, A., Kokoris-Kogias, E.: Channels: Horizontal scaling and confidentiality on permissioned blockchains. In: European Symposium on Research in Computer Security. pp. 111-131. Springer (2018)
7. Avarikioti, Z., Heimbach, L., Schmid, R., Wattenhofer, R.: Fnf-bft: Exploring performance limits of bft protocols. arXiv preprint: 2009.02235 (2020)
8. Bano, S., Sonnino, A., Al-Bassam, M., Azouvi, S., McCorry, P., Meiklejohn, S., Danezis, G.: Sok: Consensus in the age of blockchains. In: Proceedings of the 1st ACM Conference on Advances in Financial Technologies. pp. 183-198. ACM (2019)
9. Ben-Sasson, E.: A cambrian explosion of crypto proofs. https://nakamoto.com/ cambrian-explosion-of-crypto-proofs/ (2020)
10. Boneh, D., BÃ¼nz, B., Fisch, B.: Batching techniques for accumulators with applications to iops and stateless blockchains. In: Annual International Cryptology Conference. pp. 561-586. Springer (2019)
11. Bonneau, J., Clark, J., Goldfeder, S.: On bitcoin as a public randomness source. IACR Cryptology ePrint Archive, Report 2015/1015 (2015)
12. Borge, M., Kokoris-Kogias, E., Jovanovic, P., Gasser, L., Gailly, N., Ford, B.: Proofof-personhood: Redemocratizing permissionless cryptocurrencies. In: IEEE European Symposium on Security and Privacy Workshops. pp. 23-26 (2017)
13. Bracha, G., Toueg, S.: Asynchronous consensus and broadcast protocols. Journal of the ACM 32(4), 824-840 (1985)
14. BÃ¼nz, B., Goldfeder, S., Bonneau, J.: Proofs-of-delay and randomness beacons in ethereum. In: IEEE Security and Privacy on the Blockchain (2017)
15. BÃ¼nz, B., Kiffer, L., Luu, L., Zamani, M.: Flyclient: Super-light clients for cryptocurrencies. In: IEEE Symposium on Security and Privacy. pp. 928-946 (2020)
16. Cascudo, I., David, B.: SCRAPE: Scalable randomness attested by public entities. In: International Conference on Applied Cryptography and Network Security. pp. $537-556$. Springer (2017)
17. Castro, M., Liskov, B.: Practical byzantine fault tolerance. In: Proceedings of the 3rd USENIX Symposium on Operating Systems Design and Implementation. pp. 173-186 (1999)
18. Chatzigiannis, P., Baldimtsi, F., Chalkias, K.: Sok: Blockchain light clients. In: Financial Cryptography and Data Security FC (2022), https://doi.org/10.1007/ 978-3-031-18283-9_31
19. Danezis, G., Kokoris-Kogias, L., Sonnino, A., Spiegelman, A.: Narwhal and tusk: a dag-based mempool and efficient bft consensus. In: Proceedings of the Seventeenth European Conference on Computer Systems. pp. 34-50 (2022)
20. Das, S., Yurek, T., Xiang, Z., Miller, A., Kokoris-Kogias, L., Ren, L.: Practical asynchronous distributed key generation. In: 2022 IEEE Symposium on Security and Privacy (SP). pp. 2518-2534. IEEE (2022)
21. David, B., GaÅ¾i, P., Kiayias, A., Russell, A.: Ouroboros praos: An adaptivelysecure, semi-synchronous proof-of-stake blockchain. In: Annual International Conference on the Theory and Applications of Cryptographic Techniques. pp. 66-98. Springer (2018)
22. Feldman, P.: A practical scheme for non-interactive verifiable secret sharing. In: 28th Annual IEEE Symposium on Foundations of Computer Science. pp. 427-438. IEEE (1987)
23. Fisher, T., Funk, D., Sams, R.: The birthday problem and generalizations. Carlton College, Mathematics Comps Gala (2013), https://d31kydh6n6r5j5.cloudfront. net/uploads/sites/66/2019/04/birthday_comps.pdf
24. Garay, J., Kiayias, A., Leonardos, N.: The bitcoin backbone protocol: Analysis and applications. In: Annual International Conference on the Theory and Applications of Cryptographic Techniques. pp. 281-310. Springer (2015)
25. Gilad, Y., Hemo, R., Micali, S., Vlachos, G., Zeldovich, N.: Algorand: Scaling byzantine agreements for cryptocurrencies. In: Proceedings of the 26th Symposium on Operating Systems Principles. pp. 51-68. ACM (2017)
26. Kadhe, S., Chung, J., Ramchandran, K.: Sef: A secure fountain architecture for slashing storage costs in blockchains. arXiv preprint: 1906.12140 (2019)
27. Kattis, A., Bonneau, J.: Proof of necessary work: Succinct state verification with fairness guarantees. IACR Cryptology ePrint Archive, Report 2020/190 (2020)
28. Kiayias, A., Miller, A., Zindros, D.: Non-interactive proofs of proof-of-work. In: International Conference on Financial Cryptography and Data Security. pp. 505522. Springer (2020)
29. Kiayias, A., Panagiotakos, G.: On trees, chains and fast transactions in the blockchain. In: 5th International Conference on Cryptology and Information Security in Latin America. pp. 327-351 (2017)
30. Kiayias, A., Russell, A., David, B., Oliynykov, R.: Ouroboros: A provably secure proof-of-stake blockchain protocol. In: Annual International Cryptology Conference. pp. 357-388. Springer (2017)
31. Kogias, E.K., Jovanovic, P., Gailly, N., Khoffi, I., Gasser, L., Ford, B.: Enhancing bitcoin security and performance with strong consistency via collective signing. In: 25th USENIX Security Symposium. pp. 279-296 (2016)
32. Kokoris-Kogias, E.: Robust and scalable consensus for sharded distributed ledgers. IACR Cryptology ePrint Archive, Report 2019/676 (2019)
33. Kokoris-Kogias, E., Jovanovic, P., Gasser, L., Gailly, N., Syta, E., Ford, B.: Omniledger: A secure, scale-out, decentralized ledger via sharding. In: 39th IEEE Symposium on Security and Privacy. pp. 583-598. IEEE (2018)
34. Kokoris-Kogias, E., Malkhi, D., Spiegelman, A.: Asynchronous distributed key generation for computationally-secure randomness, consensus, and threshold signatures. In: 27th ACM SIGSAC Conference on Computer and Communications Security. pp. 1751-1767. ACM (2020)
35. Lamport, L., Shostak, R., Pease, M.: The byzantine generals problem. In: Concurrency: The Works of Leslie Lamport, pp. 203-226 (2019)
36. Luu, L., Narayanan, V., Zheng, C., Baweja, K., Gilbert, S., Saxena, P.: A secure sharding protocol for open blockchains. In: Proceedings of the 25th ACM SIGSAC Conference on Computer and Communications Security. pp. 17-30. ACM (2016)
37. Martino, W., Quaintance, M., Popejoy, S.: Chainweb: A proof-of-work parallelchain architecture for massive throughput. https://www.kadena.io/whitepapers (2018)
38. Maymounkov, P., Mazieres, D.: Kademlia: A peer-to-peer information system based on the xor metric. In: International Workshop on Peer-to-Peer Systems. pp. 53-65. Springer (2002)
39. Meckler, I., Shapiro, E.: Coda: Decentralized cryptocurrency at scale. https://cdn. codaprotocol.com/static/coda-whitepaper-05-10-2018-0.pdf (2018)
40. Nakamoto, S.: Bitcoin: A peer-to-peer electronic cash system (2008)
41. Pass, R., Seeman, L., Shelat, A.: Analysis of the blockchain protocol in asynchronous networks. In: Annual International Conference on the Theory and Applications of Cryptographic Techniques. pp. 643-673. Springer (2017)
42. Raab, M., Steger, A.: "balls into bins"-a simple and tight analysis. In: International Workshop on Randomization and Approximation Techniques in Computer Science. pp. 159-170. Springer (1998)
43. Rana, R., Kannan, S., Tse, D., Viswanath, P.: Free2shard: Adaptive-adversaryresistant sharding via dynamic self allocation. arXiv preprint: 2005.09610 (2020)
44. Ren, L., Nayak, K., Abraham, I., Devadas, S.: Practical synchronous byzantine consensus. arXiv preprint: 1704.02397 (2017)
45. Schindler, P., Judmayer, A., Stifter, N., Weippl, E.: HydRand: Practical continuous distributed randomness. IACR Cryptology ePrint Archive, Report 2018/319 (2018)
46. Sen, S., Freedman, M.J.: Commensal cuckoo: Secure group partitioning for largescale services. ACM SIGOPS Operating Systems Review 46(1), 33-39 (2012)
47. Sompolinsky, Y., Zohar, A.: Secure high-rate transaction processing in bitcoin. In: International Conference on Financial Cryptography and Data Security. pp. 507-527. Springer (2015)
48. Sonnino, A., Bano, S., Al-Bassam, M., Danezis, G.: Replay attacks and defenses against cross-shard consensus in sharded distributed ledgers. arXiv preprint: 1901.11218 (2019)
49. Spiegelman, A., Giridharan, N., Sonnino, A., Kokoris-Kogias, L.: Bullshark: Dag bft protocols made practical. In: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. pp. 2705-2718 (2022)
50. Stathakopoulou, C., David, T., VukoliÄ, M.: Mir-bft: High-throughput bft for blockchains. arXiv preprint: 1906.05552 (2019)
51. Syta, E., Jovanovic, P., Kogias, E.K., Gailly, N., Gasser, L., Khoffi, I., Fischer, M.J., Ford, B.: Scalable bias-resistant distributed randomness. In: IEEE Symposium on Security and Privacy. pp. 444-460 (2017)
52. Wang, G., Shi, Z.J., Nixon, M., Han, S.: Sok: Sharding on blockchain. In: Proceedings of the 1st ACM Conference on Advances in Financial Technologies. pp. 41-61. ACM (2019)
53. Wang, J., Wang, H.: Monoxide: Scale out blockchains with asynchronous consensus zones. In: 16th USENIX Symposium on Networked Systems Design and Implementation. pp. 95-112 (2019)
54. Yin, M., Malkhi, D., Reiter, M.K., Gueta, G.G., Abraham, I.: Hotstuff: Bft consensus with linearity and responsiveness. In: Proceedings of the 38th ACM Symposium on Principles of Distributed Computing. pp. 347-356. ACM (2019)
55. Zamani, M., Movahedi, M., Raykova, M.: Rapidchain: Scaling blockchain via full sharding. In: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. pp. 931-948. ACM (2018)
56. Zamyatin, A., Al-Bassam, M., Zindros, D., Kokoris-Kogias, E., Moreno-Sanchez, P., Kiayias, A., Knottenbelt, W.J.: Sok: Communication across distributed ledgers. IACR Cryptology ePrint Archive, Report 2019/1128 (2019)
