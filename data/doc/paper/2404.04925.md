# Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers 

Libo Qin** Qiguang Chen ${ }^{\star}$ ** Yuhang Zhou ${ }^{\star}$ Zhi Chen ${ }^{\diamond} \quad$ Yinghui Li ${ }^{\natural}$<br>Lizi Liao ${ }^{\sharp}$ Min Li ${ }^{\infty}$ Wanxiang Che ${ }^{\curvearrowleft}$ Philip S. Yu ${ }^{\ominus}$<br>$\cdot$ Central South University $\uparrow$ Harbin Institute of Technology $\diamond$ Shanghai AI Laboratory<br>${ }^{\natural}$ Tsinghua University ${ }^{\sharp}$ Singapore Management University ${ }^{\ominus}$ University of Illinons at Chicago<br>lbqin@csu.edu.cn, \{qgchen, car\}@ir.hit.edu.cn


#### Abstract

Multilingual Large Language Models are capable of using powerful Large Language Models to handle and respond to queries in multiple languages, which achieves remarkable success in multilingual natural language processing tasks. Despite these breakthroughs, there still remains a lack of a comprehensive survey to summarize existing approaches and recent developments in this field. To this end, in this paper, we present a thorough review and provide a unified perspective to summarize the recent progress as well as emerging trends in multilingual large language models (MLLMs) literature. The contributions of this paper can be summarized: (1) First survey: to our knowledge, we take the first step and present a thorough review in MLLMs research field according to multi-lingual alignment; (2) New taxonomy: we offer a new and unified perspective to summarize the current progress of MLLMs; (3) New frontiers: we highlight several emerging frontiers and discuss the corresponding challenges; (4) Abundant resources: we collect abundant open-source resources, including relevant papers, data corpora, and leaderboards. We hope our work can provide the community with quick access and spur breakthrough research in MLLMs.


## 1 Introduction

In recent years, remarkable progress has been witnessed in large language models (LLMs) (Brown et al., 2020; Touvron et al., 2023a; Bang et al., 2023; Zhao et al., 2023b), which have achieved excellent performance on various natural language processing tasks (Pan et al., 2023; Nguyen et al., 2023a; Trivedi et al., 2023). In addition, LLMs raise surprising emergent capabilities, including in-context learning (Min et al., 2022; Dong et al., 2022), chain-of-thought reasoning (Wei et al., 2022; Huang et al., 2023a; Qin et al., 2023a), and even planning (Driess et al., 2023; Hu et al., 2023b).[^0]

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-01.jpg?height=759&width=780&top_left_y=754&top_left_x=1049)

(b) Parameter-Frozen Alignment

Figure 1: Parameter-Tuning Alignment (§4.1) v.s. Parameter-Frozen Alignment (§4.2). The former requires the model to fine-tune the MLLM parameters for cross-lingual alignment, while the latter directly uses prompts for alignment without parameter tuning.

Nevertheless, the majority of LLMs are Englishcentric, primarily focusing on English tasks (Held et al., 2023; Zhang et al., 2023i), which makes them somewhat weak for multilingual settings, especially in low-resource scenarios.

Actually, there are over 7,000 languages in the world. With the acceleration of globalization, the success of large language models should be considered to serve diverse countries and languages. To this end, multilingual large language models (MLLMs) possess the advantage of comprehensively handling multiple languages, gaining increasing attention. Specifically, the existing MLLMs can be broadly divided into two groups based on different stages. The first series of works (Xue et al., 2020; Workshop et al., 2022; Zhang et al., 2023g; Muennighoff et al., 2022) leverage multilingual

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-02.jpg?height=760&width=1564&top_left_y=228&top_left_x=246)

Figure 2: Evolution of selected MLLMs over the past five years, where colored branches indicate different alignment stages. For models with multiple alignment stages, the final stage is represented.

data to tuning the parameters to boost the overall multilingual performance. The second series of work (Shi et al., 2022a; Qin et al., 2023b; Huang et al., 2023a) also adapt the advanced prompting strategies to unlock deeper multilingual potential of MLLMs during parameter-frozen inference stage.

While remarkable success has been achieved in the MLLMs, there still remains a lack of a comprehensive review and analysis of recent efforts in the literature, which hinders the development of MLLMs. To bridge this gap, we make the first attempt to conduct a comprehensive and detailed analysis of MLLMs. Concretely, we first introduce the widely used data resource (§3). Furthermore, due to the key challenge of alignment across languages, we introduce a novel taxonomy according to alignment strategies (§4), aiming to provide a unified perspective in the literature, which includes: parameter-tuning alignment and parameter-frozen alignment (as shown in Figure 1). Specifically, parameter-tuning alignment requires the fine-tuning of model parameters to enhance alignment between English and target languages during pre-training, supervised fine-tuning, reinforcement learning from human feedback and downstream fine-tuning. parameter-frozen alignment refers to the alignment achieved by prompting across languages that can be achieved without the need for parameter tuning. Finally, we point out some potential frontier areas as well as the corresponding challenges for MLLMs, hoping to inspire the follow-up research ( $\S 5$ ).
The contributions of this work can be summarized as follows: (1) First survey: To the best of our knowledge, we are the first to present a comprehensive survey in the MLLMs literature according to multi-lingual alignment; (2) New taxonomy: We introduce a novel taxonomy categorizing MLLMs into two alignment types: parameter-frozen and parameter-tuning, offering a unified view for understanding the MLLMs literature; (3) New frontiers: We discuss some emerging frontiers and highlight their challenges as well as opportunities, hoping to pave the way for future research developments; (4) Exhaustive resources: We make the first attempt to organize MLLMs resources including open-source software, diverse corpora, and a curated list of relevant publications, accessible at https://multilingual-llm.net.

We hope that this work can serve as a valuable resource for researchers and inspire more breakthroughs in future research ${ }^{1}$.

## 2 Preliminary

In this section, we will formally describe the definitions of monolingual large language model (\$2.1) and multilingual large language model ( $\$ 2.2$ ).

### 2.1 Monolingual Large Language Model

Monolingual large language models (LLM) can only process one language at a time. For example, as illustrated in Figure 3 (a), English and Chinese[^1]

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-03.jpg?height=525&width=797&top_left_y=246&top_left_x=230)

(b) Multilingual Large Language Model

Figure 3: Monolingual Large Language Model v.s. Multilingual Large Language Model.

LLM can separately handle English and Chinese language, respectively. Formally, considering a set of languages $\mathcal{L}=\left\{\mathcal{L}_{i}\right\}_{i=0}^{|\mathcal{L}|}$, given input utterance $\mathcal{X}_{i} \in \mathcal{L}_{i}$ in languages $\mathcal{L}_{i}$, the process of monolingual LLM ( $\mathcal{M}_{\text {mono }}$ ) generating the output $\mathcal{Y}_{i}$ can be defined as:

$$
\mathcal{Y}_{i}= \begin{cases}\mathcal{M}_{\text {mono }}\left(\mathcal{X}_{i}, \mathcal{L}_{i}\right), & \text { mono }=\mathcal{L}_{i}  \tag{1}\\ \text { Unexpect }, & \text { mono } \neq \mathcal{L}_{i}\end{cases}
$$

where Unexpect indicates that the LLM generates output in an unintended language; mono denotes the single language.

### 2.2 Multilingual Large Language Model

As shown in Figure 3 (b), unlike monolingual LLM, a multilingual LLM is capable of handling and producing content in various languages simultaneously, like English and Chinese. Formally, for MLLM $\mathcal{M}_{\text {multi }}$, where multi $\subseteq \mathcal{L}$ and $\mid$ multi $\mid \geq 2$, the model's response is given by:

$$
\begin{equation*}
\mathcal{Y}=\mathcal{M}_{\text {multi }}(\mathcal{X}) \tag{2}
\end{equation*}
$$

where $\mathcal{X}$ and $\mathcal{Y}$ belong to multiple languages, multi.

## 3 Data Resource

In this section, we describe the widely used data resources in pre-training ( $\S 3.1$ ), supervised finetuning (SFT) (§3.2) and reinforcement learning from human feedback (RLHF) (§3.3) stage (Zhao et al., 2023b) for multilingual large language model. Detailed statistics can be found in Table 1 and Table 2 in the Appendix.

### 3.1 Multilingual Pretraining Data

The widely used multilingual corpora for pretraining in MLLMs can be divided into 3 categories: (1) Manual Creation: obtains high-quality pretraining corpora through manual creation and proofreading, which consists of the Bible Corpus (Mayer and Cysouw, 2014) and MultiUN (Ziemski et al., 2016). (2) Web Crawling: involves crawling extensive multilingual data from the internet, which includes OSCAR (Suárez et al., 2019), CC-100 (Conneau et al., 2020), mC4 (Xue et al., 2021) and Redpajama-v2 (Computer, 2023). Another series of data are extracted from Wikipedia to enhance the knowledge of MLLMs. Common datasets include Wikipedia (Foundation), WikiMatrix (Schwenk et al., 2021) and WikiExpl (Han et al., 2023). (3) Benchmark Adaptation: means re-cleaning or integrating existing benchmarks to enhance data quality which includes OPUS-100 (Zhang et al., 2020), Culturax (Nguyen et al., 2023c), OPUS (Tiedemann, 2012), WMT (Kocmi et al., 2023) and ROOTS (Laurençon et al., 2022).

### 3.2 Multilingual SFT Data

Similarly, we categorize the existing multilingual SFT data into 4 classes: (1) Manual Creation: acquires SFT corpora through manual creation and proofreading, which includes SupNatInst (Wang et al., 2022b), OpenAssist (Köpf et al., 2023) and COIG-PC lite (Team, 2023a). (2) Machine Translation: translates the existing monolingual datasets into multilingual instruction datasets, which comprises xP3-MT (Muennighoff et al., 2022), MGSM8K Instruct (Chen et al., 2023b), CrossAlpaca (Ranaldi et al., 2023b; Cui et al., 2023), MultilingualSIFT (Chen et al., 2023i) and Bactrain-X (Li et al., 2023b). (3) Benchmark

Adaptation: involves transformation from existing benchmarks to instruction format. Widely used datasets include xP3 (Muennighoff et al., 2022), PolyglotPrompt (Fu et al., 2022), and BUFFET (Asai et al., 2023). (4) MLLMs Aided Generation: means that the data are automatically synthesized by the MLLMs, containing Vicuna (Chiang et al., 2023), OverMiss (Chen et al., 2023g), ShareGPT (ShareGPT, 2023), BELLE (Yunjie Ji, 2023), MultiAlpaca (Wei et al., 2023c), Guanaco (Dettmers et al., 2023) and Alpaca-4 (Peng et al., 2023).

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-04.jpg?height=1470&width=1600&top_left_y=213&top_left_x=228)

Figure 4: Taxonomy of MLLMs which includes Parameter-Tuning Alignment Methodology and Parameter-Frozen Alignment Methodology.

### 3.3 Multilingual RLHF Data

Some work leveraged the multilingual RLHF data to improve alignment. Specifically, Lai et al. (2023b) leverages multilingual ranking data for training a reward model using RLHF. Zeng et al. (2023b) introduce the TIM dataset to train a more effective reward model in multilingual contexts.

## 4 Taxonomy

As shown in Figure 4, we introduce a novel taxonomy including parameter-tuning alignment (\$4.1) and parameter-frozen alignment ( $\S 4.2$ ), which aims to provide a unified view for researchers to understand the MLLMs literature. Specifically, parameter tuning alignment (PTA) comprises a series of progressively advanced training and alignment strategies, including Pretraining Alignment, Super- vised Fine-Tuning (SFT) Alignment, Reinforcement Learning from Human Feedback (RLHF) Alignment, and, ultimately, Downstream FineTuning Alignment. These stages collectively aim to refine model parameters to align the multilingual performance systematically. Conversely, the parameter frozen alignment (PFA) focuses on four prompting strategies based on PTA: Direct Prompting, Code-Switching Prompting, Translation Alignment Prompting, and Retrieval-Augmented Alignment. This method maintains the original model parameters to achieve desired outcomes.

### 4.1 Parameter-Tuning Alignment

Parameter-tuning alignment indicates that MLLMs should tune their parameters for better cross-lingual alignment (Wen-Yi and Mimno, 2023). As shown in Figure 5, we discuss the four categories of

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-05.jpg?height=537&width=1564&top_left_y=234&top_left_x=246)

Figure 5: Overview of Parameter-Tuning Alignment (§ 4.1) Methods, which including PTA in Pretraining Stage (§ 4.1.1), PTA in SFT stage (§ 4.1.2), PTA in RLHF stage (§ 4.1.3) and PTA in Downstream Finetuning stage (§ 4.1.4).

parameter-tuning alignment (PTA), including PTA in pretraining stage (§4.1.1), PTA in SFT stage (§4.1.2), PTA in RLHF stage (§4.1.3) and PTA in Finetuning stage (\$4.1.4).

### 4.1.1 PTA in Pretraining Stage

From-scratch Pretraining Alignment. A series of approaches have achieved to alignment across languages by tuning the initially random parameters of MLLMs during pretraining (see Figure 5 (a)). Specifically, Blevins and Zettlemoyer (2022); Briakou et al. (2023); Holmström et al. (2023) observed that adding a few multilingual data during the from-scratch pretraining alignment, even unintentionally, can significantly boost the multilingual performance. Inspired by this, Zeng et al. (2022); Su et al. (2022) used bilingual data in their fromscratch pretraining for alignment. mT5 (Xue et al., 2020), Ernie3.0 (Sun et al., 2021), ByT5 (Xue et al., 2022), BLOOM (Workshop et al., 2022), LLaMA (Touvron et al., 2023b,a), PaLM (Chowdhery et al., 2022), Mistral (Jiang et al., 2023), Mixtral (Jiang et al., 2024), PolyLM (Wei et al., 2023c), Kale et al. (2021); Kim et al. (2021); Shliazhko et al. (2022); Chai et al. (2022); Schioppa et al. (2023); Abdul-Mageed et al. (2023); Uthus et al. (2023); Wei et al. (2023a); Uludoğan et al. (2024) incorporated multilingual data in pretraining stage for better alignment. Blevins et al. (2024) utilizes Mixture-of-Experts (MoE) to independently train language models on subsets of multilingual corpora to alleviate the problem of multilingual parameter competition. Furthermore, to enhance the performance of low-resource languages, umT5 (Chung et al., 2022a) and XGLM (Lin et al., 2022a) adopted equitable data sampling methods during from-scratch pretraining. Muraoka et al.
(2023) introduced VCT to leverage vision for indirect cross-lingual alignment in from-scratch pretraining.

Continual Pretraining Alignment. To address the high computational cost of from-scratch pretraining, continual pretraining alignment builds the pretraining process upon pretrained MLLMs (as shown in Figure 5 (a)). Specifically, CPM2 (Zhang et al., 2021), Sabia (Pires et al., 2023), FinGPT (Luukkonen et al., 2023), X-Gen (Vu et al., 2022), AFP (Li et al., 2023a), Cabrita (Larcher et al., 2023), LLaMAntino (Basile et al., 2023) focused on adding more target language data during continual pretraining for general performance. Further, Cui et al. (2023); HIT-SCIR (2024) emphasized extending the MLLMs' vocabularies to adapt to new languages.

### 4.1.2 PTA in SFT Stage

As illustrated in Figure 5 (b), PTA in SFT stage means leveraging multiple multilingual task data with instruction format for tuning parameters (Fu et al., 2022; Yang et al., 2023f; Team, 2023d; Chen et al., 2023c,g; Ranaldi et al., 2023a; Li et al., 2023h; Chen et al., 2023g; Santilli and Rodolà, 2023; Bao et al., 2023; Kohli et al., 2023; Holmström and Doostmohammadi, 2023; Garcia et al., 2024). In particular, models like Flan-PaLM (Chung et al., 2022b), mT0, BLOOMz (Muennighoff et al., 2022), PolyLM (Wei et al., 2023c), Tk-Instruct (Wang et al., 2022b), Chinese-Alpaca (Cui et al., 2023), Bayling (Zhang et al., 2023g) and Phoenix (Chen et al., 2023h), directly incorporated multilingual data in the SFT stage to achieve implicit multilingual alignment across languages. Besides, to
solve the scarcity of multilingual SFT task data, PaLM2 (Anil et al., 2023), Zhu et al. (2023); Cahyawijaya et al. (2023b); Li et al. (2023c); Gao et al. (2024) added translation task during the SFT alignment stage to improve alignment. Further, Upadhayay and Behzadan (2023); Chai et al. (2024); Zhu et al. (2024) began to consider using a more effective SFT alignment strategy to optimize the reasoning process.

### 4.1.3 PTA in RLHF Stage

As shown in Figure 5 (c), to achieve alignment in reinforcement learning from human feedback (RLHF) stage, Okapi (Lai et al., 2023b), LLaMA2-Chat (Touvron et al., 2023b), ChatGLM (Zeng et al., 2022), MOSS (Sun et al., 2023b), Baichuan (Yang et al., 2023a), Huozi (Team, 2023b), Qwen (Bai et al., 2023), InternLM (Team, 2023c), ParroT (Jiao et al., 2023), TigerBot (Chen et al., 2023f), MOSS (Sun et al., 2023b), YAYI2 (Luo et al., 2023b), Yang et al. (2023c); Moura Ramos et al. (2023) and Orion (Chen et al., 2024) directly integrated multilingual RLHF data for training multilingual reward models. Additionally, Zeng et al. (2023b); Dong et al. (2023); She et al. (2024) introduced a multilingual reward model to compare translation outputs across different granularity. Sun et al. (2023c) proposed a Salmon framework, to enhance multilingual RLHF by self-generating rewards for better alignment.

### 4.1.4 PTA in Downstream Finetuning Stage

Full-Parameter Finetuning Alignment Fullparameter finetuning in MLLMs means tuning all parameters in downstream tasks (see Figure 5 (d)). Specifically, GShard (Lepikhin et al., 2020), Linguist (Rosenbaum et al., 2022b), Fan et al. (2021); Bapna et al. (2022); Tseng and Lin (2022); Iyer et al. (2023), NLLB (Costa-jussà et al., 2022a) AlexTM (Soltan et al., 2022), and BigTrans (Yang et al., 2023d) focused on directly fine-tuning the full parameters across various downstream tasks (e.g., information extraction, machine translation). Xu et al. (2023c); Huot et al. (2023); Yuan et al. (2023); Li et al. (2023e) proposed multi-step or finegrained alignment strategies during full-parameter tuning. Furthermore, to enhance the efficiency, Awasthi et al. (2022); De Raedt et al. (2023); Thakur et al. (2023b); Whitehouse et al. (2023a); Bansal and Sharma (2023); Xu et al. (2023a); Reinauer et al. (2023) focused on knowledge distillation from larger to smaller MLLMs.
Parameter-Efficient Finetuning Alignment A series of studies employ Parameter-Efficient Finetuning (PEFT) alignment approaches for reducing full-parameter fine-tuning costs (Yong et al., 2022; Mujadia et al., 2023; Moslem et al., 2023b), which is shown in Figure 5 (d). Agrawal et al. (2022a); Tu et al. (2023); Park et al. (2023) proposed minimal soft prompt prefix fine-tuning for better alignment. Furthermore, Whitehouse et al. (2023b); Xiao et al. (2023); Aggarwal et al. (2024); Le et al. (2024) proposed methods based on Low-Rank Adaptation (LoRA) to achieve PEFT alignment. Further, Yoon et al. (2024) introduced a LangBridge model to bridge multilingual encoder to single-lingual LLM to effectively achieve promising performance.


#### Abstract

Takeaways (1) PTA in pretraining stage brings the essential multilingual capabilities of the MLLMs. (2) The effectiveness of alignment in MLLMs is greatly influenced by previous alignment stage, (e.g. Pretraining will significantly influence SFT).


### 4.2 Parameter-Frozen Alignment

In contrast to the traditional parameter-tuning approaches (Zheng et al., 2022), parameter-frozen alignment methods aim to perform alignment without any parameter tuning. The most popular approaches employ prompting strategies to elicit the alignment potential of MLLMs. As shown in Figure 6, this section discusses four prompting strategies for alignment without parameter tuning, which include (1) Direct Prompting, (2) Code-Switching Prompting, (3) Translation Alignment Prompting and (4) Retrieval Augmented Alignment.

### 4.2.1 Direct Prompting

As shown in Figure 6 (a), Direct Prompting means directly outputting the request without any additional instruction for implicit alignment through MLLM itself (Abdelali et al., 2023; Zhang et al., 2023e; Wang et al., 2023b,d; Lin et al., 2022b; Bansal and Sharma, 2023; Wei et al., 2023b; Pourkamali and Sharifi, 2024).

### 4.2.2 Code-Switching Prompting

As shown in Figure 6 (b), it integrates multilingual words into a single-language utterance, which is a typical language phenomenon (Winata et al., 2022b; Doğruöz et al., 2023a,b) for effective language alignment (Qin et al., 2020, 2022). Specifically, Yong et al. (2023); Amin et al. (2023) showed the effectiveness of MLLMs in cross-

![](https://cdn.mathpix.com/cropped/2024_06_04_b0888687f389deaa7999g-07.jpg?height=554&width=1604&top_left_y=231&top_left_x=226)

Figure 6: Overview of Parameter-Frozen Alignment (§ 4.2) methods, where prompts in sub-figures sourced from Qin et al. (2023b) and Zhang et al. (2023f).

lingual alignment through model-generated codeswitching texts. Furthermore, Zhang et al. (2023f) suggested the need for fairer and more detailed code-switching optimization for further research.

### 4.2.3 Translation Alignment Prompting

Translation alignment prompting approaches mean that translating the query into other languages for better alignment (see Figure 6 (c)), which can be divided into the following classes: (1) Key Information Translation: This approach focuses on extracting key information and executing translation for word-level cross-lingual alignment (Lu et al., 2023; Li et al., 2023i). (2) Direct Translation: the model directly translates the whole input, enhancing alignment performance (Etxaniz et al., 2023; Zhang et al., 2023a; Cheng et al., 2023a; Petrick et al., 2023; Hoang et al., 2023; Zeng et al., 2023a; Nambi et al., 2023; Lin et al., 2021b). (3) Stepby-step Translation: Instead of direct translation, this method prompts MLLMs to translate whole input step-by-step (Puduppully et al., 2023a; Moslem et al., 2023a; Raunak et al., 2023; Wu and Hu, 2023; Puduppully et al., 2023b; Pilault et al., 2023). (4) Restatement: Beyond preserving original semantics, some studies focus on prompting MLLM to restate multilingual inputs to enhance cross-lingual effectiveness (Shi et al., 2022a; Patel et al., 2022; Rosenbaum et al., 2022a; Asai et al., 2023; Qin et al., 2023b; Huang et al., 2023a; Tanwar et al., 2023). Further, considering the differences in multiple languages (Ohmer et al., 2023), Qin et al. (2023b); Ranaldi et al. (2023a) integrated knowledge and translation strategy across different languages by cross-lingual prompting.

### 4.2.4 Retrieval Augmented Alignment

Retrieval Augmented Alignment incorporates external retrieval during prompting to inject more knowledge in MLLMs (see Figure 6 (d)). Specifically, He et al. (2023b); Zhang et al. (2023d); Conia et al. (2023); Xu et al. (2023d); Ahmad (2024) focus on retrieving cultural or professional knowledge to enrich prompts. Another series of work focused on retrieval for high-quality alignment demonstrations, yielding significant improvements (Shi et al., 2022b; Agrawal et al., 2022b; Li et al., 2023g; Winata et al., 2023b; Garcia et al., 2023; Li et al., 2023f; Ramos et al., 2023; Kim et al., 2023a; Thakur et al., 2023a).


#### Abstract

Takeaways (1) Translation alignment prompting is more effective for crosslingual alignment. (2) Retrieval augmented alignment mitigates knowledge gaps in LLM.


## 5 Future work and New Froniter

### 5.1 Hallucination in MLLMs

While remarkable progress has been achieved in MLLMs, the current approaches still face hallucination issues (Raunak et al., 2021). Specifically, Guerreiro et al. (2023a); Aharoni et al. (2023); Dale et al. (2023); Qiu et al. (2023) have previously pointed out the hallucination phenomenon on current MLLM. Further, a series of works provide corresponding solutions in the pre-training (Pfeiffer et al., 2023), SFT (Chen et al., 2023g) and decoding (Ahuja et al., 2022; Yang et al., 2023e; Sia et al., 2023; Zeng et al., 2023a) stages.

The key challenges in this direction include: (1) Multilingual Hallucination Detection: How to effectively detect the hallucination phenomenon of

MLLM across different languages is the primary problem to be solved in this field. (2) Multilingual Hallucination Alleviation: Current strategies for hallucination alleviation still focus on incorporating extensive factual data or utilizing external systems, which pose significant challenges for multiple languages, especially low-resource languages.

### 5.2 Knowledge Editing in MLLMs

The current MLLMs still face challenges with inaccurate, inconsistent, and outdated knowledge across different languages, which limits their performance. To solve this issue, Wu et al. (2023); Wang et al. (2023c) introduce a multilingual knowledge editing approach and propose a new benchmark for knowledge editing in MLLM. In addition, Qi et al. (2023) introduce the cross-lingual consistency metric to ensure factual consistency across languages. Additionally, Wang et al. (2023e) incorporate a multilingual knowledge base into MLLMs with retrieval methods to facilitate knowledge editing.

The key challenges of this research include: (1) Continuous Knowledge Editing: How to continuously integrate new knowledge while preserving the accuracy of existing knowledge is a core challenge to explore. (2) Balancing Universal and Language-Specific Knowledge: Current work often neglects language-specific details like culture and slang, impacting user experience and causing cultural conflicts (Held et al., 2023; Beniwal et al., 2024). How to balance universal knowledge, while preserving language-specific knowledge presents a fascinating question.

### 5.3 Safety in MLLMs

With the development and application of MLLMs, researchers have found that MLLMs often suffer some serious moral (Costa-jussà et al., 2022b; Sánchez et al., 2023) and privacy (Macko et al., 2023) risks, hindering the development of MLLMs (Wang et al., 2023f; Ye et al., 2023b; Hämmerl et al., 2022; Shen et al., 2024). Therefore, how to improve the safety of MLLMs is a promising research question.

The main challenges for safe MLLM are as follows: (1) Lack of Safety Benchmark: The lack of safe data in current literature hampers the relevant research. Consequently, acquiring a large-scale safety dataset to facilitate future research has become a hot topic. (2) Removal of Unsafe Data: The multilingual data generated by MLLMs poses potential unsafe risks during training (Wang et al., 2023h). Therefore, identifying and filtering out unsafe multilingual content is a crucial issue (Bogoychev et al., 2023).

### 5.4 Fairness in MLLMs

Multilingual fairness refers to equal treatment and performance across languages and cultures (Yu et al., 2022; Shliazhko et al., 2022). But there is a significant performance gap between languages, especially on low-resource languages (Malkin et al., 2022; Sengupta et al., 2023; Ye et al., 2023a). Additionally, token consumption also varies by language in MLLMs, leading to unequal computational costs (Koishekenov et al., 2022; Hua et al., 2023; Nicosia and Piccinno, 2022; Xue et al., 2022; Sun et al., 2023a; Rust et al., 2022).

The main concerns regarding fairness in MLLM are as follows: (1) Low-resource language performance improvement: It is essential to improve the performance of low-resource languages with limited data (Lin et al., 2023; Ansell et al., 2023; Adeyemi et al., 2023). (2) Multilingual Token Cost Improvement: Current tokenizer exhibits biases in segmenting different languages, leading to varying token costs (Petrov et al., 2023; Ahia et al., 2023; Ali et al., 2023). Addressing this challenge is essential for ensuring fairer tokenization across languages.

### 5.5 Language Extension in MLLMs

Due to the limited languages supported by current work, integrating new languages into existing MLLM is a promising direction to explore (Kew et al., 2023; Shaham et al., 2024). To this end, Cui et al. (2023); Yang et al. (2023d) suggest adding languages through two-stage pre-training. Yong et al. (2022) observe that adapter-based methods are more effective than continuous pre-training.

This challenge encompasses two main aspects: (1) Multiple Languages Extension: How to dynamically and effectively extend the languages for MLLMs is an interesting research question. (2) Original Languages Preserving: Since the expansion of the model in other languages will harm the original language performance, how to prevent the language extension in MLLM from forgetting the previously learned language is a major challenge.

### 5.6 Multi-Modality Extension in MLLMs

Since the improvement in the usability of MLLM, a large amount of work has begun to further extend

MLLM into visual modality (Geigle et al., 2023; Chen et al., 2022, 2023d,e; Ramos et al., 2023; Bai et al., 2023; Zhou et al., 2023; Hu et al., 2023a; Zhou, 2023; He et al., 2023a; Guo et al., 2023), speech modality (Huang et al., 2023b, 2024; Cheng et al., 2023b), video modality (Team et al., 2023) and even other modalities.

This field faces two main challenges: (1) Complex Reasoning Exploration: Current multi-modal MLLMs are limited to simple cross-modal crosslingual tasks, with a need for more exploration in complex reasoning. (2) Comprehensive Benchmark: The current literature lacks comprehensive benchmarks, which hinders progress and evaluation in this evolving field.

## 6 Conclusion

In this work, we present a comprehensive survey of the advancements in multilingual large language models (MLLMs). Specifically, we provide a new taxonomy for MLLMs from alignment perspectives, which can offer a unified view for researchers to understand the progress of MLLMs. In addition, we highlight some emerging trends and frontiers as well as their corresponding challenges in MLLMs. We hope this work can facilitate the research and inspire more breakthroughs in MLLMs literature.

## References

Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury, Maram Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham, Fahim Dalvi, Majd Hawasly, et al. 2023. Benchmarking arabic ai with large language models. arXiv preprint arXiv:2305.14982.

Muhammad Abdul-Mageed, Abdelrahim Elmadany, Alcides Inciarte, Md Tawkat Islam Khondaker, et al. 2023. Jasmine: Arabic gpt models for few-shot learning. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 16721-16744.

David Ifeoluwa Adelani, Jade Abbott, Graham Neubig, Daniel D'souza, Julia Kreutzer, Constantine Lignos, Chester Palen-Michel, Happy Buzaaba, Shruti Rijhwani, Sebastian Ruder, et al. 2021. Masakhaner: Named entity recognition for african languages. Transactions of the Association for Computational Linguistics, 9:1116-1131.

David Ifeoluwa Adelani, Jesujoba Oluwadara Alabi, Angela Fan, Julia Kreutzer, Xiaoyu Shen, Machel Reid, Dana Ruiter, Dietrich Klakow, Peter Nabende, Ernie Chang, et al. 2022. A few thousand translations go a long way! leveraging pre-trained models for african news translation. arXiv preprint arXiv:2205.02022.

David Ifeoluwa Adelani, Marek Masiak, Israel Abebe Azime, Jesujoba Oluwadara Alabi, Atnafu Lambebo Tonja, Christine Mwase, Odunayo Ogundepo, Bonaventure FP Dossou, Akintunde Oladipo, Doreen Nixdorf, et al. 2023. Masakhanews: News topic classification for african languages. arXiv preprint arXiv:2304.09972.

Mofetoluwa Adeyemi, Akintunde Oladipo, Ronak Pradeep, and Jimmy Lin. 2023. Zero-shot cross-lingual reranking with large language models for low-resource languages. arXiv preprint arXiv:2312.16159.

Milind Agarwal, Sweta Agarwal, Antonios Anastasopoulos, Luisa Bentivogli, Ondřej Bojar, Claudia Borg, Marine Carpuat, Roldano Cattoni, Mauro Cettolo, Mingda Chen, et al. 2023. Findings of the iwslt 2023 evaluation campaign. Association for Computational Linguistics.

Divyanshu Aggarwal, Ashutosh Sathe, and Sunayana Sitaram. 2024. Maple: Multilingual evaluation of parameter efficient finetuning of large language models. arXiv preprint arXiv:2401.07598.

Željko Agic and Ivan Vulic. 2019. Jw300: A widecoverage parallel corpus for low-resource languages. Association for Computational Linguistics.

Priyanka Agrawal, Chris Alberti, Fantine Huot, Joshua Maynez, Ji Ma, Sebastian Ruder, Kuzman Ganchev, Dipanjan Das, and Mirella Lapata. 2022a. Qameleon: Multilingual qa with only 5 examples. arXiv preprint arXiv:2211.08264.

Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan Ghazvininejad. 2022b. Incontext examples selection for machine translation. arXiv preprint arXiv:2212.02437.

Roee Aharoni, Shashi Narayan, Joshua Maynez, Jonathan Herzig, Elizabeth Clark, and Mirella Lapata. 2023. Multilingual summarization with factual consistency evaluation. In Findings of the Association for Computational Linguistics: ACL 2023, pages 3562-3591.

Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R Mortensen, Noah A Smith, and Yulia Tsvetkov. 2023. Do all languages cost the same? tokenization in the era of commercial language models. arXiv preprint arXiv:2305.13707.

Syed Rameel Ahmad. 2024. Enhancing multilingual information retrieval in mixed human resources environments: A rag model implementation for multicultural enterprise. arXiv preprint arXiv:2401.01511.

Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee, Samuel Maina, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, et al. 2023a. Mega: Multilingual evaluation of generative ai. arXiv preprint arXiv:2303.12528.

Kabir Ahuja, Sunayana Sitaram, Sandipan Dandapat, and Monojit Choudhury. 2022. On the calibration of massively multilingual language models. arXiv preprint arXiv:2210.12265.

Sanchit Ahuja, Divyanshu Aggarwal, Varun Gumma, Ishaan Watts, Ashutosh Sathe, Millicent Ochieng, Rishav Hada, Prachi Jain, Maxamed Axmed, Kalika Bali, et al. 2023b. Megaverse: Benchmarking large language models across languages, modalities, models and tasks. arXiv preprint arXiv:2311.07463.

Bashar Alhafni, Go Inoue, Christian Khairallah, and Nizar Habash. 2023. Advancements in Arabic grammatical error detection and correction: An empirical investigation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6430-6448, Singapore. Association for Computational Linguistics.

Mehdi Ali, Michael Fromm, Klaudia Thellmann, Richard Rutmann, Max Lübbering, Johannes Leveling, Katrin Klug, Jan Ebert, Niclas Doll, Jasper Schulze Buschhoff, et al. 2023. Tokenizer choice for llm training: Negligible or crucial? arXiv preprint arXiv:2310.08754.

Dhiraj Amin, Sharvari Govilkar, Sagar Kulkarni, Yash Shashikant Lalit, Arshi Ajaz Khwaja, Daries Xavier, and Sahil Girijashankar Gupta. 2023. Marathi-english code-mixed text generation. arXiv preprint arXiv:2309.16202.

Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Palm 2 technical report. arXiv preprint arXiv:2305.10403.

Alan Ansell, Marinela Parović, Ivan Vulić, Anna Korhonen, and Edoardo Ponti. 2023. Unifying crosslingual transfer across scenarios of resource scarcity. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3980-3995.

Mikel Artetxe, Vedanuj Goswami, Shruti Bhosale, Angela Fan, and Luke Zettlemoyer. 2023. Revisiting machine translation for cross-lingual classification. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6489-6499, Singapore. Association for Computational Linguistics.

Mikel Artetxe, Sebastian Ruder, and Dani Yogatama. 2020. On the cross-lingual transferability of monolingual representations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4623-4637, Online. Association for Computational Linguistics.

Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi. 2023. Buffet: Benchmarking large language models for few-shot cross-lingual transfer. arXiv preprint arXiv:2305.14857.
Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita Sarawagi, and Partha Talukdar. 2022. Bootstrapping multilingual semantic parsers using large language models. arXiv preprint arXiv:2210.07313.

Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. 2023. Qwen technical report. arXiv preprint arXiv:2309.16609.

Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al. 2023. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023.

Parikshit Bansal and Amit Sharma. 2023. Large language models as annotators: Enhancing generalization of nlp models at minimal cost. arXiv preprint arXiv:2306.15766.

Eliseo Bao, Anxo Pérez, and Javier Parapar. 2023. Conversations in galician: a large language model for an underrepresented language. arXiv preprint arXiv:2311.03812.

Ankur Bapna, Isaac Caswell, Julia Kreutzer, Orhan Firat, Daan van Esch, Aditya Siddhant, Mengmeng Niu, Pallavi Baljekar, Xavier Garcia, Wolfgang Macherey, et al. 2022. Building machine translation systems for the next thousand languages. arXiv preprint arXiv:2205.03983.

Pierpaolo Basile, Elio Musacchio, Marco Polignano, Lucia Siciliani, Giuseppe Fiameni, and Giovanni Semeraro. 2023. Llamantino: Llama 2 models for effective text generation in italian language. arXiv preprint arXiv:2312.09993.

Rachel Bawden, Eric Bilinski, Thomas Lavergne, and Sophie Rosset. 2021. Diabla: a corpus of bilingual spontaneous written dialogues for machine translation. Language Resources and Evaluation, 55:635660 .

Marco Bellagente, Manuel Brack, Hannah Teufel, Felix Friedrich, Björn Deiseroth, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Koen Oostermeijer, et al. 2023. Multifusion: Fusing pre-trained models for multi-lingual, multi-modal image generation. arXiv preprint arXiv:2305.15296

Himanshu Beniwal, Mayank Singh, et al. 2024. Crosslingual editing in multilingual language models. arXiv preprint arXiv:2401.10521.

Aleksandrs Berdičevskis, Gerlof Bouma, Robin Kurtz, Felix Morger, Joey Öhman, Yvonne Adesam, Lars Borin, Dana Dannélls, Markus Forsberg, Tim Isbister, et al. 2023. Superlim: A swedish language understanding evaluation benchmark. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 8137-8153.

Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ahmad, Yuan-Fang Li, Yong-Bin Kang, and Rifat Shahriyar. 2021. Crosssum: Beyond englishcentric cross-lingual abstractive text summarization for $1500+$ language pairs. arXiv preprint arXiv:2112.08804.

Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, et al. 2022. Gpt-neox-20b: An open-source autoregressive language model. Challenges \& Perspectives in Creating Large Language Models, page 95.

Terra Blevins, Tomasz Limisiewicz, Suchin Gururangan, Margaret Li, Hila Gonen, Noah A Smith, and Luke Zettlemoyer. 2024. Breaking the curse of multilinguality with cross-lingual expert language models. arXiv preprint arXiv:2401.10440.

Terra Blevins and Luke Zettlemoyer. 2022. Language contamination helps explain the cross-lingual capabilities of english pretrained models. arXiv preprint arXiv:2204.08110.

Nikolay Bogoychev, Jelmer van der Linde, Graeme Nail, Barry Haddow, Jaume Zaragoza-Bernabeu, Gema Ramírez-Sánchez, Lukas Weymann, Tudor Nicolae Mateiu, Jindřich Helcl, and Mikko Aulamo. 2023. Opuscleaner and opustrainer, open source toolkits for training machine translation and large language models. arXiv preprint arXiv:2311.14838.

Sabri Boughorbel and Majd Hawasly. 2023. Analyzing multilingual competency of llms in multi-turn instruction following: A case study of arabic. arXiv preprint arXiv:2310.14819.

Eleftheria Briakou, Colin Cherry, and George Foster. 2023. Searching for needles in a haystack: On the role of incidental bilingualism in palm's translation capability. arXiv preprint arXiv:2305.10266.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.

Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Winata, Bryan Wilie, Fajri Koto, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, et al. 2023a. Nusacrowd: Open source initiative for indonesian nlp resources. In Findings of the Association for Computational Linguistics: ACL 2023, pages 13745-13818.

Samuel Cahyawijaya, Holy Lovenia, Tiezheng Yu, Willy Chung, and Pascale Fung. 2023b. Instructalign: Teaching novel languages with to llms through alignment-based cross-lingual instruction. arXiv preprint arXiv:2305.13627.

Yang Trista Cao, Anna Sotnikova, Jieyu Zhao, Linda X Zou, Rachel Rudinger, and Hal Daume III. 2023.
Multilingual large language models leak human stereotypes across language boundaries. arXiv preprint arXiv:2312.07141.

Linzheng Chai, Jian Yang, Tao Sun, Hongcheng Guo, Jiaheng Liu, Bing Wang, Xiannian Liang, Jiaqi Bai, Tongliang Li, Qiyao Peng, et al. 2024. xcot: Crosslingual instruction tuning for cross-lingual chain-ofthought reasoning. arXiv preprint arXiv:2401.07037.

Yekun Chai, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, and Hua Wu. 2022. Ernie-code: Beyond english-centric cross-lingual pretraining for programming languages. arXiv preprint arXiv:2212.06742.

Soravit Changpinyo, Linting Xue, Idan Szpektor, Ashish V Thapliyal, Julien Amelot, Xi Chen, and Radu Soricut. 2022. Towards multi-lingual visual question answering. arXiv preprint arXiv:2209.05401.

Du Chen, Yi Huang, Xiaopu Li, Yongqiang Li, Yongqiang Liu, Haihui Pan, Leichao Xu, Dacheng Zhang, Zhipeng Zhang, and Kun Han. 2024. Orion14b: Open-source multilingual large language models. arXiv preprint arXiv:2401.12246.

Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, and Jia Li. 2023a. Large language models meet harry potter: A dataset for aligning dialogue agents with characters. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 8506-8520.

Nuo Chen, Zinan Zheng, Ning Wu, Linjun Shou, Ming Gong, Yangqiu Song, Dongmei Zhang, and Jia Li 2023b. Breaking language barriers in multilingual mathematical reasoning: Insights and observations. arXiv preprint arXiv:2310.20246.

Pinzhen Chen, Shaoxiong Ji, Nikolay Bogoychev, Barry Haddow, and Kenneth Heafield. 2023c. Monolingual or multilingual instruction tuning: Which makes a better alpaca. arXiv preprint arXiv:2309.08958.

Xi Chen, Josip Djolonga, Piotr Padlewski, Basil Mustafa, Soravit Changpinyo, Jialin Wu, Carlos Riquelme Ruiz, Sebastian Goodman, Xiao Wang, Yi Tay, et al. 2023d. Pali-x: On scaling up a multilingual vision and language model. arXiv preprint arXiv:2305.18565.

Xi Chen, Xiao Wang, Lucas Beyer, Alexander Kolesnikov, Jialin Wu, Paul Voigtlaender, Basil Mustafa, Sebastian Goodman, Ibrahim Alabdulmohsin, Piotr Padlewski, et al. 2023e. Pali-3 vision language models: Smaller, faster, stronger. arXiv preprint arXiv:2310.09199.

Xi Chen, Xiao Wang, Soravit Changpinyo, AJ Piergiovanni, Piotr Padlewski, Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer, et al. 2022. Pali: A jointly-scaled multilingual language-image model. arXiv preprint arXiv:2209.06794.

Ye Chen, Wei Cai, Liangmin Wu, Xiaowei Li, Zhanxuan Xin, and Cong Fu. 2023f. Tigerbot: An open multilingual multitask 1lm. arXiv preprint arXiv:2312.08688.

Yijie Chen, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan $\mathrm{Xu}$, and Jie Zhou. 2023g. Improving translation faithfulness of large language models via augmenting instructions. arXiv preprint arXiv:2308.12674.

Zhihong Chen, Feng Jiang, Junying Chen, Tiannan Wang, Fei Yu, Guiming Chen, Hongbo Zhang, Juhao Liang, Chen Zhang, Zhiyi Zhang, et al. 2023h. Phoenix: Democratizing chatgpt across languages. arXiv preprint arXiv:2304.10453.

Zhihong Chen, Shuo Yan, Juhao Liang, Feng Jiang, Xiangbo Wu, Fei Yu, Guiming Hardy Chen, Junying Chen, Hongbo Zhang, Li Jianquan, Wan Xiang, and Benyou Wang. 2023i. MultilingualSIFT: Multilingual Supervised Instruction Fine-tuning.

Xin Cheng, Xun Wang, Tao Ge, Si-Qing Chen, Furu Wei, Dongyan Zhao, and Rui Yan. 2023a. Scale: Synergized collaboration of asymmetric language translation engines. arXiv preprint arXiv:2309.17061.

Yong Cheng, Yu Zhang, Melvin Johnson, Wolfgang Macherey, and Ankur Bapna. 2023b. Mu 2 slam: Multitask, multilingual speech and language models. In International Conference on Machine Learning, pages 5504-5520. PMLR.

Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with $90 \% *$ chatgpt quality.

De Choudhury et al. 2023. Ask me in english instead: Cross-lingual evaluation of large language models for healthcare queries. arXiv preprint arXiv:2310.13132.

Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.

Hyung Won Chung, Xavier Garcia, Adam Roberts, Yi Tay, Orhan Firat, Sharan Narang, and Noah Constant. 2022a. Unimax: Fairer and more effective language sampling for large-scale multilingual pretraining. In The Eleventh International Conference on Learning Representations.

Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022b. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.

Elizabeth Clark, Shruti Rijhwani, Sebastian Gehrmann, Joshua Maynez, Roee Aharoni, Vitaly Nikolaev, Thibault Sellam, Aditya Siddhant, Dipanjan Das, and
Ankur P Parikh. 2023. Seahorse: A multilingual, multifaceted dataset for summarization evaluation. arXiv preprint arXiv:2305.13194.

Jonathan H Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki. 2020. Tydi qa: A benchmark for information-seeking question answering in ty pologically di verse languages. Transactions of the Association for Computational Linguistics, 8:454-470.

Together Computer. 2023. Redpajama: an open dataset for training large language models.

Simone Conia, Min Li, Daniel Lee, Umar Minhas, Ihab Ilyas, and Yunyao Li. 2023. Increasing coverage and precision of textual information in multilingual knowledge graphs. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1612-1634.

Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Édouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 84408451 .

Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R Bowman, Holger Schwenk, and Veselin Stoyanov. 2018. Xnli: Evaluating crosslingual sentence representations. arXiv preprint arXiv:1809.05053.

Marta R Costa-jussà, Pierre Andrews, Eric Smith, Prangthip Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Daniel Licht, and Carleigh Wood. 2023. Multilingual holistic bias: Extending descriptors and patterns to unveil demographic biases in languages at scale. arXiv preprint arXiv:2305.13198.

Marta R Costa-jussà, James Cross, Onur Çelebi, Maha Elbayad, Kenneth Heafield, Kevin Heffernan, Elahe Kalbassi, Janice Lam, Daniel Licht, Jean Maillard, et al. 2022a. No language left behind: Scaling human-centered machine translation. arXiv preprint arXiv:2207.04672.

Marta R Costa-jussà, Eric Smith, Christophe Ropers, Daniel Licht, Jean Maillard, Javier Ferrando, and Carlos Escolano. 2022b. Toxicity in multilingual machine translation at scale. arXiv preprint arXiv:2210.03070.

Yiming Cui, Ziqing Yang, and Xin Yao. 2023. Efficient and effective text encoding for chinese llama and alpaca. arXiv preprint arXiv:2304.08177.

Raj Dabre, Chenhui Chu, and Anoop Kunchukuttan. 2020. A survey of multilingual neural machine translation. ACM Computing Surveys (CSUR), 53(5):138 .

David Dale, Elena Voita, Janice Lam, Prangthip Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Loïc Barrault, and Marta R Costa-jussà. 2023. Halomi: A manually annotated benchmark for multilingual hallucination and omission detection in machine translation. arXiv preprint arXiv:2305.11746.

Debtanu Datta, Shubham Soni, Rajdeep Mukherjee, and Saptarshi Ghosh. 2023. Mildsum: A novel benchmark dataset for multilingual summarization of indian legal case judgments. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 5291-5302.

Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detection and the problem of offensive language. In Proceedings of the international AAAI conference on web and social media, volume 11, pages 512-515.

Maarten De Raedt, Semere Kiros Bitew, Fréderic Godin, Thomas Demeester, and Chris Develder. 2023. Zeroshot cross-lingual sentiment classification under distribution shift: an exploratory study. arXiv preprint arXiv:2311.06549.

Andrea de Varda and Marco Marelli. 2023. Scaling in cognitive modelling: a multilingual approach to human reading times. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 139149, Toronto, Canada. Association for Computational Linguistics.

Shumin Deng, Ningyu Zhang, Feiyu Xiong, Jeff Z Pan, and Huajun Chen. 2022. Knowledge extraction in low-resource scenarios: survey and perspective arXiv preprint arXiv:2202.08063.

Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. Qlora: Efficient finetuning of quantized llms. arXiv preprint arXiv:2305.14314.

A Seza Doğruöz, Sunayana Sitaram, Barbara E Bullock, and Almeida Jacqueline Toribio. 2023a. A survey of code-switching: Linguistic and social perspectives for language technologies. arXiv preprint arXiv:2301.01967.

A. Seza Doğruöz, Sunayana Sitaram, and Zheng Xin Yong. 2023b. Representativeness as a forgotten lesson for multilingual and code-switched data collection and preparation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 5751-5767, Singapore. Association for Computational Linguistics.

Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for in-context learning. arXiv preprint arXiv:2301.00234.

Yi Dong, Zhilin Wang, Makesh Sreedhar, Xianchao Wu, and Oleksii Kuchaiev. 2023. Steerlm: Attribute conditioned sft as an (user-steerable) alternative to rlhf.
In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 11275-11288.

Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al. 2023. Palm-e: An embodied multimodal language model. arXiv preprint arXiv:2303.03378.

Cristina España-Bonet. 2023. Multilingual coarse political stance classification of media. the editorial line of a chatgpt and bard newspaper. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 11757-11777.

Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, and Mikel Artetxe. 2023. Do multilingual language models think better in english? arXiv preprint arXiv:2308.01223.

Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, et al. 2021. Beyond english-centric multilingual machine translation. The Journal of Machine Learning Research, 22(1):4839-4886.

Amila Ferron, Amber Shore, Ekata Mitra, and Ameeta Agrawal. 2023. Meep: Is this engaging? prompting large language models for dialogue evaluation in multilingual settings. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 2078-2100

Besnik Fetahu, Zhiyu Chen, Sudipta Kar, Oleg Rokhlenko, and Shervin Malmasi. 2023. Multiconer $\mathrm{v}$ : a large multilingual dataset for fine-grained and noisy named entity recognition. arXiv preprint arXiv:2310.13213.

Jack FitzGerald, Christopher Hench, Charith Peris, Scott Mackie, Kay Rottmann, Ana Sanchez, Aaron Nash, Liam Urbach, Vishesh Kakarala, Richa Singh, et al. 2022. Massive: A 1m-example multilingual natural language understanding dataset with 51 typologically-diverse languages. arXiv preprint arXiv:2204.08582.

Wikimedia Foundation. Wikimedia downloads.

Jinlan Fu, See-Kiong Ng, and Pengfei Liu. 2022. Polyglot prompt: Multilingual multitask promptraining. arXiv preprint arXiv:2204.14264.

Takuro Fujii, Koki Shibata, Atsuki Yamaguchi, Terufumi Morishita, and Yasuhiro Sogawa. 2023. How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in japanese. arXiv preprint arXiv:2306.09572.

Yoshinari Fujinuma, Siddharth Varia, Nishant Sankaran, Srikar Appalaraju, Bonan Min, and Yogarshi Vyas. 2023. A multi-modal multilingual benchmark for document image classification. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 14361-14376.

Yi R Fung, Tuhin Chakraborty, Hao Guo, Owen Rambow, Smaranda Muresan, and Heng Ji. 2022. Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly. arXiv preprint arXiv:2210.08604.

Pengzhi Gao, Zhongjun He, Hua Wu, and Haifeng Wang. 2024. Towards boosting many-to-many multilingual machine translation with large language models. arXiv preprint arXiv:2401.05861.

Gabriel Lino Garcia, Pedro Henrique Paiola, Luis Henrique Morelli, Giovani Candido, Arnaldo Cândido Júnior, Danilo Samuel Jodas, Luis Afonso, Ivan Rizzo Guilherme, Bruno Elias Penteado, and João Paulo Papa. 2024. Introducing bode: A finetuned large language model for portuguese promptbased task. arXiv preprint arXiv:2401.02909.

Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun, Melvin Johnson, and Orhan Firat. 2023. The unreasonable effectiveness of fewshot learning for machine translation. In International Conference on Machine Learning, pages 10867-10878. PMLR.

Gregor Geigle, Abhay Jain, Radu Timofte, and Goran Glavaš. 2023. mblip: Efficient bootstrapping of multilingual vision-llms. arXiv preprint arXiv:2307.06930.

Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, and Idan Szpektor. 2023. Trueteacher: Learning factual consistency evaluation with large language models. arXiv preprint arXiv:2305.11171.

Rahul Goel, Waleed Ammar, Aditya Gupta, Siddharth Vashishtha, Motoki Sano, Faiz Surani, Max Chang, HyunJeong Choe, David Greene, Kyle He, et al. 2023. Presto: A multilingual dataset for parsing realistic task-oriented dialogs. arXiv preprint arXiv:2303.08954.

Iakes Goenaga, Aitziber Atutxa, Koldo Gojenola, Maite Oronoz, and Rodrigo Agerri. 2023. Explanatory argument extraction of correct answers in resident medical exams. arXiv preprint arXiv:2312.00567.

O. Yu. Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2022. Roscoe: A suite of metrics for scoring step-by-step reasoning. ArXiv, abs/2212.07919.

Naman Goyal, Cynthia Gao, Vishrav Chaudhary, PengJen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc' Aurelio Ranzato, Francisco Guzmán, and Angela Fan. 2022. The flores-101 evaluation benchmark for low-resource and multilingual machine translation. Transactions of the Association for Computational Linguistics, 10:522-538.

Nuno M Guerreiro, Duarte Alves, Jonas Waldendorf, Barry Haddow, Alexandra Birch, Pierre Colombo, and André FT Martins. 2023a. Hallucinations in large multilingual translation models. arXiv preprint arXiv:2303.16104.
Nuno M Guerreiro, Ricardo Rei, Daan van Stigt, Luisa Coheur, Pierre Colombo, and André FT Martins. 2023b. xcomet: Transparent machine translation evaluation through fine-grained error detection. arXiv preprint arXiv:2310.10482.

Shester Gueuwou, Sophie Siake, Colin Leong, and Mathias Müller. 2023. Jwsign: A highly multilingual corpus of bible translations for more diversity in sign language processing. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9907-9927.

Wenyu Guo, Qingkai Fang, Dong Yu, and Yang Feng. 2023. Bridging the gap between synthetic and authentic images for multimodal machine translation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 2863-2874.

Rishav Hada, Varun Gumma, Adrian de Wynter, Harshita Diddee, Mohamed Ahmed, Monojit Choudhury, Kalika Bali, and Sunayana Sitaram. 2023. Are large language model-based evaluators the solution to scaling up multilingual evaluation? arXiv preprint arXiv:2309.07462.

Katharina Hämmerl, Björn Deiseroth, Patrick Schramowski, Jindřich Libovickỳ, Alexander Fraser, and Kristian Kersting. 2022. Do multilingual language models capture differing moral norms? arXiv preprint arXiv:2203.09904.

HyoJung Han, Jordan Boyd-Graber, and Marine Carpuat. 2023. Bridging background knowledge gaps in translation with automatic explicitation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9718-9735

Momchil Hardalov, Todor Mihaylov, Dimitrina Zlatkova, Yoan Dinkov, Ivan Koychev, and Preslav Nakov. 2020. Exams: A multi-subject high school examinations dataset for cross-lingual and multilingual question answering. arXiv preprint arXiv:2011.03080.

Conghui He, Zhenjiang Jin, Chao Xu, Jiantao Qiu, Bin Wang, Wei Li, Hang Yan, Jiaqi Wang, and Dahua Lin. 2023a. Wanjuan: A comprehensive multimodal dataset for advancing english and chinese large models. arXiv preprint arXiv:2308.10755.

Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023b. Exploring humanlike translation strategy with large language models. arXiv preprint arXiv:2305.04118.

William Held, Camille Harris, Michael Best, and Diyi Yang. 2023. A material lens on coloniality in nlp. arXiv preprint arXiv:2311.08391.

Daniel Hershcovich, Stella Frank, Heather Lent, Miryam de Lhoneux, Mostafa Abdou, Stephanie

Brandl, Emanuele Bugliarello, Laura Cabello Piqueras, Ilias Chalkidis, Ruixiang Cui, et al. 2022. Challenges and strategies in cross-cultural nlp. arXiv preprint arXiv:2203.10020.

HIT-SCIR. 2024. Chinese-mixtral-8x7b: An opensource mixture-of-experts llm. https://github. com/HIT-SCIR/Chinese-Mixtral-8x7B.

Ester Hlavnova and Sebastian Ruder. 2023. Empowering cross-lingual behavioral testing of nlp models with typological features. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 71817198 .

Hieu Hoang, Huda Khayrallah, and Marcin JunczysDowmunt. 2023. On-the-fly fusion of large language models and machine translation. arXiv preprint arXiv:2311.08306.

Oskar Holmström and Ehsan Doostmohammadi. 2023. Making instruction finetuning accessible to nonenglish languages: A case study on swedish models. In Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa), pages 634-642.

Oskar Holmström, Jenny Kunz, and Marco Kuhlmann. 2023. Bridging the resource gap: Exploring the efficacy of english and multilingual llms for swedish. In Proceedings of the Second Workshop on Resources and Representations for Under-Resourced Languages and Domains (RESOURCEFUL-2023), pages 92-110.

Jinyi Hu, Yuan Yao, Chongyi Wang, Shan Wang, Yinxu Pan, Qianyu Chen, Tianyu Yu, Hanghao Wu, Yue Zhao, Haoye Zhang, et al. 2023a. Large multilingual models pivot zero-shot multimodal learning across languages. arXiv preprint arXiv:2308.12038.

Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and Melvin Johnson. 2020. Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation. In International Conference on Machine Learning, pages 4411-4421. PMLR.

Mengkang Hu, Yao Mu, Xinmiao Yu, Mingyu Ding, Shiguang Wu, Wenqi Shao, Qiguang Chen, Bin Wang, Yu Qiao, and Ping Luo. 2023b. Tree-planner: Efficient close-loop task planning with large language models. arXiv preprint arXiv:2310.08582.

Songbo Hu, Xiaobin Wang, Zhangdie Yuan, Anna Korhonen, and Ivan Vulić. 2024. Dialight: Lightweight multilingual development and evaluation of taskoriented dialogue systems with large language models. arXiv preprint arXiv:2401.02208.

Songbo Hu, Han Zhou, Mete Hergul, Milan Gritta, Guchun Zhang, Ignacio Iacobacci, Ivan Vulić, and Anna Korhonen. 2023c. Multi 3 woz: A multilingual, multi-domain, multi-parallel dataset for training and evaluating culturally adapted task-oriented dialog systems. Transactions of the Association for Computational Linguistics, 11:1396-1415.

Wen-Yu Hua, Brian Williams, and Davood Shamsi. 2023. Lacos-bloom: Low-rank adaptation with contrastive objective on 8 bits siamese-bloom. arXiv preprint arXiv:2305.06404.

Haoyang Huang, Tianyi Tang, Dongdong Zhang, Wayne Xin Zhao, Ting Song, Yan Xia, and Furu Wei. 2023a. Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting. arXiv preprint arXiv:2305.07004.

W Ronny Huang, Cyril Allauzen, Tongzhou Chen, Kilol Gupta, Ke Hu, James Qin, Yu Zhang, Yongqiang Wang, Shuo-Yiin Chang, and Tara N Sainath. 2024. Multilingual and fully non-autoregressive asr with large language model fusion: A comprehensive study. arXiv preprint arXiv:2401.12789.

Zhichao Huang, Rong Ye, Tom Ko, Qianqian Dong, Shanbo Cheng, Mingxuan Wang, and Hang Li. 2023b. Speech translation with large language models: An industrial practice. arXiv preprint arXiv:2312.13585.

Fantine Huot, Joshua Maynez, Chris Alberti, Reinald Kim Amplayo, Priyanka Agrawal, Constanza Fierro, Shashi Narayan, and Mirella Lapata. 2023. $\quad$ plan: Summarizing using a content plan as cross-lingual bridge. arXiv preprint arXiv:2305.14205.

Ayyoob ImaniGooghari, Peiqin Lin, Amir Hossein Kargaran, Silvia Severini, Masoud Jalili Sabet, Nora Kassner, Chunlan Ma, Helmut Schmid, André FT Martins, François Yvon, et al. 2023. Glot500: Scaling multilingual corpora and language models to 500 languages. arXiv preprint arXiv:2305.12182.

Vivek Iyer, Pinzhen Chen, and Alexandra Birch. 2023 Towards effective disambiguation for machine translation with large language models. In Proceedings of the Eighth Conference on Machine Translation, pages 482-495.

Aiqi Jiang and Arkaitz Zubiaga. 2024. Cross-lingual offensive language detection: A systematic review of datasets, transfer approaches and challenges. arXiv preprint arXiv:2401.09244.

Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023. Mistral 7b. arXiv preprint arXiv:2310.06825.

Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024 Mixtral of experts. arXiv preprint arXiv:2401.04088.

Ming Jiang and Mansi Joshi. 2023. Cpopqa: Ranking cultural concept popularity by llms. arXiv preprint arXiv:2311.07897.

Wenxiang Jiao, Jen-tse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang, Shuming Shi, and Zhaopeng Tu. 2023. Parrot: Translating during chat using large language models tuned with human translation and feedback. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages $15009-15020$.

Sebastian Joseph, Kathryn Kazanas, Keziah Reina, Vishnesh J Ramanathan, Wei Xu, Byron C Wallace, and Junyi Jessy Li. 2023. Multilingual simplification of medical texts. arXiv preprint arXiv:2305.12532.

Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, and Graham Neubig. 2023. Multi-lingual and multi-cultural figurative language understanding. arXiv preprint arXiv:2305.16171.

Mihir Kale, Aditya Siddhant, Noah Constant, Melvin Johnson, Rami Al-Rfou, and Linting Xue. 2021. nmt5-is parallel data still relevant for pre-training massively multilingual language models? arXiv preprint arXiv:2106.02171.

Phillip Keung, Yichao Lu, György Szarvas, and Noah A Smith. 2020. The multilingual amazon reviews corpus. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4563-4568.

Tannon Kew, Florian Schottmann, and Rico Sennrich. 2023. Turning english-centric llms into polyglots: How much multilinguality is needed? arXiv preprint arXiv:2312.12683.

Jyotsana Khatri, Rudra Murthy, Amar Prakash Azad, and Pushpak Bhattacharyya. 2023. A study of multilingual versus meta-learning for language model pre-training for adaptation to unseen low resource languages. In Proceedings of Machine Translation Summit XIX, Vol. 1: Research Track, pages 26-34.

Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi, and Muhammad AbdulMageed. 2023. Gptaraeval: A comprehensive evaluation of chatgpt on arabic nlp. arXiv preprint arXiv:2305.14976.

Boseop Kim, HyoungSeok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak, Jeon Dong Hyeon, Sunghyun Park, Sungju Kim, Seonhoon Kim, Dongpil Seo, et al. 2021. What changes can large-scale language models bring? intensive study on hyperclova: Billions-scale korean generative pretrained transformers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3405-3424.

Sunkyoung Kim, Dayeon Ki, Yireun Kim, and Jinsik Lee. 2023a. Boosting cross-lingual transferability in multilingual models via in-context learning. arXiv preprint arXiv:2305.15233.
Yongil Kim, Yerin Hwang, Hyeongu Yun, Seunghyun Yoon, Trung Bui, and Kyomin Jung. 2023b. Pr-mcs: Perturbation robust metric for multilingual image captioning. arXiv preprint arXiv:2303.08389.

Tom Kocmi, Eleftherios Avramidis, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, et al. 2023. Findings of the 2023 conference on machine translation (wmt23): Llms are here but not quite there yet. In Proceedings of the Eighth Conference on Machine Translation, pages 1-42.

Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of machine translation summit $x$ : papers, pages 79-86.

Guneet Singh Kohli, Shantipriya Parida, Sambit Sekhar, Samirit Saha, Nipun B Nair, Parul Agarwal, Sonal Khosla, Kusumlata Patiyal, and Debasish Dhal. 2023. Building a llama2-finetuned llm for odia language utilizing domain knowledge instruction set. arXiv preprint arXiv:2312.12624.

Yeskendir Koishekenov, Vassilina Nikoulina, and Alexandre Berard. 2022. Memory-efficient nllb-200: Language-specific expert pruning of a massively multilingual machine translation model. arXiv preprint arXiv:2212.09811.

Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen Minh Duc, Oliver Stanley, Richárd Nagyfi, et al. 2023. Openassistant conversations-democratizing large language model alignment. arXiv preprint arXiv:2304.07327.

Sneha Kudugunta, Isaac Rayburn Caswell, Biao Zhang, Xavier Garcia, Derrick Xin, Aditya Kusupati, Romi Stella, Ankur Bapna, and Orhan Firat. 2023. Madlad400: A multilingual and document-level large audited dataset. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track.

Anoop Kunchukuttan, Pratik Mehta, and Pushpak Bhattacharyya. 2018. The IIT Bombay English-Hindi parallel corpus. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).

Olli Kuparinen, Aleksandra Miletić, and Yves Scherrer. 2023. Dialect-to-standard normalization: A largescale multilingual evaluation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 13814-13828.

Sang Kwon, Gagan Bhatia, Muhammad Abdul-Mageed, et al. 2023a. Beyond english: Evaluating llms for arabic grammatical error correction. In Proceedings of ArabicNLP 2023, pages 101-119.

Sang Yun Kwon, Gagan Bhatia, El Moatez Billah Nagoud, and Muhammad Abdul-Mageed. 2023b.

Chatgpt for arabic grammatical error correction. arXiv preprint arXiv:2308.04492.

Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, and Thien Huu Nguyen. 2023a. Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning. arXiv preprint arXiv:2304.05613.

Viet Dac Lai, Chien Van Nguyen, Nghia Trung Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan A Rossi, and Thien Huu Nguyen. 2023b. Okapi: Instructiontuned large language models in multiple languages with reinforcement learning from human feedback. arXiv preprint arXiv:2307.16039.

Celio Larcher, Marcos Piau, Paulo Finardi, Pedro Gengo, Piero Esposito, and Vinicius Caridá. 2023. Cabrita: closing the gap for foreign languages. arXiv preprint arXiv:2308.11878.

Hugo Laurençon, Lucile Saulnier, Thomas Wang, Christopher Akiki, Albert Villanova del Moral, Teven Le Scao, Leandro Von Werra, Chenghao Mou, Eduardo González Ponferrada, Huu Nguyen, et al. 2022. The bigscience roots corpus: A 1.6 tb composite multilingual dataset. Advances in Neural Information Processing Systems, 35:31809-31826.

Khoi M Le, Trinh Pham, Tho Quan, and Anh Tuan Luu. 2024. Lampat: Low-rank adaption for multilingual paraphrasing using adversarial training. arXiv preprint arXiv:2401.04348.

Minwoo Lee, Hyukhun Koh, Kang-il Lee, Dongdong Zhang, Minsung Kim, and Kyomin Jung. 2023 Target-agnostic gender-aware contrastive learning for mitigating bias in multilingual machine translation. arXiv preprint arXiv:2305.14016.

Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. 2020 Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:2006.16668.

Patrick Lewis, Barlas Oğuz, Ruty Rinott, Sebastian Riedel, and Holger Schwenk. 2019. Mlqa: Evaluating cross-lingual extractive question answering. arXiv preprint arXiv:1910.07475.

Bryan Li and Chris Callison-Burch. 2023. This land is \{Your, My\} land: Evaluating geopolitical biases in language models. arXiv preprint arXiv:2305.14610.

Chong Li, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2023a. Align after pre-train: Improving multilingual generative models with cross-lingual alignment. arXiv preprint arXiv:2311.08089.

Haonan Li, Fajri Koto, Minghao Wu, Alham Fikri Aji, and Timothy Baldwin. 2023b. Bactrian-x: A multilingual replicable instruction-following model with lowrank adaptation. arXiv preprint arXiv:2305.15011.
Haoran Li, Abhinav Arora, Shuohui Chen, Anchit Gupta, Sonal Gupta, and Yashar Mehdad. 2020. Mtop: A comprehensive multilingual task-oriented semantic parsing benchmark. arXiv preprint arXiv:2008.09335.

Jiahuan Li, Hao Zhou, Shujian Huang, Shanbo Chen, and Jiajun Chen. 2023c. Eliciting the translation ability of large language models via multilingual finetuning with translation instructions. arXiv preprint arXiv:2305.15083.

Oliver Li, Mallika Subramanian, Arkadiy Saakyan, CHWang Sky, and Smaranda Muresan. 2023d. Normdial: A comparable bilingual synthetic dialog dataset for modeling social norm adherence and violation. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages $15732-15744$.

Shangjie Li, Xiangpeng Wei, Shaolin Zhu, Jun Xie, Baosong Yang, and Deyi Xiong. 2023e. Mmnmt: Modularizing multilingual neural machine translation with flexibly assembled moe and dense blocks. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 4978-4990.

Xiaoqian Li, Ercong Nie, and Sheng Liang. 2023f. Crosslingual retrieval augmented in-context learning for bangla. In Proceedings of the First Workshop on Bangla Language Processing (BLP-2023), pages $136-151$.

Xiaoqian Li, Ercong Nie, and Sheng Liang. 2023g. From classification to generation: Insights into crosslingual retrieval augmented icl. arXiv preprint arXiv:2311.06595.

Yangning Li, Shirong Ma, Xiaobin Wang, Shen Huang, Chengyue Jiang, Hai-Tao Zheng, Pengjun Xie, Fei Huang, and Yong Jiang. 2023h. Ecomgpt: Instruction-tuning large language model with chainof-task tasks for e-commerce. arXiv preprint arXiv:2308.06966.

Yaoyiran Li, Anna Korhonen, and Ivan Vulić. 2023i On bilingual lexicon induction with large language models. arXiv preprint arXiv:2310.13995.

Xiao Liang, Yen-Min Jasmina Khaw, Soung-Yue Liew, Tien-Ping Tan, and DongHong Qin. 2023. Multilingual sentence alignment with gpt models. In 2023 4th International Conference on Artificial Intelligence and Data Sciences (AiDAS), pages 218-223. $\mathrm{IEEE}$.

Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Gong, Linjun Shou, Daxin Jiang, Guihong Cao, et al. 2020. Xglue: A new benchmark dataset for cross-lingual pretraining, understanding and generation. arXiv preprint arXiv:2004.01401.

Bill Yuchen Lin, Seyeon Lee, Xiaoyang Qiao, and Xiang Ren. 2021a. Common sense beyond English: Evaluating and improving multilingual language models for commonsense reasoning. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1274-1287, Online. Association for Computational Linguistics.

Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.

Peiqin Lin, Chengzhi Hu, Zheyu Zhang, André FT Martins, and Hinrich Schütze. 2023. mplm-sim: Unveiling better cross-lingual similarity and transfer in multilingual pretrained language models. arXiv preprint arXiv:2305.13684.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, and Xian Li. 2022a. Few-shot learning with multilingual generative language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9019-9052, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, et al. 2021b Few-shot learning with multilingual language models. arXiv preprint arXiv:2112.10668.

Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, et al. 2022b. Few-shot learning with multilingual generative language models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9019-9052.

Chen Cecilia Liu, Fajri Koto, Timothy Baldwin, and Iryna Gurevych. 2023a. Are multilingual llms culturally-diverse reasoners? an investigation into multicultural proverbs and sayings. arXiv preprint arXiv:2309.08591.

Peng Liu, Lemei Zhang, Terje Nissen Farup, Even W Lauvrak, Jon Espen Ingvaldsen, Simen Eide, Jon Atle Gulla, and Zhirong Yang. 2023b. Nlebench+ norglm: A comprehensive empirical analysis and benchmark dataset for generative language models in norwegian. arXiv preprint arXiv:2312.01314.

Xuebo Liu, Yutong Wang, Derek F Wong, Runzhe Zhan, Liangxuan Yu, and Min Zhang. 2023c. Revisiting commonsense reasoning in machine translation: Training, evaluation and challenge. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 15536-15550.

Lianzhang Lou, Xi Yin, Yutao Xie, and Yang Xiang. 2023. Cceval: A representative evaluation benchmark for the chinese-centric multilingual machine translation. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1017610184 .

Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei. 2023. Chainof-dictionary prompting elicits translation in large language models. arXiv preprint arXiv:2305.06575.

Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023a. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. arXiv preprint arXiv:2308.09583.

Yin Luo, Qingchao Kong, Nan Xu, Jia Cao, Bao Hao, Baoyu Qu, Bo Chen, Chao Zhu, Chenyang Zhao, Donglei Zhang, et al. 2023b. Yayi 2: Multilingual open-source large language models. arXiv preprint arXiv:2312.14862.

Risto Luukkonen, Ville Komulainen, Jouni Luoma, Anni Eskelinen, Jenna Kanerva, Hanna-Mari Kupari, Filip Ginter, Veronika Laippala, Niklas Muennighoff, Aleksandra Piktus, et al. 2023. Fingpt: Large generative models for a small language. arXiv preprint arXiv:2311.05640.

Chenyang Lyu, Jitao Xu, and Longyue Wang. 2023. New trends in machine translation using large language models: Case examples with chatgpt. arXiv preprint arXiv:2305.01181.

Chunlan Ma, Ayyoob ImaniGooghari, Haotian Ye, Ehsaneddin Asgari, and Hinrich Schütze. 2023. Taxi1500: A multilingual dataset for text classification in 1500 languages. arXiv preprint arXiv:2305.08487.

Dominik Macko, Robert Moro, Adaku Uchendu, Jason Lucas, Michiharu Yamashita, Matúš Pikuliak, Ivan Srba, Thai Le, Dongwon Lee, Jakub Simko, et al. 2023. Multitude: Large-scale multilingual machinegenerated text detection benchmark. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9960-9987.

Dominik Macko, Robert Moro, Adaku Uchendu, Ivan Srba, Jason Samuel Lucas, Michiharu Yamashita, Nafis Irtiza Tripto, Dongwon Lee, Jakub Simko, and Maria Bielikova. 2024. Authorship obfuscation in multilingual machine-generated text detection. $\operatorname{arXiv}$ preprint arXiv:2401.07867.

Ankita Maity, Anubhav Sharma, Rudra Dhar, Tushar Abhishek, Manish Gupta, and Vasudeva Varma. 2023. Multilingual bias detection and mitigation for indian languages. arXiv preprint arXiv:2312.15181.

Dan Malkin, Tomasz Limisiewicz, and Gabriel Stanovsky. 2022. A balanced data approach for evaluating cross-lingual transfer: Mapping the linguistic blood bank. arXiv preprint arXiv:2205.04086.

Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta Kar, and Oleg Rokhlenko. 2022. Multiconer: a largescale multilingual dataset for complex named entity recognition. arXiv preprint arXiv:2208.14536.

Thomas Mayer and Michael Cysouw. 2014. Creating a massively parallel Bible corpus. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC'14), pages 31583163, Reykjavik, Iceland. European Language Resources Association (ELRA).

John Mendonça, Alon Lavie, and Isabel Trancoso. 2023a. Towards multilingual automatic open-domain dialogue evaluation. In Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue, pages 130-141.

John Mendonça, Patrícia Pereira, Helena Moniz, Joao Paulo Carvalho, Alon Lavie, and Isabel M Trancoso. 2023b. Simple llm prompting is state-of-the-art for robust and multilingual dialogue evaluation. In Proceedings of The Eleventh Dialog System Technology Challenge, pages 133-143.

James Michaelov, Catherine Arnett, Tyler Chang, and Ben Bergen. 2023. Structural priming demonstrates abstract grammatical representations in multilingual language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3703-3720.

Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the role of demonstrations: What makes in-context learning work? arXiv preprint arXiv:2202.12837.

Shubham Mittal, Megha Sundriyal, and Preslav Nakov 2023. Lost in translation, found in spans: Identifying claims in multilingual social media. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3887-3902, Singapore. Association for Computational Linguistics.

Mehrad Moradshahi, Tianhao Shen, Kalika Bali, Monojit Choudhury, Gael de Chalendar, Anmol Goel, Sungkyun Kim, Prashant Kodali, Ponnurangam Kumaraguru, Nasredine Semmar, Sina Semnani, Jiwon Seo, Vivek Seshadri, Manish Shrivastava, Michael Sun, Aditya Yadavalli, Chaobin You, Deyi Xiong, and Monica Lam. 2023. X-RiSAWOZ: High-quality end-to-end multilingual dialogue datasets and fewshot agents. In Findings of the Association for Computational Linguistics: ACL 2023, pages 2773-2794, Toronto, Canada. Association for Computational Linguistics.

Yasmin Moslem, Rejwanul Haque, and Andy Way. 2023a. Adaptive machine translation with large language models. arXiv preprint arXiv:2301.13294.
Yasmin Moslem, Rejwanul Haque, and Andy Way. 2023b. Fine-tuning large language models for adaptive machine translation. arXiv preprint arXiv:2312.12740.

Miguel Moura Ramos, Patrick Fernandes, António Farinhas, and André FT Martins. 2023. Aligning neural machine translation models: Human feedback in training and inference. arXiv e-prints, pages arXiv2311.

Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey Schoelkopf, et al. 2022. Crosslingual generalization through multitask finetuning. arXiv preprint arXiv:2211.01786.

Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, Nedjma Ousidhoum, David Ifeoluwa Adelani, Seid Muhie Yimam, Ibrahim Sa'id Ahmad, Meriem Beloucif, Saif Mohammad, Sebastian Ruder, et al. 2023. Afrisenti: A twitter sentiment analysis benchmark for african languages. arXiv preprint arXiv:2302.08956.

Vandan Mujadia, Ashok Urlana, Yash Bhaskar, Penumalla Aditya Pavani, Kukkapalli Shravya, Parameswari Krishnamurthy, and Dipti Misra Sharma. 2023. Assessing translation capabilities of large language models involving english and indian languages. arXiv preprint arXiv:2311.09216.

Benjamin Muller, John Wieting, Jonathan H Clark, Tom Kwiatkowski, Sebastian Ruder, Livio Baldini Soares, Roee Aharoni, Jonathan Herzig, and Xinyi Wang. 2023. Evaluating and modeling attribution for cross-lingual question answering. arXiv preprint arXiv:2305.14332.

Masayasu Muraoka, Bishwaranjan Bhattacharjee, Michele Merler, Graeme Blackwood, Yulong Li, and Yang Zhao. 2023. Cross-lingual transfer of large language model by visually-derived supervision toward low-resource languages. In Proceedings of the 31st ACM International Conference on Multimedia, pages 3637-3646

Akshay Nambi, Vaibhav Balloli, Mercy Ranjit, Tanuja Ganu, Kabir Ahuja, Sunayana Sitaram, and Kalika Bali. 2023. Breaking language barriers with a leap: Learning strategies for polyglot llms. arXiv preprint arXiv:2305.17740.

Tarek Naous, Michael J Ryan, Mohit Chandra, and Wei Xu. 2023a. Towards massively multi-domain multilingual readability assessment. arXiv preprint arXiv:2305.14463.

Tarek Naous, Michael J Ryan, and Wei Xu. 2023b. Having beer after prayer? measuring cultural bias in large language models. arXiv preprint arXiv:2305.14456.

Shashi Narayan, Shay B Cohen, and Mirella Lapata. 2018. Don't give me the details, just the
summary! topic-aware convolutional neural networks for extreme summarization. arXiv preprint arXiv:1808.08745.

Hoang Nguyen, Ye Liu, Chenwei Zhang, Tao Zhang, and Philip Yu. 2023a. CoF-CoT: Enhancing large language models with coarse-to-fine chain-of-thought prompting for multi-domain NLU tasks. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 12109-12119, Singapore. Association for Computational Linguistics.

Laura Nguyen, Thomas Scialom, Benjamin Piwowarski, and Jacopo Staiano. 2023b. Loralay: A multilingual and multimodal dataset for long range and layout-aware summarization. arXiv preprint arXiv:2301.11312.

Thuat Nguyen, Chien Van Nguyen, Viet Dac Lai, Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Ryan A Rossi, and Thien Huu Nguyen. 2023c. Culturax: A cleaned, enormous, and multilingual dataset for large language models in 167 languages. arXiv preprint arXiv:2309.09400.

Massimo Nicosia and Francesco Piccinno. 2022. Evaluating byte and wordpiece level models for massively multilingual semantic parsing. arXiv preprint arXiv:2212.07223.

Kelechi Ogueji, Yuxin Zhu, and Jimmy Lin. 2021. Small data? no problem! exploring the viability of pretrained multilingual language models for lowresourced languages. In Proceedings of the 1st Workshop on Multilingual Representation Learning, pages $116-126$.

Xenia Ohmer, Elia Bruni, and Dieuwke Hupkes. 2023. Evaluating task understanding through multilingual consistency: A chatgpt case study. arXiv preprint arXiv:2305.11662.

OpenAI. 2022. Chatgpt.

OpenAI. 2023. Gpt-4 technical report.

Wenbo Pan, Qiguang Chen, Xiao Xu, Wanxiang Che, and Libo Qin. 2023. A preliminary evaluation of chatgpt for zero-shot dialogue understanding. arXiv preprint arXiv:2304.04256.

Xiaoman Pan, Thamme Gowda, Heng Ji, Jonathan May, and Scott Miller. 2019. Cross-lingual joint entity and word embedding to improve entity linking and parallel sentence mining. In Proceedings of the 2nd Workshop on Deep Learning Approaches for LowResource NLP (DeepLo 2019), pages 56-66, Hong Kong, China. Association for Computational Linguistics.

Rrubaa Panchendrarajan and Arkaitz Zubiaga. 2024. Claim detection for automated fact-checking: A survey on monolingual, multilingual and cross-lingual research. arXiv preprint arXiv:2401.11969.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311-318.

Nohil Park, Joonsuk Park, Kang Min Yoo, and Sungroh Yoon. 2023. On the analysis of cross-lingual prompt tuning for decoder-based multilingual model. arXiv preprint arXiv:2311.07820.

Ajay Patel, Bryan Li, Mohammad Sadegh Rasooli, Noah Constant, Colin Raffel, and Chris CallisonBurch. 2022. Bidirectional language models are also few-shot learners. In The Eleventh International Conference on Learning Representations.

Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. arXiv preprint arXiv:2304.03277.

Frithjof Petrick, Christian Herold, Pavel Petrushkov, Shahram Khadivi, and Hermann Ney. 2023. Document-level language models for machine translation. arXiv preprint arXiv:2310.12303.

Aleksandar Petrov, Emanuele La Malfa, Philip HS Torr, and Adel Bibi. 2023. Language model tokenizers introduce unfairness between languages. arXiv preprint arXiv:2305.15425.

Jonas Pfeiffer, Francesco Piccinno, Massimo Nicosia, Xinyi Wang, Machel Reid, and Sebastian Ruder. 2023. mmt5: Modular multilingual pre-training solves source language hallucinations. arXiv preprint arXiv:2305.14224.

Fred Philippy, Siwen Guo, and Shohreh Haddadan. 2023. Towards a common understanding of contributing factors for cross-lingual transfer in multilingual language models: A review. arXiv preprint arXiv:2305.16768.

Jonathan Pilault, Xavier Garcia, Arthur Bražinskas, and Orhan Firat. 2023. Interactive-chainprompting: Ambiguity resolution for crosslingual conditional generation with interaction. arXiv preprint arXiv:2301.10309.

Ramon Pires, Hugo Abonizio, Thales Rogério, and Rodrigo Nogueira. 2023. Sabi \'a: Portuguese large language models. arXiv preprint arXiv:2304.07880.

Edoardo Maria Ponti, Goran Glavaš, Olga Majewska, Qianchu Liu, Ivan Vulić, and Anna Korhonen. 2020. Xcopa: A multilingual dataset for causal commonsense reasoning. arXiv preprint arXiv:2005.00333.

Maja Popović. 2017. chrF++: words helping character n-grams. In Proceedings of the Second Conference on Machine Translation, pages 612-618, Copenhagen, Denmark. Association for Computational Linguistics.

Nooshin Pourkamali and Shler Ebrahim Sharifi. 2024. Machine translation with large language models: Prompt engineering for persian, english, and russian directions. arXiv preprint arXiv:2401.08429.

Ratish Puduppully, Raj Dabre, Ai Ti Aw, and Nancy F Chen. 2023a. Decomposed prompting for machine translation between related languages using large language models. arXiv preprint arXiv:2305.13085.

Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre, Aiti Aw, and Nancy Chen. 2023b. Decomt: Decomposed prompting for machine translation between related languages using large language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 45864602 .

Poorna Chander Reddy Puttaparthi, Soham Sanjay Deo, Hakan Gul, Yiming Tang, Weiyi Shang, and Zhe Yu. 2023. Comprehensive evaluation of chatgpt reliability through multilingual inquiries. arXiv preprint arXiv:2312.10524.

Jirui Qi, Raquel Fernández, and Arianna Bisazza. 2023. Cross-lingual consistency of factual knowledge in multilingual language models. arXiv preprint arXiv:2310.10378.

Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, and Wanxiang Che. 2023a. Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages. arXiv preprint arXiv:2310.14799.

Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, and Wanxiang Che. 2023b. Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages.

Libo Qin, Qiguang Chen, Tianbao Xie, Qixin Li, JianGuang Lou, Wanxiang Che, and Min-Yen Kan. 2022. Gl-clef: A global-local contrastive learning framework for cross-lingual spoken language understanding. arXiv preprint arXiv:2204.08325.

Libo Qin, Minheng Ni, Yue Zhang, and Wanxiang Che. 2020. Cosda-ml: Multi-lingual code-switching data augmentation for zero-shot cross-lingual nlp. arXiv preprint arXiv:2006.06402.

Yifu Qiu, Yftah Ziser, Anna Korhonen, Edoardo M Ponti, and Shay B Cohen. 2023. Detecting and mitigating hallucinations in multilingual summarisation. arXiv preprint arXiv:2305.13632.

Diana Rakhimova, Aidana Karibayeva, and Assem Turarbek. 2024. The task of post-editing machine translation for the low-resource language. Applied Sciences, 14(2):486.

Krithika Ramesh, Sunayana Sitaram, and Monojit Choudhury. 2023. Fairness in language models beyond english: Gaps and challenges. arXiv preprint arXiv:2302.12578.
Rita Ramos, Bruno Martins, and Desmond Elliott. 2023. Lmcap: Few-shot multilingual image captioning by retrieval augmented language model prompting. arXiv preprint arXiv:2305.19821.

Leonardo Ranaldi, Giulia Pucci, and Andre Freitas. 2023a. Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations. arXiv preprint arXiv:2308.14186.

Leonardo Ranaldi, Giulia Pucci, and Andre Freitas. 2023b. Empowering cross-lingual abilities of instruction-tuned large language models by translation-following demonstrations. arXiv preprint arXiv:2308.14186.

Vikas Raunak, Arul Menezes, and Marcin JunczysDowmunt. 2021. The curious case of hallucinations in neural machine translation. arXiv preprint arXiv:2104.06683.

Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, and Arul Menezes. 2023. Leveraging gpt-4 for automatic translation post-editing. arXiv preprint arXiv:2305.14878.

Evgeniia Razumovskaia, Joshua Maynez, Annie Louis, Mirella Lapata, and Shashi Narayan. 2022. Little red riding hood goes around the globe: Crosslingual story planning and generation with large language models. arXiv preprint arXiv:2212.10471.

Ricardo Rei, Craig Stewart, Ana C Farinha, and Alon Lavie. 2020. Comet: A neural framework for mt evaluation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2685-2702.

Raphael Reinauer, Patrick Simianer, Kaden Uhlig, Johannes EM Mosig, and Joern Wuebker. 2023. Neural machine translation models can learn to be few-shot learners. arXiv preprint arXiv:2309.08590.

Juan Diego Rodriguez, Katrin Erk, and Greg Durrett. 2023. X-parade: Cross-lingual textual entailment and information divergence across paragraphs. arXiv preprint arXiv:2309.08873.

Andy Rosenbaum, Saleh Soltan, Wael Hamza, Amir Saffari, Marco Damonte, and Isabel Groves. 2022a. Clasp: Few-shot cross-lingual data augmentation for semantic parsing. AACL-IJCNLP 2022, page 444.

Andy Rosenbaum, Saleh Soltan, Wael Hamza, Yannick Versley, and Markus Boese. 2022b. Linguist: Language model instruction tuning to generate annotated utterances for intent classification and slot tagging. arXiv preprint arXiv:2209.09900.

Sebastian Ruder, Noah Constant, Jan Botha, Aditya Siddhant, Orhan Firat, Jinlan Fu, Pengfei Liu, Junjie Hu, Dan Garrette, Graham Neubig, et al. 2021. Xtreme-r: Towards more challenging and nuanced multilingual evaluation. arXiv preprint arXiv:2104.07412.

Phillip Rust, Jonas F Lotz, Emanuele Bugliarello, Elizabeth Salesky, Miryam de Lhoneux, and Desmond Elliott. 2022. Language modelling with pixels. arXiv preprint arXiv:2207.06991.

Michael J Ryan, Tarek Naous, and Wei Xu. 2023. Revisiting non-english text simplification: A unified multilingual benchmark. arXiv preprint arXiv:2305.15678.

Eduardo Sánchez, Pierre Andrews, Pontus Stenetorp, Mikel Artetxe, and Marta R Costa-jussà. 2023. Gender-specific machine translation with large language models. arXiv preprint arXiv:2309.03175.

Andrea Santilli and Emanuele Rodolà. 2023. Camoscio: An italian instruction-tuned llama. arXiv preprint arXiv:2307.16456.

Andrea Schioppa, Xavier Garcia, and Orhan Firat. 2023. Cross-lingual supervision improves large language models pre-training. arXiv preprint arXiv:2305.11778.

Tim Schott, Daniel Furman, and Shreshta Bhat. 2023. Polyglot or not? measuring multilingual encyclopedic knowledge in foundation models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 11238-11253.

Sebastian Schuster, Sonal Gupta, Rushin Shah, and Mike Lewis. 2018. Cross-lingual transfer learning for multilingual task oriented dialog. arXiv preprint arXiv:1810.13327.

Holger Schwenk, Vishrav Chaudhary, Shuo Sun, Hongyu Gong, and Francisco Guzmán. 2021. WikiMatrix: Mining 135M parallel sentences in 1620 language pairs from Wikipedia. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 1351-1361, Online. Association for Computational Linguistics.

Alessandro Seganti, Klaudia Firlag, Helena Skowronska, Michał Satława, and Piotr Andruszkiewicz. 2021. Multilingual entity and relation extraction dataset and model. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 1946-1955, Online. Association for Computational Linguistics.

Thibault Sellam, Dipanjan Das, and Ankur P Parikh. 2020. Bleurt: Learning robust metrics for text generation. arXiv preprint arXiv:2004.04696.

Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, Onkar Pandit, Rahul Pal, et al. 2023. Jais and jais-chat: Arabic-centric foundation and instruction-tuned open generative large language models. arXiv preprint arXiv:2308.16149.
Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, and Matan Eyal. 2024. Multilingual instruction tuning with just a pinch of multilinguality. arXiv preprint arXiv:2401.01854.

ShareGPT. 2023. Sharegpt.

Shuaijie She, Shujian Huang, Wei Zou, Wenhao Zhu, Xiang Liu, Xiang Geng, and Jiajun Chen. 2024. Mapo: Advancing multilingual reasoning through multilingual alignment-as-preference optimization. arXiv preprint arXiv:2401.06838.

Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, and Daniel Khashabi. 2024. The language barrier: Dissecting safety challenges of llms in multilingual contexts. arXiv preprint arXiv:2401.13136.

Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, et al. 2022a. Language models are multilingual chain-of-thought reasoners. arXiv preprint arXiv:2210.03057.

Peng Shi, Rui Zhang, He Bai, and Jimmy Lin. 2022b Xricl: Cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing. arXiv preprint arXiv:2210.13693.

Oleh Shliazhko, Alena Fenogenova, Maria Tikhonova, Vladislav Mikhailov, Anastasia Kozlova, and Tatiana Shavrina. 2022. mgpt: Few-shot learners go multilingual. arXiv preprint arXiv:2204.07580.

Suzanna Sia, Alexandra DeLucia, and Kevin Duh. 2023. Anti-Im decoding for zero-shot in-context machine translation. arXiv preprint arXiv:2311.08324.

Saleh Soltan, Shankar Ananthakrishnan, Jack FitzGerald, Rahul Gupta, Wael Hamza, Haidar Khan, Charith Peris, Stephen Rawls, Andy Rosenbaum, Anna Rumshisky, et al. 2022. Alexatm 20b: Few-shot learning using a large-scale multilingual seq $2 \mathrm{seq}$ model. arXiv preprint arXiv:2208.01448.

Guijin Son, Hanwool Lee, Suwan Kim, Jaecheol Lee, Je Won Yeom, Jihyu Jung, Jung Woo Kim, and Songseong Kim. 2023. Hae-rae bench: Evaluation of korean knowledge in language models. arXiv preprint arXiv:2309.02706.

Yixiao Song, Kalpesh Krishna, Rajesh Bhatt, and Mohit Iyyer. 2022. Sling: Sino linguistic evaluation of large language models. arXiv preprint arXiv:2210.11689.

Anirudh Srinivasan and Eunsol Choi. 2022. Tydip: A dataset for politeness classification in nine typologically diverse languages. In Findings of the Association for Computational Linguistics: EMNLP 2022, pages 5723-5738.

Nicolas Stefanovitch and Jakub Piskorski. 2023. Holistic inter-annotator agreement and corpus coherence estimation in a large-scale multilingual annotation campaign. In Proceedings of the 2023 Conference on

Empirical Methods in Natural Language Processing, pages 71-86.

Hui Su, Xiao Zhou, Houjin Yu, Xiaoyu Shen, Yuwen Chen, Zilin Zhu, Yang Yu, and Jie Zhou. 2022. Welm: A well-read pre-trained language model for chinese. arXiv preprint arXiv:2209.10372.

Pedro Javier Ortiz Suárez, Benoît Sagot, and Laurent Romary. 2019. Asynchronous pipeline for processing huge corpora on medium to low resource infrastructures. In 7th Workshop on the Challenges in the Management of Large Corpora (CMLC-7). LeibnizInstitut für Deutsche Sprache.

Jimin Sun, Patrick Fernandes, Xinyi Wang, and Graham Neubig. 2023a. A multi-dimensional evaluation of tokenizer-free multilingual pretrained models. In Findings of the Association for Computational Linguistics: EACL 2023, pages 1680-1690.

Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, and Xipeng Qiu. 2023b. Moss: Training conversational language models from synthetic data.

Yu Sun, Shuohuan Wang, Shikun Feng, Siyu Ding, Chao Pang, Junyuan Shang, Jiaxiang Liu, Xuyi Chen, Yanbin Zhao, Yuxiang Lu, et al. 2021. Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation. arXiv preprint arXiv:2107.02137.

Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David Cox, Yiming Yang, and Chuang Gan. 2023c. Salmon: Self-alignment with principle-following reward models. arXiv preprint arXiv:2310.05910.

Eshaan Tanwar, Manish Borthakur, Subhabrata Dutta, and Tanmoy Chakraborty. 2023. Multilingual llms are better cross-lingual in-context learners with alignment. arXiv preprint arXiv:2305.05940.

COIG PC Team. 2023a. Coig pc.

Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805

Huozi Team. 2023b. Huozi: An open-source universal llm. https://github.com/HIT-SCIR/ huozi.

InternLM Team. 2023c. Internlm: A multilingual language model with progressively enhanced capabilities.
YuLan Team. 2023d. Yulan-chat: An open-source bilingual chatbot. https://github.com/ RUC-GSAI/YuLan-Chat.

Nandan Thakur, Luiz Bonifacio, Xinyu Zhang, Odunayo Ogundepo, Ehsan Kamalloo, David Alfonso-Hermelo, Xiaoguang Li, Qun Liu, Boxing Chen, Mehdi Rezagholizadeh, et al. 2023a. Nomiracl: Knowing when you don't know for robust multilingual retrieval-augmented generation. arXiv preprint arXiv:2312.11361.

Nandan Thakur, Jianmo Ni, Gustavo Hernández Ábrego, John Wieting, Jimmy Lin, and Daniel Cer. 2023b. Leveraging llms for synthesizing training data across many languages in multilingual dense retrieval. arXiv preprint arXiv:2311.05800.

Ashish V Thapliyal, Jordi Pont-Tuset, Xi Chen, and Radu Soricut. 2022. Crossmodal-3600: A massively multilingual multimodal evaluation dataset. arXiv preprint arXiv:2205.12522.

David Thulke, Yingbo Gao, Petrus Pelser, Rein Brune, Rricha Jalota, Floris Fok, Michael Ramos, Ian van Wyk, Abdallah Nasir, Hayden Goldstein, et al. 2024. Climategpt: Towards ai synthesizing interdisciplinary research on climate change. arXiv preprint arXiv:2401.09646.

Jörg Tiedemann. 2012. Parallel data, tools and interfaces in OPUS. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12), pages 2214-2218, Istanbul, Turkey. European Language Resources Association (ELRA).

Alexey Tikhonov and Max Ryabinin. 2021. It's all in the heads: Using attention heads as a baseline for crosslingual transfer in commonsense reasoning. arXiv preprint arXiv:2106.12066.

Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.

Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2023. Interleaving retrieval with chain-of-thought reasoning for knowledgeintensive multi-step questions. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10014-10037, Toronto, Canada. Association for Computational Linguistics.

Kuang Tseng and Chow-Sing Lin. 2022. Enhancing natural language inference of cross-lingual n-shot transfer with multilingual data. In 2022 8th International Conference on Applied System Innovation (ICASI), pages 68-71. IEEE.

Lifu Tu, Jin Qu, Semih Yavuz, Shafiq Joty, Wenhao Liu, Caiming Xiong, and Yingbo Zhou. 2023. Efficiently aligned cross-lingual transfer learning for conversational tasks using prompt-tuning. arXiv preprint arXiv:2304.01295.

Yuxiang Tuo, Wangmeng Xiang, Jun-Yan He, Yifeng Geng, and Xuansong Xie. 2023. Anytext: Multilingual visual text generation and editing. arXiv preprint arXiv:2311.03054.

Gökçe Uludoğan, Zeynep Yirmibeşoğlu Balal, Furkan Akkurt, Melikşah Türker, Onur Güngör, and Susan Üsküdarl. 2024. Turna: A turkish encoder-decoder language model for enhanced understanding and generation. arXiv preprint arXiv:2401.14373.

Bibek Upadhayay and Vahid Behzadan. 2023. Taco: Enhancing cross-lingual transfer for low-resource languages in llms through translation-assisted chain-ofthought processes. arXiv preprint arXiv:2311.10797.

Ashok Urlana, Pinzhen Chen, Zheng Zhao, Shay B Cohen, Manish Shrivastava, and Barry Haddow. 2023. Pmindiasum: Multilingual and cross-lingual headline summarization for languages in india. arXiv preprint arXiv:2305.08828.

David Uthus, Santiago Ontañón, Joshua Ainslie, and Mandy Guo. 2023. mlongt5: A multilingual and efficient text-to-text transformer for longer sequences.

Yash Verma, Anubhav Jangra, Raghvendra Kumar, and Sriparna Saha. 2023. Large scale multi-lingual multi-modal summarization dataset. arXiv preprint arXiv:2302.06560.

Giorgos Vernikos and Andrei Popescu-Belis. 2024. Don't rank, combine! combining machine translation hypotheses using quality estimation. arXiv preprint arXiv:2401.06688.

David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and George Foster. 2022. Prompting palm for translation: Assessing strategies and performance. arXiv preprint arXiv:2211.09102.

Tu Vu, Aditya Barua, Brian Lester, Daniel Cer, Mohit Iyyer, and Noah Constant. 2022. Overcoming catastrophic forgetting in zero-shot cross-lingual generation. arXiv preprint arXiv:2205.12647.

Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, Ai Ti Aw, and Nancy F Chen. 2023a. Seaeval for multilingual foundation models: From cross-lingual alignment to cultural reasoning. arXiv preprint arXiv:2309.04766.
Jiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li, Jianfeng Qu, and Jie Zhou. 2023b. Crosslingual summarization via chatgpt. arXiv preprint arXiv:2302.14229.

Jiaan Wang, Yunlong Liang, Zengkui Sun, Yuxuan Cao, and Jiarong Xu. 2023c. Cross-lingual knowledge editing in large language models. arXiv preprint arXiv:2309.08952.

Jiaan Wang, Fandong Meng, Ziyao Lu, Duo Zheng, Zhixu Li, Jianfeng Qu, and Jie Zhou. 2022a. Clidsum: A benchmark dataset for cross-lingual dialogue summarization. arXiv preprint arXiv:2202.05599.

Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, and Zhaopeng Tu. 2023d. Document-level machine translation with large language models. arXiv preprint arXiv:2304.02210.

Weixuan Wang, Barry Haddow, and Alexandra Birch. 2023e. Retrieval-augmented multilingual knowledge editing. arXiv preprint arXiv:2312.13040.

Wenxuan Wang, Zhaopeng Tu, Chang Chen, Youliang Yuan, Jen-tse Huang, Wenxiang Jiao, and Michael R Lyu. 2023f. All languages matter: On the multilingual safety of large language models. arXiv preprint arXiv:2310.00905.

Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b. Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks. arXiv preprint arXiv:2204.07705.

Yuhang Wang, Yanxu Zhu, Chao Kong, Shuyu Wei, Xiaoyuan Yi, Xing Xie, and Jitao Sang. 2023g. Cdeval: A benchmark for measuring the cultural dimensions of large language models. arXiv preprint arXiv:2311.16421.

Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan $\mathrm{Su}$, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek Mahmoud, Alham Fikri Aji, et al. 2023h. M4: Multigenerator, multi-domain, and multi-lingual black-box machine-generated text detection. arXiv preprint arXiv:2305.14902.

Zhiruo Wang, Grace Cuenca, Shuyan Zhou, Frank F Xu, and Graham Neubig. 2022c. Mconala: a benchmark for code generation from multiple natural languages. arXiv preprint arXiv:2203.08388.

Zhiruo Wang, Shuyan Zhou, Daniel Fried, and Graham Neubig. 2022d. Execution-based evaluation for open-domain code generation. arXiv preprint arXiv:2212.10481.

Aman Kassahun Wassie. 2023. Machine translation for ge'ez language. arXiv preprint arXiv:2311.14530.

Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.

Tianwen Wei, Liang Zhao, Lichang Zhang, Bo Zhu, Lijie Wang, Haihua Yang, Biye Li, Cheng Cheng, Weiwei Lui, Rui Hu, et al. 2023a. Skywork: A more open bilingual foundation model. arXiv preprint arXiv:2310.19341.

Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, et al. 2023b. Zeroshot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205.

Xiangpeng Wei, Haoran Wei, Huan Lin, Tianhao Li, Pei Zhang, Xingzhang Ren, Mei Li, Yu Wan, Zhiwei Cao, Binbin Xie, et al. 2023c. Polylm: An open source polyglot large language model. arXiv preprint arXiv:2307.06018.

Leonie Weissweiler, Valentin Hofmann, Anjali Kantharuban, Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkarni, Abhishek Vijayakumar, Haofei Yu, Hinrich Schuetze, Kemal Oflazer, and David Mortensen. 2023. Counting the bugs in ChatGPT's wugs: A multilingual investigation into the morphological capabilities of a large language model. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 6508-6524, Singapore. Association for Computational Linguistics.

Andrea Wen-Yi and David Mimno. 2023. Hyperpolyglot llms: Cross-lingual interpretability in token embeddings. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 1124-1131.

Chenxi Whitehouse, Monojit Choudhury, and Alham Fikri Aji. 2023a. Llm-powered data augmentation for enhanced crosslingual performance. arXiv preprint arXiv:2305.14288.

Chenxi Whitehouse, Fantine Huot, Jasmijn Bastings, Mostafa Dehghani, Chu-Cheng Lin, and Mirella Lapata. 2023b. Parameter-efficient multilingual summarisation: An empirical study. arXiv preprint arXiv:2311.08572.

Genta Winata, Shijie Wu, Mayank Kulkarni, Thamar Solorio, and Daniel Preotiuc-Pietro. 2022a. Crosslingual few-shot learning on unseen languages. In Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 777-791, Online only. Association for Computational Linguistics.

Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Rahmad Mahendra, Fajri Koto, Ade Romadhony, Kemal Kurniawan, David Moeljadi, Radityo Eko Prasojo, Pascale Fung, Timothy Baldwin,
Jey Han Lau, Rico Sennrich, and Sebastian Ruder. 2023a. NusaX: Multilingual parallel sentiment dataset for 10 Indonesian local languages. In Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 815-834, Dubrovnik, Croatia. Association for Computational Linguistics.

Genta Indra Winata, Alham Fikri Aji, Zheng-Xin Yong, and Thamar Solorio. 2022b. The decades progress on code-switching research in nlp: A systematic survey on trends and challenges. arXiv preprint arXiv:2212.09660.

Genta Indra Winata, Liang-Kang Huang, Soumya Vadlamannati, and Yash Chandarana. 2023b. Multilingual few-shot learning via language model retrieval. arXiv preprint arXiv:2306.10964.

BigScience Workshop, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra Sasha Luccioni, François Yvon, et al. 2022. Bloom: A 176bparameter open-access multilingual language model. arXiv preprint arXiv:2211.05100.

Suhang Wu, Minlong Peng, Yue Chen, Jinsong Su, and Mingming Sun. 2023. Eva-kellm: A new benchmark for evaluating knowledge editing of llms. arXiv preprint arXiv:2308.09954.

Yangjian Wu and Gang Hu. 2023. Exploring prompt engineering with gpt language models for documentlevel machine translation: Insights and findings. In Proceedings of the Eighth Conference on Machine Translation, pages 166-169.

Zedian Xiao, William Held, Yanchen Liu, and Diyi Yang. 2023. Task-agnostic low-rank adapters for unseen english dialects. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 7857-7870.

Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Hassan Awadalla. 2023a. A paradigm shift in machine translation: Boosting translation performance of large language models. arXiv preprint arXiv:2309.11674.

Nan Xu, Fei Wang, Ben Zhou, Bang Zheng Li, Chaowei Xiao, and Muhao Chen. 2023b. Cognitive overload: Jailbreaking large language models with overloaded logical thinking. arXiv preprint arXiv:2311.09827.

Ningyu Xu, Qi Zhang, Jingting Ye, Menghan Zhang, and Xuanjing Huang. 2023c. Are structural concepts universal in transformer language models? towards interpretable cross-lingual generalization. arXiv preprint arXiv:2310.12794.

Shaoyang Xu, Junzhuo Li, and Deyi Xiong. 2023d. Language representation projection: Can we transfer factual knowledge across languages in multilingual language models? In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 3692-3702.

Weijia Xu, Batool Haider, and Saab Mansour. 2020 End-to-end slot alignment and recognition for crosslingual NLU. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5052-5063, Online. Association for Computational Linguistics.

Dao Xuan-Quy, Le Ngoc-Bich, Vo The-Duy, Phan Xuan-Dung, Ngo Bac-Bien, Nguyen Van-Tien, Nguyen Thi-My-Thanh, and Nguyen Hong-Phuoc. 2023. Vnhsge: Vietnamese high school graduation examination dataset for large language models. arXiv preprint arXiv:2305.12199.

Linting Xue, Aditya Barua, Noah Constant, Rami AlRfou, Sharan Narang, Mihir Kale, Adam Roberts, and Colin Raffel. 2022. Byt5: Towards a token-free future with pre-trained byte-to-byte models. Transactions of the Association for Computational Linguistics, 10:291-306.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer. arXiv preprint arXiv:2010.11934.

Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2021. mt5: A massively multilingual pre-trained text-to-text transformer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 483-498.

Ankit Yadav, Shubham Chandel, Sushant Chatufale, and Anil Bandhakavi. 2023. Lahm: Large annotated dataset for multi-domain and multilingual hate speech identification. arXiv preprint arXiv:2304.00913.

Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, et al. 2023a. Baichuan 2: Open large-scale language models. arXiv preprint arXiv:2309.10305.

Chih-Kai Yang, Kuan-Po Huang, Ke-Han Lu, ChunYi Kuan, Chi-Yuan Hsiao, and Hung-yi Lee. 2023b. Investigating zero-shot generalizability on mandarin-english code-switched asr and speech-totext translation of recent foundation models with selfsupervision and weak supervision. arXiv preprint arXiv:2401.00273.

Guangyu Yang, Jinghong Chen, Weizhe Lin, and Bill Byrne. 2023c. Direct preference optimization for neural machine translation with minimum bayes risk decoding. arXiv preprint arXiv:2311.08380.

Muyun Yang, Xixin Hu, Hao Xiong, Jiayi Wang, Yiliyaer Jiaermuhamaiti, Zhongjun He, Weihua Luo, and Shujian Huang. 2019a. Ccmt 2019 machine translation evaluation report. In Machine Translation: 15th China Conference, CCMT 2019, Nanchang, China, September 27-29, 2019, Revised Selected Papers 15, pages 105-128. Springer.
Wen Yang, Chong Li, Jiajun Zhang, and Chengqing Zong. 2023d. Bigtrans: Augmenting large language models with multilingual translation capability over 100 languages. arXiv preprint arXiv:2305.18098.

Yahan Yang, Soham Dan, Dan Roth, and Insup Lee. 2023e. Understanding calibration for multilingual question answering models. arXiv preprint arXiv:2311.08669.

Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. 2019b. Paws-x: A cross-lingual adversarial dataset for paraphrase identification. arXiv preprint arXiv:1908.11828.

Zijian Győző Yang, László János Laki, Tamás Váradi, and Gábor Prószéky. 2023f. Mono- and multilingual gpt-3 models for hungarian. In International Conference on Text, Speech, and Dialogue, pages 94-104. Springer.

Jiacheng Ye, Xijia Tao, and Lingpeng Kong. 2023a. Language versatilists vs. specialists: An empirical revisiting on multilingual transfer ability. arXiv preprint arXiv:2306.06688.

Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, and Malihe Alikhani. 2023b. Multilingual content moderation: A case study on reddit. arXiv preprint arXiv:2302.09618.

Da Yin, Hritik Bansal, Masoud Monajatipoor, Liunian Harold Li, and Kai-Wei Chang. 2022. Geomlama: Geo-diverse commonsense probing on multilingual pre-trained language models. arXiv preprint arXiv:2205.12247.

Zheng-Xin Yong, Hailey Schoelkopf, Niklas Muennighoff, Alham Fikri Aji, David Ifeoluwa Adelani, Khalid Almubarak, M Saiful Bari, Lintang Sutawika, Jungo Kasai, Ahmed Baruwa, et al. 2022. Bloom+ 1: Adding language support to bloom for zero-shot prompting. arXiv preprint arXiv:2212.09535.

Zheng-Xin Yong, Ruochen Zhang, Jessica Zosa Forde, Skyler Wang, Samuel Cahyawijaya, Holy Lovenia, Genta Indra Winata, Lintang Sutawika, Jan Christian Blaise Cruz, Long Phan, et al. 2023. Prompting multilingual large language models to generate codemixed texts: The case of south east asian languages. arXiv e-prints, pages arXiv-2303.

Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, and Minjoon Seo. 2024. Langbridge: Multilingual reasoning without multilingual supervision. arXiv preprint arXiv:2401.10695.

Xinyan Velocity Yu, Akari Asai, Trina Chatterjee, Junjie Hu, and Eunsol Choi. 2022. Beyond counting datasets: a survey of multilingual dataset construction and necessary resources. arXiv preprint arXiv:2211.15649.

Fei Yuan, Yinquan Lu, Wenhao Zhu, Lingpeng Kong, Lei Li, Yu Qiao, and Jingjing Xu. 2023. Lego-mt:

Learning detachable models for massively multilingual machine translation. In Findings of the Association for Computational Linguistics: ACL 2023, pages $11518-11533$.

Yan Gong Yiping Peng Qiang Niu Lei Zhang Baochang Ma Xiangang Li Yunjie Ji, Yong Deng. 2023. Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases. arXiv preprint arXiv:2303.14742.

Daniel Zeman, Joakim Nivre, Mitchell Abrams, Elia Ackermann, Noëmi Aepli, Hamid Aghaei, Željko Agić, Amir Ahmadi, et al. 2022. Universal dependencies 2.10. LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University.

Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414.

Jiali Zeng, Fandong Meng, Yongjing Yin, and Jie Zhou. 2023a. Improving machine translation with large language models: A preliminary study with cooperative decoding. arXiv preprint arXiv:2311.02851.

Jiali Zeng, Fandong Meng, Yongjing Yin, and Jie Zhou. 2023b. Tim: Teaching large language models to translate with comparison. arXiv preprint arXiv:2307.04408.

Biao Zhang, Barry Haddow, and Alexandra Birch. 2023a. Prompting large language model for machine translation: A case study. arXiv preprint arXiv:2301.07069.

Biao Zhang, Philip Williams, Ivan Titov, and Rico Sennrich. 2020. Improving massively multilingual neural machine translation and zero-shot translation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 16281639, Online. Association for Computational Linguistics.

Chen Zhang, Luis Fernando D'Haro, Chengguang Tang, Ke Shi, Guohua Tang, and Haizhou Li. 2023b. xdialeval: A multilingual open-domain dialogue evaluation benchmark. arXiv preprint arXiv:2310.08958.

Chiyu Zhang, Khai Duy Doan, Qisheng Liao, and Muhammad Abdul-Mageed. 2023c. The skipped beat: A study of sociopragmatic understanding in llms for 64 languages. arXiv preprint arXiv:2310.14557.

Min Zhang, Limin Liu, Zhao Yanqing, Xiaosong Qiao, Su Chang, Xiaofeng Zhao, Junhao Zhu, Ming Zhu, Song Peng, Yinglu Li, et al. 2023d. Leveraging multilingual knowledge graph to boost domain-specific entity translation of chatgpt. In Proceedings of Machine Translation Summit XIX, Vol. 2: Users Track, pages 77-87.
Ran Zhang, Jihed Ouni, and Steffen Eger. 2023e. Crosslingual cross-temporal summarization: Dataset, models, evaluation. arXiv preprint arXiv:2306.12916.

Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz, and Alham Fikri Aji. 2023f. Multilingual large language models are not (yet) codeswitchers. arXiv preprint arXiv:2305.14235.

Ruochen Zhang and Carsten Eickhoff. 2023. Crocosum: A benchmark dataset for cross-lingual code-switched summarization. arXiv preprint arXiv:2303.04092.

Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, et al. 2023g. Bayling: Bridging cross-lingual alignment and instruction following through interactive translation for large language models. arXiv preprint arXiv:2306.10968.

Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068.

Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi. 2020. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations.

Wenxuan Zhang, Sharifah Mahani Aljunied, Chang Gao, Yew Ken Chia, and Lidong Bing. 2023h. M3exam: A multilingual, multimodal, multilevel benchmark for examining large language models. arXiv preprint arXiv:2306.05179.

Xiang Zhang, Senyu Li, Bradley Hauer, Ning Shi, and Grzegorz Kondrak. 2023i. Don't trust gpt when your question is not in english. arXiv preprint arXiv:2305.16339.

Xiaotian Zhang, Chunyang Li, Yi Zong, Zhengyu Ying, Liang He, and Xipeng Qiu. 2023j. Evaluating the performance of large language models on gaokao benchmark. arXiv preprint arXiv:2305.12474.

Yusen Zhang, Jun Wang, Zhiguo Wang, and Rui Zhang. 2023k. Xsemplr: Cross-lingual semantic parsing in multiple natural languages and meaning representations. arXiv preprint arXiv:2306.04085.

Zhengyan Zhang, Yuxian Gu, Xu Han, Shengqi Chen, Chaojun Xiao, Zhenbo Sun, Yuan Yao, Fanchao Qi, Jian Guan, Pei Ke, et al. 2021. Cpm-2: Large-scale cost-effective pre-trained language models. AI Open, 2:216-224.

Ziyin Zhang, Yikang Liu, Weifang Huang, Junyu Mao, Rui Wang, and Hai Hu. 20231. Mela: Multilingual evaluation of linguistic acceptability. arXiv preprint arXiv:2311.09033.

Biao Zhao, Weiqiang Jin, Javier Del Ser, and Guang Yang. 2023a. Chatagri: Exploring potentials of chatgpt on cross-linguistic agricultural text classification. arXiv preprint arXiv:2305.15024.

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023b. A survey of large language models. arXiv preprint arXiv:2303.18223.

Bo Zheng, Zhouyang Li, Fuxuan Wei, Qiguang Chen, Libo Qin, and Wanxiang Che. 2022. HIT-SCIR at MMNLU-22: Consistency regularization for multilingual spoken language understanding. In Proceedings of the Massively Multilingual Natural Language Understanding Workshop (MMNLU-22), pages 35-41, Abu Dhabi, United Arab Emirates (Hybrid). Association for Computational Linguistics.

Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023. Judging 11 -as-a-judge with mt-bench and chatbot arena. arXiv preprint arXiv:2306.05685.

Shanshan Zhong, Zhongzhan Huang, Shanghua Gao, Wushao Wen, Liang Lin, Marinka Zitnik, and Pan Zhou. 2023a. Let's think outside the box: Exploring leap-of-thought in large language models with creative humor generation. arXiv preprint arXiv:2312.02439.

Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. 2023b. Agieval: A human-centric benchmark for evaluating foundation models. arXiv preprint arXiv:2304.06364.

Chulun Zhou, Yunlong Liang, Fandong Meng, Jinan $\mathrm{Xu}$, Jinsong Su, and Jie Zhou. 2023. Rc3: Regularized contrastive cross-lingual cross-modal pretraining. arXiv preprint arXiv:2305.07927.

Di Zhou and Yinxian Zhang. 2023. Red ai? inconsistent responses from gpt3. 5 models on political issues in the us and china. arXiv preprint arXiv:2312.09917.

Kairui Zhou. 2023. Accessible instruction-following agent. arXiv preprint arXiv:2305.06358.

Wenhao Zhu, Shujian Huang, Fei Yuan, Shuaijie She, Jiajun Chen, and Alexandra Birch. 2024. Question translation training for better multilingual reasoning. arXiv preprint arXiv:2401.07817.

Wenhao Zhu, Yunzhe Lv, Qingxiu Dong, Fei Yuan, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, and Lei Li. 2023. Extrapolating large language models to non-english by aligning languages. arXiv preprint arXiv:2308.04948.

Michał Ziemski, Marcin Junczys-Dowmunt, and Bruno Pouliquen. 2016. The United Nations parallel corpus v1.0. In Proceedings of the Tenth International Conference on Language Resources and Evaluation
(LREC'16), pages 3530-3534, Portorož, Slovenia. European Language Resources Association (ELRA).

Vilém Zouhar and Ondřej Bojar. 2024. Quality and quantity of machine translation references for automated metrics. arXiv preprint arXiv:2401.01283.
