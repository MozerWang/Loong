# Advances and Open Challenges in Federated Learning with Foundation Models 

Chao Ren, Member, IEEE, Han Yu, Senior Member, IEEE, Hongyi Peng, Xiaoli Tang, Anran Li, Member, IEEE,<br>Yulan Gao, Member, IEEE, Alysa Ziying Tan, Member, IEEE, Bo Zhao,<br>Xiaoxiao Li, Member, IEEE, Zengxiang Li, and Qiang Yang, Fellow, IEEE


#### Abstract

The integration of Foundation Models (FMs) with Federated Learning (FL) presents a transformative paradigm in Artificial Intelligence (AI), offering enhanced capabilities while addressing concerns of privacy, data decentralization, and computational efficiency. This paper provides a comprehensive survey of the emerging field of Federated Foundation Models (FedFM), elucidating their synergistic relationship and exploring novel methodologies, challenges, and future directions that the $F L$ research field needs to focus on in order to thrive in the age of foundation models. A systematic multi-tiered taxonomy is proposed, categorizing existing FedFM approaches for model training, aggregation, trustworthiness, and incentivization. Key challenges, including how to enable FL to deal with high complexity of computational demands, privacy considerations, contribution evaluation, and communication efficiency, are thoroughly discussed. Moreover, the paper explores the intricate challenges of communication, scalability and security inherent in training/finetuning FMs via FL, highlighting the potential of quantum computing to revolutionize the training, inference, optimization and data encryption processes. This survey underscores the importance of further research to propel innovation in FedFM, emphasizing the need for developing trustworthy solutions. It serves as a foundational guide for researchers and practitioners interested in contributing to this interdisciplinary and rapidly advancing field.


The work is supported, in part, by the Internal talent award (TRACS) with Wallenberg-NTU Presidential Postdoctoral Fellowship, Wallenberg AI, Autonomous Systems and Software Program (WASP) and Nanyang Technological University, Sweden and Singapore; the National Research Foundation Singapore and DSO National Laboratories under the AI Singapore Programme (No: AISG2-RP-2020-019); and the RIE 2020 Advanced Manufacturing and Engineering (AME) Programmatic Fund (No. A20G8b0102), Singapore.

Chao Ren is currently a Wallenberg-NTU Presidential Postdoctoral Fellow with the College of Computing and Data Science, Nanyang Technological University, Singapore; and School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Sweden (e-mail: renc0003@e.ntu.edu.sg).

Han Yu is a Nanyang Assistant Professor at the College of Computing and Data Science, Nanyang Technological University, Singapore (Corresponding Author, e-mail: han.yu@ ntu.edu.sg).

Hongyi Peng, Xiaoli Tang, Bo Zhao, and Alysa Ziying Tan are PhD Candidates at the College of Computing and Data Science, Nanyang Technological University, Singapore (e-mail: \{hongyi001, xiaoli001, bo008, s190109\}@ntu.edu.sg).

Anran Li and Yulan Gao are post-doctoral research fellows at the College of Computing and Data Science, Nanyang Technological University, Singapore (e-mail: \{anran.li, yulan.gao\} @ ntu.edu.sg).

Zengxiang $\mathrm{Li}$ is the Executive Vice President of the Digital Research Institute of ENN Group, Langfang, China (e-mail: lizengxiang@enn.cn).

Xiaoxiao $\mathrm{Li}$ is an Assistant Professor at the Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada (e-mail: xiaoxiao.li@ece.ubc.ca).

Qiang Yang is Professor Emeritus at the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, and the Chief AI Officer of WeBank, Shenzhen, China (e-mail: qyang@cse.ust.hk).
Index Terms-Federated learning, foundation models, large language models, efficient training/aggregation, trustworthiness, incentivization, contribution evaluation, quantum computing.

## I. INTRODUCTION

The Artificial Intelligence (AI) landscape is undergoing significant advancement propelled by the emergence of Foundation Models (FMs) [1], [2]. These models are named for their essential role as the foundational backbone for a wide range of learning tasks with diverse modalities [3]. While technically representing an evolutionary rather than revolutionary development in AI [2], FMs have significantly reshaped model training and deployment practices through their widespread application. FMs are typically pre-trained on large-scale datasets using self-supervised learning methods. This pre-training equips them with general and adaptable knowledge, applicable across diverse tasks. Such practice arises from the high costs associated with FM training and the relatively limited scale of available datasets for these tasks, rendering the traditional training-from-scratch paradigm impractical.

Recently, FMs with their diverse designs and learning processes have achieved remarkable success in tackling complex tasks that were once considered too difficult or even impossible. Particularly in Natural Language Processing (NLP), FMs such as those in the GPT series [4]-[6], LLaMa [7] and PaLM [8] have demonstrated extraordinary capabilities. In computer vision, Segment Anything [9] has emerged as a standout performer. In the realm of Generative AI models, Stable Diffusion [10] has garnered significant attention. Notably, DALL-E [11] and CLIP [12] have demonstrated outstanding performance in multi-modal tasks, bridging the understanding of textual and visual data. Nevertheless, the success of FMs comes at a high cost. The enhanced capabilities necessitate a substantial amount of high-quality training data and computational resources. This underscores the potential value of a collaborative learning paradigm, one that enables the distribution of both data resources and computational loads.

Federated learning (FL) [13], a collaborative learning approach, has received significant interest for its potential in enhancing privacy, leveraging distributed datasets, and distributing computational loads. Training/fine-tuning FMs via FL offers several advantages. FL can broaden the data horizons for FMs by aggregating diverse data sources from both the public and private sectors [14], including research institutions

TABLE I

COMPARISON BETWEEN FedEM AND TRADITIONAL FMS

| FACTORS | FedFM |  | TRADITIONAL FMs |  |
| :---: | :---: | :---: | :---: | :---: |
| Data Efficiency | More Diverse Data Across Devices | $\checkmark$ | Higher Data Demand for Same Performance | $x$ |
| Data Privacy | Privacy Preserving Mechanisms | $\checkmark$ | Centralized Data Collection | $x$ |
| Model Performance | Diverse and Adaptive Improvement | $\checkmark$ | Lack Diversity and Personalization | $x$ |
| System Operation | Distributed Coordination | $\checkmark$ | Central Management | $x$ |
| Scalability | Scalable to Multiple Participants | $\checkmark$ | Unscalable with much Larger Datasets | $x$ |
| Deployment | Challenging | $x$ | Easier to Setup | $\checkmark$ |
| Consistency | Not Particularly Controllable | $x$ | Controllable for Consistent Updating | $\checkmark$ |
| Latency | Distributed Communication and Computation | $x$ | Lower under Centralized Environment | $\checkmark$ |

TABLE II

Comparison OF EXISTING REVIEWS ANd PoSITION PAPERS WITH THIS SURVEY PAPER

| YEARS | REFERENCES | FedFM <br> TAXONOMY | FedFM <br> EFFICIENCY | FedFM <br> TRUSTWORTHINESS | FedFM <br> INCENTIVIZATION | FedFM <br> EVALUATION | FedFM <br> FRAMEWORK | FedFM <br> CHALLENGES | FedFM <br> FUTURE <br> DIRECTIONS |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 2023 | Chen et al. 14 | $x$ | $\checkmark$ | $x$ | $x$ | $x$ | $x$ | $\checkmark$ | $x$ |
|  | Zhuang et al. 15 | $x$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $x$ | $x$ | $\checkmark$ | $\checkmark$ |
|  | Yu et al. 16 | $x$ | $\checkmark$ | $\checkmark$ | $x$ | $x$ | $x$ | $\checkmark$ | $x$ |
|  | Kang et al. 17] | $\checkmark$ | $\checkmark$ | $\checkmark$ | $x$ | $x$ | $x$ | $\checkmark$ | $\checkmark$ |
| 2024 | Herbert et al. 18 | $\checkmark$ | $\checkmark$ | $x$ | $x$ | $x$ | $x$ | $x$ | $\checkmark$ |
|  | Li et al. 19 . | $\checkmark$ | $x$ | $\checkmark$ | $x$ | $x$ | $x$ | $\checkmark$ | $x$ |
|  | This paper | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ | $\checkmark$ |

and industries. It can also distribute computational loads among multiple participants, leading to more efficient resource utilization and mitigating the risk of $\mathrm{AI}$ monopolies by major technology companies. On the other hand, the robustness of FMs strengthens the effectiveness of FL, particularly in managing non-iid (non-independent and identically distributed) data. Moreover, the flexibility of FMs in adapting to various downstream tasks facilitates easier personalization of FL models. These benefits highlight the promising potential of integrating FMs with FL.

Recent efforts to integrate FMs into the FL training process have introduced a range of novel techniques and designs. We refer to these emerging approaches as Federated Foundation Models (FedFM). The motivation for FedFM is to address the limitations of traditional FMs and improve upon them by leveraging the potential of FL, offering several advantages over traditional FMs. The key factors driving the development of FedFM are summarized in Table I (with $\checkmark$ indicating advantages, and $\boldsymbol{x}$ indicating limitations). Table I contrasts FedFM and traditional FMs across a diverse spectrum of topics ranging from data efficiency, data privacy, model performance, system operation, scalability, deployment, consistency and latency, to the broader array of trustworthy AI.

As the research field of FedFM is still emerging, there are currently only two position papers [14], [19] and four review papers [15]-[18] on this topic. Table [I] compares these existing position papers and review paper with our survey paper in terms of the coverage of important aspects of FedFM (with $\checkmark$ indicating mentioned, and $\boldsymbol{X}$ indicating no discussion). While the aforementioned survey efforts provide a reasonable overview of some aspects of FedFM, they tend to be brief and often lack comprehensiveness. Moreover, they are limited to considering selected aspects of FedFM, such as training/aggregation efficiency and trustworthiness, which does not provide a comprehensive overview of this interdisciplinary field for readers. Additionally, they neglect key issues of FedFM contribution evaluation and frameworks. To the best of our knowledge, this survey provides the most comprehensive coverage of the FedFM topic.

The primary contribution of this survey paper is the proposal of a systematic multi-tiered taxonomy for FedFM. It categorizes existing approaches and identifies key challenges and opportunities in this domain, encompassing innovative strategies for FedFM training and aggregation, strategies for achieving trustworthiness, and designs for FedFM incentive mechanism prioritizing efficiency, privacy, novel contribution evaluation, and active selection. Additionally, we explore the potential of quantum computing to enhance the effectiveness, efficiency and security of FedFM. Our survey not only reviews existing works, but also comprehensively discusses the motivations behind these approaches, often inspired by developments and insights regarding FMs. Finally, we outline promising future research directions, aiming to inspire advancements in the creation of efficient, secure and scalable FedFM approaches.

The paper is organized as follows. Section II introduces FMs and FL, concepts relevant to our discussion. Section III describes the FedFM taxonomy, which encompasses several key aspects: training and aggregation methods, ensuring trustworthiness, creating effective incentive mechanisms, and managing evaluation. Section IV focuses on aggregation, communication and computational efficiency, highlighting the nuanced considerations required for the effective deployment
of FedFM. Section V addresses the critical areas of Byzantinerobustness and privacy for FedFM. Section VI highlights the complexity of developing effective incentive mechanisms for FedFM. Section VII describes and compares prevailing FedFM frameworks. Section VIII discusses open research challenges of FedFM in terms of memory, computation, and communication, while also delving into potential future directions involving quantum computing techniques and effective evaluation. Finally, section IX concludes the paper.

## II. TERMINOLOGY

This section aims to provide an overview of FMs and FL, outlining the fundamental concepts and historical development trajectories that have propelled their current prominence in the field.

## A. Foundation Models

The term FMs was coined in [2] to denote the role of such models as a foundational base, from which numerous task-specific models can be built through adaptation. FMs emphasize the stability of their architecture during training and the consistency of parameters throughout the adaptation phase. This term also signifies a profound shift in AI research and deployment, which began in the field of NLP, where the synergy of large-scale models and transfer learning [20] resulted in the development of powerful models. The scale of FMs manifests in three key dimensions: 1) the sizes of the models, 2) the extensive computational resources required for training, and 3) the substantial volume of data consumed. For example, GPT-2 [4] consists of 1.3 billion parameters with a memory footprint of approximately $2.6 \mathrm{~GB}$, while GPT-3 [5] consists of 175 billion parameters with a memory footprint of around 350 GB in half-precision format. GPT-4 [6] further extends this scale to over one trillion parameters. In terms of computational resources, training FMs demands substantial power. For instance, the LLaMA [7] model, requires 2,048 NVIDIA A100 GPUs for a duration of 21 days for training, while the vision transformer in CLIP [21] requires 8 core TPUv3 for approximately 30 days for training. Additionally, FMs consume vast amounts of training data. GPT-3 [5], for instance, is trained on a dataset with 300 billion tokens, equivalent to hundreds of gigabytes of data. Research suggests a potential depletion of high-quality language data by 2026 [22], raising concerns that data availability might eventually impede the advancement of FMs.

## B. Federated Learning

FL aims to collaboratively train models across multiple decentralized data owners holding potentially sensitive local data in a privacy-preserving manner [13]. The essence of FL lies in its ability to learn a shared model by aggregating locally computed updates, rather than directly accessing or sharing the raw data. This machine learning (ML) paradigm not only enhances privacy and security, but also enables the utilization of distributedly owned data for model training, making it particularly suitable for mission critical applications, such as healthcare [23] and finance [24], where data privacy is of paramount concern.

The typical FL process involves several key steps. Initially, a global model is distributed to all participating FL clients from the FL server. Each client then trains the ML model on its local data to derive an updated local model. These model updates are subsequently sent back to the FL server, and then are aggregated to update the global model. Such cycle is repeated until convergences or specific performance criteria are met. A widely used framework in FL is Federated Averaging (FedAvg) [25], renowned for its ability to aggregate model updates with minimal communication overhead. This is particularly crucial in FL settings, where a potentially large number of participants may have limited communication bandwidth [26].

To achieve meaningful real-world impact, FL must address several intricate challenges, including non-independently and identically distributed (non-IID) data across clients, system heterogeneity, and scalability [13]. Non-IID data can introduce biases into models by favoring the data distribution of specific participants [27]. System heterogeneity, characterized by variations in computation and communication capabilities among client participants, can result in uneven contributions to the model training process. Additionally, scalability concerns arise as the number of participants increases, necessitating the development of efficient algorithms and infrastructure to manage the aggregation of updates and distribution of the global model. The development of FL continues to evolve, spurred by advancements in both theoretical research and practical applications across various industries. FL is anticipated to play a pivotal role in building AI solutions that prioritize user privacy and data sovereignty.

## III. The Proposed FedFM TaXonomY

In the rapidly evolving domain of FL, the integration of FMs into federated settings, termed FedFM, represents a significant leap forward. This integration aims to leverage the capabilities of FMs and the collaborative training process of FL to enable FedFM to access privately owned decentralized data. The development of FedFM requires rethinking of several key aspects of the current FL paradigm: 1) achieving efficiency in federated training and aggregation, 2) ensuring trustworthiness, and 3) building effective incentive mechanisms. Each part plays a crucial role in the successful implementation and operation of FedFM. Based on the above considerations, we propose a novel and multi-tiered FedFM taxonomy, as illustrated in Fig. 1 .

## A. Efficient Federated Training and Aggregation: The Foundation of FedFM

Research on FL training and aggregation methods for FedFM seeks to address the unique challenges posed by the size and complexity of FMs. The goal is to adapt traditional FL training methods to work efficiently with FMs, minimizing computational efficiency and communication overheads. This

![](https://cdn.mathpix.com/cropped/2024_06_04_322e01caebc2cdbc0f4cg-04.jpg?height=905&width=892&top_left_y=182&top_left_x=150)

Fig. 1: The proposed taxonomy of FedFM.

includes finding ways to effectively aggregate parameter updates involving FMs from potentially a large number of FL clients without overwhelming the communication network.

Existing federated training and aggregation research that holds potential for FedFM generally focus on three main areas: 1) advanced aggregation methods, 2) enhancing computational efficiency, and 3) enhancing communication efficiency. We summarize key trends in each of these areas:

- FedFM Aggregation: Under this topic, we explore weighted averaging-based methods and promising new techniques. Weighted averaging is a widely adopted federated aggregation approach for local model updates in FedFM. Despite its simplicity, such methods are favored due to their efficiency and the computational challenges of more complex aggregation techniques given the vast scale of FMs. Nevertheless, innovative aggregation strategies are emerging which can be more effective for FedFM. Simple methods, such as model soups, which have shown promising results in enhancing model accuracy and robustness by averaging weights of models fine-tuned with different hyper-parameters. In addition, Mixture of Experts (MoE)-based models can be useful for developing sophisticated aggregation strategies that improve the performance of FedFM.
- Computationally Efficient FedFM: Research in this area focuses on adapting pre-trained FMs to specific tasks with minimal adjustments to the model parameters. Techniques like Parameter-Efficient Fine-Tuning (PEFT), Prompt Tuning (PT), and Instruction Tuning (IT) are possible ways to enhance FedFM computational efficiency. These methods allow for significant reductions in the computational and storage demands by only fine-tuning a small subset of the model parameters.
- Communication Efficient FedEM: Research in this areas focuses on strategies to enhance efficiency in transmitting FM updates between FL clients and the FL server. It generally involves two primary approaches: 1) model pruning, which selectively transmit important FM parameters; and 2) model compression, which aims reduce the size of the model being exchanged. These strategies are crucial for managing the increased communication overhead introduced by the large sizes of FMs and enhancing the scalability of FedFM.

This part of the review underscores the evolving landscape of on FedFM research, detailing the challenges, strategies, and innovations in this interdisciplinary field. The focus on scaling, communication, and computational efficiency reflects the nuanced considerations required to effectively deploy FedFM.

## B. Trustworthiness: A Crucial Pillar of FedFM Integrity

Research on trustworthy FedFM encompasses strategies to ensure that the system is robust against attacks and preserves the privacy of participants' data. This involves developing mechanisms to protect against poisoning attacks which aim to corrupt the model and privacy-preserving techniques. The focus is on maintaining the integrity of the learning process and safeguarding participant data from breaches.

Trustworthy FedFM address the critical areas of Byzantinerobustness and privacy preservation in the context of FedFM, exploring the challenges and proposing solutions to ensure the integrity and security of these systems. We summarize key trends in each of these areas:

- Byzantine Robustness: Research in this area discusses how poisoning attacks, both untargeted and targeted, aim to compromise the integrity of global models in FL systems. Untargeted attacks disrupt the training process to prevent convergence, while targeted attacks manipulate the model output subtly. The complexity and heterogeneity of FedFM training tasks make these attacks particularly challenging to execute and defend against. Byzantine-robust aggregation rules are also being proposed to counteract poisoning attacks, including geometrical outlier detection, top performance selection, and other hybrid schemes. However, the effectiveness of these defenses has been questioned in FedFM settings, calling for novel approaches tailored to its complexities.
- Privacy Preservation: Research on privacy attacks explore the threat landscape of FL, including membership inference and data reconstruction attacks. Membership inference attacks aim to determine whether specific data samples were used in training, while data reconstruction attacks seek to recreate the original training data. The large scales of FMs and the nature of FedFM introduce new vulnerabilities and challenges in defending against these privacy attacks. Research on privacy defenses focuses on developing strategies to counteract privacy attacks, focusing on a balance between preserving knowledge integrity and ensuring privacy. Techniques like
differential privacy, confidence masking, and model compression are highlighted as means to protect client data privacy in FedFM without significantly compromising the quality of local model updates.

This part of the review on FedFM research underscores the intricate balance required to achieve trustworthiness, emphasizing the need for innovative solutions to address the dual challenges of Byzantine-robustness and privacy preservation. The complexity of FMs and the FL environment necessitates a re-evaluation of traditional defense mechanisms and development of new strategies to ensure the integrity and privacy of such advanced learning systems.

## C. Incentive Mechanisms: Fostering Participation, Collaboration, and Adaptability of FedFM

The participation of data owners is vital for the success of FedFM. Incentive mechanisms are often leveraged to motivate data owners to contribute their local data and computational resources. These mechanisms often draw upon economic and game theories to fairly compensate participants for their contributions. The challenge lies in creating a system that balances the need to encourage participation with the practicalities of managing the distribution of rewards. Research in FedFM incentive mechanism design delves into the crucial aspects of FL participant selection, contribution evaluation, and reward distribution. We summarize key trends in each of these areas:

- Participant Selection: Research in this area develops strategies for selecting participants to join the FL process, emphasizing the importance of both traditional approaches (e.g., Contract Theory, Game theory, auctions) and emerging model-centric approaches. Contract Theory-based mechanisms are employed in scenarios with information asymmetry, focusing on computation and communication resource optimization before determining rewards. Game theoretic approaches aim to optimize resources, while offering incentives through server-client negotiations. Auction-based schemes focus on attracting high-quality participants by addressing latency and resource burdens efficiently. Model-centric approaches select FL participants based on the characteristics of participants' models rather than just the resources they hold, introducing the concepts of horizontal taskspecific training fitness and vertical training capability.
- Contribution Evaluation: Research in this area addresses the challenges of evaluating participant contributions in FedFM, particularly dealing with the impracticality of Shapley Value-based methods due to high latency and the compositional gap inherent in FMs. The complexity of FMs and the sheer volume of participants amplify the latency in training and inference, making timely feedback challenging. FMs face difficulties in generating correct answers to compositional problems, indicating that direct contribution evaluation for FMs built by FedFM is beyond current capabilities.
- Reward Distribution: Research in this area focuses on the intricate balance required in designing reward distribution mechanisms that align with the objectives of FedFM (e.g., deterring free-riding, managing the costs associated with rewards to ensure project sustainability). Incentive alignment ensures that rewards are structured to motivate FL participants and align with the FedFM goals. Minimizing free-riding requires mechanisms to ensure participants cannot benefit from FedFM without making positive contributions. Cost management strikes a delicate balance between incentivizing FL participants and maintaining the FedFM financial viability.

FedFM incentive mechanism design emphasizes the complexity of effectively motivating data owner participation. It suggests that addressing the interconnected challenges of participant selection, contribution evaluation, and reward distribution is crucial for the success and sustainability of FedFM.

## D. Summary of the Proposed FedFM Taxonomy

The proposed FedFM taxonomy covers the fundamental aspects of FedFM, highlighting the need for robust training and aggregation methods, trustworthiness in the form of Byzantine-robustness and privacy preservation, and novel incentive mechanisms to encourage active and meaningful participation. These areas are where the involvement of FMs necessitates significant revisions to the current FL techniques. In subsequent sections, we conduct comprehensive literature review on each of these topics, and put forth a vision for promising future research directions.

## IV. TowARdS EFFICIENT FedFM

In this section, we review and discuss current literature on the topic of efficient collaborative model training/fine-tuning and aggregation for FedFM, focusing on emerging settings and scenarios that arise as a result of combining FL with FMs.

## A. FedFM Training and Aggregation

To grasp the challenges involved in integrating FMs into the FL process, a revision of the general FL procedure is necessary. FL typically operates under the control and decisionmaking of the central server with the primary purpose of collaboratively training a Deep Learning (DL) model $\boldsymbol{\theta}$ across $N$ clients over multiple rounds, as outlined in Algorithm 1. The integration of FMs, with their considerable sizes, introduces challenges at various stages of the FL process. These challenges can be distilled into three critical research questions (highlighted in blue in Algorithm 17:

1) How to aggregate FMs to enhance performance? Given that one of the primary goals of FL is to improve the global model performance, the challenge lies in designing aggregation approaches that are suited for the scale and complexity of FMs. Despite the large body of existing FL model aggregation techniques, few are tailored for FMs.
2) How to improve FL computational efficiency so that FMs can be efficiently hosted and updated by FL

![](https://cdn.mathpix.com/cropped/2024_06_04_322e01caebc2cdbc0f4cg-06.jpg?height=575&width=1808&top_left_y=309&top_left_x=148)

Fig. 2: Taxonomy of enabling techniques for efficient FedFM. The diagram categorizes existing methods into three main domains: 1) Aggregation, 2) Computational Efficiency, and 3) Communication Efficiency. Each domain is further divided into specific strategies that address the challenges of FedFM.

clients? In traditional FL, especially in cross-device scenarios where client devices often have limited memory and compute power, finding ways to efficiently host

```
Algorithm 1 Opportunities for efficient training and aggrega-
tion of FMs under the existing FL procedure
    Input: $N$ clients, local epochs $E$, learning rate $\eta$, initial
    global model weights $\boldsymbol{\theta}^{1}$, total number of communication
    round $R$
    for each round $t=1,2, \ldots, R$ do
        Server selects a subset of $m$ clients $S_{t}$
        for each client $i \in S_{t}$ in parallel do
            $\boldsymbol{\theta}_{i}^{t+1} \leftarrow$ ClientUpdate $\left(i, \boldsymbol{\theta}^{t}\right)$
        end for
        $\boldsymbol{\theta}^{t+1} \leftarrow \operatorname{Aggregate}\left(\left\{\boldsymbol{\theta}_{i}^{t+1}\right\}_{i=1}^{m}\right)$
    end for
    procedure ClientUpdate $\left(i, \boldsymbol{\theta}^{t}\right)$ :
    $\mathcal{B} \leftarrow$ (split $\mathcal{D}_{c}$ into batch of size $B$ )
    for each local epoch $i$ from 1 to $E$ do
        for batch $b \in \mathcal{B}$ do
            $\boldsymbol{\theta}_{i}^{t} \leftarrow \boldsymbol{\theta}^{t+1}-\eta \nabla \mathcal{L}\left(\boldsymbol{\theta}^{t} ; b\right)$
            How to improve the computational efficiency so that
            FMs can be efficiently hosted and updated on FL
            clients?
        end for
    end for
    return $\boldsymbol{\theta}_{i}^{t}$ to the server How to improve communication
    efficiency when $\boldsymbol{\theta}_{i}^{t}$ is large?
    procedure Aggregate $\left(\left\{\boldsymbol{\theta}_{i}^{t+1}\right\}_{i=1}^{m}\right)$
    FedAvg [25]: $\boldsymbol{\theta}^{t+1} \leftarrow \frac{1}{m} \sum_{i=1}^{m} \boldsymbol{\theta}_{i}^{t+1}$
    or
    Aggregation methods for FMs to enhance performance?
```

and update models is already a significant challenge. The substantial increase in the size of FMs exacerbates this challenge, highlighting the need for techniques with significantly improved computational efficiency.

3) How to improve communication efficiency? FL often involves transmitting model updates between clients and the server. The enormous size of FMs creates significant communication overhead that overwhelms the network. Thus, developing more efficient communication strategies is essential for the scalability of FedFM.

Therefore, our survey examines innovative methods and strategies useful for FedFM from three dimensions: 1) aggregation methods for enhanced effectiveness, 2) techniques for boosting computational efficiency, and 3) techniques for improving communication efficiency. We further break down each dimension into sub-areas for more detailed analysis (Fig. 27.

For aggregation methods, we examine the traditional weighted average approach, which is the prevailing approach in current FedFM works. In addition, we explore a selection of promising aggregation techniques, which can be particularly effective for FedFM, offering insights into their potential applicability and benefits.

For computational efficiency, we divide existing approaches into three categories.

- Parameter-efficient Fine-tuning: which aims to adapt a pre-trained FM to a specific task by adjusting only a minimal subset of its parameters.
- Prompt Tuning: which seeks to enhance FM performance without direct model training, but with carefully crafted textual prompts instead.
- Instruction Tuning: which fine-tunes FMs by making the model learn to follow and execute a sequence of instructions instead of traditional input-output pairs.

For communication efficiency, we divide existing ap-

TABLE III

SIZES OF FMS UNDER FL SETTING

| METHODS | YEAR $\downarrow$ | SIZE (M) |
| :--- | :---: | :---: |
| FedPAQ [30] | 2020 | 0.2 |
| HeteroFL [31]] | 2020 | 11 |
| LotteryFL [32] | 2020 | 138 |
| FjORD [33] | 2021 | 11 |
| H-FL [34] | 2021 | 138 |
| PruneFL [35] | 2022 | 132 |
| FedPM [36] | 2022 | 12 |
| FedTiny []7] | 2022 | 132 |
| SoteriaFL [38] | 2022 | 0.05 |
| FedPrompt [\|49] | 2022 | 223 |
| FedBERT |  |  |
| FedCLIP [41] | 2022 | 117 |
| FedPEFT [42] | 2023 | 85 |
| FedPETuning [43] | 2023 | 85 |
| SLoRA [44] | 2023 | 125 |
| FedOBD [45] | 2023 | 67 |
| FedIT [46] | 2023 | 7,000 |
| FwdLLM [47] | 2024 | 7,000 |

proaches into two categories.

- Model Pruning: which focuses on selectively transmitting critical parameters between clients and the server, ensuring only the most vital information is shared.
- Model Compression: which aims to decrease the total number of the model parameters being transmitted.


## B. Scaling Efforts for FedFM

It is useful to recognize that traditional FL typically involves models with fewer than 10 million parameters. For instance, the largest base model aggregated by FedAvg [25] is typically a stacked LSTM with approximately 5 million parameters. The seminal paper of FedProx [28] is tested with a stacked LSTM with roughly 2 million parameters. The largest base model tested with SCAFFOLD [29] is a 2-layer CNN with an estimated parameter count under 5 million. With transformerbased models, FL techniques are starting to be tested on larger models. However, to significantly scale up this respect of FL not only requires new techniques, but also new experiment designs for improved evaluation. Although recent studies have started to evaluate new FL methods with larger base models, they are still markedly smaller than FMs which are achieving breakthrough performance under centralized training settings.

We list the methods reviewed alongside with the largest base models involved in their evaluations in Table III and Table IV. The substantial difference for model sizes between existing FL research and centralized FMs might cast doubts on the feasibility and practicality of the FL techniques for FedFM, calling for further experimental studies involving large-scale FMs. Such an effort depends on the availability of frameworks that can streamline implementation. Thus, in Section VII, we analyze the support for FMs in existing FL frameworks.
TABLE IV

SiZes of FMS Under CentraliZed LeARning SETting

| METHODS | YEAR $\downarrow$ | SIZE (M) |
| :--- | :---: | :---: |
| BERT [48] | 2018 | 340 |
| GPT1 [49] | 2018 | 117 |
| GPT2 [4] | 2019 | 1,500 |
| GPT3 [5] | 2020 | 175,000 |
| ViT [50] | 2020 | 632 |
| LLAMA [7] | 2023 | 70,000 |
| LLAVA [51] | 2024 | 15,000 |

## C. Aggregation Methods for FedFM

## 1) Weighted Average:

As shown in Algorithm 1, the local training process of traditional FL yields a set of local models $\left\{\boldsymbol{\theta}_{1}^{t}, \boldsymbol{\theta}_{2}^{t}, \ldots, \boldsymbol{\theta}_{m}^{t}\right\}$ at communication round $t$. These models are transmitted to the server where they undergo an aggregation process to produce global model $\boldsymbol{\theta}^{\boldsymbol{t + 1}} \leftarrow \operatorname{Aggregate}\left(\left\{\boldsymbol{\theta}_{1}^{t}, \boldsymbol{\theta}_{2}^{t}, \ldots, \boldsymbol{\theta}_{m}^{t}\right\}\right)$. The aggregation step is pivotal in FL, as the overall FL model performance relies on it [52]. Consequently, the development of aggregation methods that balance efficiency with efficacy remains a central theme in FL research. The predominant approach involves computing a weighted average of the parameters from local models (i.e., the weighted average method). Prominent examples of this approach include FedAvg/FedSGD [25], FedProx [28], and FedMA [53].

To the best of our knowledge, currently, there is not FL aggregation technique specifically tailored for FedFM. The prevailing practice has gravitated towards adopting the basic vanilla versions of FedAvg or FedSGD, with the latter being equivalent to FedAvg when the number of local epochs $(E)$ is set to one. Table $V$ provides a summary of the aggregation methods adopted by existing FedFM works.

The preference for simple weighted averaging by existing FedFM methods has been driven by three primary factors.

- The scale of FMs results in a significant computational overhead for the aggregation process at the server-side, rendering more complex methods such as FedMA 53] less appealing, particularly considering the computational challenge of running Hungarian algorithms on billions of parameters. FedAvg-based methods are not only efficient but also well-suited for parallelization, making them effective for aggregating a large number of parameters.
- Recent benchmarking studies [54] indicate that empirically, FedAvg-based techniques often outperform more complex methods across a variety of datasets and FMs.
- Perhaps most crucially, many existing methods incorporate the weighted averaging concept inherent in $\mathrm{Fe}-$ dAvg (e.g., by aggregating only a subset of parameters). These methods shall be discussed in detail in Section IV-D Some studies have demonstrated a preference for FedSGD over FedAvg [30], [38], [47] due to its superior performance, partially attributable to the asymmetric nature of computational and network costs [47].

TABLE V

FL AGGReGation MEthodS

| METHODS | AGGReGATION |
| :--- | :---: |
| FedPAQ [30] | FedSGD |
| SoteriaFL [38]] | FedSGD |
| FwdLLM [47] | FedSGD |
| HeteroFL [31] | FedAvg |
| LotteryFL [32] | FedAvg |
| FjORD [33] | FedAvg |
| H-FL [34] | FedAvg |
| PruneFL [35] | FedAvg |
| FedPM [36] | FedAvg |
| FedTiny [37] | FedAvg |
| FedPrompt [39] | FedAvg |
| FedBERT [40] | FedAvg |
| FedCLIP [41] | FedAvg |
| FedPEFT [42] | FedAvg |
| FedPETuning [43] | FedAvg |
| SLoRA [44] | FedAvg |
| FedOBD [45] | FedAvg |
| FedIT [46] | FedAvg |

## 2) Promising New Techniques:

In traditional FL, there is commonly a trade-off between the complexity, frequency and overhead of aggregation methods and the performance of the resulting global model. Increased complexity and frequency, along with increased overhead, nudge FL closer to distributed learning, where aggregation occurs after every local iteration, leading to low efficiency. Conversely, reducing these factors can enhance efficiency but often results in reduced model performance. With bandwidth being a limiting factor, the significantly larger sizes of FMs tip the balance in favour of simpler aggregation techniques.

Recently, promising studies have emerged, suggesting that simpler aggregation methods can be effective. The concept demonstrated in [55] shows that averaging the weights of several models, each fine-tuned with varying hyper-parameters, can enhance both accuracy and robustness. This finding has notably been observed with large pre-trained models. This phenomenon suggests that aggregating independently trained FMs just once after training might still yield performance improvements. Building on this insight, [56] advocates for the utilization of FMs that have been fine-tuned across a spectrum of tasks, by averaging all the fine-tuned weights to produce the final model. This final model shows enhanced generalization to out-of-distribution data, indicating that averaging FMs, particularly those fine-tuned on disparate local tasks, can be a promising aggregation technique for FedFM.

On the other hand, the potential for more sophisticated aggregation strategies remains. The emergence of Mixture of Experts (MoE)-based language models, exemplified by GLaM [57] and ST-MoE [58], has showcased exceptional capabilities across various tasks. These MoE architectures incorporate a myriad of smaller, specialized sub-models orchestrated by a routing function that aligns with the principle of dedicated local models in FL. The efficacy of MoE models is significantly influenced by their learned routing mechanisms [59]. This concept resembles the aggregation strategies in FL, where local model outputs are synthesized to form a global model. The routing mechanism in MoE could inspire a novel class of aggregation strategies in FL, where dynamic data-driven approaches could allocate model contributions in a similar manner. Exploring aggregation strategies that mirror MoE's routing scheme, adapting it to the distributed nature of FL, could inspire new FedFM model aggregation methods. Such exploration might involve designing algorithms that not only learn from local data but also intelligently decide how to combine local updates to form a robust global model, potentially redefining FedFM aggregation approach as a learned component rather than a fixed rule.

## D. Computationally Efficient FedFM

This section delves into recent advances in training FMs via FL techniques, with a focus on enhancing computational efficiency. Specifically, we examine a set of methods including: 1) Parameter-Efficient Fine-Tuning (PEFT), 2) Prompt Tuning, and 3) Instruction Tuning. These three types of methods have been shown to be feasible.

Traditionally, FL has predominantly involved full model training, a process where all parameters of a model are trained from the ground up. This approach includes strategies for training entire FedFM framework. For instance, [40] explores federated pre-training of models within the BERT family, which can include up to 117 million parameters. As a foundational architecture for many FMs, BERT represents a critical component of this research domain.

Training FMs from scratch in an FL context has demonstrated its potential. However, this approach tends to be less reliable and less effective for models exceeding 100 million parameters. The substantial computation and communication requirements associated with training such larger models significantly constrain the feasibility of traditional full model FL training techniques for FMs. Consequently, the shift from pre-training towards more computationally efficient adaptation methods (e.g., PEFT, prompt tuning, instruction tuning) is promising for overcoming these limitations.

## 1) Parameter-Efficient Fine-Tuning:

PEFT refines FMs by optimizing a minimal subset of model parameters, strategically positioned throughout the model. This approach significantly reduces computational and storage requirements, demonstrating that even large models can be efficiently adapted by tweaking a handful of parameters [60]. A pioneering PEFT technique, adapter tuning [61], modifies pre-trained models with minimal parameter adjustments. It integrates specialized adapters with a bottleneck design between model layers. BitFit [62] selectively updates only the bias terms within FMs, leaving other components unchanged. Low Rank Adaptation (LoRA) [63] updates attention weights through low-rank matrices, thereby minimizing the number of parameters required for training. Typically, the proportion of trainable parameters in such methods is around $1 \%$ of the
entire FM. For instance, conventional fine-tuning of a model like GPT-3 necessitates adjusting approximately 175 billion parameters-a task that is untenable for most industry and academic settings. By employing LoRA and focusing solely on low-rank matrices within each transformer layer, the training process involves just 37.7 million parameters.

Under FL settings, Sun et al. [42] introduced FedPEFT, an innovative approach for fine-tuning FMs. This method freezes the majority of the model weights, focusing on adjusting a minimal subset of parameters tailored to specific downstream tasks. FedPEFT evaluates the efficiency of four distinct PEFT strategies including, Head-tuning, Bias, Adapter and Prompt-in the context of the Vision Transformers (ViT-B) with 85 million parameters. Their findings demonstrate that these targeted fine-tuning methods achieve comparable results to centralized model fine-tuning with non-IID data, while remarkably reducing communication overhead by over $99 \%$. FedCLIP [12] also experimented with an Adaptor-based PEFT method using adapter aggregation even based on FedAvg, showing the better performance than standard FedProx and FedAvg. FedPETuning [43] conducted an extensive benchmark analysis of adapter-based fine-tuning techniques under FL settings. Their findings indicate that both approaches, integrating additional adapters and utilizing LoRA, can achieve comparable accuracy. However, LoRA-based fine-tuning incurs only one third of the communication overhead required by methods involving extra adapters.

The above methods are primarily designed for IID scenarios. Compared to complete fine-tuning, they often result in lower accuracy. In contrast, SLoRA [44] introduced an optimization of LoRA tailored for non-IID FL settings. It employs a ratio to moderate the influence of updates from individual clients, aiming to counteract the drift caused by heterogeneous data distributions. Although it reportedly matches the performance levels of full model fine-tuning, it requires a considerable warm-up period to ensure that all clients share a common initialization of LoRA.

FwdLLM [47] is designed to adapt FMs for use on mobile devices with stricter resource constraints. To address this issue, it integrates Backpropagation (BP)-free training with parameter-efficient training approaches. Rather than relying on traditional back-propagation to calculate precise gradients, the BP-free method introduces minor and self-generating perturbations to these ML model parameters. It then evaluates how these perturbations affect model predictions compared to the original unperturbed model. If a perturbation results in predictions that are closer to the actual labels, it is considered to be guiding the model towards the global optimum. Remarkably, FwdLLM demonstrates substantial performance enhancements, achieving convergence three orders of magnitude faster and reducing the memory footprint by close to 15 times.

## 2) Prompt Tuning:

Prompt tuning is a highly effective strategy for adapting pre-trained models to specific downstream tasks. This technique involves appending natural language texts to either the beginning or the end of inputs or outputs. It aims to guide the pre-trained models towards executing particular functions [64], [65]. Among the various fine-tuning methods, prompt tuning stands out for a variety of benefits, which make them particularly suitable for FL for which computational efficiency and task effectiveness are paramount.

A key significant advantage of prompt tuning is that it often does not require modifications to the FM parameters, thereby markedly lowering computational overhead. Furthermore, in scenarios involving limited training data, skillfully crafted prompts can effectively substitute for hundreds of labeled examples [66], demonstrating its potential to enhance model performance with minimal resources. Prompt tuning specifically focuses on optimizing the likelihood of obtaining a desired output by augmenting the original input with trainable embedded prompts. It is important to note that under FL settings, the desired outputs can differ across FL clients.

FedPrompt [39] introduced an approach that focuses on efficient transmission and aggregation of prompts generated across FL clients. It aims to enhance the performance of a pre-trained model on specific downstream tasks by centrally combining the insights gained from locally generated prompts. Their results highlight the challenges posed by data heterogeneity and the inconsistency of desired outputs across FL clients. It has been observed that such heterogeneity in data distributions and objectives leads to performance decline of $5-10 \%$ compared to models trained in a centralized manner.

## 3) Instruction Tuning:

Instruction tuning is an effective method for improving the functionality and manageability of LLMs [67]. It involves additional training of FMs using pairs of instructions and the corresponding outputs, where an instruction specifies a task for a model and the output represents the expected result in accordance with the given instruction. The appeal of employing instruction tuning for FedFM stems not only from its computational efficiency, which facilitates the quick adaptation of FMs to particular domains. In this way, there is no need for extensive re-training or modifications to the model structure. In addition, it also effectively narrows the divergence between FMs' inherent next-word prediction goals and the actual user intent, aligning with the aim of personalized FL [27]. This approach also leads to more consistent and predictable model behaviors. Through instruction-based fine-tuning, models are more closely guided in output generation, ensuring alignment with user expectations and enhancing overall controllability.

FedIT [46] explores the application of instruction tuning to the LLaMA-7B model under FL settings, catering to a variety of client-specific tasks simultaneously. Similar to methods discussed previously, FedIT also applies LoRA for fine-tuning FMs and leverages FedAvg for aggregating LoRA parameters. A distinctive aspect of FedIT is its utilization of structured instruction-output pairs for fine-tuning FMs. The findings from their study indicate that federated instruction tuning, offers substantial benefits over centralized training approaches. This demonstrates its potential to enhance model performance effectively, even in the presence of task diversity.

## E. Communication Efficient FedFM

The complexity of FMs directly translates to inflated communication overhead between FL clients and the FL server in FedFM, hindering efficient collaboration. Although as discussed in Section IV-D it is not always necessary to transmit an entire FM, fine-tuning billion-parameter FMs by adapter still requires the transmission of millions of parameters. This highlights the need for communication efficient FedFM research. In this section, we highlight two primary strategies for enhancing efficiency: 1) model pruning and 2) model compression.

## 1) Model Pruning:

Model pruning aims to identify and retain only the essential parts of the model for a specific purpose. An early model pruning approach is HeteroFL [31], which aims to accommodate heterogeneous model architectures within FL by adaptively distributing sub-networks suited to the capacities of individual clients. It selects and aggregates subsets of the global model, pruning of a large model into a variety of smaller more manageable models in effect. FjORD [33] implements ordered dropout, a technique that organizes knowledge within a deep neural network in a structured and hierarchical manner. This allows for the extraction of compact sub-models without retraining. Ordered dropout enhances computational efficiency by dropping model components in sequence rather than at random, aligning with the optimization capabilities of contemporary linear algebra libraries. The approach is complemented by a self-distillation process to refine the model further.

Building on these foundations, PruneFL [35] proposed a two-stage model pruning process specifically designed for FL environments. Initially, a "warm-up" phase involves selecting a single capable and trusted client to prune the model using its local data, thereby starting the FL process with a streamlined model. In the subsequent "adaptive pruning" phase, the server periodically adjusts the model by removing or reintroducing parameters over multiple iterations. FedPM [36] adopts a strategy inspired by the lottery ticket hypothesis for model pruning. Rather than utilizing a pruned model as an initial point, it initializes the random binary mask guided by the common seed for all clients. At the end of each round of FL training, clients return their binary masks to the server. The server then constructs a global model by computing a weighted average of these masks. FedTiny [37] follows a similar approach to PruneFL, but with a novel initialization step. It utilizes batch normalization values from clients' data as the basis for selecting a shared initialization, thereby enhancing adaptability to diverse client data distributions.

## 2) Model Compression:

Another approach for improving the communication efficiency of FedEM is through model compression. Unlike pruning which typically removes or masks unnecessary parameters without changing model structures, compression involves transforming the model structure or using quantization and coding techniques to represent the model more compactly 1[^0]

Deep models often operate with full precision (32-bit), but in practice such high degree for computation may be not always necessary. FedPAQ [30] leverages this fact to reduce communication overhead. Note that dynamic quantization only benefits communication. Depending on the infrastructure, the model updates might need to cast back to full precision, thereby incurring additional computational burden. SoteriaFL [38] strikes a balance among privacy, convergence accuracy and communication efficiency. For model compression, it utilizes a straightforward algorithm, CDP-SGD, which effectively integrates communication compression with DP-SGD for enhanced efficiency.

H-FL [34] addresses the challenges posed by the statistical heterogeneity of client data, which often leads to performance degradation in FL models. A notable aspect of its design is the utilization of lossy singular value decomposition (SVD) [69] applied to the feature matrix for model compression. While this technique enables efficient data representation, it compromises model accuracy. To counteract this, H-FL incorporates a bias correction mechanism that is activated prior to each FL training round on the client side. It is designed to adjust the gradients of features affected by the lossy compression. This corrector comprises of multiple fully connected layers, which are sequentially arranged and whose parameters are dynamically updated based on the SVD outcomes of the features extracted from the initial, shallow model layers.

FedOBD [45] segments a large model into semantic blocks. It enables FL server and clients to selectively exchange quantized blocks. This strategy assesses the importance of blocks over individual parameters, enabling the selective omission of less critical blocks to significantly reduce communication overhead, while preserving model performance. In addition, FedOBD incorporates the advanced Adaptive Deterministic Quantization for Neural Networks (NNADQ) to further improve communication efficiency. Results show that it can achieve a two-fold reduction in communication costs compared to FedPAQ, highlighting its potential in improving communication efficiency for FedFM.

## V. TowARdS TRustWortHY FedFM

Attacks and defenses on traditional FL process have been extensively studied [70]. In this section, we review selected studies on robustness and privacy issues in FL, and point out the potential new changes or challenges FedFM could bring about. We further break down each domain into specific areas as shown in Fig. 3.

## A. Robustness of FedFM

There are numerous studies on robust FL, among which the robustness against poisoning attacks launched by Byzantine clients is the main focus. Diverse poisoning attacks that exploit vulnerabilities in FL and various Byzantine-robust FL schemes have been proposed.

1) Poisoning Attacks:

FL poisoning attacks aim to compromise either the global model or the training process. They can be divided into

![](https://cdn.mathpix.com/cropped/2024_06_04_322e01caebc2cdbc0f4cg-11.jpg?height=689&width=1808&top_left_y=249&top_left_x=161)

Fig. 3: Taxonomy for trustworthy FedFM techniques consisting of two main domains: 1) Robustness and 2) Privacy, each of which is further divided into specific strategies that address the challenges of FedFM.

two categories: 1) untargeted attacks and 2) targeted attacks, based on whether the attacks aim to disrupt global model convergence or manipulate the model outputs.

Untargeted Attacks: They are often launched by attackers to prevent the FL model from achieving convergence. Specifically, the attackers could craft and submit local models that introduce significantly high variances if aggregated into the global model, perturbing and even blocking it from being optimized towards the global optimum. An example is the Gaussian attack, in which poisoned model parameters are randomly sampled from a Gaussian distribution. Various advanced poisoning sample generation algorithms [71]-[75] usually aim to craft samples in training datasets to make the models achieve maximum validation losses.

However, achieving the objective of such attacks can be challenging in FedFM, due to the large sizes and high local heterogeneity of FM training tasks. Firstly, to achieve validation loss maximization, an attacker needs to repeatedly train a local shadow model to form a differentiable poisoning sample optimization objective. This is infeasible in FedFM considering the huge costs introduced by FMs. Secondly, the local ML tasks can be heterogeneous, making it hard for such attacks to compromise global FM convergence or performance.

Targeted Attacks: They are usually utilized by attackers to manipulate the specific global model outputs, while maintaining its benign performance. During the training phase, the attackers inject crafted poisoned samples into the training dataset, which can perturb the decision boundaries of the model within a small sub-space, resulting in missclassifications. These perturbations usually depend on the victim model's overfitting the trigger patterns on benign inputs. Various trigger generation schemes [76]-[78] have been proposed to make attacks stealthier. Targeted attacks on FL [79], [80] have been proposed to elevate the survivability and utility of the attacks.

Under FedFM settings, the reliance on contextual inputs (i.e., in-context learning) makes the prompts given by the trainer play a significant role in FM training. This can be a potential vulnerability to be exploited by targeted attacks. Various prompt-based targeted poisoning attacks against language models [81]-[83] have been proposed, which could also threaten the integrity of FedFM.

Defending against targeted attacks is more challenging under FedFM settings. Specifically, due to the high complexity of FM training tasks, the poisoned input that triggers the FM misbehavior is more stealthy. Existing backdoor detection approaches [84], [85] mainly rely on generating cross-category sample transfer shortcuts via optimization, given the model and total number of categories. However, the ML tasks for FMs introduce a enormously high level of complexity (e.g., millions of image classification categories), making existing defense mechanism against targeted FL attacks intractable.

## 2) Byzantine-Robust Local Model Aggregation:

To defend against FL poisoning attacks, the FL server usually adopts Byzantine-robust aggregation rules to ensure poisoned local model updates are excluded from model aggregation. Such aggregation rules can be divided into three categories: 1) geometrical outlier detection, 2) top performance selection, and 3) other hybrid schemes.

Geometrical Outlier Detection: These schemes discard local model updates which are regarded as geometric outliers, and only aggregates the remaining ones to form the global model. Some approaches [86] calculate the Euclidian distances among local model updates to determine the divergences among them, and remove those with the highest degree of heterogeneity from the majority. Others [87] analyze the parameter-wise geometrical divergence, removing the smallest and largest values of the same parameter of all model updates, and only aggregating the remainders to produce the final corresponding parameter in the global model.

However, these schemes are not compatible with FedFM.

Specifically, due to the significant multi-modality of local models and high levels of heterogeneity among local data distributions, there might be significant natural geometric divergence among benign local model updates, sometimes even making them geometrically incomparable. Besides, the huge scales of FMs also make the calculation of divergence computationally intensive. Hence, for FedFM, existing defenses against FL poisoning attacks from Byzantine clients might not be effective.

Top Performance Selection: These schemes require a clean validation dataset to be stored by the central FL server to evaluate each local model update from the clients, selecting and aggregating the ones with top performance. Some schemes [88], [89] choose to aggregate the local model updates that contribute the largest validation loss reduction. Others [90] choose to aggregate the local model updates that contribute the largest accuracy improvement.

However, these schemes might not be feasible under FedFM settings. Specifically, due to the significant heterogeneity of local training tasks, benign local model updates might also show sub-optimal perform on the validation dataset. It can be challenging to construct a validation dataset due to the currently unclear evaluation metrics for FM performance. The huge scales of FMs and the corresponding datasets also make effective evaluation of local model updates costly.

Other Hybrid Schemes: Research works have emerged [91]-[93] in an attempt to form hybrids schemes to take advantages of the aforementioned by combining them together. These works often update a benchmark model with a central clean dataset, and lower the weights assigned to local model updates that significantly deviate from the benchmark (or even discard them completely) during aggregation. Although these methods have achieved superior robustness, they have also inherited the limitations from the aforementioned categories of approaches which make them incompatible with the FedFM settings.

## B. Privacy of FedFM

Privacy preservation has always been an important focus of FL research. A wide range of privacy attacks have been studied and potential defenses have been proposed.

## 1) Privacy Attacks:

Privacy attacks in FL are generally designed to access the victim client's private information given based on auxiliary information essential for FL model training (e.g., the victim's local model updates or gradients). They can be divided into two categories: 1) membership inference attacks, which attempt to infer the involvement of a specific data sample in FL training, and 2) data reconstruction attacks, which attempt to recover a victim client's original training data.

Membership Inference Attacks: They aim to infer whether a specific data sample is in a victim client's local training dataset, which can be used to infer about the victim's private information such as identity for instance. Specifically, with a victim client's model (white box) or a trained shadow model that imitates it (black box), the attacker could train an attack model that infers whether a data sample belongs to the victim's local dataset. Schemes like [94]-[96] under black box settings usually train several shadow models with datasets partitioned in a variety of ways into training and validation sets. Then, correspondingly labeled as in (indicating used for training) and out (indicating not used for training), training and validation data, together with their predictions/logits, form the training dataset for the attack models. Recent studies have proven that such attacks can work on generative models (e.g., diffusion models [97]), demonstrating the potential risks of membership inference attacks on FedFM.

However, the reliance on the original victim or shadow model makes this category of attacks difficult to implement under FedFM settings. The significant scale of FMs and the highly restricted external access to FMs (black box nature) make existing membership inference attacks designed for FL intractable for FedFM. Nevertheless, recent studies [98] have proposed membership inference attacks which do not rely on a shadow model against prompt-based LLMs. Therefore, the threat still exists.

Data Reconstruction Attacks: These attacks aim to reconstruct the actual training data used from a victim client's model. Through various optimization methods (e.g., model inversion, gradient matching, adversarial training), an attacker can generate data samples that are close to the original ones in the victim's training dataset. Schemes based on diverse techniques (e.g., gradient matching [99], [100], GAN [101]) have been developed and demonstrated to be effective under the traditional FL settings.

Due to the large sizes of FMs, data reconstruction attacks on FedFM can incur significantly costs. However, recent studies show that in various FM training scenarios, the model's superior ability of information representation and frequent model-client interactions can lead to privacy leakage, making data reconstruction attacks feasible. With specifically crafted prompts, FMs could generate sensitive feedback [102]-[104], from which the attackers can gain access to private information about the training datasets.

## 2) Potential Defenses:

A wide range of defenses against privacy attacks in traditional FL settings have been proposed to preserve clients' data privacy. The mainstream schemes are generally designed to make trade-offs between knowledge integrity and privacy guarantees. Specifically, through model perturbation or compression techniques (e.g., differential privacy, confidence masking, model compression/sparsification), clients can reduce the risk of exposure of local private information through model parameters, while avoiding significantly negative impact on model performance.

By adding statistical noises to the shared local model updates, differential privacy techniques can provide guarantees on privacy preservation to different extents [105]-[107]. The trade-off between privacy preservation and model performance has been widely studied, with Game Theory often being leveraged to constrain the variance of the noises added to the model while compensating the privacy risks of clients through incentive mechanisms [108], [109]. The difficulty of

TABLE VI

Summary of THE Main Categories of InCEnTive MECHANiSMS In FL

|  | GENERAL <br> OBJECTIVES | APPLICATION <br> SCENARIOS | MAIN <br> ADVANTAGES | MAIN <br> DISADVANTAGES | RELATED <br> WORKS |
| :---: | :---: | :---: | :---: | :---: | :---: |
| Contract <br> theory | Maximizing the clients' key <br> performance indicators | Scenarios with complete infor- <br> mation asymmetry | Efficient resource- <br> based reward | Reliance on traditional <br> optimization methods | $115-$ |
| Game <br> theory | Finding equilibrium solutions <br> among participants to achieve <br> utility maximization | Scenarios where interactions <br> among participants are complex | Efficient handling of <br> multifaceted goals | Prolonging training time | $120,121,123-131$ |
| Auction <br> mechanism | Maximizing the social welfare | Scenarios with high competition | Fairness \& efficiency | May lead to dishonest <br> behaviors | $132-153$ |

recovering private local data could be further enhanced by incorporating mechanisms of gradient/model compression and sparsification [110]-[113]. Due to the tension between model performance and degree of compression, the trade-off between performance and privacy is also an important topic of study [113], [114], aiming to find potentially optimal solutions of privacy guarantee with limited impact on performance.

Due to their simplicity and flexibility, the approaches mentioned above are compatible with FL schemes with various modalities and scales. Hence, they could be promising solutions to addressing privacy issues under FedFM settings.

## VI. TowardS Incentive MECHANISMS FOR FedFM

The remarkable success of FL depends on clients (a.k.a., data owners) actively engaging during the training process. In reality, data owners might hesitate to join FL without proper compensation, especially if it involves significant commitment of local resources for training FMs. Thus, developing robust incentive mechanisms is imperative to motivating clients to participate in the FedFM training process, while deterring misbehaviours through punitive measures. Table VI provides an overview of existing incentive mechanisms in FL.

## A. FL Incentive Mechanisms

Contract theory, game theory and auction mechanism are three widely adopted techniques in FL incentive mechanism design. Thus, we review and discuss existing works based on these three categories.

## 1) Contract Theory-based Methods.

To address the information asymmetry issue, [115] devised an incentive mechanism categorizing FL participants based on data quality and compute resources, offering rewards based on contributions. FL participants select contracts to maximize profits, facing penalties for failures to meet the terms. This approach attracts high-quality data owners, enhancing FL performance and optimizing incentive payouts. Compared to Stackelberg game-based methods [116]-[118], it is more adaptable to asymmetric information.

However, [119] noted limitations in existing techniques [115], [120], [121], which only allowed the FL server to make decisions based on a single dimension of consideration. They proposed a two-dimensional incentive scheme considering training costs and communication delays, dealing with incomplete information regarding heterogeneous device networks. FL clients offering specific training data sizes and timely updates are selected, with penalties for non-compliance. Their method can effectively deal with a weak level of information asymmetry. However, strong information asymmetry challenges server decision-making, potentially leading to incentive mismatches.

## 2) Game Theory-based Methods:

Stackelberg Game-based Methods: In FL, direct communication between the server and clients for exchanging model parameters has been identified as a source of inefficiency. To tackle this issue, [121] proposed a relay network to construct a communication platform, introducing a Stackelberg game to analyze the interaction between clients and the server. This game involves decisions about transmission power and relay node selection due to wireless network interference. In [120], the emphasis is placed on fair treatment of clients, recognizing potential selfish behaviours. They addressed challenges in synchronous batch tasks, introducing an incentive scheme to reduce time delay through a Stackelberg game. Another contribution by [123] focused on enhancing communication efficiency by a crowdsourcing framework. They employed a two-stage Stackelberg game to model the interaction between mobile edge computing (MEC) servers and clients. Rewards are determined based on local model accuracy. Building on these works, [124], [125] extended Stackelberg game-based FL incentive mechanisms to model interactions in edge networks. The server acts as a leader offering a reward, motivating clients to perform more FL training rounds to improve model accuracy. [126] criticized existing incentive schemes for privacy burdens on the FL server. They proposed a twostage Stackelberg game to ensure privacy with a specialized budget. Users can strive towards optimizing utility under a given privacy budget. In [127], a distributed market model involving IoT devices, MEC operators and a cloud operator was introduced. It leverages Stackelberg game to optimize revenue and energy consumption. These studies highlight the importance of incentive design, privacy preservation, and efficient communication in FL, demonstrating the potential of Stackelberg games in optimizing server-client interactions.

Yardstick Competition-based Methods: Stackelberg game-based approaches tend to be time-consuming [128]. To address this, [128] introduced a novel yardstick competition scheme, aiming to reduce training time in synchronous stochastic gradient descent. The yardstick serves as a benchmark, calculating acceptable delay with rewards being determined based on client deviations from it. However, this approach estimates delay solely based on CPU power without
considering communications related factors.

Shapley Value-based Methods: In [129], a two-phase framework incentivizing edge servers in a collaborative cloudedge-device setting was proposed. It leverages Shapley Value (SV) to distribute rewards based on edge server contributions. However, it does not incentivize data-contributing devices. SVbased methods [154] can assess contributions by FL clients, but often incur high computation costs. To address this issue, [130] introduced the Contribution Index (CI) based on SVs. It is effective but only applicable to horizontal FL settings.

Temporal Incentivization: In [131], the Federated Learning Incentivizer (FLI) was designed to address delays in compensating FL contributors. FLI is a real-time payment algorithm. It emphasizes fair treatment and efficient budget allocation. Compared with contemporary schemes, FLI is able to deal with practical FL scenarios in which the revenue generated by the FL model is gradually received and disseminated among contributors in a post-hoc fashion.

## 3) Auction-based Incentivization:

Reverse Auction-based Methods: Approaches based on reverse auction aim to help the server select clients in a monopoly market to maximize its utility [141]-[150]. They often leverage techniques such as reputation, blockchain, deep reinforcement learning, and graph neural networks. Moreover, they are typically tailored for monopoly markets, where there is only one server (i.e., data consumer) and multiple clients. For example, RRAFL [146] incorporates reputation and blockchain into a reverse auction. The data consumer publicizes its FL task, and clients bid for it unde RRAFL. The data consumer then determines the winning clients based on their reputation values, which are derived from their data quality and reliability track records in a blockchain.

Forward Auction-based Methods: Methods in this category study how multiple data consumers shall bid for the same pool of clients to maximize their utility [151]-[153]. In [151], an optimal bidding function was proposed for data consumers, considering not only their limited budgets and the suitability of clients, but also prior auction-related knowledge such as the distribution of clients and the probability of winning the ongoing auction. It demonstrates that the estimation of client utility and the appropriate winning function significantly impact the optimal bidding strategy.

Double Auction-based Methods: FL incentive mechanisms based on double auction generally aim for social welfare maximization, social cost minimization or maximizing all servers or clients utility [132]-[135]. They facilitate optimal client-server matching and pricing, and are applicable in cases where there are multiple FL servers and multiple FL clients. For example, in [133], an iterative double auctionbased method for computing resource trade was proposed to achieve social welfare maximization. The method alternates between optimizing three objectives, while adhering to pricing rules to determine the winners and pricing.

Combinatorial Auction-based Methods: Similar to those based on double auction mechanisms, methods based on combinatorial auction mechanisms also aim to maximize social welfare, minimize social cost and maximize the utility of all involved FL servers or clients [136]-[140]. They are suitable for scenarios in which FL clients sell resources in the form of packages, and FL servers compete for these packages. For instance, in [140], a multi-round sequential combinatorial auction model was adopted to allocate clients with limited resources to servers with heterogeneous resource requirements. In this approach, servers sequentially publicize their resource requirements and bidding values for different clients. The client-server matching and payments are then optimized.

## B. Discussions on FedFM Incentive Mechanisms

It is worth noting that the current incentive mechanisms primarily emphasize participant selection based on a datacentric approach in traditional FL settings. Specifically, the FL server determines participant recruitment by assessing the characteristics of the data held by the candidates. Nevertheless, given the expansive scale and nuanced execution specifics of FedFM, it might be beneficial for FedFM to adopt a model-centric approach for participant selection, selecting participants based on the characteristics of their models. In the next section, we envision promising approaches for designing effective incentive mechanisms for $F e d F M$ from three interconnected and critical directions (as shown in Fig. 4p: 1) participants selection, 2) contribution evaluation, and 3) reward distribution.

## C. FedFM Participant Selection

The model selection process in FedFM encompasses two critical dimensions: 1) horizontal fitness for task-specific training and 2) vertical capability for training.

1) Horizontal Fitness for Task-Specific Training:

The horizontal dimension, addressing the fitness of taskspecific training, entails the selection of a model that meets the training requirements for various tasks. Given the huge scale of typical FMs, direct training from scratch can be challenging. Consequently, a strategy of pre-training followed by finetuning is commonly adopted. Typically, techniques such as LoRA [63] are applied for fine-tuning the pre-trained model to align with downstream tasks, which might turn out to be diverse (e.g., NLP, computer vision). In this context, the pretrained FM should be robust and flexible enough to adapt to various downstream tasks. To achieve this goal, it is necessary to select a mixture of FMs hosted by FL participants based on their task training abilities. To this end, it is crucial to gain insight into the relationships among participants as well as the relationships between participants and the training tasks.

Relationships among Participants: There are two types of relationships among participants: 1) the substitute relationship and 2) the complementary relationship. In the context of FedFM, a substitute relationship between two participants implies that the model or contribution of one participant can be substituted by those of another, without significantly affecting the overall performance or objective of FedFM. It suggests a degree of similarity or equivalence in the roles of the

![](https://cdn.mathpix.com/cropped/2024_06_04_322e01caebc2cdbc0f4cg-15.jpg?height=450&width=1808&top_left_y=187&top_left_x=148)

Fig. 4: Illustration of challenges faced by incentive mechanism design in FedFM.

two participants in FedFM. The complementary relationship among participants in FedFM refers to a situation where the contributions, capabilities or characteristics of different participants complement each other, thereby enhancing the overall performance or effectiveness of FedFM.

To effectively manage various participants based on their relationships, clustering can adopted, drawing inspiration from their successful application in conventional FL 155. In particular, according to the relationship among participants, they can be grouped into clusters, with substitute participants assigned to the same cluster while complementary participants assigned to different clusters. Then, in the participation selection process, multi-agent mechanisms [152] could be leveraged with each agent assigned to help manage a cluster, in order to achieve the target performance goals for FedFM.

Relationships between Participants and Training Tasks: With FMs pre-trained on publicly available datasets with general knowledge, the significance of uniqueness of local data and domain-specific knowledge of each FedFM participant becomes important for enhancing domain-specific FM performance. To effectively manage the relationships among participants and training tasks, a possible approach is to adopt a combination of relationship networks, reputation systems, blockchains, and graph neural networks:

- Graph Neural Networks (GNNs) [156]: GNNs offer powerful means to model the complex interconnections among participants, their local data, domain expertise, and the target tasks or domains. Through encapsulating these intricate relationships, the network can discern the relevance and synergies among participants' contributions to particular domains or tasks. Leveraging this insight, strategies for knowledge transfer, model personalization, and resource allocation can be orchestrated, thereby maximizing the utilization of participants' distinct data and expertise to boost domain-specific FedFM performance.
- Reputation Systems [146], [152]: A reputation system can incentivize participants to contribute high-quality, domain-specific data and knowledge to the FedFM training process. Participants can earn higher reputations by consistently providing valuable contributions, which, in turn, can grant them increased training resources, greater influence over global model updates, or preferential access to personalized domain-specific models.
The tracking of participants' reputation can be facilitated by blockchains [146], which support transparency, immutability and decentralization. This encourages participants to curate and share their most relevant and unique local data, ultimately benefiting the performance of domain-specific FedFM.


## 2) Vertical Capability for Training:

The vertical dimension, focused on the ability to train, entails selecting a mixture of model components that can be assembled into a coherent FM. A large-scale FM can be divided into various components based on the role of each of them. These components can be combined together through techniques akin to conventional FL. For instance, in heterogeneous FL, the local model of each participant can be segmented into two primary parts: the feature extractor and the classifier [157]. The feature extractor maps the input data into the latent space representation, while the classifier translates these representations into output logits.

In [158], [159], FedLEGO was proposed to address model heterogeneity issues in conventional FL. It treats participants' local models as a LEGO toy, disassembling them into bricks by layers. Subsequently, FedLEGO reassembles these bricks into new model structures. Drawing inspiration from heterogeneous FL, we envision that FM construction can be performed similar to LEGO, where it can consist of various functional building blocks hosted by diverse FedFM participants to be assembled together. We envision a multi-step approach for FedFM model training through layer-wise decomposition, functionwise layer grouping, reassembly candidate generation, and candidate stitching.

- Layer-wise Decomposition: Initially, the FedFM model is disassembled into layers, focusing on the operation type of each model component. This step aims to identify the layers and their corresponding operation types within the FMs.
- Function-wise Layer Grouping: Subsequently, in the function-driven layer grouping step, these layers are grouped based on their functional similarities. Utilizing K-means style algorithms, these layers can be clustered together based on their functional attributes.
- Reassembly Candidate Generation: The reassembly candidate generation step involves assembling various functional candidates by combining the learned layer
groups based on their functions. This step results in multiple functional candidates with diverse configurations.
- Candidate Stitching: Finally, the functional candidates are stitched together to form various FMs tailored to specific downstream tasks. This approach enhances the adaptability and flexibility of FedFM, allowing for the construction of task-specific FMs by reassembling learned functional components.

This envisioned modular approach can enhance the flexibility and adaptability of FedFM. It allows for the construction of diverse model configurations tailored to specific tasks or requirements. This Lego-inspired approach can be promising in dealing with model heterogeneity, promoting collaborative learning in FedFM settings.

## D. FedFM Contribution Evaluation

Participant contribution evaluation is crucial to the success of FedFM for the following reasons. Firstly, the intricate non-linearity and complexity of FedFM pose a challenge for stakeholders to understand the internal working mechanisms and decision making processes. This lack of transparency can diminish trust and impede adoption, especially in safetycritical sectors like finance and healthcare [160]. Secondly, the evaluation of FedFM contributes to an enhanced understanding of their strengths and weaknesses. For instance, the PromptBench benchmark [161] demonstrated that existing FMs are sensitive to adversarial prompts, thereby emphasizing the importance of prompt engineering for better model performance.

Contribution evaluation in FedFM is more challenging compared to the current approaches for centralized FMs or traditional FL. Firstly, different from centralized FM evaluations, FedFM cannot directly assess the quality of the training data used due to privacy protection requirements. Secondly, FedFM evaluation is limited by the resource constraints in terms of communication power and local computation of the FL clients involved. Thirdly, compared to traditional FL, FedFM evaluation can involve a large number of sequences, resulting in insufficient test coverage [162].

There are a number of existing evaluation methods for traditional FL and centralized FMs, but few for FedFM. In this section, we discuss existing evaluation methods and envision promising research directions for designing new FedFM evaluation protocols. We present approaches which cover relevant works to evaluate the model performance, analysis the decision results, and provide insights into the contributions of individual participants and datasets.

## 1) Contribution Evaluation for Traditional FL:

## Client and Sample Contribution Evaluations:

The performance of the global FL model highly relies on the quality of the local dataset. Client and sample contribution evaluation can help the FL server analysis this through tracing back to local data, and is important to model aggregation. FL client and sample contribution evaluation methods can be divided into two main categories: 1) Shapley value (SV)-based evaluation and 2) influence-based evaluation (Table VII).
Shapley Value-based Evaluation: SV-based evaluation methods provide insights into FL clients' data via evaluating their contributions to the performance of the final FL model. Existing SV-based evaluation methods mostly focus on improving computational efficiency, while maintaining accuracy performance of the estimated SV. The original SV method is prohibitively expensive since the required utility function evaluation grows exponentially with the number of FL participants.

Existing FL evaluations based on efficient SV calculation can be divided into two categories: 1) accelerating withinround evaluations, and 2) decreasing the number of rounds of sub-model evaluation. For the accelerating within-round evaluation approach, instead of re-training them from scratch, gradient-based SV [163] and local embedding-based SV [164] methods have been proposed to reconstruct sub-models. For the decreasing the number of rounds of sub-model evaluation approach, three popular methods have been proposed. The first evaluates every possible sub-model within the original SV setting based on gradient-based estimation [130], [165]. The second method leverages randomly sampled permutation evaluation [166], [167] which produces the estimated SV of an FL participant as its expected contribution. However, since the number of selected permutations is fixed, potentially important permutations may be overlooked, leading to inaccurate estimation. Thus, the third approach [168], [169] combines the within-round and between-round truncation approach and the guided Monte Carlo sampling and in order to prioritize submodel permutations based on their importance.

Another branch studies the problem of secure SV calculation under malicious settings. In [170], a two-server secure SV calculation protocol was designed, which leverages a hybrid scheme to avoid ciphertext-ciphertext multiplications. Another work [171] designed a group-based SV computation scheme leveraging a blockchain-based secure aggregation framework in order to protect participants' data privacy.

Influence-based Evaluation: Although SV-based FL client and sample contribution evaluation consider the complex dependencies among clients, they are generally highly expensive to compute. Influence-based FL contribution evaluation methods have been proposed to efficiently evaluate the contribution of FL clients and their local data samples on FL model performance. Existing influence-based methods can be divided into two main branches. The first [172], [173] perturbs clients or their local samples to retrain FL models, and uses the difference in performance (e.g., test loss, test accuracy) between the new and the original model to approximate client or sample contribution. However, since this method requires retraining of FL models on all clients' datasets or individual samples, the evaluation procedure is prohibitively expensive [174, 175.

The second category uses influence function methods 175 that leverage the second-order optimization technique to avoid the expensive retraining. An early approach leveraging influence functions in client contribution evaluation is Fedinfluence [176]. To measure the influence of a client, Fedinfluence sums up all sample influence values since there is

TABLE VII

SUMmarY of EVALUATIONS OF TRaditional FL ModeLS

| Evaluations of <br> Traditional FL Models | Detailed Methods <br> $\checkmark$ : suitable | STAKEHOLDERS |  | THREAT <br> MODELS |  | PRIVACY <br> PROTECTION <br> TARGETS |  |  | PRIVACY <br> PROTECTION <br> TECHNIQUES |  |  | EFFECTIVENESS <br> METRICS |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  |  | S1 | $\overline{S 2}$ | $\overline{\mathrm{A} 1}$ | $\overline{\mathrm{A} 2}$ | $\mathrm{P} 1$ | $\overline{\mathrm{P} 2}$ | $\overline{\mathrm{P} 3}$ | T1 | $\mathrm{T} 2$ | T3 | E1 | E2 |
| Client \& Sample <br> Contribution Evaluation | Influence-based | $\checkmark$ |  | $\checkmark$ | $\checkmark$ | \begin{tabular}{llllll}
\end{tabular} |  |  | $\checkmark$ |  |  | $\checkmark$ |  |
|  | Shapley value-based | $\checkmark$ | $\bar{\checkmark}$ | $\checkmark$ |  | $\bar{\checkmark}$ |  |  | $\checkmark$ | $\checkmark$ |  | $\bar{V}$ | $\bar{\checkmark}$ |
| Feature Contribution <br> Evaluation | Model-Agnostic |  | $\checkmark$ |  |  |  |  |  |  | $\checkmark$ | $\checkmark$ | $\checkmark$ |  |
|  | Model-Specific |  | $\checkmark$ | $\checkmark$ |  |  |  | $\checkmark$ |  | $\checkmark$ |  | $\checkmark$ |  |
| S1: To FL Ser <br> S2: To FL Clie | A1: Semi-Honest Part <br> A2: Malicious Partici\| |  | P1: Raw Dati <br> P2: Data Dist <br> P3: Label |  | T1: <br> T2: <br> T3: | mnon | Pmit | ncry | 的 | E1: Post-Interpretation Performan <br> E2: Faithfulness |  |  |  |

an additive property of the influence function when measuring changes in test predictions [177]. However, this approach requires clients to calculate the inverse of the Hessian matrix and transmit it, which incurs large computation and communication overhead. To reduce the overhead of influence approximation, emerging methods [174], [178]-[180] leverage the Hessian vector product to approximate the influence values. They are capable of achieving the linear operation costs, making them promising for practical adoption.

## Feature Contribution Evaluation:

Model-Agnostic Evaluation: These methods consider an FL model as a black-box and attempts to measure the relevance of each feature to the learning task to filter out irrelevant ones. They leverage various statistical measures (e.g., mutual information, F-statistics, Gini-impurity [181]-[183]) to compute per-feature relevance scores. Another branch of methods use efficient gradient-based SV estimation approaches for feature contribution evaluation [172], [184]. However, they methods require the FL server to familiarize all the IDs of clients' features, which might violate clients privacy and make them unsuitable for practical vertical FL applications.

Model Specific Evaluation: The utilization of attentionbased evaluation method enables the server to interpret which specific parts of inputs are leveraged by the global FL model. In [185], a hierarchical attention mechanism is proposed which develops task-specific attentions to access personal feature correlations. Besides, a temporal attention layer is designed to evaluate cross-client temporal correlations at the FL server level. The final visualization of the attention weights is used to determine which features the global model focuses for individual predictions. Another work, Flames2Graph [186], offers a personalized evaluation approach for the multivariate time series FL classification issue, which can extract and visualize the essential sequences that highly activate network neurons to capture the temporal dependencies among them. Furthermore, [187], [188] proposed a federated feature selection method, which introduces a Gaussian stochastic dual-gate based on the $l_{0}$ constraints to efficiently and privately approximate the probability of selected feature.

## 2) Contribution Evaluation for Centralized FMs:

Existing evaluation approaches designed for FMs can be divided into: 1) model-based evaluation, and 2) training databased evaluation.

## Model-based FM Evaluation:

The initial objective of language models, particularly FMs, is to enhance language processing task performance (e.g., inference accuracy, robustness, trustworthiness). There are two common evaluation methods for FMs: 1) automated evaluation, and 2) human evaluation.

Automated Evaluation: Automated evaluation of FMs commonly adopts standard indicators or metrics and evaluation tools to assess model performance. These include accuracy, fairness, ROUGE [189] and BERTScore [190]. For instance, the BLEU score 191 has been leveraged to measure the similarity and quality between the text generated by the FM and the reference text by the machine translation task. Due to its simplicity and automatic computing, this evaluation metric is widely adopted by existing FM evaluation effort. In addition, with the deployment of FMs, more advanced automated evaluation approaches are emerging. For example, Lin et al. [192] proposed a unified multidimensional automated evaluation approach, LLM-EVAL, for domain conversations. PandaLM [193] trained an additional LLM to evaluate different models, which is suitable for reproducible and automated language model evaluation.

Human Evaluation: Human evaluation aims to assess the quality and accuracy of FM-generated results by human participation. Different from automated evaluation, human evaluation focuses more on specific application scenarios and can provide more comprehensive results. Usually, evaluators consist of experts, researchers or the target users. Recent human evaluation methods involve tasks including generation, summarization and analogical reasoning tasks. Bubeck et al. [194] conducted various human-crafted tests on GPT-4. It can be observed that GPT-4 performs close to or even exceeds human performance on various tasks. In practice, automated evaluation and human evaluation are considered for adoption on a case-by-case basis.

## Training Data-based FM Evaluation:

During fine-tuning, the training data might not be equally important for a pre-trained FM. On the one hand, pre-trained FMs are prone to significant performance degradation with noisy data. This effect can be further amplified when noisy samples are highly influential to the model. On the other hand, specific knowledge embedded within some samples might have been extracted after several training rounds. Therefore,
they can be ignored afterwards without affecting final finetuned model performance. Therefore, it is important to identify noisy samples and important samples in the fine-tuning data to improve training efficiency and model performance. Jain et al. [195] evaluate FMs from the data-based perspective by eliminating the need for laborious labeling of new data. In [196], an efficient SV-based data evaluation method has been proposed. It achieves this design goal through an efficient sampling-based method that aggregates SV values calculated from subsets for valuation of the entire training set, and a value transfer method that leverages value information extracted from a simple classifier trained by representations. DataInf [179] is a computationally efficient influence approximation method that is based on an easy-to-compute closed-form expression. It can be easily applied to FMs.

## 3) Contribution Evaluation for FedFM:

As for evaluating FedEM, so far, there have been few relevant works. The work [197] proposed a logic rule learning approach to select the optimal chain-of-thoughts prompts for improving the interpretability of federated prompt selection for multi-domain FMs. They cast this problem as a bilevel program, and solve it through variational expectation maximization. The work [198] proposed to evaluate FedFM by comparing the performance of the federated parameterefficient fine-tuned model with traditional centralized finetuning methods. FedIT [199] leverages FL framework for FM instruction tuning and conducted studies on the widely used GPT-4 to exploit the heterogeneous and diverse sets of instructions. FedNLP [200] is a benchmark framework for evaluating FL methods on four common formulations of NLP tasks: text classification, sequence tagging, question answering and seq2seq generation. They proposed a universal interface between Transformer-based language models (e.g., BERT, BART) and FL methods under various non-IID partitioning strategies.

SV-based methods have been extensively employed in conventional FL scenarios to assess the contribution of each participant. However, applying SV-based methods to measure contributions in FedFM settings presents two notable challenges: inference latency and compositional gap.

## Inference Latency:

Due to the substantial number of model parameters, directly utilizing SV-based methods for contribution evaluation in FedFM is impractical [168]. The vast scale of participants, coupled with a large number of participation records, significantly amplifies the complexity and time-latency involved in both training and inference. The large model size further hinders the feasibility of incorporating timely contribution feedback to update and refine the utility of each participant, as is customary in traditional FL settings. This timely feedback plays a pivotal role in the participant selection process.

## Compositional Gap:

FMs often grapple with the issue of a compositional gap, where they struggle to generate correct answers to compositional problems, even though they can correctly answer all their sub-problems [201]. Directly requiring contributions from FMs for each participant is currently beyond their capabilities. FMs cannot fully exploit the open-world knowledge encoded in them [202], [203], making it challenging to assess the contribution of each participant or even each component under FedFM settings.

## E. FedFM Reward Distribution

Similar to traditional FL, FedFM reward distribution needs to address the following issues.

## 1) Incentive Alignment.

Reward distribution mechanisms must align with the overarching goals of FedFM. This includes decisions about the structure of rewards (e.g., monetary vs. non-monetary), whether rewards are distributed centrally or via smart contracts on a blockchain, and the criteria for reward eligibility. Ensuring that incentives align with the FedFM objectives is essential for motivating participation.

## 2) Free-Riding Minimization:

To maintain the integrity of the incentive structure, it is crucial to prevent free-riding, where some participants benefit without actively contributing to FedFM. Effective mechanisms, such as requiring a minimum level of participation or using reputation systems, can deter free-riding behaviours.

## 3) Cost Balancing:

Managing the costs associated with rewards while ensuring the long-term sustainability of FedFM is a delicate balancing act. Striking the right balance between incentivizing participants adequately and maintaining the financial viability is essential for long-term sustainable operation of FedFM.

## VII. FedFM FRAMEWORKS

Setting up FedFM involves a multi-faceted approach involving both the software and hardware aspects to enable distributed training and fine-tuning across diverse devices while maintaining data privacy and security. It can be significantly facilitated by well-designed platforms and libraries supporting FL and the unique requirements of FMs. Here, we discuss leading FL frameworks which support large-scale FMs.

An overview of prospective platforms and libraries for FedFM are shown in Table VIII We focus on frameworks such as FedML [204], FederatedScope-LLM [205], FateLLM [206], and OpenFedLLM [54], comparing the methods supported, dataset compatibility and maximum model sizes as showcased in their examples. The findings reveal a trend towards integrating state-of-the-art techniques to facilitate FedFM. However, there appears to be little emphasis on computational efficiency. Notably, all frameworks have been assessed with contemporary large-scale FMs, underscoring their practical relevance. Utilizing these frameworks can facilitate the reassessment of techniques previously surveyed with actual FMs, potentially catalyzing novel research directions.

Implementing FedFM is an emerging and evolving research area, with continuously improving tools and practices. Selecting the right combination of platforms and libraries depends on the specific requirements of FedFM tasks, including the

TABLE VIII

COMPARATIVE ANALYSIS OF FL FRAMEWORKS THAT SUPPORT FMS

|  | NO. OF SUPPORTED <br> AGGREGATION <br> METHODS | METHODS TO IMPROVE <br> COMPUTATIONAL <br> EFFICIENCY | METHODS TO IMPROVE <br> COMMUNICATION <br> EFFICIENCY | NO. OF <br> DATASETS | LARGEST <br> MODEL |
| :--- | :--- | :--- | :--- | :--- | :--- |
| FedML 204 | 11 | PEFT (powered by HuggingFace) | None | Unknown | LLaMa2 (7B) |
| FederatedScope-LLM 205 | 1 | LoRA, P-Tuning, Prompt-Tuning, <br> Instruction-Tuning | None | 6 | LLaMa (7B) |
| Fate-LLM 206 | 1 | LoRA, Prompt Tuning, <br> Full Fine-Tuning | Quantization, <br> Knowledge Distillation | 3 | LLaMa (7B) |
| OpenFedLLM 544 | 7 | LoRA, Instruction Tuning | Quantization | 8 | LLaMa2 (7B) |

type of FMs involved, privacy, security and scalability requirements, as well as the computational resources available.

## VIII. ChallengeS and Promising Directions

Bringing FedFM into practice involves overcoming some technical and logistical challenges, including managing heterogeneous data and compute resources, ensuring robust and secure communication, and developing efficient algorithms for federated optimization and aggregation. Due to regulatory considerations, when implementing FedFM, it is crucial to monitor and mitigate biases that might arise from uneven data distributions across data owners. Auditing and fairness-aware algorithms can help address these concerns. In this section, we discuss the memory, computation and communication challenges of FedFM, as well as promising future research directions, exploring the synergy between quantum computing and FedFM as well as novel ways of evaluation to help the field advance further.

## A. Memory and Computing Challenges facing FedFM

The integration of FMs with FL poses several key challenges, primarily focused on managing the substantial requirements for memory and computation resources.

High Demand for Memory Resources: The large scale of FMs, often involving billions of parameters, results in significant memory demands. This is particularly challenging in FL environments, where client devices may have limited memory capacities. The key challenge is developing strategies to accommodate these large models efficiently within the memory constraints of diverse client devices.

High Demand for Computing Resources: In FedFM, the demand for high computational resources on FL client devices poses a persistent challenge. Despite strategies to mitigate this, it remains an open issue. Approaches such as model splitting [207] and model compression [208] have been proposed. In addition, efforts are made to develop lighter models and more efficient training algorithms [209] that are less taxing on device resources. Yet, these solutions only offer a partial remedy. The research on federated optimization [25], [210] indicate that finding the right balance between maintaining model performance and managing resource constraints is an ongoing struggle. Although these advances mark progress, ensuring that FedFM is adaptable for devices with diverse capabilities continues to be a significant open research question.
Balancing Efficiency with Model Performance: A pivotal aspect of FedFM research is finding a balance between reducing model sizes for compatibility with FL constraints while maintaining model performance [211]. New strategies need to be developed for achieving this balance, ensuring that models are both efficient in terms of resource utilization and effective in terms of performance.

Efficient Data Curation: Managing the distribution of large datasets necessary for training FMs in a federated manner presents unique challenges. Key to this is the development of methods for efficient data handling, which minimizes data redundancy and optimizes data usage across multiple nodes during the training process.

## B. Communication Challenges facing FedEM

Through revealing the inherent complexity of FMs, combined with the distributed nature of FL, we identify the following key communication challenges facing FedFM. This section discusses the multifaceted challenges associated with communication overheads, bandwidth constraints, latency, resource demand, security, scalability, and privacy, which affect the operational efficiency of FedFM (Table IX).

Increased Communication Overhead vs. Bandwidth Constraints: Bandwidth constraints present a critical challenge to FedFM [226]. The sheer size of FMs necessitates large transmission overhead, which is compounded by the need for frequent communication across distributed training devices (i.e., clients and servers). While strategies like model compression (using techniques like pruning, quantization, and knowledge distillation) aim to reduce the size of the models, and thus the network load [227], they only partially alleviate the bandwidth demand. Sparse communication techniques [228], which focus on sharing only essential model updates, help to some extent but do not entirely solve the problem. Asynchronous communication strategies [229] and edge computing [230] can reduce network congestion and data transmission volume. Yet, they cannot fully compensate for the inherent high transmission requirements of FedFM. Efficient coding schemes optimize data transmission [231], but the fundamental challenge of transmitting large volumes of data in a bandwidth-limited environment persists. Collectively, these approaches would make strides in addressing bandwidth issues, but they do not completely solve the challenge, highlighting the pressing need for innovative solutions in the field of FedFM [15].

TABLE IX

Summary of Communication ChallengeS and Potential Mitigation StrateGies in FedEM

| Challenge | MITIGATION <br> STRATEGIES | RELEVANT WORKS |
| :--- | :--- | :--- |
| Bandwidth Constraints / Latency Issues | Model Compression, Sparse Communication, <br> Asynchronous Communication, Efficient Coding Schemes |  |
| Resource Demands on Clients | Model Splitting, Model Compression, <br> Lighter Models, Efficient Training Algorithms |  |
| Communication Overheads / Scalability Issues | Efficient Network Protocols, Load Balancing, <br> Active Client Selection |  |
| Privacy Concerns and Security Issues | Homomorphic Encryption |  |

Latency Issues: The long time it takes to transmit large volumes of parameter across clients and the FL server is a significant obstacle in FedFM. This delay is more pronounced when dealing with complex models and numerous, often geographically dispersed, FL clients. To mitigate this, techniques such as efficient data serialization [232] and optimizing network protocols have been investigated. Moreover, implementing edge computing [230], where data processing occurs closer to the sources, helps in reducing the round-trip time for parameter transmission. Despite these efforts, latency remains an open challenge for FedFM, often impacting the overall speed and responsiveness of the model training and fine-tuning processes [233].

Scalability Issues: This problem arises because as more devices join the network, managing and processing their inputs becomes more complex and resource-intensive. To tackle this, strategies such as efficient network protocols [220], [234] and load balancing techniques [221] have been studied to manage the increased traffic and computational demands. Moreover, client selection [235], where only a subset of clients are active at any given time, can help manage the load. However, despite these efforts, scalability remains a challenge for FedFM. As the number of FL participants and the complexity of the FMs increase, achieving scalability remains a major obstacle, affecting both the effectiveness and adoption of FedFM.

Security Issues: In FedFM supported by advanced network technologies like 5G and beyond (B5G), security issues pose a significant challenge. The diversity in computing and communication capabilities across different participants in the network, stemming from variations in hardware (e.g., CPU, GPU), network connections (e.g., 4G, 5G, B5G, WiFi) and energy resources (e.g., battery, charged), leads to system heterogeneity [236]-[238]. This diversity can introduce inconsistencies and vulnerabilities in FedFM [239]. Moreover, the presence of unreliable devices within the network might lead to Byzantine failures as highlighted in [240], [241]. These failures refer to scenarios where certain nodes in the network act in a faulty or malicious manner, further complicating the security landscape of FedFM. The varying levels of security across different devices exacerbate the difficulty in defending against attacks and ensuring system reliability. Despite ongoing efforts to enhance FL security [28], these inherent vulnerabilities in FedFM remain open.

Privacy Issues: Privacy concerns in FedFM remain a significant challenge, despite the ongoing privacy protection research in traditional FL settings. While FL enhances privacy by sharing model updates rather than raw data, there are still vulnerabilities during interactions between FL participants [242]. For instance, adversaries can exploit these vulnerabilities to perform attacks such as membership inference or gradient leakage [242]-[244], aiming to extract local training data from devices. Existing countermeasures, such as homomorphic encryption (HE) and secure multi-party computation (SMC), while effective in enhancing FL privacy to some extent, fall short in fully addressing these malicious attacks. As detailed in [245], HE can protect against data leakage but is less effective against more sophisticated threats like membership inference and gradient leakage attacks. However, it cannot be efficiently applied on large-scale FMs. Despite these efforts in improving privacy protection, the evolving nature of threats and the complexity of FL systems, particularly in the context of FMs, means that privacy concerns remain a pressing and unresolved issue in FedFM. The development of more advanced and resilient privacy-preserving mechanisms continues to be a critical need in this field.

## C. Promising Direction: Quantum Computing for FedFM

The integration of quantum computing with FedFM presents a transformative opportunity to enhance FedFM [246]. This integration could revolutionize the efficiency and capability of these models [247]. In this section, we envision how four promising quantum computing techniques (Table $X$ : 1) quantum machine learning, 2) quantum optimization, 3) quantum security and 4) a combination of quantum entanglement and quantum aggregation hold promise to improve the efficiency, trustworthiness and incentives aspects of FedFM.

Quantum ML for FedFM: A key area in which quantum computing can make a significant impact is matrix operations, which are widely utilized in ML training. Quantum ML algorithms can perform these operations much faster than classical algorithms [248]. In the context of FedFM, this speedup can be particularly beneficial given the large matrices involved in such models [249]. Another crucial element in ML is gradientbased optimization, vital for training neural networks (NNs) in LLMs. Quantum algorithms promise more efficient gradient computation, potentially expediting the optimization process in FedFM settings. This enhancement hold the promise to lead to faster convergence during the training process.

The ability of quantum computing to efficiently perform certain types of sampling and approximation (e.g., Monte

TABLE X

PoTENTIAL FOR QUANTUM CoMPUTING TECHNIQUES TO ENHANCE FedFM

| Quantum Computing <br> Techniques $(\checkmark$ means suitable) | GENERAL OBJECTIVES | ASPECTS OF FedFM |  |  |
| :---: | :---: | :---: | :---: | :---: |
|  |  | Efficiency | Incentivization | Trustworthiness |
| Quantum Machine Learning | Quantum Speedup for FedFM <br> (including Training, Inference, and Fine-tuning) | $\checkmark$ | $\checkmark$ |  |
| Quantum Optimization | Leveraging Quantum and Classical Capabilities <br> to Optimize FedFM Objective and Cost Functions | $\checkmark$ | $\checkmark$ |  |
| Quantum Security | Quantum Enhanced Data Encryption <br> and Quantum Communications for FedFM |  |  | $\checkmark$ |
| Quantum Entanglement and Aggregation | Quantum Entanglement Synchronized Updating <br> and Quantum Aggregation for FedFM | $\checkmark$ |  | $\checkmark$ |

Carlo sampling) can be advantageous for many ML tasks. For example, [250] have demonstrated a framework for reservoir computing with nonlinear quantum reservoirs, showcasing the computational capabilities across classical and quantum regimes. Quantum systems enable more efficient data structure representation, which can expedite computation in NNs during inference. When fine-tuning FedFM models for specific tasks, feature selection is a crucial process. Quantum computing can offer efficient solutions for this process, enhancing the performance of the resulting FMs [251]. Lastly, quantum parallelism can support simultaneous evaluation of different hyper-parameter settings. This capability is significant for the hyper-parameter tuning process, a time-consuming aspect of FM fine-tuning. Moreover, the capability of quantum computing for handling high-dimensional spaces can aid in optimizing the high-dimensional parameter space of FMs more efficiently.

Overall, quantum computing can accelerate training and inference, enhancing fine-tuning, and offering innovative approaches to complex computational tasks in FedFM settings. This paradigm shift can notably improve the efficiency and effectiveness of FedEM.

Quantum Optimization for FedFM: Quantum optimization in ML, particularly in the context of FedFM, stands as a significant advancement in training methodologies. Leveraging quantum computing capabilities, these techniques aim to optimize ML models more effectively, focusing on finding the most suitable parameters to minimize loss functions and enhance overall performance. Methods like the Quantum Approximate Optimization Algorithm (QAOA) [252] and Variational Quantum Eigensolver (VQE) [253] represent a leap forward in solving optimization problems. These quantumbased solutions can outperform classical algorithms, especially in navigating complex, high-dimensional solution spaces typical in FMs. Such algorithms are not only efficient in locating global minima, which can be challenging for classical methods, but also provide more effective ways to fine-tune model parameters, thereby accelerating convergence to optimal solutions and enhancing the efficiency of fine-tuning [254]. Quantum Annealing leverages quantum tunneling to efficiently explore solution spaces and find global minima of objective functions. Its ability to escape local minima makes it a valuable tool in the optimization process. It offers a novel approach to optimizing parameters, especially in FedFM.

The integration of quantum and classical optimization steps in hybrid algorithms offers a balanced approach. By utilizing quantum processors for the more computationally demanding parts and classical processors for other parts, these hybrid models leverage the strengths of both quantum and classical computing. They can be particularly effective in overcoming current limitations of quantum computing, while still harnessing its advantages for optimization tasks [255]. Global optimization is a key factor in FedFM settings, where the objective is to achieve consensus among distributed models. Quantum algorithms can efficiently aggregate local updates and conduct global optimization. This can produce more effective and cohesive FMs in a collaborative learning environment. The incorporation of quantum optimization into FedFM represents a promising direction. By enhancing the efficiency of finding optimal solutions, these quantum-based techniques have the potential to significantly improve the performance and effectiveness of FedFM models.

Quantum Security for FedFM: Quantum computing-based encryption methods are promising for enhancing the privacy and security of FedFM [248]. Quantum Key Distribution (QKD) employs quantum properties to create a secure communication channel [256], [257]. It enables the generation of a shared random secret key for encryption and decryption. Its sensitivity to eavesdropping ensures high security. In addition, device-independent QKD (DI-QKD) offers an even higher level of security by not requiring trust in the quantum devices used in the protocol [258]. In FedFM settings, QKD can securely distribute keys among participants, ensuring secure communication and model updates.

Quantum encryption methods use quantum states for secure information representation and transmission. They can help FedFM protect the model parameters transmitted across the federated network. As quantum adversaries threaten classical encryption methods, quantum-secure cryptography develops new techniques that are secure against them. Its incorporation into FedFM is essential for long-term security. Quantum authentication protocols ensure the authenticity of data and participants, which is crucial in FedFM settings to defend against malicious activities and maintain integrity. Quantumsecure hash functions can provide data integrity and authentication. They remain secure against quantum attacks, thus enhancing data integrity in FedFM [259]. Quantum homomorphic encryption allows computations on encrypted data without decryption. It can offer privacy protection on transmitted model parameters during the collaborative learning effort in FedFM [260]. Blind quantum computing enables
private quantum computations [261]. It can be leveraged to allow FedFM participants to contribute to the learning processes without revealing their data. Quantum secure multiparty computation (SMPC) can extend classical SMPC to the quantum realm for FL without revealing individual data [262], thereby ensuring secure communication in FedFM.

Overall, these secure quantum computing methods can be leveraged to build a comprehensive framework for ensuring unparalleled security and privacy in data encryption and communication in FedFM settings.

Quantum Entanglement and Quantum Aggregation for FedFM: Quantum entanglement offers a novel approach to synchronizing updates in FedFM. This quantum phenomenon, where two or more particles become interconnected so that the state of one instantly influences the others, can be useful for FedFM in multiple ways. Theoretically, quantum entanglement might enable immediate synchronization of model updates across different nodes in a federated network [263]. Using entangled particles to represent model parameters allows changes in one node to be instantly reflected in all other entangled nodes, ensuring real-time synchronization of updates. Reaching consensus on model updates among distributed nodes is a significant challenge in FedFM. Quantum entanglement can achieve highly resource-efficient synchronization by reducing communication overhead and allowing for more effective error correction [264]. This can save bandwidth and computational resources, with quantum entanglement-assisted aggregation potentially correlating model updates from different nodes more efficiently. While still in the theoretical stage, the potential impact of quantum entanglement on FedFM could revolutionize the way model updates are synchronized, with highly enhanced efficiency, security and resource management.

Quantum aggregation in FedFM involves leveraging quantum computing principles for aggregating model updates from various nodes. This process aims to compute a global model update that effectively integrates local model changes from each node, potentially enhancing both efficiency and security. Key approaches in quantum aggregation include the follows. Quantum superposition [265] and quantum interference [266] involve using quantum superposition to represent multiple model updates on a single quantum state. This state can then be processed to compute a global model updating. Quantum interference, where quantum states interfere constructively or destructively, can facilitate efficient FedFM aggregation. Quantum summation algorithms can perform aggregation tasks more efficiently than classical algorithms [267]. Leveraging quantum cryptography techniques, quantum secure aggregation of model updates can preserve privacy while enabling effective aggregation. While detailed studies specific to FedFM and quantum aggregation are not yet available, the principles of quantum computing offer promising pathways for enhancing the efficiency and security of FedFM model aggregation.

## D. Promising Direction: Evaluation of FedEM

Multimodal Data Evaluation: Existing FL evaluation approaches are generally designed for single-modal data and cannot be directly adopted by FedFM where multimodal data which are combinatorial objects (e.g., integers, dates, URL strings, phone numbers) are often involved. The multiple modalities and heterogeneity among data owners make it hard to match samples and conduct model aggregations. Furthermore, when there are noisy samples in certain modalities, how to select high-quality data and train high-performance models via FedFM is still an open challenge.

Robust Evaluation: It is crucial to maintain robustness against varying inputs in FMs trained via FedFM. For example, employing identical prompts with distinct grammars and expressions might result in different outputs from ChatGPT and other LLMs, which indicates the lack of robustness of current LLMs to input variations. Although there exist prior work on robustness evaluation, there is still considerable room for improving, including using more diverse evaluation sets and developing more efficient evaluations to achieve robustness task performance.

Evaluation under Complex Threat Models: Existing FL evaluation methods are mostly based on the simple threat model of semi-honest participants. This renders them susceptible to scenarios in which the server or clients are colluding or malicious. It is imperative to relax this simplifying assumption to enable future FedFM evaluation methods to handle more realistic threats in practice. Moreover, understanding how the adversaries can exploit the interpretations derived from FedFM evaluation methods to compromise the system is also crucial for the adoption of FedFM by mission-critical applications.

Efficiency and Accuracy Trade-offs: Existing FL evaluation techniques (e.g., shapely value, influence functions) incur high computation and communication costs if directly used to evaluate FedFM. This is especially challenging if resourceconstrained devices are involved. Therefore, research focusing on trade-off between efficiency and accuracy is very important for FedFM evaluation for practical adoption.

Actionable Recommendation based on FedFM Evaluation: FedFM evaluation is not the ultimate goal, but rather a means to its enhancement. A powerful evaluation system should not only provide benchmark results, but also deliver insightful analyses, recommendations and guidance for future FedFM enhancement. With evaluation results, we obtain conclusions regarding model performance, robustness, stability and other factors. It is important to explore adaptive explainable federated learning techniques (e.g., federated neuro-symbolic learning) to provide FedFM designers with actionable recommendations on how to enhance FedFM.

## IX. CONCLUSIONS

In this paper, we provide a comprehensive and perspective survey on the development of FedFM, representing a significant step towards building FM-based AI systems in an efficient and collaborative manner. The survey efforts reveal a complex yet promising set of topics intersecting FL and FMs. As FedFM continue to evolve, the focus on training and aggregation methodologies, trustworthiness measures, incentive mechanisms, and participant management strategies will be
crucial for its success. This field is essential for unlocking the full potential of FL in leveraging the power of FMs. The proposed taxonomy for FedFM and novel strategies for participant selection and model training pave the way for future research, particularly in enhancing privacy-preserving techniques and leveraging quantum computing for improved security and efficiency. Overall, the convergence of FedFM demonstrates significant potential in advancing AI capabilities while effectively addressing critical challenges in data privacy and model trustworthiness.

## REFERENCES

[1] Y. Yuan, "On the power of foundation models," in International Conference on Machine Learning. PMLR, 2023, pp. 40 519-40 530.

[2] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill et al., "On the opportunities and risks of foundation models," arXiv preprint arXiv:2108.07258, 2021.

[3] C. Zhou, Q. Li, C. Li, J. Yu, Y. Liu, G. Wang, K. Zhang, C. Ji, Q. Yan, L. He et al., "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt," arXiv preprint arXiv:2302.09419, 2023.

[4] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al., "Language models are unsupervised multitask learners," OpenAI blog, vol. 1, no. 8, p. 9, 2019.

[5] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.

[6] OpenAI, "Gpt-4 technical report," ArXiv, vol. abs/2303.08774, 2023 [Online]. Available: https://arxiv.org/abs/2303.08774

[7] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar et al., "Llama: Open and efficient foundation language models," arXiv preprint arXiv:2302.13971, 2023

[8] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann et al., "Palm: Scaling language modeling with pathways," arXiv preprint arXiv:2204.02311, 2022.

[9] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo et al., "Segment anything," arXiv preprint arXiv:2304.02643, 2023.

[10] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, "High-resolution image synthesis with latent diffusion models," in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2022, pp. 10684-10695.

[11] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen, and I. Sutskever, "Zero-shot text-to-image generation," in International Conference on Machine Learning. PMLR, 2021, pp. 8821-8831.

[12] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark et al., "Learning transferable visual models from natural language supervision," in International conference on machine learning. PMLR, 2021, pp. 8748-8763.

[13] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al., "Advances and open problems in federated learning," Foundations and trends ${ }^{\circledR}$ in machine learning, vol. 14, no. 1-2, pp. 1-210, 2021.

[14] C. Chen, X. Feng, J. Zhou, J. Yin, and X. Zheng, "Federated large language model: A position paper," arXiv preprint arXiv:2307.08925, 2023.

[15] W. Zhuang, C. Chen, and L. Lyu, "When foundation model meets federated learning: Motivations, challenges, and future directions," arXiv preprint arXiv:2306.15546, 2023.

[16] S. Yu, J. P. Muñoz, and A. Jannesari, "Federated foundation models: Privacy-preserving and collaborative learning for large models," arXiv preprint arXiv:2305.11414, 2023.

[17] Y. Kang, T. Fan, H. Gu, L. Fan, and Q. Yang, "Grounding foundation models through federated transfer learning: A general framework," arXiv preprint arXiv:2311.17431, 2023.

[18] H. Woisetschläger, A. Isenko, S. Wang, R. Mayer, and H.-A. Jacobsen, "A survey on efficient federated learning methods for foundation model training," arXiv preprint arXiv:2401.04472, 2024.
[19] X. Li and J. Wang, "Position paper: Assessing robustness, privacy, and fairness in federated learning integrated with foundation models," arXiv preprint arXiv:2402.01857, 2024.

[20] S. J. Pan and Q. Yang, "A survey on transfer learning," IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345$1359,2010$.

[21] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al., "An image is worth 16x16 words: Transformers for image recognition at scale," arXiv preprint arXiv:2010.11929, 2020.

[22] P. Villalobos, J. Sevilla, L. Heim, T. Besiroglu, M. Hobbhahn, and A. Ho, "Will we run out of data? an analysis of the limits of scaling datasets in machine learning," arXiv preprint arXiv:2211.04325, 2022.

[23] D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin, O. Dobre, and W.-J. Hwang, "Federated learning for smart healthcare: A survey," ACM Computing Surveys (Csur), vol. 55, no. 3, pp. 1-37, 2022.

[24] G. Long, Y. Tan, J. Jiang, and C. Zhang, "Federated learning for open banking," in Federated Learning: Privacy and Incentive. Springer, 2020, pp. 240-254.

[25] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas, "Communication-efficient learning of deep networks from decentralized data," in Artificial intelligence and statistics. PMLR, 2017, pp. $1273-1282$.

[26] Q. Yang, Y. Liu, Y. Cheng, Y. Kang, T. Chen, and H. Yu, Federated Learning. Springer, Cham, 2020, vol. Synthesis Lectures on Artificial Intelligence and Machine Learning.

[27] A. Z. Tan, H. Yu, L. Cui, and Q. Yang, "Towards personalized federated learning," IEEE Transactions on Neural Networks and Learning Systems, 2022.

[28] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, "Federated optimization in heterogeneous networks," Proceedings of Machine learning and systems, vol. 2, pp. 429-450, 2020.

[29] S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T Suresh, "Scaffold: Stochastic controlled averaging for federated learning," in International conference on machine learning. PMLR, 2020, pp. 5132-5143.

[30] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani, "Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization," in International Conference on Artificial Intelligence and Statistics. PMLR, 2020, pp. 2021-2031.

[31] E. Diao, J. Ding, and V. Tarokh, "Heterofl: Computation and communication efficient federated learning for heterogeneous clients," arXiv preprint arXiv:2010.01264, 2020.

[32] A. Li, J. Sun, B. Wang, L. Duan, S. Li, Y. Chen, and H. Li, "Lotteryfl: Personalized and communication-efficient federated learning with lottery ticket hypothesis on non-iid datasets," arXiv preprint arXiv:2008.03371, 2020.

[33] S. Horvath, S. Laskaridis, M. Almeida, I. Leontiadis, S. Venieris, and N. Lane, "Fjord: Fair and accurate federated learning under heterogeneous targets with ordered dropout," Advances in Neural Information Processing Systems, vol. 34, pp. 12 876-12 889, 2021.

[34] H. Yang, "H-fl: A hierarchical communication-efficient and privacyprotected architecture for federated learning," arXiv preprint arXiv:2106.00275, 2021.

[35] Y. Jiang, S. Wang, V. Valls, B. J. Ko, W.-H. Lee, K. K. Leung, and L. Tassiulas, "Model pruning enables efficient federated learning on edge devices," IEEE Transactions on Neural Networks and Learning Systems, 2022.

[36] B. Isik, F. Pase, D. Gunduz, T. Weissman, and M. Zorzi, "Sparse random networks for communication-efficient federated learning," arXiv preprint arXiv:2209.15328, 2022.

[37] H. Huang, L. Zhang, C. Sun, R. Fang, X. Yuan, and D. Wu, "Distributed pruning towards tiny neural networks in federated learning," in 2023 IEEE 43rd International Conference on Distributed Computing Systems (ICDCS). IEEE, 2023, pp. 190-201.

[38] Z. Li, H. Zhao, B. Li, and Y. Chi, "Soteriafl: A unified framework for private federated learning with communication compression," Advances in Neural Information Processing Systems, vol. 35, pp. 4285-4300, 2022.

[39] H. Zhao, W. Du, F. Li, P. Li, and G. Liu, "Fedprompt: Communicationefficient and privacy-preserving prompt tuning in federated learning," in ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp. 1-5.

[40] Y. Tian, Y. Wan, L. Lyu, D. Yao, H. Jin, and L. Sun, "Fedbert: When federated learning meets pre-training," ACM Transactions on Intelligent Systems and Technology (TIST), vol. 13, no. 4, pp. 1-26, 2022.

[41] W. Lu, X. Hu, J. Wang, and X. Xie, "Fedclip: Fast generalization and personalization for clip in federated learning," arXiv preprint arXiv:2302.13485, 2023.

[42] G. Sun, M. Mendieta, T. Yang, and C. Chen, "Exploring parameterefficient fine-tuning for improving communication efficiency in federated learning," arXiv preprint arXiv:2210.01708, 2022.

[43] Z. Zhang, Y. Yang, Y. Dai, Q. Wang, Y. Yu, L. Qu, and Z. Xu, "Fedpetuning: When federated learning meets the parameter-efficient tuning methods of pre-trained language models," in Annual Meeting of the Association of Computational Linguistics 2023. Association for Computational Linguistics (ACL), 2023, pp. 9963-9977.

[44] S. Babakniya, A. R. Elkordy, Y. H. Ezzeldin, Q. Liu, K.-B. Song, M. ElKhamy, and S. Avestimehr, "Slora: Federated parameter efficient finetuning of language models," arXiv preprint arXiv:2308.06522, 2023

[45] Y. Chen, Z. Chen, P. Wu, and H. Yu, "Fedobd: Opportunistic block dropout for efficiently training large-scale neural networks through federated learning," arXiv preprint arXiv:2208.05174, 2022.

[46] J. Zhang, S. Vahidian, M. Kuo, C. Li, R. Zhang, G. Wang, and Y. Chen, "Towards building the federated gpt: Federated instruction tuning," arXiv preprint arXiv:2305.05644, 2023

[47] M. Xu, Y. Wu, D. Cai, X. Li, and S. Wang, "Fwdllm: Efficient fedllm using forward gradient," arXiv preprint arXiv:2308.13894, 2023

[48] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," arXiv preprint arXiv:1810.04805, 2018.

[49] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, "Improving language understanding with unsupervised learning," Open AI, 2018.

[50] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly et al., "An image is worth 16x16 words: Transformers for image recognition at scale," arXiv preprint arXiv:2010.11929, 2020.

[51] H. Liu, C. Li, Q. Wu, and Y. J. Lee, "Visual instruction tuning," Advances in neural information processing systems, vol. 36, 2024.

[52] B. Liu, N. Lv, Y. Guo, and Y. Li, "Recent advances on federated learning: A systematic survey," arXiv preprint arXiv:2301.01299, 2023.

[53] H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni, "Federated learning with matched averaging," arXiv preprint arXiv:2002.06440, 2020.

[54] R. Ye, W. Wang, J. Chai, D. Li, Z. Li, Y. Xu, Y. Du, Y. Wang, and S. Chen, "Openfedllm: Training large language models on decentralized private data via federated learning," arXiv preprint arXiv:2402.06954, 2024

[55] M. Wortsman, G. Ilharco, S. Y. Gadre, R. Roelofs, R. Gontijo-Lopes, A. S. Morcos, H. Namkoong, A. Farhadi, Y. Carmon, S. Kornblith et al., "Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time," in International Conference on Machine Learning. PMLR, 2022, pp. 23 965-23 998.

[56] A. Rame, K. Ahuja, J. Zhang, M. Cord, L. Bottou, and D. Lopez-Paz, "Model ratatouille: Recycling diverse models for out-of-distribution generalization," in Proceedings of the 40th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202. PMLR, 23-29 Jul 2023, pp. 28 656-28 679. [Online]. Available: https://proceedings.mlr.press/v202/rame23a.html

[57] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Firat et al., "Glam: Efficient scaling of language models with mixture-of-experts," in International Conference on Machine Learning. PMLR, 2022, pp. 5547-5569.

[58] B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer, and W. Fedus, "St-moe: Designing stable and transferable sparse expert models," arXiv preprint arXiv:2202.08906, 2022.

[59] F. Xue, Z. Zheng, Y. Fu, J. Ni, Z. Zheng, W. Zhou, and Y. You, "Openmoe: An early effort on open mixture-of-experts language models," arXiv preprint arXiv:2402.01739, 2024.

[60] N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, Y. Chen, C.M. Chan, W. Chen et al., "Parameter-efficient fine-tuning of large-scale pre-trained language models," Nature Machine Intelligence, vol. 5, no. 3, pp. 220-235, 2023.

[61] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly, "Parameter-efficient transfer learning for nlp," in International Conference on Machine Learning. PMLR, 2019, pp. 2790-2799.
[62] E. B. Zaken, S. Ravfogel, and Y. Goldberg, "Bitfit: Simple parameterefficient fine-tuning for transformer-based masked language-models," arXiv preprint arXiv:2106.10199, 2021.

[63] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, "Lora: Low-rank adaptation of large language models," arXiv preprint arXiv:2106.09685, 2021.

[64] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz, E. Agirre, I. Heintz, and D. Roth, "Recent advances in natural language processing via large pre-trained language models: A survey," ACM Computing Surveys, vol. 56, no. 2, pp. 1-40, 2023.

[65] W. Yuan, G. Neubig, and P. Liu, "Bartscore: Evaluating generated text as text generation," Advances in Neural Information Processing Systems, vol. 34, pp. 27 263-27 277, 2021.

[66] T. L. Scao and A. M. Rush, "How many data points is a prompt worth?" arXiv preprint arXiv:2103.08493, 2021

[67] S. Zhang, L. Dong, X. Li, S. Zhang, X. Sun, S. Wang, J. Li, R. Hu, T. Zhang, F. Wu et al., "Instruction tuning for large language models: A survey," arXiv preprint arXiv:2308.10792, 2023.

[68] Y. Cheng, D. Wang, P. Zhou, and T. Zhang, "A survey of model compression and acceleration for deep neural networks," arXiv preprint arXiv:1710.09282, 2017

[69] V. Klema and A. Laub, "The singular value decomposition: Its computation and some applications," IEEE Transactions on automatic control, vol. 25, no. 2, pp. 164-176, 1980.

[70] L. Lyu, H. Yu, X. Ma, C. Chen, L. Sun, J. Zhao, Q. Yang, and P. S. Yu, "Privacy and robustness in federated learning: Attacks and defenses," IEEE Transactions on Neural Networks and Learning Systems, 2022.

[71] B. Biggio, B. Nelson, and P. Laskov, "Poisoning attacks against support vector machines," in Proceedings of the 29th International Conference on Machine Learning, ICML 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012. icml.cc / Omnipress, 2012.

[72] X. Chen, C. Liu, B. Li, K. Lu, and D. Song, "Targeted backdoor attacks on deep learning systems using data poisoning," CoRR, vol. abs/1712.05526, 2017. [Online]. Available: http://arxiv.org/abs/1712. 05526

[73] M. Fang, G. Yang, N. Z. Gong, and J. Liu, "Poisoning attacks to graph-based recommender systems," in Proceedings of the 34th Annual Computer Security Applications Conference, ACSAC 2018, San Juan, PR, USA, December 03-07, 2018. ACM, 2018, pp. 381-392

[74] M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li, "Manipulating machine learning: Poisoning attacks and countermeasures for regression learning," in 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA. IEEE Computer Society, 2018, pp. 19-35.

[75] A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras, and T. Goldstein, "Poison frogs! targeted clean-label poisoning attacks on neural networks," in Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, 2018, pp. 6106-6116.

[76] T. Gu, B. Dolan-Gavitt, and S. Garg, "Badnets: Identifying vulnerabilities in the machine learning model supply chain," CoRR, vol abs/1708.06733, 2017

[77] Y. He, Z. Shen, C. Xia, J. Hua, W. Tong, and S. Zhong, "SGBA: A stealthy scapegoat backdoor attack against deep neural networks," Comput. Secur., vol. 136, p. 103523, 2024.

[78] R. Hou, T. Huang, H. Yan, L. Ke, and W. Tang, "A stealthy and robust backdoor attack via frequency domain transform," World Wide Web (WWW), vol. 26, no. 5, pp. 2767-2783, 2023.

[79] E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, "How to backdoor federated learning," in The 23rd International Conference on Artificial Intelligence and Statistics, AISTATS 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy], ser. Proceedings of Machine Learning Research, vol. 108. PMLR, 2020, pp. 2938-2948

[80] X. Lyu, Y. Han, W. Wang, J. Liu, B. Wang, J. Liu, and X. Zhang, "Poisoning with cerberus: Stealthy and colluded backdoor attack against federated learning," in Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023. AAAI Press, 2023, pp. 9020-9028.

[81] K. Mei, Z. Li, Z. Wang, Y. Zhang, and S. Ma, "NOTABLE: transferable backdoor attacks against prompt-based NLP models," in Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023. Association for Computational Linguistics, 2023, pp. $15551-15565$.

[82] S. Zhao, J. Wen, A. T. Luu, J. Zhao, and J. Fu, "Prompt as triggers for backdoor attack: Examining the vulnerability in language models," in Proceedings of the 2023 Conference on Empirical Methods in Natural

Language Processing, EMNLP 2023, Singapore, December 6-10, 2023. Association for Computational Linguistics, 2023, pp. 12303-12317.

[83] W. Du, Y. Zhao, B. Li, G. Liu, and S. Wang, "PPT: backdoor attacks on pre-trained models via poisoned prompt tuning," in Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022. ijcai.org, 2022, pp. 680-686

[84] B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao, "Neural cleanse: Identifying and mitigating backdoor attacks in neural networks," in 2019 IEEE Symposium on Security and Privacy, SP 2019, San Francisco, CA, USA, May 19-23, 2019. IEEE, 2019, pp. 707-723.

[85] S. Feng, G. Tao, S. Cheng, G. Shen, X. Xu, Y. Liu, K. Zhang, S. Ma, and X. Zhang, "Detecting backdoors in pre-trained encoders," in IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023. IEEE, 2023, pp. 16352-16362.

[86] P. Blanchard, E. M. E. Mhamdi, R. Guerraoui, and J. Stainer, "Machine learning with adversaries: Byzantine tolerant gradient descent," in Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, 2017, pp. 119-129.

[87] D. Yin, Y. Chen, K. Ramchandran, and P. L. Bartlett, "Byzantine-robust distributed learning: Towards optimal statistical rates," in Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018, ser. Proceedings of Machine Learning Research, vol. 80. PMLR, 2018, pp. 5636-5645.

[88] C. Xie, S. Koyejo, and I. Gupta, "Zeno: Distributed stochastic gradient descent with suspicion-based fault-tolerance," in Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, ser. Proceedings of Machine Learning Research, vol. 97. PMLR, 2019, pp. 6893-6901.

[89] -, "Zeno++: Robust fully asynchronous SGD," in Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, ser. Proceedings of Machine Learning Research, vol. 119. PMLR, 2020, pp. 10495-10 503.

[90] M. Fang, X. Cao, J. Jia, and N. Z. Gong, "Local model poisoning attacks to byzantine-robust federated learning," in 29th USENIX Security Symposium, USENIX Security 2020, August 12-14, 2020. USENIX Association, 2020, pp. 1605-1622.

[91] M. Hao, H. Li, G. Xu, H. Chen, and T. Zhang, "Efficient, private and robust federated learning,' in ACSAC '21: Annual Computer Security Applications Conference, Virtual Event, USA, December 6 - 10, 2021. ACM, 2021, pp. 45-60.

[92] X. Cao, M. Fang, J. Liu, and N. Z. Gong, "Fltrust: Byzantine-robust federated learning via trust bootstrapping," in 28th Annual Network and Distributed System Security Symposium, NDSS 2021, virtually, February 21-25, 2021. The Internet Society, 2021.

[93] S. Prakash and A. S. Avestimehr, "Mitigating byzantine attacks in federated learning," arXiv preprint arXiv:2010.07541, 2020.

[94] R. Shokri, M. Stronati, C. Song, and V. Shmatikov, "Membership inference attacks against machine learning models," in 2017 IEEE symposium on security and privacy (SP). IEEE, 2017, pp. 3-18.

[95] L. Liu, Y. Wang, G. Liu, K. Peng, and C. Wang, "Membership inference attacks against machine learning models via prediction sensitivity," IEEE Trans. Dependable Secur. Comput., vol. 20, no. 3, pp. 23412347, 2023.

[96] H. Yan, S. Li, Y. Wang, Y. Zhang, K. Sharif, H. Hu, and Y. Li, "Membership inference attacks against deep learning models via logits distribution," IEEE Trans. Dependable Secur. Comput., vol. 20, no. 5, pp. 3799-3808, 2023.

[97] J. Duan, F. Kong, S. Wang, X. Shi, and K. Xu, "Are diffusion models vulnerable to membership inference attacks?" in International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, ser. Proceedings of Machine Learning Research, A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202. PMLR, 2023, pp. 8717-8730.

[98] W. Fu, H. Wang, C. Gao, G. Liu, Y. Li, and T. Jiang, "Practical membership inference attacks against fine-tuned large language models via self-prompt calibration," CoRR, vol. abs/2311.06062, 2023

[99] L. Zhu, Z. Liu, and S. Han, "Deep leakage from gradients," in Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. B. Fox, and R. Garnett, Eds., 2019, pp. $14747-14756$.
[100] B. Zhao, K. R. Mopuri, and H. Bilen, "idlg: Improved deep leakage from gradients," CoRR, vol. abs/2001.02610, 2020

[101] X. Yuan, K. Chen, J. Zhang, W. Zhang, N. Yu, and Y. Zhang, "Pseudo label-guided model inversion attack via conditional generative adversarial network," in Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI 2023. AAAI Press, 2023, pp. 3349-3357.

[102] Y. Wu, X. Li, Y. Liu, P. Zhou, and L. Sun, "Jailbreaking GPT$4 \mathrm{~V}$ via self-adversarial attacks with system prompts," CoRR, vol. abs/2311.09127, 2023

[103] Z. X. Yong, C. Menghini, and S. H. Bach, "Low-resource languages jailbreak GPT-4," CoRR, vol. abs/2310.02446, 2023.

[104] G. Deng, Y. Liu, Y. Li, K. Wang, Y. Zhang, Z. Li, H. Wang, T. Zhang, and Y. Liu, "Jailbreaker: Automated jailbreak across multiple large language model chatbots," CoRR, vol. abs/2307.08715, 2023.

[105] R. Xue, K. Xue, B. Zhu, X. Luo, T. Zhang, Q. Sun, and J. Lu, "Differentially private federated learning with an adaptive noise mechanism," IEEE Trans. Inf. Forensics Secur., vol. 19, pp. 74-87, 2024.

[106] S. D. Okegbile, J. Cai, H. Zheng, J. Chen, and C. Yi, "Differentially private federated multi-task learning framework for enhancing humanto-virtual connectivity in human digital twin," IEEE J. Sel. Areas Commun., vol. 41, no. 11, pp. 3533-3547, 2023.

[107] X. Lin, J. Wu, J. Li, C. Sang, S. Hu, and M. J. Deen, "Heterogeneous differential-private federated learning: Trading privacy for utility truthfully," IEEE Trans. Dependable Secur. Comput., vol. 20, no. 6, pp. 5113-5129, 2023.

[108] P. Sun, H. Che, Z. Wang, Y. Wang, T. Wang, L. Wu, and H. Shao, "Painfl: Personalized privacy-preserving incentive for federated learning," IEEE Journal on Selected Areas in Communications, vol. 39, no. 12, pp. 3805-3820, 2021.

[109] P. Sun, X. Chen, G. Liao, and J. Huang, "A profit-maximizing model marketplace with differentially private federated learning," in IEEE INFOCOM 2022-IEEE Conference on Computer Communications. IEEE, 2022, pp. 1439-1448.

[110] R. Hu, Y. Gong, and Y. Guo, "Federated learning with sparsificationamplified privacy and adaptive optimization," arXiv preprint arXiv:2008.01558, 2020.

[111] R. Hu, Y. Guo, and Y. Gong, "Federated learning with sparsified model perturbation: Improving accuracy under client-level differential privacy," IEEE Transactions on Mobile Computing, 2023.

[112] B. Wang, F. Wu, Y. Long, L. Rimanic, C. Zhang, and B. Li, "Datalens: Scalable privacy preserving training via gradient compression and aggregation," in Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, 2021, pp. 2146-2168.

[113] W.-N. Chen, D. Song, A. Ozgur, and P. Kairouz, "Privacy amplification via compression: Achieving the optimal privacy-accuracycommunication trade-off in distributed mean estimation," Advances in Neural Information Processing Systems, vol. 36, 2024.

[114] X. Zhang, Y. Kang, K. Chen, L. Fan, and Q. Yang, "Trading off privacy, utility, and efficiency in federated learning," ACM Transactions on Intelligent Systems and Technology, vol. 14, no. 6, pp. 1-32, 2023.

[115] J. Kang, Z. Xiong, S. Niyato, and J. Zhang, "Incentive mechanism for reliable federated learning: A joint optimization approach to combining reputation and contract theory," IEEE Internet of Things Journal, vol. 6 , no. 6, pp. 10700-10714, 2019.

[116] J. Kang, Z. Xiong, D. Niyato, D. Ye, D. I. Kim, and J. Zhao, "Toward secure blockchain-enabled internet of vehicles: Optimizing consensus management using reputation and contract theory," IEEE Transactions on Vehicular Technology, vol. 68, no. 3, pp. 2906-2920, 2019

[117] Z. Hou, H. Chen, Y. Li, and B. Vucetic, "Incentive mechanism design for wireless energy harvesting-based internet of things," IEEE Internet of Things Journal, vol. 5, no. 4, pp. 2620-2632, 2017.

[118] T. Liu, J. Li, F. Shu, M. Tao, W. Chen, and Z. Han, "Design of contract-based trading mechanism for a small-cell caching system," IEEE Transactions on Wireless Communications, vol. 16, no. 10, pp. 6602-6617, 2017

[119] N. Ding, Z. Fang, and J. Huang, "Incentive mechanism design for federated learning with multi-dimensional private information," in 2020 18th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOPT). IEEE, 2020, pp. $1-8$.

[120] Y. Sarikaya and O. Ercetin, "Motivating workers in federated learning: A stackelberg game perspective," IEEE Networking Letters, vol. 2, no. 1, pp. 23-27, 2019.

[121] S. Feng, D. Niyato, P. Wang, D. I. Kim, and Y.-C. Liang, "Joint service pricing and cooperative relay communication for federated learning," in 2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE

Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). IEEE, 2019, pp. 815-820.

[122] W. Y. B. Lim, J. Huang, Z. Xiong, J. Kang, D. Niyato, X.-S. Hua, C. Leung, and C. Miao, "Towards federated learning in uav-enabled internet of vehicles: A multi-dimensional contract-matching approach," IEEE Transactions on Intelligent Transportation Systems, vol. 22, no. 8, pp. 5140-5154, 2021.

[123] S. R. Pandey, N. H. Tran, and C. S. Hong, "A crowdsourcing framework for on-device federated learning," IEEE Transactions on Wireless Communications, vol. 19, no. 5, pp. 3241-3256, 2020.

[124] C. T. Dinh, N. H. Tran, M. N. Nguyen, C. S. Hong, W. Bao, A. Y. Zomaya, and V. Gramoli, "Federated learning over wireless networks: Convergence analysis and resource allocation," IEEE/ACM Transadinh2020federatedctions on Networking, vol. 29, no. 1, pp. 398$409,2020$.

[125] L. U. Khan, S. R. Pandey, N. H. Tran, W. Saad, Z. Han, M. N. Nguyen, and C. S. Hong, "Federated learning for edge networks: Resource optimization and incentive mechanism," IEEE Communications Magazine, vol. 58, no. 10, pp. 88-93, 2020.

[126] R. Hu and Y. Gong, "Trading data for learning: Incentive mechanism for on-device federated learning," in GLOBECOM 2020-2020 IEEE Global Communications Conference. IEEE, 2020, pp. 1-6.

[127] J. Lee, D. Kim, and D. Niyato, "Market analysis of distributed learning resource management for internet of things: A game-theoretic approach," IEEE Internet of Things Journal, vol. 7, no. 9, pp. 8430$8439,2020$.

[128] Y. Sarikaya and O. Ercetin, "Regulating workers in federated learning by yardstick competition," in Proceedings of the 13th EAI International Conference on Performance Evaluation Methodologies and Tools, 2020, pp. $150-155$.

[129] X. Qu, Q. Hu, and S. Wang, "Privacy-preserving model training architecture for intelligent edge computing," Computer Communications, vol. 162, pp. 94-101, 2020.

[130] T. Song, Y. Tong, and S. Wei, "Profit allocation for federated learning," in IEEE BigData, 2019, pp. 2577-2586.

[131] H. Yu, Z. Liu, Y. Liu, T. Chen, M. Cong, X. Weng, D. Niyato, and Q. Yang, "A sustainable incentive scheme for federated learning," IEEE Intelligent Systems, vol. 35, no. 4, pp. 58-69, 2020.

[132] Z. Li, Z. Yang, S. Xie, W. Chen, and K. Liu, "Credit-based payments for fast computing resource trading in edge-assisted internet of things," IEEE Internet of Things Journal, vol. 6, no. 4, pp. 6606-6617, 2019.

[133] N. Krishnaraj, K. Bellam, B. Sivakumar, and A. Daniel, "The future of cloud computing: Blockchain-based decentralized cloud/fog solutionschallenges, opportunities, and standards," Blockchain Security in Cloud Computing, pp. 207-226, 2022.

[134] A. Zavodovski, S. Bayhan, N. Mohan, P. Zhou, W. Wong, and J. Kangasharju, "Decloud: Truthful decentralized double auction for edge clouds," in Proceedings of the 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS'19), 2019, pp. 2157-2167.

[135] H.-J. Hong, W. Fan, C. E. Chow, X. Zhou, and S.-Y. Chang, "Optimizing social welfare for task offloading in mobile edge computing," in Proceedings of the 2020 IFIP Networking Conference (Networking'20), 2020, pp. 524-528.

[136] T. Bahreini, H. Badri, and D. Grosu, "An envy-free auction mechanism for resource allocation in edge computing systems," in Proceedings of the 2018 IEEE/ACM Symposium on Edge Computing (SEC'18), 2018, pp. 313-322.

[137] G. Gao, M. Xiao, J. Wu, H. Huang, S. Wang, and G. Chen, "Auctionbased vm allocation for deadline-sensitive tasks in distributed edge cloud," IEEE Transactions on Services Computing, vol. 14, no. 6, pp. $1702-1716,2019$.

[138] Y. Jiao, P. Wang, D. Niyato, and Z. Xiong, "Social welfare maximization auction in edge computing resource allocation for mobile blockchain," in Proceedings of the 2018 IEEE International Conference on Communications (ICC'18), 2018, pp. 1-6.

[139] Y. Jiao, P. Wang, D. Niyato, and K. Suankaewmanee, "Auction mechanisms in cloud/fog computing resource allocation for public blockchain networks," IEEE Transactions on Parallel and Distributed Systems, vol. 30, no. 9, pp. 1975-1989, 2019.

[140] S. Yang, "A task offloading solution for internet of vehicles using combination auction matching model based on mobile edge computing," IEEE Access, vol. 8, pp. 53 261-53 273, 2020.

[141] Y. Jiao, P. Wang, D. Niyato, B. Lin, and D. I. Kim, "Toward an automated auction framework for wireless federated learning services market," IEEE Transactions on Mobile Computing, vol. 20, no. 10, pp. $3034-3048,2020$.
[142] R. Zeng, S. Zhang, J. Wang, and X. Chu, "Fmore: An incentive scheme of multi-dimensional auction for federated learning in MEC," in ICDCS, 2020, pp. 278-288.

[143] C. Ying, H. Jin, X. Wang, and Y. Luo, "Double insurance: Incentivized federated learning with differential privacy in mobile crowdsensing," in 2020 International Symposium on Reliable Distributed Systems (SRDS). IEEE, 2020, pp. 81-90

[144] T. H. T. Le, N. H. Tran, Y. K. Tun, Z. Han, and C. S. Hong, "Auction based incentive design for efficient federated learning in cellular wireless networks," in WCNC, 2020, pp. 1-6.

[145] T. H. Thi Le, N. H. Tran, Y. K. Tun, M. N. H. Nguyen, S. R. Pandey, Z. Han, and C. S. Hong, "An incentive mechanism for federated learning in wireless cellular networks: An auction approach," IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 48744887, 2021.

[146] J. Zhang, Y. Wu, and R. Pan, "Incentive mechanism for horizontal federated learning based on reputation and reverse auction," in $W W W$, 2021, p. 947-956.

[147] P. Roy, S. Sarker, M. A. Razzaque, M. Mamun-or Rashid, M. M. Hassan, and G. Fortino, "Distributed task allocation in mobile device cloud exploiting federated learning and subjective logic," Journal of Systems Architecture, vol. 113, p. 101972, 2021.

[148] Y. Deng, F. Lyu, J. Ren, Y.-C. Chen, P. Yang, Y. Zhou, and Y. Zhang, "Fair: Quality-aware federated learning with precise user incentive and model aggregation," in INFOCOM, 2021.

[149] J. Zhang, Y. Wu, and R. Pan, "Auction-based ex-post-payment incentive mechanism design for horizontal federated learning with reputation and contribution measurement," arXiv preprint arXiv:2201.02410, 2022.

[150] -, "Online auction-based incentive mechanism design for horizontal federated learning with budget constraint," arXiv preprint, p. 2201.09047, 2022.

[151] X. Tang and H. Yu, "Utility-maximizing bidding strategy for data consumers in auction-based federated learning," in Proceedings of the 2023 IEEE International Conference on Multimedia and Expo (ICME'23), 2023.

[152] X. Tang and H. Yu", "Competitive-cooperative multi-agent reinforcement learning for auction-based federated learning," in Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI'23), 2023.

[153] X. Tang and H. Yu, "Multi-session budget optimization for forward auction-based federated learning," arXiv preprint arXiv:2311.12548, 2023.

[154] Y. Liu, Z. Ai, S. Sun, S. Zhang, Z. Liu, and H. Yu, "Fedcoin: A peerto-peer payment system for federated learning," in Federated learning. privacy and incentive. Springer, 2020, pp. 125-138.

[155] A. Ghosh, J. Chung, D. Yin, and K. Ramchandran, "An efficient framework for clustered federated learning," Advances in Neural Information Processing Systems, vol. 33, pp. 19 586-19 597, 2020.

[156] R. Liu, P. Xing, Z. Deng, A. Li, C. Guan, and H. Yu, "Federated graph neural networks: Overview, techniques and challenges," arXiv preprint arXiv:2202.07256, 2022.

[157] L. Yi, G. Wang, X. Liu, Z. Shi, and H. Yu, "FedGH: Heterogeneous federated learning with generalized global header," in Proceedings of the 31st ACM International Conference on Multimedia (ACM MM'23), 2023, pp. 8686-8696.

[158] J. Wang, S. Cui, and F. Ma, "Fedlego: Enabling heterogenous model cooperation via brick reassembly in federated learning," in International Workshop on Federated Learning for Distributed Data Mining, 2023 .

[159] J. Wang, X. Yang, S. Cui, L. Che, L. Lyu, D. Xu, and F. Ma, "Towards personalized federated learning via heterogeneous model reassembly," arXiv preprint arXiv:2308.08643, 2023

[160] A. Li, R. Liu, M. Hu, L. A. Tuan, and H. Yu, "Towards interpretable federated learning," arXiv preprint arXiv:2302.13473, 2023.

[161] K. Zhu, J. Wang, J. Zhou, Z. Wang, H. Chen, Y. Wang, L. Yang, W. Ye, N. Z. Gong, Y. Zhang et al., "Promptbench: Towards evaluating the robustness of large language models on adversarial prompts," arXiv preprint arXiv:2306.04528, 2023.

[162] M. Kuchnik, V. Smith, and G. Amvrosiadis, "Validating large language models with relm," Proceedings of Machine Learning and Systems, vol. 5, 2023.

[163] L. Nagalapatti and R. Narayanam, "Game of gradients: Mitigating irrelevant clients in federated learning," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 10, 2021, pp. 90469054 .

[164] Z. Fan, H. Fang, Z. Zhou, J. Pei, M. P. Friedlander, and Y. Zhang, "Fair and efficient contribution valuation for vertical federated learning," arXiv preprint arXiv:2201.02658, 2022.

[165] S. Wei, Y. Tong, Z. Zhou, and T. Song, "Efficient and fair data valuation for horizontal federated learning," in Federated Learning. Springer, 2020, pp. 139-152.

[166] T. Wang, J. Rausch, C. Zhang, R. Jia, and D. Song, "A principled approach to data valuation for federated learning," in Federated Learning. Springer, 2020, pp. 153-167.

[167] J. Wang, L. Zhang, A. Li, X. You, and H. Cheng, "Efficient participant contribution evaluation for horizontal and vertical federated learning," in 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE, 2022, pp. 911-923.

[168] Z. Liu, Y. Chen, H. Yu, Y. Liu, and L. Cui, "Gtg-shapley: Efficient and accurate participant contribution evaluation in federated learning," ACM Transactions on Intelligent Systems and Technology (TIST), vol. 13, no. 4 , pp. 1-21, 2022.

[169] Z. Liu, Y. Chen, Y. Zhao, H. Yu, Y. Liu, R. Bao, J. Jiang, Z. Nie, Q. Xu, and Q. Yang, "Contribution-aware federated learning for smart healthcare," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 11, 2022, pp. 12396-12404.

[170] S. Zheng, Y. Cao, and M. Yoshikawa, "Secure shapley value for crosssilo federated learning," arXiv preprint arXiv:2209.04856, 2022.

[171] S. Ma, Y. Cao, and L. Xiong, "Transparent contribution evaluation for secure federated learning on blockchain," in 2021 IEEE 37th International Conference on Data Engineering Workshops (ICDEW). IEEE, 2021, pp. 88-91.

[172] G. Wang, C. X. Dang, and Z. Zhou, "Measure contribution of participants in federated learning," in IEEE Big Data, 2019, pp. 2597-2604.

[173] L. Zhang, L. Fan, Y. Luo, and L.-Y. Duan, "Intrinsic performance influence-based participant contribution estimation for horizontal federated learning," ACM Transactions on Intelligent Systems and Technology (TIST), vol. 13, no. 6, pp. 1-24, 2022.

[174] A. Li, L. Zhang, J. Wang, J. Tan, F. Han, Y. Qin, N. M. Freris, and X.Y. Li, "Efficient federated-learning model debugging," in 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEE, 2021, pp. 372-383.

[175] P. W. Koh and P. Liang, "Understanding black-box predictions via influence functions," in International conference on machine learning. PMLR, 2017, pp. 1885-1894.

[176] Y. Xue, C. Niu, Z. Zheng, S. Tang, C. Lyu, F. Wu, and G. Chen, "Toward understanding the influence of individual clients in federated learning," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 12, 2021, pp. 10 560-10 567.

[177] P. W. W. Koh, K.-S. Ang, H. Teo, and P. S. Liang, "On the accuracy of influence functions for measuring group effects," Advances in neural information processing systems, vol. 32, 2019.

[178] A. Li, L. Zhang, J. Wang, F. Han, and X.-Y. Li, "Privacy-preserving efficient federated-learning model debugging," IEEE Transactions on Parallel and Distributed Systems, vol. 33, no. 10, pp. 2291-2303, 2021.

[179] Y. Kwon, E. Wu, K. Wu, and J. Zou, "Datainf: Efficiently estimating data influence in lora-tuned llms and diffusion models," arXiv preprint arXiv:2310.00902, 2023

[180] A. Li, L. Zhang, J. Tan, Y. Qin, J. Wang, and X.-Y. Li, "Sample-level data selection for federated learning," in IEEE INFOCOM 2021-IEEE Conference on Computer Communications. IEEE, 2021, pp. 1-10.

[181] P. Cassara, A. Gotta, and L. Valerio, "Federated feature selection for cyber-physical systems of systems," IEEE Transactions on Vehicular Technology, vol. 71, no. 9, pp. 9937-9950, 2022.

[182] X. Li, R. Dowsley, and M. De Cock, "Privacy-preserving feature selection with secure multiparty computation," in International Conference on Machine Learning. PMLR, 2021, pp. 6326-6336.

[183] F. Pan, D. Meng, Y. Zhang, and X. Li, "Secure federated feature selection for cross-feature federated learning," arXiv preprint, 2020.

[184] G. Wang, "Interpret federated learning with shapley values," arXiv preprint arXiv:1905.04519, 2019.

[185] Y. Chen, Y. Ning, Z. Chai, and H. Rangwala, "Federated multi-task learning with hierarchical attention for sensor data analytics," in 2020 International Joint Conference on Neural Networks (IJCNN). IEEE, 2020, pp. 1-8.

[186] R. Younis, Z. Ahmadi, A. Hakmeh, and M. Fisichella, "Flames2graph: An interpretable federated multivariate time series classification framework," 2023.

[187] A. Li, H. Peng, L. Zhang, J. Huang, Q. Guo, H. Yu, and Y. Liu, "Fedsdg-fs: Efficient and secure feature selection for vertical federated learning," arXiv preprint arXiv:2302.10417, 2023.
[188] A. Li, J. Huang, J. Jia, H. Peng, L. Zhang, L. A. Tuan, H. Yu, and X.-Y. Li, "Efficient and privacy-preserving feature importance-based vertical federated learning," IEEE Transactions on Mobile Computing, no. 01, pp. 1-17, 2023.

[189] C.-Y. Lin, "Rouge: A package for automatic evaluation of summaries," in Text summarization branches out, 2004, pp. 74-81.

[190] T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi, "Bertscore: Evaluating text generation with bert," arXiv preprint arXiv:1904.09675, 2019.

[191] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, "Bleu: a method for automatic evaluation of machine translation," in Proceedings of the 40th annual meeting of the Association for Computational Linguistics, 2002, pp. 311-318.

[192] Y.-T. Lin and Y.-N. Chen, "Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models," arXiv preprint arXiv:2305.13711, 2023.

[193] Y. Wang, Z. Yu, Z. Zeng, L. Yang, C. Wang, H. Chen, C. Jiang, R. Xie, J. Wang, X. Xie et al., "Pandalm: An automatic evaluation benchmark for $11 \mathrm{~lm}$ instruction tuning optimization," arXiv preprint $\operatorname{arXiv:2306.05087,~} 2023$.

[194] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg et al., "Sparks of artificial general intelligence: Early experiments with gpt-4," arXiv preprint arXiv:2303.12712, 2023.

[195] N. Jain, K. Saifullah, Y. Wen, J. Kirchenbauer, M. Shu, A. Saha, M. Goldblum, J. Geiping, and T. Goldstein, "Bring your own data! self-supervised evaluation for large language models," arXiv preprint arXiv:2306.13651, 2023.

[196] S. Schoch, R. Mishra, and Y. Ji, "Data selection for fine-tuning large language models using transferred shapley values," arXiv preprint arXiv:2306.10165, 2023.

[197] P. Xing, S. Lu, and H. Yu, "Fedlogic: Interpretable federated multidomain chain-of-thought prompt selection for large language models," arXiv preprint arXiv:2308.15324, 2023

[198] J. Zhao, "Privacy-preserving fine-tuning of artificial intelligence (ai) foundation models with federated learning, differential privacy, offsite tuning, and parameter-efficient fine-tuning (peft)," Authorea Preprints, 2023 .

[199] J. Zhang, S. Vahidian, M. Kuo, C. Li, R. Zhang, G. Wang, and Y. Chen, "Towards building the federated gpt: Federated instruction tuning," arXiv preprint arXiv:2305.05644, 2023.

[200] B. Y. Lin, C. He, Z. Zeng, H. Wang, Y. Huang, C. Dupuy, R. Gupta, M. Soltanolkotabi, X. Ren, and S. Avestimehr, "Fednlp: Benchmarking federated learning methods for natural language processing tasks," arXiv preprint arXiv:2104.08815, 2021

[201] O. Press, M. Zhang, S. Min, L. Schmidt, N. A. Smith, and M. Lewis, "Measuring and narrowing the compositionality gap in language models," arXiv preprint arXiv:2210.03350, 2022.

[202] W.-C. Kang, J. Ni, N. Mehta, M. Sathiamoorthy, L. Hong, E. Chi, and D. Z. Cheng, "Do llms understand user preferences? evaluating llms on user rating prediction," arXiv preprint arXiv:2305.06474, 2023.

[203] S. Dai, N. Shao, H. Zhao, W. Yu, Z. Si, C. Xu, Z. Sun, X. Zhang, and J. Xu, "Uncovering chatgpt's capabilities in recommender systems," arXiv preprint arXiv:2305.02182, 2023.

[204] C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma, A. Singh, H. Qiu et al., "Fedml: A research library and benchmark for federated machine learning," arXiv preprint arXiv:2007.13518, 2020.

[205] W. Kuang, B. Qian, Z. Li, D. Chen, D. Gao, X. Pan, Y. Xie, Y. Li, B. Ding, and J. Zhou, "Federatedscope-llm: A comprehensive package for fine-tuning large language models in federated learning," arXiv preprint arXiv:2309.00363, 2023.

[206] T. Fan, Y. Kang, G. Ma, W. Chen, W. Wei, L. Fan, and Q. Yang, "Fate-1lm: A industrial grade federated learning framework for large language models," arXiv preprint arXiv:2310.10049, 2023.

[207] C. Thapa, P. C. M. Arachchige, S. Camtepe, and L. Sun, "Splitfed: When federated learning meets split learning," in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 36, no. 8, 2022, pp. 8485-8493.

[208] S. M. Shah and V. K. Lau, "Model compression for communication efficient federated learning," IEEE Transactions on Neural Networks and Learning Systems, 2021.

[209] C. He, M. Annavaram, and S. Avestimehr, "Group knowledge transfer: Federated learning of large CNNs at the edge," Advances in Neural Information Processing Systems, vol. 33, pp. 14 068-14080, 2020.

[210] J. Konečnỳ, H. B. McMahan, D. Ramage, and P. Richtárik, "Federated optimization: Distributed machine learning for on-device intelligence," arXiv preprint arXiv:1610.02527, 2016.

[211] C. Ren, H. Yu, R. Yan, Q. Li, Y. Xu, D. Niyato, and Z. Y. Dong, "Secfedsa: A secure differential privacy-based federated learning approach for smart cyber-physical grid stability assessment," IEEE Internet of Things Journal, 2023.

[212] Y. Shen, J. Shao, X. Zhang, Z. Lin, H. Pan, D. Li, J. Zhang, and K. B Letaief, "Large language models empowered autonomous edge ai for connected intelligence," IEEE Communications Magazine, 2024.

[213] D. Wu, W. Yang, H. Jin, X. Zou, W. Xia, and B. Fang, "Fedcomp: A federated learning compression framework for resource-constrained edge computing devices," IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2023.

[214] Y. Mao, Z. Zhao, M. Yang, L. Liang, Y. Liu, W. Ding, T. Lan, and X.P. Zhang, "Safari: Sparsity-enabled federated learning with limited and unreliable communications," IEEE Transactions on Mobile Computing, 2023.

[215] C. Xu, Y. Qu, Y. Xiang, and L. Gao, "Asynchronous federated learning on heterogeneous devices: A survey," Computer Science Review, vol. 50, p. 100595, 2023.

[216] M. Liu, S. Ho, M. Wang, L. Gao, Y. Jin, and H. Zhang, "Federated learning meets natural language processing: A survey," arXiv preprint arXiv:2107.12603, 2021.

[217] M. Chawla, G. R. Gupta, S. Gaddam, and M. Wadhwa, "Beyond federated learning for iot: Efficient split learning with caching \& model customization," IEEE INTERNET OF THINGS JOURNAL, p. 1, 2024.

[218] W. Zhang, T. Zhou, Q. Lu, Y. Yuan, A. Tolba, and W. Said, "Fedsl: A communication efficient federated learning with split layer aggregation," IEEE Internet of Things Journal, 2024

[219] Y. Liao, Y. Xu, H. Xu, Z. Yao, L. Wang, and C. Qiao, "Accelerating federated learning with data and model parallelism in edge computing," IEEE/ACM Transactions on Networking, 2023.

[220] M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, "Federated learning: A survey on enabling technologies, protocols, and applications," IEEE Access, vol. 8, pp. 140 699-140725, 2020.

[221] N. H. Tran, W. Bao, A. Zomaya, M. N. Nguyen, and C. S. Hong, "Federated learning over wireless networks: Optimization model design and analysis," in IEEE INFOCOM 2019-IEEE conference on computer communications. IEEE, 2019, pp. 1387-1395.

[222] Z. Charles, N. Mitchell, K. Pillutla, M. Reneer, and Z. Garrett, "Towards federated foundation models: Scalable dataset pipelines for group-structured learning," Advances in Neural Information Processing Systems, vol. 36, 2024

[223] W. Jin, Y. Yao, S. Han, C. Joe-Wong, S. Ravi, S. Avestimehr, and C. He, "Fedml-he: An efficient homomorphic-encryptionbased privacy-preserving federated learning system," arXiv preprint arXiv:2303.10837, 2023

[224] S. A. Rieyan, M. R. K. News, A. M. Rahman, S. A. Khan, S. T. J. Zaarif, M. G. R. Alam, M. M. Hassan, M. Ianni, and G. Fortino, "An advanced data fabric architecture leveraging homomorphic encryption and federated learning," Information Fusion, vol. 102, p. 102004, 2024.

[225] R. Aziz, S. Banerjee, S. Bouzefrane, and T. Le Vinh, "Exploring homomorphic encryption and differential privacy techniques towards secure federated learning paradigm," Future internet, vol. 15, no. 9, p. 310,2023

[226] M. Fariborz, M. Samani, P. Fotouhi, R. Proietti, I.-M. Yi, V. Akella, J. Lowe-Power, S. Palermo, and S. B. Yoo, "LLM: Realizing lowlatency memory by exploiting embedded silicon photonics for irregular workloads," in International Conference on High Performance Computing. Springer, 2022, pp. 44-64

[227] A. Jaiswal, Z. Gan, X. Du, B. Zhang, Z. Wang, and Y. Yang, "Compressing LLMs: The truth is rarely pure and never simple," arXiv preprint arXiv:2310.01382, 2023.

[228] M. Mestoukirdi, O. Esrafilian, D. Gesbert, Q. Li, and N. Gresset, "Sparser random networks exist: Enforcing communicationefficient federated learning via regularization," arXiv preprint arXiv:2309.10834, 2023.

[229] Q. Xia, W. Ye, Z. Tao, J. Wu, and Q. Li, "A survey of federated learning for edge computing: Research problems and solutions," HighConfidence Computing, vol. 1, no. 1, p. 100008, 2021

[230] X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, "In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning," Ieee Network, vol. 33, no. 5, pp. 156-165, 2019.

[231] K. Yue, R. Jin, C.-W. Wong, and H. Dai, "Communication-efficient federated learning via predictive coding," IEEE Journal of Selected Topics in Signal Processing, vol. 16, no. 3, pp. 369-380, 2022.
[232] D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao, L. Sani, K. H. Li, T. Parcollet, P. P. B. de Gusmão et al., "Flower: A friendly federated learning research framework," arXiv preprint arXiv:2007.14390, 2020.

[233] M. Xu, Y. Wu, D. Cai, X. Li, and S. Wang, "Federated fine-tuning of billion-sized language models across mobile devices," arXiv preprint arXiv:2308.13894, 2023

[234] C. Ren, Y. Xu, and R. Zhang, "An interpretable deep learning method for power system transient stability assessment via tree regularization," IEEE Transactions on Power Systems, vol. 37, no. 5, pp. 3359-3369 2021.

[235] Y. Shi, H. Yu, and C. Leung, "Towards fairness-aware federated learning," IEEE Transactions on Neural Networks and Learning Systems, 2023.

[236] C. Ren and Y. Xu, "Robustness verification for machine-learning-based power system dynamic security assessment models under adversarial examples," IEEE Transactions on Control of Network Systems, vol. 9 , no. 4, pp. 1645-1654, 2022.

[237] C. Ren, X. Du, Y. Xu, Q. Song, Y. Liu, and R. Tan, "Vulnerability analysis, robustness verification, and mitigation strategy for machine learning-based power system stability assessment model under adversarial examples," IEEE Transactions on Smart Grid, vol. 13, no. 2, pp. $1622-1632,2021$

[238] C. Ren and Y. Xu, "A universal defense strategy for data-driven power system stability assessment models under adversarial examples," IEEE Internet of Things Journal, 2022.

[239] Y. Liu, J. Peng, J. Kang, A. M. Iliyasu, D. Niyato, and A. A. Abd ElLatif, "A secure federated learning framework for $5 \mathrm{~g}$ networks," IEEE Wireless Communications, vol. 27, no. 4, pp. 24-31, 2020.

[240] M. Fang, X. Cao, J. Jia, and N. Gong, "Local model poisoning attacks to \{Byzantine-Robust \} federated learning," in 29th USENIX security symposium (USENIX Security 20), 2020, pp. 1605-1622

[241] J. Tian, B. Wang, R. Guo, Z. Wang, K. Cao, and X. Wang, "Adversarial attacks and defenses for deep-learning-based unmanned aerial vehicles," IEEE Internet of Things Journal, vol. 9, no. 22, pp. 22399 22409,2021

[242] Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally, "Deep gradient compression: Reducing the communication bandwidth for distributed training," arXiv preprint arXiv:1712.01887, 2017.

[243] J. Tian, C. Shen, B. Wang, X. Xia, M. Zhang, C. Lin, and Q. Li, "Lesson: Multi-label adversarial false data injection attack for deep learning locational detection," IEEE Transactions on Dependable and Secure Computing, 2024.

[244] J. Tian, B. Wang, Z. Wang, K. Cao, J. Li, and M. Ozay, "Joint adversarial example and false data injection attacks for state estimation in power systems," IEEE Transactions on Cybernetics, vol. 52, no. 12, pp. $13699-13713,2021$.

[245] T. Huang, W. Yang, J. Wu, J. Ma, X. Zhang, and D. Zhang, "A survey on green $6 \mathrm{~g}$ network: Architecture and technologies," IEEE access, vol. 7, pp. 175758-175768, 2019.

[246] B. Q. Group, "Quafu-rl: The cloud quantum computers based quantum reinforcement learning," arXiv preprint arXiv:2305.17966, 2023.

[247] Z. Liang, J. Cheng, R. Yang, H. Ren, Z. Song, D. Wu, X. Qian, T. Li, and Y. Shi, "Unleashing the potential of llms for quantum computing: A study in quantum architecture design," arXiv preprint arXiv:2307.08191, 2023.

[248] C. Ren, H. Yu, R. Yan, M. Xu, Y. Shen, H. Zhu, D. Niyato, Z. Y. Dong, and L. C. Kwek, "Towards quantum federated learning," arXiv preprint arXiv:2306.09912, 2023.

[249] A. Khan, G. Saha, and R. K. Pal, "Quantum computing based inference of grns," in Bioinformatics and Biomedical Engineering: 5th International Work-Conference, IWBBIO 2017, Granada, Spain, April 26-28, 2017, Proceedings, Part II 5. Springer, 2017, pp. 221-233.

[250] S. A. Khan, F. Hu, G. Angelatos, and H. E. Türeci, "Physical reservoir computing using finitely-sampled quantum systems," arXiv preprint arXiv:2110.13849, 2021

[251] J. Bausch, "Recurrent quantum neural networks," Advances in neural information processing systems, vol. 33, pp. 1368-1379, 2020.

[252] E. Farhi, J. Goldstone, and S. Gutmann, "A quantum approximate optimization algorithm," arXiv preprint arXiv:1411.4028, 2014.

[253] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O'brien, "A variational eigenvalue solver on a photonic quantum processor," Nature communications vol. 5, no. 1, p. 4213, 2014

[254] W. M. Kirby and P. J. Love, "Variational quantum eigensolvers for sparse hamiltonians," Physical review letters, vol. 127, no. 11, p. 110503,2021 .

[255] N. Kuete Meli, F. Mannel, and J. Lellmann, "A universal quantum algorithm for weighted maximum cut and ising problems," Quantum Information Processing, vol. 22, no. 7, p. 279, 2023.

[256] R. Kaewpuang, M. Xu, D. Niyato, H. Yu, Z. Xiong, and X. S. Shen, "Adaptive resource allocation in quantum key distribution (qkd) for federated learning," in 2023 International Conference on Computing, Networking and Communications (ICNC). IEEE, 2023, pp. 71-76.

[257] C. Ren, H. Xu, Minrui Yu, Z. Xiong, Z. Zhang, and D. Niyato, "Variational quantum circuit and quantum key distribution-based quantum federated learning: A case of smart grid dynamic security assessment," International Conference on Communications, 2024.

[258] C. Ren, R. Yan, M. Xu, H. Yu, Y. Xu, D. Niyato, and Z. Y. Dong, "Qfdsa: A quantum-secured federated learning system for smart grid dynamic security assessment," IEEE Internet of Things Journal, 2023.

[259] D. Gurung, S. R. Pokhrel, and G. Li, "Performance analysis and evaluation of post quantum secure blockchain federated learning," arXiv preprint arXiv:2306.14772, 2023.

[260] B. Buyukates, J. So, H. Mahdavifar, and S. Avestimehr, "Lightverifl: Lightweight and verifiable secure federated learning," in Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022), 2022.

[261] S. Barz, E. Kashefi, A. Broadbent, J. F. Fitzsimons, A. Zeilinger, and P. Walther, "Demonstration of blind quantum computing," science, vol. 335, no. 6066, pp. 303-308, 2012.

[262] G.-J. Qu and M.-M. Wang, "Secure multi-party quantum computation based on blind quantum computation," International Journal of Theoretical Physics, vol. 60, no. 8, pp. 3003-3012, 2021.

[263] R. Horodecki, P. Horodecki, M. Horodecki, and K. Horodecki, "Quantum entanglement," Reviews of modern physics, vol. 81, no. 2, p. 865, 2009 .

[264] J. Troupe, S. Haldar, I. Agullo, and P. Kwiat, "Quantum clock synchronization for future nasa deep space quantum links and fundamental science," arXiv preprint arXiv:2209.15122, 2022.

[265] J. R. Friedman, V. Patel, W. Chen, S. Tolpygo, and J. E. Lukens, "Quantum superposition of distinct macroscopic states," nature, vol. 406, no. 6791, pp. 43-46, 2000.

[266] O. Romero-Isart, A. C. Pflanzer, F. Blaser, R. Kaltenbaek, N. Kiesel, M. Aspelmeyer, and J. I. Cirac, "Large quantum superpositions and interference of massive nanometer-sized objects," Physical review letters, vol. 107, no. 2, p. 020405, 2011.

[267] D. K. Park, I. Sinayskiy, M. Fingerhuth, F. Petruccione, and J.-K. K. Rhee, "Quantum forking for fast weighted power summation," arXiv preprint arXiv:1902.07959, 2019.


[^0]:    ${ }^{1}$ Some research regards pruning as a model compression method |68|.

