# MUlTimodAL DeEP LEARNING OF Word-OF-MOUTH TEXT AND DEMOGRAPHICS TO PREDICT CUSTOMER RATING: HANDLING CONSUMER HETEROGENEITY IN MARKETING 

A PREPRINT<br>Junichiro Niimi ${ }^{*}$ 1,2<br>${ }^{1}$ Meijo University<br>${ }^{2}$ RIKEN AIP


#### Abstract

In the marketing field, understanding consumer heterogeneity, which is the internal or psychological difference among consumers that cannot be captured by behavioral logs, has long been a critical challenge. However, a number of consumers today usually post their evaluation on the specific product on the online platform, which can be the valuable source of such unobservable differences among consumers. Several previous studies have shown the validity of the analysis on text modality, but on the other hand, such analyses may not necessarily demonstrate sufficient predictive accuracy for text alone, as they may not include information readily available from cross-sectional data, such as consumer profile data. In addition, recent advances in machine learning techniques, such as large-scale language models (LLMs) and multimodal learning have made it possible to deal with the various kind of dataset simultaneously, including textual data and the traditional cross-sectional data, and the joint representations can be effectively obtained from multiple modalities. Therefore, this study constructs a product evaluation model that takes into account consumer heterogeneity by multimodal learning of online product reviews and consumer profile information. We also compare multiple models using different modalities or hyper-parameters to demonstrate the robustness of multimodal learning in marketing analysis.


Keywords Multimodal Learning $\cdot$ BERT $\cdot$ Customer Relationship Management $\cdot$ Word-of-Mouth $\cdot$ LLM

## 1 Introduction

Deep learning is currently used in various fields. In the field such as image recognition, it is already common to obtain features that affect the target variable by the feature extraction of deep learning [1], and it is considered one of the most powerful advantages of deep learning [2]. In the field of customer relationship management (CRM) in marketing, it also has been widely employed in various ways of prediction and demonstrated the validity of utilizing deep learning, such as customer segmentation [3], customer lifetime value (CLV) [4, 5], purchases (in the future or current session) [6, 7, 8], churn [9, 10], and other tasks [11].

However, within the vast field of data science, a problematic factor, referred as consumer heterogeneity, has been identified, particularly in marketing. In marketing analysis, we combine a variety of behavioral log data; however, all the data recorded in the behavioral logs are the results of behaviors. The Differences in the psychological attributes among consumers that cause those behaviors cannot be obseerved by such logs. Many previous studies have highlighted the importance of considering heterogeneity [12, 13].

In terms of combining various data, multimodal learning [14, 15] has become widely popular in machine learning applications in general. It combines and learns different types of multiple data (i.e., modality), for example, audio and its corresponding text, in a state close to the original data. This method allows modeling that considers the relationships between modalities. However, in the marketing field, analysis using such a variety of data is generally conducted by variablizing each data into a single dataset [16].[^0]

This paper is organized as follows. The previous studies are reviewed in Section 2, and the methodology (proposed model and used data) is shown in Section 3. An overview of the analysis is described in Section 4. The results of the analysis are presented in Section 5. Finally, we present the discussion and conclusions in Section 6.

## 2 Related Work

### 2.1 Text Analysis in Marketing

Natural Language Processing (NLP) techniques have been proposed for analyzing text modalities using deep learning. Among them, bidirectional encoder representations from transformers (BERT) [17] and their extensions [18, 19] are some of the most popular methods because of their wide applicability, which is not limited to NLP tasks, such as machine translation and question answering. For pre-training, it has learned a contextual language representations using large text corpus; therefore, it can be further applied to various downstream tasks through fine-tuning. Many models have already undergone pretraining with extensive data, enabling effective analysis with relatively small datasets. In recent years, an extension of BERT into multiple languages, known as multilingual BERT (mBERT), has emerged, and several models for the Japanese version, which is the focus of this study, have also been proposed (e.g., BERT models trained by Cyber Agent [20] and Tohoku NLP Group [21]). Before the advent of BERT, vectorization methods such as word2 vec [22] and doc2vec [23] had been used to map sentences to feature vectors. Compared with techniques that produce a single- word embedding representation, the advantage of BERT is that it is context-wise, which means that it produces a representation based on other terms in the sentence [17, 24].

For the actual use of these methods in marketing, especially regarding word-of-mouth texts, this study [24] predicts user review (that is, sentiment) for smartphone games using review texts collected from the Google Play Store, which compare several techniques to obtain word representations, including RNN [25], CNN [26], LSTM [27], BERT, mBERT, DistilBERT [18], and RoBERTa [19]. In addition, a study [28] adopted BERT to predict customers' ratings of hotels in seven criteria (e.g., overall ratings, value, and service) simultaneously, using online review texts for the recommender system. They indicated that BERT could predict a more accurate rating by considering the context of a review text. Another study regarding social media marketing [29] adopts BERT to capture the social media engagements and comments of influencers of eight categories on Instagram. Thus, several studies have used BERT to map word-of-mouth documents to feature maps to predict customer evaluations.

In addition, while BERT has two different scale: Base (approx. 110 million parameters) and Large (approx. 340 million parameters), the extent to which such scales of BERT affect the result of the analysis for relatively small text data is yet to be clarified, particularly in non-English model $s^{2}$

### 2.2 Multimodal Learning in Marketing

Multimodal learning involves learning representations from multiple modalities such as images, videos, audio, and text. A combination of these enables the construction of a robust learner based on the relationships among modalities that cannot be obtained by learning a single modality [15]. There are a variety of applications, including the integration of information from multiple sources and interconversion between modalities, applied to a wide range of academic fields such as medicine, human-computer interaction, biometrics, and remote sensing [30]. In contrast to this rise in multimodal learning, research on multimodal learning in the marketing field is relatively scarce. One possible reason is that marketing data analysis involves a mixture of various data in different formats, such as server logs, ID-POS, GPS, survey responses, and customer information. Although analyses combining various datasets are widely practiced, they are typically conducted by variablizing multiple data and merging them into a single set for analysis 3

However, there are a few notable instances, such as studies that construct a multimodal deep learning model to predict consumer loyalty with the source-target attention mechanism [31], which datasets with different dimensionality are input simultaneously; however, by using bidirectional LSTM, the time-series data is converted to two-dimensional and unified to a single representation with cross-sectional data by feature fusion ${ }^{4}$.

### 2.3 Consumer Heterogeneity in Marketing

Both the studies mentioned above highlight that it is possible to enhance discriminative power by considering demographic variables as a context affecting actual behavior. In the CRM context, the problem of consumer heterogeneity has long been highlighted, where even consumers who perform same behavior have unobservable differences [12],[^1]such as demographic and psychographic differences. In general, this kind of difference is unobservable in behavioral logs such as ID-POS data. Several studies have attempted to capture such differences using statistical modeling, such as structural equation modeling (SEM) and Bayesian mixture models [32, 33]. When it comes to the evaluation of the results addressed in this study, even among customers who have the same rating (number of stars), the reasons for the rating must differ; however, this difference cannot be observed in the cross-sectional data. In recent years, with the availability of a variety of large-scale data, document data such as word-of-mouth on online platforms have been used in the aforementioned studies as an important source for understanding consumer preferences [34].

Thus, several studies have utilized BERT and text data to make predictions that account for consumer heterogeneity. In general, the review text has more or less amount of reason why they evaluate the venue in such rating. In other words, the data, although it is behavioral log, can be the important source of understanding consumer heterogeneity. Therefore, this study utilize product review as a means to capture consumer heterogeneity to predict with better performance.

On the other hand, relying sorely on the feature extraction of machine learning is not advisable because domain knowledge is not incorporated into the analysis. In fact, several studies have shown that in multimodal learning, the combination of extracted features and handcrafted variables achieves the best prediction accuracy [1, 16]. Therefore, this study constructs a multimodal deep learning model that combines the review text with handcrafted user profile variables to achieve a robust and precise model.

## 3 Proposed Model

Based on previous studies of multimodal learning using time series and cross-sectional data [17], we present a conceptual model of multimodal deep learning that integrates three smaller neural network components, referred to as subnetworks or subnets. In this study, they are called text-specific subnetworks (X1-subnet), cross-sectional-data-specific subnetworks (X2-subnet), and output subnetworks (output-subnet). The construction of each subnet is described in the following subsections.

### 3.1 Text-Specific Subnetworks (X1-subnet)

First, we describe the structure of the X1-subnet, which specializes in processing text data. The purpose of this subnet is to map word-of-mouth texts (whose lengths differ among users) onto a two-dimensional single-feature map. The actual component included two layers: a tokenization layer and a BERT layer. In this study, BERT was used to obtain embedded representations of text data; therefore, the X1-subnet (tokenizer and BERT layers) is freezed throughout the actual training process, which means that the parameters of the subnet are held fixed in the pre-trained state.

![](https://cdn.mathpix.com/cropped/2024_06_04_a75d6c2d33a2963d18b0g-3.jpg?height=49&width=1645&top_left_y=1515&top_left_x=240)
(len $\max$ represents the maximum number of tokens of the text among $N$ sets of data). After processing in the BERT layer with batch size $n$, we obtained the feature map as the pooler output of BERT as the $(n$, len max $)$ tensor 5

### 3.2 Cross-Sectional-Data-Specific Subnetworks (X2-subnet)

Next, we describe the structure of the X2-subnet handling two-dimensional cross-sectional data. This subnet consists of a typical deep neural network with feed-forward layers (FFLs). An input layer for the X2-subnet receives a 2dimensional tensor $\left(n, J_{\text {in }}\right)$, with batch size $n$ and $J_{\text {in }}$ variables in the cross-sectional data. After processing, $\left(n, J_{\text {out }}\right)$ feature map is obtained as the output.

### 3.3 Output Subnetworks (output-subnet)

Textual and cross-sectional data, processed in parallel in each dedicated subnet are sent to the output subnet. In this subnet, both the feature maps, stemming from $\mathrm{X} 1$ and $\mathrm{X} 2$, are unified as a joint representation by feature fusion laye 6 . and the obtained feature map would be ( $n$, len $\max +J_{\text {out }}$ ) tensor. After the feature fusion, the joint representation is processed through one or more FFLs, and finally classification is conducted with Softmax layer. All the FFLs throughout the model employed a hyperbolic tangent function (tanh) for layer activation.

## 4 Analysis

### 4.1 Dataset

To conduct this analysis, we randomly selected one product from the women's cosmetics market. The target product had to be well-recognized in Japan and already out of production. We collected data from 1040 participants online.[^2]

![](https://cdn.mathpix.com/cropped/2024_06_04_a75d6c2d33a2963d18b0g-4.jpg?height=1314&width=1001&top_left_y=270&top_left_x=562)

Figure 1: Model Architecture

The actual data contains three kinds of modalities: rating for the product (7-point Likert scale), word-of-mouth texts for the product, and demographic information 7 Finally, the sample size is 1532 (i.e., $N=1532$ ).

Next, we process the survey text in the general way of preprocessing in NLP. The text contained line breaks, pictographs, emoticons, and other characters that were not appropriate for analysis. Therefore, in the preprocessing stage, these elements were replaced with periods only when they were placed at the end of the sentence; otherwise, the elements were removed. Subsequently, all successive punctuation periods are merged into a single period. Consequently, the maximum length of the text data was set as $l e n_{\max }=200$.

### 4.2 Model Evaluation

This study adopts a simple binary classification for the task, similar to previous studies [24]. User ratings were dichotomized into two classes based on the rating scale. Six and seven stars were classified as Loyalty $=1$ (loyalty is high) and Loyalty $=0$ (loyalty is not high), respectively. The obtained dataset was divided into a training set (75\%) and a test set $(25 \%)$. The model performance was evaluated using both training and test accuracies and the number of epochs to converge.

This study aims to validate several key points to compare the models. First, to validate the usefulness of multimodal learning in marketing, we construct three basic models according to their modalities: X1-modal, X2-modal, and[^3]

Table 1: Model Settings

| Parameters | Candidates |
| :--- | :--- |
| Model Parameters |  |
| Number of Epochs | 200 (with Early-Stopping in 50 Epochs) |
| Batchsize $(n)$ | 64 |
| Optimizer | \{Adam, Adamax, Nadam \} |
| Loss Function | Binary Cross-entropy |
| X1-subnet | mBERT (Japanese) |
| Structure | \{bert-base-japanese-v3, |
| Model | bert-base-japanese-char-v3, |
|  | bert-large-japanesese-v2, |
|  |  |
| X2-subnet | 2 |
| Number of Hidden Layers | 10 |
| Number of Neurons in the Layer | tanh |
| Activation Function | 2 |
| output-subnet | 10 |
| Number of Hidden Layers | tanh |
| Number of Neurons in the Layer |  |
| Activation Function |  |

Note. tanh stands for hyperbolic tangent function.

multimodal. This comparison allowed for the verification of changes in prediction accuracy by combining multiple modalities. Especially in marketing analysis, review texts can be a valuable source for comprehending consumer heterogeneity in user ratings.

Next, we examined the change in prediction accuracy using multiple pre-trained models within BERT. Regarding the Japanese language model, several models of different scales (that is, numbers of parameters), different training datasets, and tokenization methods (in particular, with regard to Japanese models, some are trained on a word-by-word basis, whereas others are trained on a character-by-character basis) have already been proposed, and the extent to which the prediction accuracy differs depending on the use of these models is yet to be clarified. Nowadays, we can easily switch the pre-trained model in BERT by changing one line of the code, which makes it easy to compare the accuracies of different pre-trained models. As it has already been shown in the literatures [24, 28, 29] that models using BERT-like architectures achieve higher accuracy compared to those using Collaborative Filtering, LSTM, CNN, and other benchmark models, this study sticks to comparing among multiple models using BERT.

The model settings are shown in Table 11 In the case where several candidates are shown in the setting, we utilize a grid search to explore the settings that maximize the test accuracy. For example, we compared the prediction accuracy among the four pre-trained models in BERT (bert base/large in word/char) and among three optimizers (Adaptive Moment Estimation, Adam [35], Adamax [35], and Nesterov-accelerated Adaptive Moment Estimation, Nadam [36]).

The training process was conducted with a maximum of 200 epochs and 64 batch sizes. Early Stopping [37] was employed with a patience of 50 epochs, which terminates the training if no improvement in the accuracy of the validation data was observed within 50 epochs.

## 5 Results

The best models for each modality are listed in Table 2. First, in both the training and test results, the prediction accuracy improved the most with multimodal learning. Although these results do not allow us to evaluate whether multimodal learning immediately improves the prediction accuracy, multimodal learning with the bert-base-japanesev3 model shows the highest prediction accuracy for the test data, which indicates that the extension to multimodal learning alone does not improve the prediction accuracy. For multimodal learning, we need to carefully consider factors such as the task to be solved with the multimodal model, the relationship between the modalities, and the quality of the data, because several previous studies have shown that the prediction accuracy in multimodal learning can be influenced by such factors [38].

Table 2: Result I (Accuracy in Train and Test Data)

| BERT Model / Modality | Train |  |  | Test |  |  | Epochs |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | Both | $\mathrm{X} 1$ | $\mathrm{X} 2$ | Both | $\mathrm{X} 1$ | $\mathrm{X} 2$ | Both | $\mathrm{X} 1$ | $\mathrm{X} 2$ |
| cl-tohoku/bert-base-japanese-v3 | 0.705 | 0.708 | -1 | 0.711 | 0.703 | - | 36 | 38 | - |
| cl-tohoku/bert-base-japanese-char-v3 | 0.683 | 0.686 | - | 0.690 | 0.678 | - | 41 | 42 | - |
| cl-tohoku/bert-large-japanese-v2 | $0.712 \quad$ | 0.698 | - | 0.695 | 0.699 | - | 95 | 190 | - |
| cl-tohoku/bert-large-japanese-char-v2 | 0.681 | 0.658 | - | 0.690 | 0.703 | - | 58 | 18 | - |
| None | - | - | 0.555 | - | - | 0.623 | - | - | 29 |

Note. Numbers in bold represent the best accuracy in training and testing and the best epochs.

Table 3: Result II (Group Average)

| Optimizer | Train | Test | Epochs |  | Modality | Train | Test | Epochs |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Adam | 0.646 | 0.659 | 58.4 |  | Both | 0.681 | $\mathbf{0 . 6 8 3}$ | 70.2 |
| Adamax | 0.627 | 0.651 | 61.7 |  | X1 | $\mathbf{0 . 6 8 5}$ | 0.681 | 58.9 |
| Nadam | $\mathbf{0 . 6 4 6}$ | $\mathbf{0 . 6 6 2}$ | $\mathbf{4 6 . 2}$ |  | X2 | 0.546 | 0.604 | $\mathbf{3 5 . 5}$ |

Note. Numbers in bold represent the best accuracy in training and testing and the best epochs.

Second, in the comparison of four pre-trained models, note that upgrading to the BERT Large model did not always lead to a significant improvement in accuracy. Regarding the scale of the model, there is a tendency for an increase in the number of epochs required for model training with bert-large-japanese-v2, and the X1-modality has reached 190 epochs. This result might indicate the potential for further improvement with an increase in the number of epochs; however, large model is not always necessary because other models have shown higher prediction accuracy in fewer epochs.

In addition, a comparison of the mean accuracies among certain conditions is listed in Table 3 In terms of the optimizer, although the training accuracy is almost the same between Adam and Nadam, the latter is better in terms of both test accuracy and the best epoch, which means that, on average, Nadam achieved a higher generalization performance in a shorter tim 8 . In terms of modality, the X1-modal shows high accuracy, as listed in Table 2, for the training process; however, multimodal learning, on average, still shows the highest accuracy for the test data. This result suggests that, on average, multimodal learning improves generalization performance. As expected, the accuracy of the analysis using only X2-modal remains low for both training and testing, although the model converged early.

## 6 Conclusions

This study attempts to construct a multimodal deep learning model that predicts the user ratings of a product using both review text and user profile data simultaneously to account for consumer heterogeneity. First, as academic implications, even when both review and demographic data are relatively small, both the best model and the average score by modality, the prediction accuracy is the best when they are combined, which indicates that multimodal learning that accounts for consumer heterogeneity allows analysis with high robustness and generalizability. Second, it can be shown that, at least when dealing with relatively short sentences such as those used in this study (len $\max ^{2}=$ 200), a larger BERT model does not necessarily contribute to an improvement in prediction accuracy. This implies that, particularly in small datasets like those used in this study, converting sentences into word embeddings with BERT is important while the scale of the BERT model is not necessarily critical. Next, the conceptual model presented in this study, as a way to extend review data with cross-sectional data or as a way to extend cross-sectional data with review data, has a potential to be extended to various prediction models in marketing analysis with higher prediction accuracy, compared to conventional methods.

Finally, owing to the constraints of data collection, this study relies on consumer ratings as a proxy for behavioral loyalty and predicts whether it is high or not using the proposed model. However, this methodology can be extended to purchase prediction models by incorporating data that include purchase history and more demographics. A few models in previous studies [31] fused modalities twice within a model through the use of attention mechanisms and feature fusion, which aims to enhance prediction accuracy and robustness. Moreover, regarding the actual analysis, further improvements in accuracy can be expected by adopting techniques such as dropout [39]. In addition, although[^4]the multimodal learning model developed in this study, which utilizes actual review texts as a source of information for understanding consumer heterogeneity, is based on the assumption that consumer heterogeneity is embedded in the review texts, the actual causal relationships need to be carefully examined for the presence of potential endogeneity between the variables.

## Acknowledgements

All computations in this study were conducted using RAIDEN, which is a computational infrastructure hosted by RIKEN AIP. We would like to express our gratitude to all the members of AIP who maintain the system.

## References

[1] Loris Nanni, Stefano Ghidoni, and Sheryl Brahnam. Handcrafted vs. non-handcrafted features for computer vision classification. Pattern Recognition, 71:158-172, 2017.

[2] Yoshua Bengio. Deep learning of representations: Looking forward. In International Conference on Statistical Language and Speech Processing, pages 1-37. Springer, 2013.

[3] Licheng Zhao, Yi Zuo, and Katsutoshi Yada. Sequential classification of customer behavior based on sequenceto-sequence learning with gated-attention neural networks. Advances in Data Analysis and Classification, pages $1-33,2022$.

[4] Rafet Sifa, Julian Runge, Christian Bauckhage, and Daniel Klapper. Customer lifetime value prediction in noncontractual freemium settings: Chasing high-value users using deep neural networks and smote. 2018.

[5] Pei Pei Chen, Anna Guitart, Ana Fernández del Río, and Africa Periánez. Customer lifetime value in video games using deep learning and parametric models. In 2018 IEEE international conference on big data (big data), pages 2134-2140. IEEE, 2018.

[6] Jan Valendin, Thomas Reutterer, Michael Platzer, and Klaudius Kalcher. Customer base analysis with recurrent neural networks. International Journal of Research in Marketing, 39(4):988-1018, 2022.

[7] Arthur Toth, Louis Tan, Giuseppe Di Fabbrizio, and Ankur Datta. Predicting shopping behavior with mixture of rnns. In $e C O M @$ SIGIR, 2017.

[8] Long Guo, Lifeng Hua, Rongfei Jia, Binqiang Zhao, Xiaobo Wang, and Bin Cui. Buying or browsing?: Predicting real-time purchasing intent using attention-based deep network with multiple behavior. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining, pages 1984-1992, 2019.

[9] C Gary Mena, Arno De Caigny, Kristof Coussement, Koen W De Bock, and Stefan Lessmann. Churn prediction with sequential data and deep neural networks. a comparative analysis. arXiv preprint arXiv:1909.11114, 2019.

[10] Philip Spanoudes and Thomson Nguyen. Deep learning in customer churn prediction: unsupervised feature learning on abstract company independent feature vectors. arXiv preprint arXiv:1703.03869, 2017.

[11] Mainak Sarkar and Arnaud De Bruyn. Lstm response models for direct marketing analytics: Replacing feature engineering with deep learning. Journal of Interactive Marketing, 53(1):80-95, 2021.

[12] Peter E Rossi, Robert E McCulloch, and Greg M Allenby. The value of purchase history data in target marketing. Marketing Science, 15(4):321-340, 1996.

[13] Werner J Reinartz and Vita Kumar. The impact of customer relationship characteristics on profitable lifetime duration. Journal of marketing, 67(1):77-99, 2003.

[14] Nitish Srivastava and Russ R Salakhutdinov. Multimodal learning with deep boltzmann machines. Advances in neural information processing systems, 25, 2012.

[15] Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y Ng. Multimodal deep learning. In ICML, 2011.

[16] Junichiro Niimi and Takahiro Hoshino. Predicting purchases with using the variety of customer behaviors analysis of the purchase history and the browsing history by deep learning-. Transactions of the Japanese Society for Artificial Intelligence, 32(2):B-G63_1-9, 2017.

[17] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

[18] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv, 2019.

[19] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.

[20] Alex Andonian, Quentin Anthony, Stella Biderman, Sid Black, Preetham Gali, Leo Gao, Eric Hallahan, Josh Levy-Kramer, Connor Leahy, Lucas Nestler, Kip Parker, Michael Pieler, Shivanshu Purohit, Tri Songz, Wang Phil, and Samuel Weinbach. GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch, 82021.

[21] Tohoku NLP Group. cl-tohoku/bert-japanese (github: https://github.com/cl-tohoku/bert-japanese), 2023.

[22] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.

[23] Quoc Le and Tomas Mikolov. Distributed representations of sentences and documents. In International conference on machine learning, pages 1188-1196. PMLR, 2014.

[24] Zeynep Hilal Kilimci. Prediction of user loyalty in mobile applications using deep contextualized word representations. Journal of Information and Telecommunication, 6(1):43-62, 2022.

[25] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. nature, 323(6088):533-536, 1986.

[26] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.

[27] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780, 1997.

[28] Yuanyuan Zhuang and Jaekyeong Kim. A bert-based multi-criteria recommender system for hotel promotion management. Sustainability, 13(14):8039, 2021.

[29] Seungbae Kim, Xiusi Chen, Jyun-Yu Jiang, Jinyoung Han, and Wei Wang. Evaluating audience loyalty and authenticity in influencer marketing via multi-task multi-relational learning. In Proceedings of the International AAAI Conference on Web and Social Media, volume 15, pages 278-289, 2021.

[30] Dhanesh Ramachandram and Graham W Taylor. Deep multimodal learning: A survey on recent advances and trends. IEEE signal processing magazine, 34(6):96-108, 2017.

[31] Maher Ala'raj, Maysam F Abbod, and Munir Majdalawieh. Modelling customers credit card behaviour using bidirectional lstm neural networks. Journal of Big Data, 8(1):1-27, 2021.

[32] Carsten Hahn, Michael D Johnson, Andreas Herrmann, and Frank Huber. Capturing customer heterogeneity using a finite mixture pls approach. Schmalenbach Business Review, 54:243-269, 2002.

[33] Thomas Otter, Regina Tüchler, and Sylvia Frühwirth-Schnatter. Capturing consumer heterogeneity in metric conjoint analysis using bayesian mixture models. International Journal of Research in Marketing, 21(3):285297, 2004.

[34] Silvana Aciar, Debbie Zhang, Simeon Simoff, and John Debenham. Recommender system based on consumer product reviews. In 2006 IEEE/WIC/ACM International Conference on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06), pages 719-723. IEEE, 2006.

[35] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.

[36] Timothy Dozat. Incorporating nesterov momentum into adam. 2016.

[37] Lutz Prechelt. Early stopping-but when? In Neural Networks: Tricks of the trade, pages 55-69. Springer, 1998.

[38] Douwe Kiela and Léon Bottou. Learning image embeddings using convolutional neural networks for improved multi-modal semantics. In Proceedings of the 2014 Conference on empirical methods in natural language processing (EMNLP), pages 36-45, 2014.

[39] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929$1958,2014$.


[^0]:    *jniimi@meijo-u.ac.jp

[^1]:    ${ }^{2}$ The results are comparable between the model scales since both BERT models of Base and Large are designed to handle the same number of input tokens.

    ${ }^{3}$ The information loss occurring in the process of converting behavioral log into cross-sectional data may lead to a decrease in the accuracy of marketing analysis using deep learning. In other words, the manually variablized features cannot be sufficient statistics for the task on their own.

    ${ }^{4}$ Notably, in both studies, data fusion is conducted twice in one network structure: source-target attention and feature fusion.

[^2]:    ${ }^{5}$ The maximum length of the text $l e n_{\max } \leq 512$ since it cannot be exceeded the maximum number of tokens that BERT can deal with.

    ${ }^{6}$ However, a more rigorous call of feature fusion in this study should be "intermediate fusion" [30].

[^3]:    ${ }^{7}$ Since the cosmetic we focus on is a product intended for use by females, the survey was limited to females who purchased the products themselves.

[^4]:    ${ }^{8}$ Note that the time required for training one epoch did not differ significantly among optimizers.

