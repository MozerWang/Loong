# DYNAMIC GENERATION OF PERSONALITIES WITH LARGE LANGUAGE MODELS 

Jianzhi Liu ${ }^{1}$ Hexiang Gu ${ }^{1}$ Tianyu Zheng ${ }^{1}$<br>Liuyu Xiang ${ }^{1}$ Huijia Wu ${ }^{1}$ Jie $\mathbf{F u}^{2 *}$ Zhaofeng He ${ }^{1 *}$<br>${ }^{1}$ Beijing University of Posts and Telecommunications ${ }^{2}$ HKUST<br>\{lujianzhi,guhexiang, zhengtianyu,liuyuxiang,huijiawu,zhaofenghe\}@bupt.edu.cn<br>jiefu@ust.hk


#### Abstract

In the realm of mimicking human deliberation, large language models (LLMs) show promising performance, thereby amplifying the importance of this research area. Deliberation is influenced by both logic and personality. However, previous studies predominantly focused on the logic of LLMs, neglecting the exploration of personality aspects. In this work, we introduce Dynamic Personality Generation (DPG), a dynamic personality generation method based on Hypernetworks. Initially, we embed the Big Five personality theory into GPT-4 to form a personality assessment machine, enabling it to evaluate characters' personality traits from dialogues automatically. We propose a new metric to assess personality generation capability based on this evaluation method. Then, we use this personality assessment machine to evaluate dialogues in script data, resulting in a personality-dialogue dataset. Finally, we fine-tune DPG on the personality-dialogue dataset. Experiments prove that DPG's personality generation capability is stronger after fine-tuning on this dataset than traditional fine-tuning methods, surpassing prompt-based GPT-4.


## 1 Introduction

Large language models (LLMs) such as GPT-4 (Achiam et al., 2023) and Palm (Chowdhery et al., 2023) demonstrate impressive cognitive abilities. This enables LLMs to deliberate like humans. However, human deliberation is influenced by both logic and personality (Cantor, 1990; Griffin et al., 2015). Previous research primarily focuses on enabling LLMs to simulate human deliberation from a logical perspective (Zhu et al., 2023; Wang et al., 2023b; Chen et al., 2023), while neglecting the study of personality aspects. Exploring how to shape the personalities of LLMs and influence their deliberation is a topic worth studying.

In psychological research, the Big Five personality traits are recognized as models for studying human personality (Costa Jr and McCrae, 1992). Some works introduce them into LLM research as a method to measure the personalities of LLMs (Wang et al., 2023a; Safdari et al., 2023). To impart specific personality traits to pre-trained language models requires complex and well-designed prompts (Li et al., 2023b; Jiang et al., 2023c). The proficiency of prompt designers significantly influences the accuracy of personality shaping (Safdari et al., 2023). Some approaches address the issue of heavy prompt dependency by incorporating external knowledge bases or utilizing supervised fine-tuning with personalized data (Wang et al., 2023c; Li et al., 2023a). However, these methods introduce data dependencies, as shaping a new personality necessitates gathering a specific set of role-specific data. Therefore, the challenge lies in creatively generating new personalities while reducing reliance on prompts and data.

In this paper, we propose a novel approach to personality generation called Dynamic Personality Generation (DPG), as depicted in Figure 1. Our goal is to reshape the personalities of LLMs by integrating the personality traits and dialogue styles of different script characters. Drawing upon psychological knowledge, we employ GPT-4 to generate personality trait markers and annotate a dataset of personality-character dialogues. Subsequently, we train Hypernetworks (Ha et al., 2016) to generate adapters for LLMs, effectively shaping their personalities. Experimental results demonstrate[^0]the effectiveness of our annotated data in personality shaping for LLMs. Our DPG approach outperforms traditional fine-tuning methods and state-of-the-art pre-trained models like GPT-4, offering a more dynamic and nuanced approach to personality shaping in large-scale models.

![](https://cdn.mathpix.com/cropped/2024_06_04_bcdd5ad5284ffc6f20d1g-02.jpg?height=556&width=1330&top_left_y=394&top_left_x=403)

Figure 1: Illustration of the Dynamic Generation of Personalities (DPG). Personality Assessment:The Big Five personality traits are quantified into 11 scores ranging from -5 to 5 . GPT-4, equipped with expertise in personality assessment, evaluates the character's Big Five personality traits through dialogue. Personality Generation: Adapters are inserted into the pre-trained LLMs, and hypernetworks are trained using dialogue data with personality scores. This allows for the generation of different adapter weights based on the prompt, enabling the LLMs to exhibit diverse personalities.

This work makes the following contributions:

- To assess personality traits from role dialogues, we improve existing machine assessment methods (Wang et al., 2023a) by incorporating knowledge from the Big Five personality traits. This approach allows us to analyze character dialogues and generate more stable and reliable assessments of personality traits.
- We evaluate the personality traits of characters involved in conversations through dialogues from novels, movies, and other scripts, creating a personality-dialogue dataset. Experiments prove the effectiveness of this dataset in generating characters with personalities.
- We propose a method called Dynamic Personality Generation (DPG) that enables the generation of new personalities in LLMs by integrating personality information from historical dialogues. Experimental results demonstrate that DPG outperforms traditional fine-tuning methods and prompt-based GPT-4 (Achiam et al., 2023).


## 2 Task Formulation

The research aims to develop a methodology for the LLM chatbot to adopt different personalities based on user prompts. This involves evaluating conversations to ensure the generated personality aligns with the prompt and engages in meaningful and coherent conversations.

## 3 Related Work

Personality Assessment for Large Language Models: The lexical hypothesis suggests that it's possible to assess an individual's personality through dialogue (Costa Jr and McCrae, 1992; McCrae and Costa Jr, 1989; Crowne, 2007; John et al., 2008). Recent work evaluates the Big Five personality traits and Myers-Briggs Type Indicator of large language models using open-ended questions and interviews questionnaires (Karra et al., 2023; Jiang et al., 2023a; Caron and Srivastava, 2022; Song et al., 2023; Singh and Aarabhi, 2023; Jiang et al., 2023b). Using tools such as Apply Magic Sauce $^{2}$ and GPT-4 to predict personality traits from conversations proves to be effective(Wang et al., 2023a; Safdari et al., 2023).

Personality Editing of Large Language Models: Recent studies showcase the remarkable capabilities of LLMs for generating distinct personalities. These models achieve this by integrating external knowledge bases (Xue et al., 2023;[^1]

Zhao et al., 2020), employing complex multi-turn prompts (Zhong et al., 2022), and leveraging unique script data through fine-tuning. By adopting role-playing or personality-driven approaches, these models can assume specific personalities (Wei et al., 2023; Shanahan et al., 2023; Salemi et al., 2024; Maas et al., 2023; Li et al., 2023c, 2024; Yan et al., 2023; Tao et al., 2023; Pan et al., 2023; Safdari et al., 2023). However, these methods have limitations in terms of reconstructing existing characters and cannot generate new ones with creativity. Additionally, each character necessitates a separate and detailed dataset for external knowledge or fine-tuning. Therefore, our research is dedicated to developing a method that effectively utilizes script data to generate new personalities.

## 4 Data Construction

Our research greatly benefits from the contributions of ROLELLM (Wang et al., 2023c) and ChatHaruhi (Li et al., 2023a). They provide us with character dialogue data that spans a wide range of personality traits, represented as $D_{\text {Script }}, D_{\text {Augment }}$. In this case, $D_{\text {Script }}$ represents real character dialogues extracted from novels and other texts, while $D_{\text {Augment }}$ represents character-generated dialogues enhanced by LLMs like GPT-4.

In this section, we introduce personality assessment and data cleaning work. Firstly, we clarify the lack of coherence and completeness in the dialogue data (Section 4.1). We then test the stability of three personality evaluators to obtain a more reliable personality assessment method (Section 4.2). Lastly, we examine the personality-dialogue dataset and remove data points where the personality traits significantly deviate from the character's central personality (Section 4.3). As a result, we obtain a clean personality-dialogue dataset that is suitable for personality generation. The statistical information of the dataset is presented in Figure 2 and Table 2.

### 4.1 The Coherence and Contextual Integrity of the Dialogues

The performance of LLMs in role-playing tasks can be negatively affected if they are fine-tuned with data that contains noise (Wang et al., 2023c). This is because LLMs tend to internalize and reproduce the inconsistencies and irregularities present in the noisy training data. As a result, the models may struggle to generate coherent and contextually appropriate responses, diminishing their effectiveness in role-playing scenarios. It is crucial to prioritize the cleanliness and relevance of training data to ensure the optimal performance and proficiency of LLMs in complex tasks like role-playing. The effectiveness of GPT as an evaluator has been firmly established in previous studies (Fu et al., 2023; Gilardi et al., 2023; Zheng et al., 2024). We utilize the evaluation capabilities of GPT-3.5 to assess the Coherence and Contextual Integrity of dialogues.

Coherence: Responses should be relevant to the questions, and each dialogue turn should revolve around the same topic.

Contextual Integrity: Dialogues should include sufficient contextual information to ensure that responses are generated based on the questions.

### 4.2 The Reliability of Personality Assessment

### 4.2.1 The Big Five Personality

The Big Five Personality Traits is a widely accepted model in psychology that describes the five core dimensions of human personality, which are Openness(O), Conscientiousness(C), Extraversion(E), Agreeableness(A), and Neuroticism(N) (Costa Jr and McCrae, 1992).

### 4.2.2 Confidence in Personality Assessment Methods

Evaluating personality traits from dialogue data using machines has been proven effective (Wang et al., 2023a; Safdari et al., 2023). We map each dimension of the Big Five personality traits to integers ranging from -5 to 5, similar to the approach in (Wang et al., 2023a). Lower scores indicate lower attributes of that personality, while higher scores indicate higher attributes. We then enhance the LLMs-based personality assessment machine in (Wang et al., 2023a) by incorporating expert knowledge of the Big Five personality traits (Costa Jr and McCrae, 1992), resulting in GPT-4 with Embedded Psychological Knowledge ( $F_{\text {Knowledge-gpt4 }}$ ). Internal consistency is a vital indicator used to evaluate the reliability of measuring the Big Five personality traits (Vacha-Haase, 1998; Thompson and Vacha-Haase, 2000; Botella et al., 2010; Wheeler et al., 2011). Similar to Jian (Jiang et al., 2024), we employ variance as the foundation for assessing the effectiveness of the following three methods: Prompt-based GPT-3.5 $\left(F_{\text {Prompt-gpt3.5 }}\right)$, Prompt-based GPT-4 $\left(F_{\text {Prompt-gpt4 }}\right.$ ) from (Wang et al., 2023a), and GPT-4 with Embedded Psychological Knowledge ( $F_{\text {Knowledge-gpt4 }}$ ) which we have enhanced. For more detailed information on the assessment process, please refer to Appendix A.2.

| Method | $\sigma_{O}^{2}$ | $\sigma_{C}^{2}$ | $\sigma_{E}^{2}$ | $\sigma_{A}^{2}$ | $\sigma_{N}^{2}$ | $\sigma_{\text {Avg. }}^{2}$ |
| :--- | :---: | :---: | :--- | :--- | :--- | :--- |
| $F_{\text {Prompt-gpt3.5 }}$ | 0.940 | 0.794 | 1.199 | 1.344 | 0.869 | 1.0292 |
| $F_{\text {Prompt-gpt4 }}$ | 0.728 | 0.673 | 0.689 | $\mathbf{1 . 2 1 0}$ | 0.887 | 0.8374 |
| $F_{\text {Knowledge-gpt } 4}$ | $\mathbf{0 . 4 8 7}$ | $\mathbf{0 . 6 5 9}$ | $\mathbf{0 . 6 3 3}$ | 1.249 | $\mathbf{0 . 6 9 2}$ | $\mathbf{0 . 7 4 4}$ |

Table 1: The intrinsic consistency evaluation results of Prompt-based GPT-3.5, Prompt-base GPT-4 and GPT4 with Embedded Psychological Knowledge. $\sigma_{(O|C| E|A| N)}^{2}$ represents the variance in assessments of openness, conscientiousness, extraversion, agreeableness, and neuroticism. $\sigma_{\text {Avg. }}^{2}$ denotes the average variance. The results indicate that $F_{\text {Knowledge-gpt4 }}$ demonstrates superior internal consistency in assessments other than agreeableness compared to other methodologies. The results of our best model are in Blue .

Table 1 presents the evaluation results, indicating that $F_{\text {Knowledge-gpt } 4}$ provides a more reliable assessment of personality traits from dialogues. Following the same experimental procedure outlined earlier, we employed $F_{\text {Knowledge-gpt } 4}$ to evaluate our entire dialogue dataset, resulting in the creation of a dataset denoted as $D=D_{\text {ScriptPair }}, D_{\text {AugmentPair }}$. $D_{\text {ScriptPair }}$ and $D_{\text {AugmentPair }}$ are represented as $<$ dialogueSet, $(O, C, E, A, N)>$, where dialogueSet represents a set of dialogues, and $(O, C, E, A, N)$ represents the Big Five personality assessment scores for the evaluated character in that set.

### 4.3 Personality Displacement Caused by LLMs Enhancement

We present the personality assessment scores in a coordinate space, revealing that each character's personality revolves around a central point, which we refer to as the personality center. This observation is consistent with the conclusion drawn in (Wang et al., 2023a). The partiality of personality assessment based on dialogue likely contributes to this pattern.

There are concerns that enhanced data compared to script data may produce excessive personality biases. For characters with both script data and enhanced data, we calculated the mean $\mu_{s}, \mu_{g}$ and variances $\sigma_{s}^{2}, \sigma_{g}^{2}$ for the assessment scores $(O, C, E, A, N)_{\text {Script }}$ and $(O, C, E, A, N)_{\text {Augment }}$. We found that the personality center of the assessment displacement after enhancement ( $\mu_{s}$ differs $\mu_{q}$ ). Additionally, characters in the script data exhibit a more diverse personality compared to those in the enhanced data ( $\mu_{\sigma_{s}^{2}}>\mu_{\sigma_{g}^{2}}$ ). To reduce the impact of outlier data on training, we removed data that deviated excessively from the personality center. (See Appendix A. 2 for details.)

## 5 Network Method

### 5.1 Personality Shaping Based on LoRA

LoRA (Hu et al., 2021) is developed to train extensive pre-trained models while minimizing the need for training resources. Previous research demonstrates the effectiveness of utilizing LoRA for fine-tuning LLMs for downstream tasks. In our study, we employ LoRA-based fine-tuning on the personality-dialogue dataset personality dataset to train our LLMs. This approach allows LoRA to imbue LLMs with specific personality traits, thereby shaping the model's personality.

To achieve this, we apply LoRA to each Attention layer of LLMs, utilizing the following mathematical formula 1:

$$
\begin{equation*}
y=F_{\theta_{\text {Pre-train }}}(x)+F_{\theta_{\text {LoRA }}}\left(F_{\theta_{\text {LoRA }}}(x)\right) \tag{1}
\end{equation*}
$$

Here, $x$ represents the input of the attention layer, $y$ denotes the output of the attention layer, and $\theta$ signifies the neural network parameters. $\theta_{P r e-t r a i n}$ represents the weights of the pre-trained layer. In this context, the parameters $\theta_{\text {LoRA }}$ and $\theta_{L o R A_{B}}$ play a crucial role in shaping the personality of LLMs.

### 5.2 Personality Generation Based on Hypernetworks

Hypernetworks (Ha et al., 2016) is a technique that allows one neural network to generate parameters for another neural network within the same architecture. This approach enhances the flexibility of the network, enabling it to dynamically adjust its network weights based on various tasks or input data. In our study, we employ Hypernetworks as the generator for the weights of the LoRA layer, as depicted in Figure 3. By using Hypernetworks, we can generate

| Key | Value |
| :--- | :---: |
| Dialogue rounds(Part/All) |  |
| - In English | $16896 / 56547$ |
| - In Chinese | $39649 / 56547$ |
| Big Five Personality(High/Low) |  |
| Openness |  |
| -In English | $15458 / 1438$ |
| -In Chinese | $36829 / 2820$ |
| Conscientiousness |  |
| -In English | $14112 / 2784$ |
| -In Chinese | $33734 / 5915$ |
| Extroversion | $12264 / 4632$ |
| -In English | $33599 / 6050$ |
| -In Chinese |  |
| Agreeableness | $9359 / 7537$ |
| -In English | $22106 / 17543$ |
| -In Chinese | $6683 / 10213$ |
| Neuroticism | $7794 / 31855$ |
| -In English |  |

Table 2: Statistics of the Dataset

![](https://cdn.mathpix.com/cropped/2024_06_04_bcdd5ad5284ffc6f20d1g-05.jpg?height=453&width=574&top_left_y=264&top_left_x=1163)

(a) English Dataset

![](https://cdn.mathpix.com/cropped/2024_06_04_bcdd5ad5284ffc6f20d1g-05.jpg?height=458&width=572&top_left_y=774&top_left_x=1161)

(b) Chinese Dataset

Figure 2: Personality Rating Statistics, different colors represent distinct scores.

![](https://cdn.mathpix.com/cropped/2024_06_04_bcdd5ad5284ffc6f20d1g-05.jpg?height=372&width=609&top_left_y=1489&top_left_x=758)

Figure 3: Generating Lora weights based on Hypernetworks. The Pretrained weights $W$ are frozen ( $\odot$ ), and the LoRA's weights $\left(\right.$ Weight $_{A}$ and $W$ eight $_{B}$ ) are generated by hypernet (Hypernet ${ }_{A}$ and Hypernet ${ }_{B}$ ), with only the weights of the hypernet being trained. $\rightarrow$ represents the data transfer path of LoRA (Hu et al., 2021). $\rightarrow$ represents the data transfer path where hypernet generates LoRA's weights

different sets of LoRA weights for different inputs, representing distinct personality traits. This generative capability empowers the LLMs to produce content with various personality traits. The mathematical formulas are presented in Equation 2 .

$$
\begin{equation*}
\theta_{\text {LoRA }_{*}}=F_{\text {Hypernet }_{*}}(x) \tag{2}
\end{equation*}
$$

Where $\theta_{L o R A_{*}}$ represents the weights of the LoRA layer, carrying personality traits. $F_{\text {Hypernet }_{*}}$ denotes MLP-based Hypernetworks neural networks used for generative personality trait expression. $x$ represents the input to the network.

### 5.3 Implementation of LoRA Based on Hypernetworks in LLMs

We integrate a Hypernetworks-based LoRA layer structure into each Attention layer of the LLMs. This guarantees that our approach is plug-and-play compatible with pre-trained LLMs of various transformer architecture sizes. The parameters of the pre-trained model are kept frozen, and we exclusively train the Hypernet network within each layer. Under this network architecture, we can conduct end-to-end training without modifying the parameters of the pre-trained model, thus allowing the LLMs to develop distinct personality traits.

## 6 Experiments

### 6.1 Experiment Setup

Dataset: We conduct experiments using a personality-dialogue dataset. The Chinese and English data are split and used for parallel experiments without interfering with each other. The dataset is preprocessed into a supervised training format, as described in Appendix C.3.

Base Models: For the Chinese data, we use Glm3-3B-Chat (Zeng et al., 2022) and Yi-6B-Chat (AI et al., 2024) as the pre-training bases. As for the English data, we use LLama2-7B-Chat-hf (Touvron et al., 2023) and Yi-6B-Chat (AI et al., 2024) as the pre-training bases.

Baseline: Our baseline consists of three distinct approaches:

- Prompt-based pre-trained model. Here, GPT-4 (Achiam et al., 2023) is utilized as the pre-trained model. Two versions of prompts are used, including one with a system (GPT-4 w/i Sys.P.) prompt and one without (GPT-4 w/o Sys.P.).
- Applying supervised fine-tuning to a subset of the parameters of the pre-trained model (Freeze-SFT). (Hiyouga, 2023) provides support for this method.
- Implementing LoRA-based(Hu et al., 2021) supervised fine-tuning on the pre-trained model (LoRA-SFT). (Mangrulkar et al., 2022) provides support for this method.

Evaluation Criteria: Conversational ability and personality-shaping ability are used as evaluation criteria.

- Conversational Ability: We are inspired by CharacterEval(Tu et al., 2024) and use three metrics for evaluation: Fluency (Flu.), Coherency (Coh.), and Consistency (Con.) to ensure readable and criteria-compliant answers. Prompt-based GPT-3.5 is used as an evaluator (refer to AppendixC.2).
- Personality Shaping Ability: We employ the Euclidean distance between the prompted personality and the evaluated personality as the Personality Shaping Deviation Coefficient (P.S.D.C.) to assess the ability to shape personality.


## Test Methods:

- For pre-trained models, we use the [character name], [character prompt personality], and [the five historical character dialogues closest to the prompt personality for that character from the dataset] as the system prompt. We use the test question as the user prompt for testing.
- For Freeze-SFT, LoRA-SFT, and DPG, we first fine-tune the model using the dataset and then use the character name, character prompt personality, and test question as the prompts for testing.

Section 6.1.1, 6.1.2, and 6.1.3 introduce three testing tasks, respectively.

### 6.1.1 Performance in Scripted Dialogue

We select ten characters with the highest number of dialogue rounds from the personality dialogue dataset to serve as [character names]. For each character, we randomly selected five dialogue excerpts (including personality ratings [prompt personality] and dialogue content [questions for testing]) as the test set. The remaining data serves as the training set to train our model and baseline. Additionally, for pre-training, we also need to select five additional dialogue excerpts as supplementary information for the character profiles.

### 6.1.2 Performance Evaluation using Open-Ended Questions

To further evaluate the performance of personality shaping, we use the open-ended questions provided in (Wang et al., 2023a) as the test set. For each character, their personality central tendency (the average of personality ratings) serves as the prompt personality. The remaining evaluation settings are the same as in 6.1.1.

### 6.1.3 Evaluate the Ability to Generate New Personality

To evaluate the model's ability to generate entirely new personalities, we rate the Big Five personality traits of openness, neuroticism, and agreeableness on four levels: $-5,-2,2$, and 5. Regarding conscientiousness and extraversion, given the significant deviation of the model from average human values (Wang et al., 2023a; Safdari et al., 2023), we opt to calculate their mean as a substitute (Conscientiousness mean: 3, Extraversion mean: 2). By arranging and combining these five dimensions of traits, we form 64 unique personality combinations. These personality combinations serve as replacements for the prompt in 6.1 .2 personalities during the experiments.

### 6.2 Main Result

The experimental results are presented using LLama-7B as an example. For more experimental results and detailed descriptions, refer to Appendix B.1.

| Method | Flu. $\uparrow$ | Coh. $\uparrow$ | Con. $\uparrow$ | P.S.D.C. $\downarrow$ |
| :---: | :---: | :---: | :---: | :---: |
| Freeze-SFT | $84.31 \%$ | $72.23 \%$ | $53.14 \%$ | 5.52 |
| LoRA-SFT | $97.96 \%$ | $94.31 \%$ | $91.12 \%$ | 4.25 |
| DPG(ours) | $98.39 \%$ | $\mathbf{9 5 . 6 4 \%}$ | $\mathbf{9 2 . 2 3 \%}$ | $\mathbf{3 . 1 4}$ |
| GPT-4 w/o Sys.P. | $\mathbf{9 9 . 7 3 \%}$ | $86.13 \%$ | $84.67 \%$ | 3.44 |
| GPT-4 w/i Sys.P. | $99.31 \%$ | $87.48 \%$ | $85.21 \%$ | 3.36 |

Table 3: The evaluation results of the Script Dialogue Test for Llama-7B-En. Fluency (Flu.), Coherence (Coh.), and Consistency (Con.) represent three dimensions of conversational ability, while the personality Shaping Deviation Coefficient (P.S.D.C.) represents the capability to shape personality. The data (\%) indicates the proportion of cases considered correct out of the total test cases. The results of our best model are in Blue .

| Method | Flu. $\uparrow$ | Coh. $\uparrow$ | Con. $\uparrow$ | P.S.D.C. $\downarrow$ |
| :---: | :---: | :---: | :---: | :---: |
| Freeze-SFT | $73.47 \%$ | $42.16 \%$ | $21.84 \%$ | 6.23 |
| LoRA-SFT | $88.27 \%$ | $87.97 \%$ | $84.67 \%$ | 4.92 |
| DPG(ours) | $94.09 \%$ | $\mathbf{9 3 . 2 7 \%}$ | $\mathbf{9 1 . 0 6 \%}$ | $\mathbf{2 . 8 6}$ |
| GPT-4 w/o Sys.P. | $98.26 \%$ | $86.29 \%$ | $87.41 \%$ | 3.22 |
| GPT-4 w/i Sys.P. | $\mathbf{9 8 . 5 4 \%}$ | $88.93 \%$ | $88.19 \%$ | 3.06 |

Table 4: The evaluation results of the Open-Ended Questions Test for Llama-7B-En. The results of our best model are in Blue .

Script Dialogue Test: Table 3 demonstrates that DPG excels in Conversational Ability, surpassing the benchmark in Coherence (Coh.) and Consistency (Con.), but falls slightly behind GPT-4 in Fluency (Flu.). When it comes to Personality Shaping Ability, DPG outperforms all other baselines.

Open-Ended Questions: Table 4 showcases the performance of Llama-7B-En on the Open-Ended Questions test. The results align with those from the Scripted Dialogue Test, with DPG maintaining its lead. Conversely, LoRA-SFT and Freeze-SFT show more noticeable performance declines, while GPT-4 remains relatively stable.

| Method | Flu. $\uparrow$ | Coh. $\uparrow$ | Con. $\uparrow$ | P.S.D.C. $\downarrow$ |
| :---: | :---: | :---: | :---: | :---: |
| Freeze-SFT | $69.77 \%$ | $29.93 \%$ | $\backslash$ | $\backslash$ |
| LoRA-SFT | $84.47 \%$ | $71.41 \%$ | $65.53 \%$ | 5.62 |
| DPG(ours) | $92.36 \%$ | $\mathbf{8 8 . 9 3 \%}$ | $\mathbf{8 5 . 7 9 \%}$ | $\mathbf{3 . 8 3}$ |
| GPT-4 w/o Sys.P. | $\mathbf{9 8 . 1 3 \%}$ | $85.57 \%$ | $81.37 \%$ | 6.46 |
| GPT-4 w/i Sys.P. | $97.35 \%$ | $87.28 \%$ | $82.94 \%$ | 6.21 |

Table 5: The evaluation results of the Personality Generation Capability for Llama-7B-En. The results of our best model are in Blue .

New Personality Generation Capabilities: Table 5 presents the results of the personality generation capability assessment. Despite a slight decrease, DPG still demonstrates the effective ability to generate personalities. LoRA-SFT
also retains some capability for generating personalities. However, there is a significant decrease in the personality generation capability of GPT-4, with its P.S.D.C. value approaching the mathematical expectation of guessing the personality score, which is 7.07 (explained in Appendix B.3). Furthermore, Freeze-SFT has lost its conversational ability, making it impossible to evaluate personality based on dialogue generation.

| P.S.D.C. | Scripted Dialogue |  |  |  | Open-Ended Questions |  |  | New Personality Generation |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | Raw | w/o p.s. | w/o c.i. | Raw | w/o p.s. | w/o c.i. | Raw | w/o p.s. | w/o c.i. |
| GPT-4 w/i Sys.P. | 3.36 | 3.57 | 4.34 | 3.06 | 3.36 | 4.69 | 6.21 | 6.94 | 4.53 |
| LLama-7B-DPG | 3.14 | 6.12 | 3.49 | 2.86 | 5.94 | 3.27 | 3.83 | 6.07 | 3.92 |

Table 6: Results of an Ablation Study of GPT-4 and DPG Personality Shaping Ability. (w/o p.s.) means that the prompt does not include personality scores. (w/o c.i.) for GPT-4 means that the prompt does not contain character information, while for DPG, it involves using Jams or Mary as replacements for character names.
![](https://cdn.mathpix.com/cropped/2024_06_04_bcdd5ad5284ffc6f20d1g-08.jpg?height=350&width=1480&top_left_y=855&top_left_x=298)

Figure 4: Illustrate the relationship between prompt personalities and assessed personalities in the new personality generation task by DPG, mainly across the dimensions of openness $(\mathrm{O})$, agreeableness (A), and neuroticism (N). The prompt personalities are divided into four levels: $-5,-2,2$, and 5 , while the assessed personalities are divided into eleven levels from -5 to 5 . The color in each cell represents the frequency of the relationship's occurrence (for example, when Prompt Openness is -5 , the frequency of Assess Openness being -5 is higher than that of Assess Openness being 5).

### 6.3 Discussion

The performance of personality generation in a single dimension: As shown in Figure 4, DPG demonstrates excellent performance across the dimensions of Openness (O), Agreeableness (A), and Neuroticism (N). In comparison to Openness and Neuroticism, DPG exhibits stronger generation capabilities in Agreeableness. capabilities in Agreeableness.

The contribution of character information prompts and personality score prompts to personality generation capability: Ablation experiments validate the impact of character information and personality score on the capability to shape personality, as shown in Table 6. For DPG, character information prompts, compared to personality score prompts, play a less determining role in shaping personality, even without specific decoupling of character information and personality scores during fine-tuning. For GPT-4, masking character information still results in a consistently strong performance across all three experiments. Even in the absence of personality scores, GPT-4 exhibits a robust capability in shaping personality in both scripted dialogues and open-ended question tests. This reveals that GPT-4's capacity to shape personality depends more heavily on character information cues than on personality scores. Such a significant dependence on character information leads to suboptimal performance in tasks involving the generation of new personalities.

## 7 Conclusion

We introduce DPG, a method for dynamically generating personality using LLMs. We enhance the personality assessment capability of GPT-4 by incorporating expert knowledge of the Big Five personality traits. Additionally, we construct a dialogue dataset with character-based personality evaluations. Through the use of DPG on this dataset, we fine-tune the pre-trained LLMs to enable them to dynamically generate personalities. Experimental results demonstrate the superiority of our approach compared to all fine-tuning baselines, even surpassing GPT-4's performance when using prompts alone.

## Limitations

The accurate and stable assessment of personality from conversations remains a subject worth investigating. In terms of personality cues, using more concrete words such as "kind, wicked, and enthusiastic" can enhance human understanding compared to the Big Five personality scores. Additionally, it is crucial to explore how to decouple character information from personality traits for a better understanding of dynamic personality formation. In our future research, we will focus on concretizing personality descriptions and decoupling character information from personality traits.

## Ethics Statement

The character dialogue data mentioned in this work all comes from scripts or is generated by large language models. The majority are from fictional characters in novels, films, and television works and do not involve any personal privacy information.

All characters and data assets mentioned in this work are used solely for scientific research purposes. If anything infringes upon the rights of the characters themselves or their creators, please contact us, and we will remove the infringing information.

Fine-tuning LLMs with scripted dialogues may lead to jailbreaking behaviors, undermining the original human safety alignment principles. This could result in LLMs generating responses that are biased, violent, or possess other undesirable traits. All outcomes of this work are intended solely for research purposes. Researchers and users utilizing this work must ensure that LLMs adhere to human ethical standards.

## References

Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774.

AI, ., :, Young, A., Chen, B., Li, C., Huang, C., Zhang, G., Zhang, G., Li, H., Zhu, J., et al. (2024). Yi: Open foundation models by 01.ai.

Botella, J., Suero, M., and Gambara, H. (2010). Psychometric inferences from a meta-analysis of reliability and internal consistency coefficients. Psychological Methods, 15(4):386.

Cantor, N. (1990). From thought to behavior:" having" and" doing" in the study of personality and cognition. American psychologist, 45(6):735.

Caron, G. and Srivastava, S. (2022). Identifying and manipulating the personality traits of language models.

Chen, W., Su, Y., Zuo, J., Yang, C., Yuan, C., Qian, C., Chan, C.-M., Qin, Y., Lu, Y., Xie, R., et al. (2023). Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents. arXiv preprint arXiv:2308.10848.

Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. (2023). Palm: Scaling language modeling with pathways. Journal of Machine Learning Research, 24(240):1-113.

Costa Jr, P. T. and McCrae, R. R. (1992). The five-factor model of personality and its relevance to personality disorders. Journal of personality disorders, 6(4):343-359.

Crowne, D. P. (2007). Personality theory. Oxford University Press.

Fu, J., Ng, S.-K., Jiang, Z., and Liu, P. (2023). Gptscore: Evaluate as you desire. arXiv preprint arXiv:2302.04166.

Gilardi, F., Alizadeh, M., and Kubli, M. (2023). Chatgpt outperforms crowd-workers for text-annotation tasks. arXiv preprint arXiv:2303.15056.

Griffin, A. S., Guillette, L. M., and Healy, S. D. (2015). Cognition and personality: an analysis of an emerging field. Trends in ecology \& evolution, 30(4):207-214.

Ha, D., Dai, A., and Le, Q. V. (2016). Hypernetworks.

Hiyouga (2023). Llama factory. https: / / github.com/hiyouga/LLaMA-Factory.

Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. (2021). Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685.

Jiang, G., Xu, M., Zhu, S.-C., Han, W., Zhang, C., and Zhu, Y. (2023a). Evaluating and inducing personality in pre-trained language models.

Jiang, G., Xu, M., Zhu, S.-C., Han, W., Zhang, C., and Zhu, Y. (2024). Evaluating and inducing personality in pre-trained language models. Advances in Neural Information Processing Systems, 36.

Jiang, H., Zhang, X., Cao, X., and Kabbara, J. (2023b). Personallm: Investigating the ability of large language models to express big five personality traits.

Jiang, H., Zhang, X., Cao, X., Kabbara, J., and Roy, D. (2023c). Personallm: Investigating the ability of gpt-3.5 to express personality traits and gender differences. arXiv preprint arXiv:2305.02547.

John, O. P., Naumann, L. P., and Soto, C. J. (2008). Paradigm shift to the integrative big five trait taxonomy. Handbook of personality: Theory and research, 3(2):114-158.

Karra, S. R., Nguyen, S. T., and Tulabandhula, T. (2023). Estimating the personality of white-box language models.

Li, C., Leng, Z., Yan, C., Shen, J., Wang, H., Mi, W., Fei, Y., Feng, X., Yan, S., Wang, H., et al. (2023a). Chatharuhi: Reviving anime character in reality via large language model. arXiv preprint arXiv:2308.09597.

Li, C., Wang, J., Zhang, Y., Zhu, K., Hou, W., Lian, J., Luo, F., Yang, Q., and Xie, X. (2023b). Large language models understand and can be enhanced by emotional stimuli. arXiv preprint arXiv:2307.11760.

Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., and Ghanem, B. (2023c). Camel: Communicative agents for "mind" exploration of large language model society.

Li, Z., Chen, G., Shao, R., Jiang, D., and Nie, L. (2024). Enhancing the emotional generation capability of large language models via emotional chain-of-thought. arXiv preprint arXiv:2401.06836.

Maas, C., Carey, F., Wheeler, C., Saatchi, E., Billington, P., and Yaffa, J. (2023). To infinity and beyond: Show-1 and showrunner agents in multi-agent simulations.

Mangrulkar, S., Gugger, S., Debut, L., Belkada, Y., Paul, S., and Bossan, B. (2022). Peft: State-of-the-art parameterefficient fine-tuning methods. https://github.com/huggingface/peft.

McCrae, R. R. and Costa Jr, P. T. (1989). More reasons to adopt the five-factor model.

Pan, Y., Tang, Y., and Niu, Y. (2023). An empathetic user-centric chatbot for emotional support. arXiv preprint arXiv:2311.09271.

Safdari, M., Serapio-García, G., Crepy, C., Fitz, S., Romero, P., Sun, L., Abdulhai, M., Faust, A., and Matarić, M. (2023). Personality traits in large language models. arXiv preprint arXiv:2307.00184.

Salemi, A., Mysore, S., Bendersky, M., and Zamani, H. (2024). Lamp: When large language models meet personalization.

Shanahan, M., McDonell, K., and Reynolds, L. (2023). Role-play with large language models.

Singh, U. and Aarabhi, P. (2023). Can ai have a personality? In 2023 IEEE Conference on Artificial Intelligence (CAI), pages 205-206.

Song, X., Gupta, A., Mohebbizadeh, K., Hu, S., and Singh, A. (2023). Have large language models developed a personality?: Applicability of self-assessment tests in measuring personality in llms.

Tao, M., Liang, X., Shi, T., Yu, L., and Xie, Y. (2023). Rolecraft-glm: Advancing personalized role-playing in large language models. arXiv preprint arXiv:2401.09432.

Thompson, B. and Vacha-Haase, T. (2000). Psychometrics is datametrics: The test is not reliable. Educational and Psychological Measurement, 60(2):174-195.

Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

Tu, Q., Fan, S., Tian, Z., and Yan, R. (2024). Charactereval: A chinese benchmark for role-playing conversational agent evaluation. arXiv preprint arXiv:2401.01275.

Vacha-Haase, T. (1998). Reliability generalization: Exploring variance in measurement error affecting score reliability across studies. Educational and Psychological Measurement, 58(1):6-20.

Wang, X., Fei, Y., Leng, Z., and Li, C. (2023a). Does role-playing chatbots capture the character personalities? assessing personality traits for role-playing chatbots. arXiv preprint arXiv:2310.17976.

Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X., and Liang, Y. (2023b). Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. arXiv preprint arXiv:2302.01560.

Wang, Z. M., Peng, Z., Que, H., Liu, J., Zhou, W., Wu, Y., Guo, H., Gan, R., Ni, Z., Zhang, M., et al. (2023c). Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models. arXiv preprint arXiv:2310.00746.

Wei, J., Shuster, K., Szlam, A., Weston, J., Urbanek, J., and Komeili, M. (2023). Multi-party chat: Conversational agents in group settings with humans and models.

Wheeler, D. L., Vassar, M., Worley, J. A., and Barnes, L. L. (2011). A reliability generalization meta-analysis of coefficient alpha for the maslach burnout inventory. Educational and Psychological Measurement, 71(1):231-244.

Xue, B., Wang, W., Wang, H., Mi, F., Wang, R., Wang, Y., Shang, L., Jiang, X., Liu, Q., and Wong, K.-F. (2023). Improving factual consistency for knowledge-grounded dialogue systems via knowledge enhancement and alignment.

Yan, M., Li, R., Zhang, H., Wang, H., Yang, Z., and Yan, J. (2023). Larp: Language-agent role play for open-world games. arXiv preprint arXiv:2312.17653.

Zeng, A., Liu, X., Du, Z., Wang, Z., Lai, H., Ding, M., Yang, Z., Xu, Y., Zheng, W., Xia, X., et al. (2022). Glm-130b: An open bilingual pre-trained model. arXiv preprint arXiv:2210.02414.

Zhao, X., Wu, W., Tao, C., Xu, C., Zhao, D., and Yan, R. (2020). Low-resource knowledge-grounded dialogue generation.

Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E., et al. (2024). Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36.

Zhong, H., Dou, Z., Zhu, Y., Qian, H., and Wen, J.-R. (2022). Less is more: Learning to refine dialogue history for personalized dialogue generation.

Zhu, X., Chen, Y., Tian, H., Tao, C., Su, W., Yang, C., Huang, G., Li, B., Lu, L., Wang, X., et al. (2023). Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory. arXiv preprint arXiv:2305.17144.
